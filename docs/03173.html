<html>
<head>
<title>Text Mining: How to extract Amazon Reviews using Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本挖掘:如何使用Scrapy提取亚马逊评论</h1>
<blockquote>原文：<a href="https://medium.com/codex/text-mining-how-to-extract-amazon-reviews-using-scrapy-5bd709cb826c?source=collection_archive---------2-----------------------#2021-08-21">https://medium.com/codex/text-mining-how-to-extract-amazon-reviews-using-scrapy-5bd709cb826c?source=collection_archive---------2-----------------------#2021-08-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/56409a091ab229b153082ffb027b1879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sTRQrSP4XVgaaIBCgBnIPQ.jpeg"/></div></div></figure><p id="43b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">想过吗？如果有办法知道你的产品性能如何，人们对你的产品感觉如何，生活会变得更容易。解决方案-文本挖掘技术。</p><h2 id="4c06" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">我们先来了解一下什么是NLP或者文本挖掘？</h2><p id="79d3" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">NLP代表文本、语音、图像、符号等的自然语言处理。涉及文本的语言学分析被称为文本挖掘，它使用计算方法和技术从书籍、金融报告、新闻文章、社交媒体消息、维基百科等的非结构化文本数据中提取高质量的结构化信息。</p><p id="cf05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当今时代，互联网充斥着海量数据，其中80%的数据是非结构化数据。一般来说，对非结构化内容的解释或理解对人来说通常很容易，但对机器或计算机程序来说却非常复杂。背后的原因；它充满了模棱两可、模糊、有影响力和概率性的术语和短语，它经常强烈依赖常识、知识和推理，有时还带有讽刺意味。因此，需要将数据转换为结构化数据，以执行分析并生成有意义的见解。</p><p id="2e0a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有许多技术可用于执行文本挖掘，本文的目的是学习使用Scrapy。</p><h2 id="63a5" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">现在，让我们学习如何使用SCRAPY从亚马逊提取产品评论。</h2><p id="9082" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">要提取亚马逊上销售的产品的评论，您需要遵循以下步骤:</p><h2 id="236c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第一步:</h2><p id="f806" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">如果您使用的是conda，那么您可以使用下面的命令从conda-forge安装scrapy。</p><blockquote class="ko kp kq"><p id="6bfe" class="iq ir kr is b it iu iv iw ix iy iz ja ks jc jd je kt jg jh ji ku jk jl jm jn hb bi translated"><strong class="is hj">康达安装-康达锻造废料</strong></p></blockquote><p id="7c34" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您没有使用conda，您可以使用pip并使用下面的命令将其直接安装到您的系统中。</p><blockquote class="ko kp kq"><p id="8a25" class="iq ir kr is b it iu iv iw ix iy iz ja ks jc jd je kt jg jh ji ku jk jl jm jn hb bi translated"><strong class="is hj">！pip安装scrapy </strong></p></blockquote><h2 id="e11d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第二步:</h2><p id="3594" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">scrapy安装后，从conda打开cmd提示符。</p><p id="fc21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在cmd提示符下使用以下命令创建一个scrapy项目。</p><blockquote class="ko kp kq"><p id="c75d" class="iq ir kr is b it iu iv iw ix iy iz ja ks jc jd je kt jg jh ji ku jk jl jm jn hb bi translated"><strong class="is hj">scrapy start project scrap _ Amazon reviews</strong></p></blockquote><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/2069141ba08a2002ae557352a9e9b064.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*-6GqsiGEShTwGPv_d4vmGg.png"/></div></figure><p id="1d43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦你创建了这个项目，你会在你的系统根目录下找到“Scrape_AmazonReviews”文件。其中，一个是文件夹，包含您的scrapy代码，另一个是您的scrapy配置文件。Scrapy配置有助于在服务器上运行和部署Scrapy项目。</p><h2 id="1538" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第三步:</h2><p id="def1" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">一旦我们有了项目，我们需要创建一个蜘蛛。蜘蛛是一段python代码，它决定了网页如何被废弃。它是抓取不同网页并从中提取内容的主要组件。在我们的例子中，这将是执行访问亚马逊和抓取亚马逊评论任务的代码块。要创建一个蜘蛛，您可以在同一个cmd提示符下键入以下命令。</p><blockquote class="ko kp kq"><p id="ea4f" class="iq ir kr is b it iu iv iw ix iy iz ja ks jc jd je kt jg jh ji ku jk jl jm jn hb bi translated"><strong class="is hj">刺儿头genspider Amazon _ review</strong><a class="ae la" href="https://www.amazon.in/" rel="noopener ugc nofollow" target="_blank"><strong class="is hj">https://www.amazon.in/</strong></a></p></blockquote><p id="fc26" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将在您的根目录中创建名为“amazon_review.py”的python文件，您需要将该文件放在名为“Scrape _ Amazon reviews \ Scrape _ Amazon reviews \ spiders”的文件夹中。</p><p id="3a8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“amazon_review.py”文件包含以下零碎的解析器代码:</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="ea6b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第四步:</h2><p id="a913" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">Spider是在项目目录下的“spiders”文件夹中创建的。一旦你进入“Scrape_AmazonReviews”文件夹/项目，你会看到一个类似下面的目录结构。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/331e3642d22538c236e50bd6206062cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*nptwIJGh9__tGIfvDraBcQ.png"/></div></figure><p id="371e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">剪贴簿文件描述:</strong></p><p id="778d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们更详细地了解一下“Scrape _ Amazon reviews”Scrapy项目结构和里面的支持文件。Scrapy项目目录中的主要文件包括:</p><p id="0280" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">items.py</p><p id="71ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">项目是将装载抓取的数据的容器。</p><p id="579c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">中间件. py</p><p id="4390" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">蜘蛛中间件是Scrapy的蜘蛛处理机制的挂钩框架，您可以插入自定义功能来处理发送给蜘蛛进行处理的响应，并处理蜘蛛生成的请求和项目。</p><p id="560f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">管道. py</p><p id="faa1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在一个项目被爬行器抓取之后，它被发送到项目管道，该管道通过顺序执行的几个组件来处理它。每个项目管道组件都是一个Python类。</p><p id="da8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">settings.py</p><p id="c89c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它允许用户自定义所有Scrapy组件的行为，包括核心，扩展，管道和蜘蛛本身。</p><p id="d896" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">蜘蛛文件夹</p><p id="1668" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spiders是一个目录，包含了所有作为Python类的spider/crawler。每当一个人运行/抓取任何蜘蛛，然后scrapy看这个目录，并试图找到蜘蛛的名称提供的用户。蜘蛛定义了如何抓取某个站点或一组站点，包括如何执行抓取以及如何从它们的页面中提取数据。</p><h2 id="afb8" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第五步:</h2><p id="df9a" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">分析网页的HTML结构:</p><p id="d289" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了您的理解，我们来举一个亚马逊上可以买到的以下产品的例子:<a class="ae la" href="https://www.amazon.in/product-reviews/9387779262/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&amp;pageNumber=" rel="noopener ugc nofollow" target="_blank">https://www . Amazon . in/product-reviews/9387779262/ref = cm _ Cr _ getr _ d _ paging _ btm _ prev _ 1？ie=UTF8 &amp; pageNumber= </a>(从亚马逊的这个网页中提取产品评论)</p><p id="80e0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，在我们真正开始用python编写抓取亚马逊评论的spider实现之前，我们需要识别目标网页中的模式。</p><p id="a888" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是我们试图抓取的页面，其中包含了亚马逊上关于产品“我的第一个图书馆:10本儿童板书”的不同评论。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es le"><img src="../Images/046920dd9728d4a758bc48fd2caf99f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*m8CcQx3c_VfniimokD4vVg.png"/></div></figure><p id="7133" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们首先使用浏览器中的inspect-element特性打开网页。在那里你可以看到网页的HTML代码。经过一点探索，我发现下面的HTML结构可以在网页上显示评论。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/55285cdb6df2534f88636e8a12b4927a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_oVAvPEqZgTZsWozVIebDQ.png"/></div></div></figure><p id="61f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在评论页面上，有一个id为“cm_cr-review_list”的分部。该分部有多个子分部，评审内容位于其中。我们计划从网页中提取星级和评论文本。进一步考察，我们可以看到，每一个点评细分都进一步划分为多个区块。</p><p id="675a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中一个模块包含所需的星级评定，其他模块包含所需的评论文本。通过更仔细地观察，我们可以很容易地看到，星级划分由类属性“review-rating”表示，评论文本由类“review-text”表示。我们现在需要做的就是使用我们的Scrapy解析器来挑选这些模式。</p><h2 id="d9df" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第六步:</h2><p id="5993" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">然后我们需要定义一个解析函数，当我们的蜘蛛访问一个新页面时，这个函数就会被激活。在解析函数中，我们需要识别目标页面结构中的模式。然后，蜘蛛会寻找这些模式，并从网页中提取出来。</p><p id="ff97" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是抓取亚马逊评论的Scrapy解析器的代码示例。我们把文件命名为“extract_reiews.py”，保存在“Scrape _ Amazon reviews \ Scrape _ Amazon reviews \ spiders”文件夹中。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="cac3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第七步:</h2><p id="ba07" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">最后，我们成功地建立了我们的蜘蛛。现在剩下的唯一任务就是运行这个蜘蛛。我们可以使用runspider命令来运行这个蜘蛛。输入要运行的蜘蛛文件，输出文件存储收集的结果。在下面的例子中，蜘蛛文件是amazon_reviews.py，输出文件是amazon_reviews.csv</p><p id="44ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要运行此命令，请打开cmd提示符并键入以下命令:</p><blockquote class="ko kp kq"><p id="b8ef" class="iq ir kr is b it iu iv iw ix iy iz ja ks jc jd je kt jg jh ji ku jk jl jm jn hb bi translated"><strong class="is hj">scrapy run spider scrap _ Amazon reviews \ scrap _ Amazon reviews \ spiders \ extract _ reviews . py-o extract _ reviews . CSV</strong></p></blockquote><p id="8bd7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">提取的“extract_reviews.csv”将保存到默认目录。</p><h2 id="3975" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第八步:</h2><p id="091c" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">提取的reviews文件已准备就绪，可以使用python打开，如下所示:</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="fcc1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出如下所示:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/15f018d9cd97e980c52a9eb3d6753d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*kvdAG-AygQ09HwpJ5EkdfA.png"/></div></figure><h2 id="c797" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">第九步:</h2><p id="2dc2" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">针对不同的产品评论测试我们的代码。让我们检查一下我们的代码是否在不同的产品上工作，例如说博世洗衣机前负荷与web链接如下:<a class="ae la" href="https://www.amazon.in/Bosch-Inverter-Control-Automatic-Loading/product-reviews/B08SR372S7/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&amp;reviewerType=all_reviews&amp;pageNumber=" rel="noopener ugc nofollow" target="_blank">https://www . Amazon . in/Bosch-Inverter-Control-Automatic-Loading/product-reviews/b 08 Sr 372s 7/ref = cm _ Cr _ ARP _ d _ paging _ btm _ next _ 2？ie = UTF8&amp;reviewer type = all _ reviews&amp;page number =</a></p><p id="e498" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用这个替换前面的“extract_reiews.py”中的web链接，并运行cmd作为</p><blockquote class="ko kp kq"><p id="6382" class="iq ir kr is b it iu iv iw ix iy iz ja ks jc jd je kt jg jh ji ku jk jl jm jn hb bi translated"><strong class="is hj">scrapy run spider scrap _ Amazon reviews \ scrap _ Amazon reviews \ spiders \ extract _ reviews _ test 2 . py-o extract _ reviews _ test 2 . CSV</strong></p></blockquote><p id="aa78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">并使用pandas python阅读它。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="5ae5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">耶！有用！</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/7287dc3ce61b90efd8732d1ac4594c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*oA7foVLENLvqftlcmqW7BA.png"/></div></figure><p id="5792" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您的结构化数据文件已经准备好使用机器学习或人工智能算法执行NLP语言分析。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><p id="9036" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我将在下一篇文章中写更多关于如何执行自然语言处理文本挖掘的内容，包括文本预处理、特征提取、命名实体识别和情感挖掘或对亚马逊上产品评论的情感分析。所以请关注我在<a class="ae la" rel="noopener" href="/subscribe/@vaitybharati">媒体</a>上的帖子😃快乐学习！</p><p id="744f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请关注我的<a class="ae la" href="https://github.com/vaitybharati" rel="noopener ugc nofollow" target="_blank"> GitHub </a>有170多个这样的库。</p><p id="91f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另外，请告诉我，你对这篇文章有什么看法。</p></div></div>    
</body>
</html>