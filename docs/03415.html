<html>
<head>
<title>Uni-Variate Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一元线性回归</h1>
<blockquote>原文：<a href="https://medium.com/codex/linear-regression-on-single-variable-f35e6a73dab6?source=collection_archive---------13-----------------------#2021-09-01">https://medium.com/codex/linear-regression-on-single-variable-f35e6a73dab6?source=collection_archive---------13-----------------------#2021-09-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/004d40bad700321cc8af22af5e175cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YAbKxmoQ9848RNCb"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">艾萨克·史密斯在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="7190" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大家好。今天我们将步入我们的第一个监督学习算法。线性回归是游戏的名字。在这篇文章中，我们将编码我们的算法，然后用它作为我们的预测模型。</p><h2 id="3f86" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">什么是线性回归？</h2><p id="615b" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">线性回归是一种统计监督学习技术，使用一个或多个独立特征建立线性关系来预测因变量。它也被称为“最佳拟合线”。线性回归的基本思想是找到一条符合数据点集的直线。</p><h2 id="f6f7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">模型表示</h2><p id="a7f2" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated"><strong class="ix hj">符号:</strong></p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/5c2230df93cf747e9597d1683b2a5da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*Rn-ib4iwT9Fsu3CX8MUIFw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">记号</figcaption></figure><p id="5813" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一般来说，回归过程由下面的流程图解释:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/ee01c5045e15ef2aa1fa36146409e275.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/0*whADn3nOt4o1L-Tw.png"/></div></figure><p id="9cc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了生成假设(线)，将训练数据植入学习过程。假设是使用输入数据预测输出值的函数。假设(h)是一个将x映射到y的函数。</p><p id="adf2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在线性回归的情况下，假设(h)由以下等式表示:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/3b0bc032e0fc9db7867d1fa4f76c8b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*41soIPVen-DprammXeuXHQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">一元回归公式</figcaption></figure><p id="ef32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参数的图形表示:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es la"><img src="../Images/abb1d949279b27bd7a1c77dfeb78e3cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/0*1EySUo_94n9irc9K.png"/></div></figure><p id="d1e7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设的图示:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/f3f9479e30c0cefe602792414ba8edc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_i_0WQ_ehRmA9Xc1.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">假设</figcaption></figure><p id="0790" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上图中，我们可以清楚地见证，有一个线性的趋势。随着“x”值的增加，“y”值也会增加。</p><p id="7d92" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，x是独立变量，y是输出变量，θ₀是截距，截距是常数，θ₁是斜率。</p><p id="5c62" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">考虑一个数据集，其中包含基于城市人口的快餐车利润信息。</p><p id="647d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们导入所需的库:</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="67ba" class="jt ju hi lk b fi lo lp l lq lr">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span></pre><p id="893f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">并将数据集加载到熊猫数据框架中</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="fd5c" class="jt ju hi lk b fi lo lp l lq lr">data = pd.read_csv('ex1data1.txt', header=None)<br/>data.head()</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/5895ce138fb8dd2fdf528aa155fa5d40.png" data-original-src="https://miro.medium.com/v2/resize:fit:334/format:webp/1*du8V3fo7TzkVRo4jYA1diw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">输出:data.head()</figcaption></figure><p id="6191" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里0( <em class="lt"> </em>即x，<strong class="ix hj"> <em class="lt">万人城市的</em> </strong>是输入变量)和1(即y，<strong class="ix hj"> <em class="lt">万元利润</em> </strong>是输出变量)</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="1abc" class="jt ju hi lk b fi lo lp l lq lr">data.describe()</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/e00c32321496790e928f24b3de9bb2a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*l1qUCWyaJx863N6bgDn25A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">输出:data.describe()</figcaption></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><p id="4b29" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在开始任何任务之前，通过可视化来理解数据通常是有用的。对于这个数据集，我们将使用散点图来可视化数据，因为它只有两个属性可以绘制(利润和人口)。我们在现实生活中遇到的许多其他问题都是多维的，不能用二维图来表示。</p><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="8daf" class="jt ju hi lk b fi lo lp l lq lr">plt.scatter(data[0], data[1], marker="x", c='red', alpha=0.5)<br/>plt.xticks(np.arange(5, 30, step=5))<br/>plt.yticks(np.arange(-5, 30, step=5))<br/>plt.xlabel("Population of a city(10,000s)")<br/>plt.ylabel("Profit($10,000)")<br/>plt.title("Profit vs. Population")</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/cd5725fee08c5401d73adf4b3f4d7b9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*Vx3X9ZGdj-kEeK8nDp5umw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">输出:散点图</figcaption></figure><p id="3675" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从这张图中我们可以看到线性趋势，随着人口的增加，利润也增加。</p><p id="d4e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为我们用的是线性回归，假设类似于直线的方程。为了拟合数据，我们也可以使用任何一种函数作为假设(<strong class="ix hj"><em class="lt">【h(x)】</em></strong>)。</p><h2 id="811b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">如何为假设选择好的参数？</h2><p id="fa6c" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">目标是设置参数，使h(x)接近每个x的y值。例如，选择θ₀和θ₁，使h(x)接近每个x的y值。<br/>该条件可以用数字表示如下:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/153f5601fe4be58ec756d9883d94237e.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/0*U6mcDRSVL0MfaUkK.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">价值函数</figcaption></figure><p id="3cb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个表达式叫做成本函数，损失函数，等等…这个表达式的结果叫做成本，损失，等等…最终，一切都是一样的。有许多类型的成本函数可用。均方差(MSE)成本函数是回归问题中通常使用的函数，如上所示。</p><p id="b640" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">好与坏假设的图示:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/34c4f09daf54f6b88b06ac3ca7d9d890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*TBY_5wvjfvqurA01LdU6RA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">好与坏的假设</figcaption></figure><p id="f9e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上图我们可以推断，点与棕色线之间的距离彼此较远，点与绿色线之间的距离彼此较近。因此，绿线将具有最小成本(<strong class="ix hj"> <em class="lt">好假设</em> </strong>)，而棕色线将具有最大成本(<strong class="ix hj"> <em class="lt">坏假设</em> </strong>)。上面的等式将试图找到减少h(x)损失的线。</p><p id="21f9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们进一步分析成本函数:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/5b8dce3eae7a904c618b9dbd150fb7e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWCR3O62rxCwMvqXqvqUaw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料来源:吴恩达</figcaption></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="b161" class="jt ju hi lk b fi lo lp l lq lr">def compute_cost(X, y, theta):<br/>    m = len(y)<br/>    h_theta = X.dot(theta)<br/>    J = 1/(2*m) * np.sum((h_theta-y)**2)<br/>    return J</span></pre></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="lj lk ll lm aw ln bi"><span id="f5f3" class="jt ju hi lk b fi ly lz ma mb mc lp l lq lr">mod_data = data.values<br/>m = len(mod_data[:,-1])<br/>X = np.column_stack((np.ones((m, 1)), mod_data[:, 0].reshape(m, 1)))<br/>y = mod_data[:, 1].reshape(m, 1)<br/>theta = np.zeros((2, 1))<br/><br/>iterations = 1500<br/>alpha = 0.01<br/>J = compute_cost(X, y, theta)</span></pre><h2 id="40d5" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">最小化成本函数的梯度下降</h2><p id="3f5e" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">梯度下降法是一种流行的最小化代价函数损失的算法。</p><ul class=""><li id="cf51" class="md me hi ix b iy iz jc jd jg mf jk mg jo mh js mi mj mk ml bi translated">J(θ₀、θ₁)有某种功能</li><li id="0da6" class="md me hi ix b iy mm jc mn jg mo jk mp jo mq js mi mj mk ml bi translated">目标:</li></ul><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/279ec83fa817c4201972230a6d0fb76a.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/0*hmQJ5z6u-0GzuxCe.png"/></div></figure><ul class=""><li id="bca4" class="md me hi ix b iy iz jc jd jg mf jk mg jo mh js mi mj mk ml bi translated">从θ₀，θ₁.开始</li><li id="fe13" class="md me hi ix b iy mm jc mn jg mo jk mp jo mq js mi mj mk ml bi translated">不断改变θ₀，θ₁，以减少J(θ₀，θ₁)，直到我们有希望在最低限度结束。</li></ul><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/8763bc6d70a49f5ceea6507e33ffd557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJOYknshe_djms0GB9JxoQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料来源:吴恩达</figcaption></figure><p id="6325" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更新参数规则:</p><ul class=""><li id="82ee" class="md me hi ix b iy iz jc jd jg mf jk mg jo mh js mi mj mk ml bi translated">找到假设→ h(x) = θ₀ + θ₁x</li><li id="738c" class="md me hi ix b iy mm jc mn jg mo jk mp jo mq js mi mj mk ml bi translated">然后使用假设和数据中的输出变量来计算成本:</li></ul><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/153f5601fe4be58ec756d9883d94237e.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/0*U6mcDRSVL0MfaUkK.png"/></div></figure><ul class=""><li id="e9d0" class="md me hi ix b iy iz jc jd jg mf jk mg jo mh js mi mj mk ml bi translated">然后更新theta，如下所示:</li></ul><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/e598d7b8c6e20043ceefac8a8fd3b75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*laATObvHj5VJI81xAbeeNA.png"/></div></figure><p id="28aa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Alpha或学习率决定了算法达到最小成本值(即，给出最小成本值的参数值)所采取的步长。我们必须注意的非常重要的细节是，我们必须<strong class="ix hj">同时更新θ₁和θ₀</strong>。我们不应该更新θ₀，然后升级成本函数，然后θ₁，这不是我们想要的工作方式。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="af74" class="jt ju hi lk b fi lo lp l lq lr">def gradientDescent(X, y, theta, alpha, n_iters, graph=True):<br/>    m = len(y)<br/>    J_history = []<br/>    <br/>    for i in range(n_iters):<br/>        h_theta = X.dot(theta)<br/>        err = np.dot(X.T, (h_theta - y))<br/>        descent = alpha * 1/m * err<br/>        theta -= descent<br/>        <br/>        J_history.append(compute_cost(X, y, theta))<br/>    if graph:<br/>        plt.plot(J_history)<br/>        plt.xlabel("No. of Iterations")<br/>        plt.ylabel("J(theta)")<br/>        plt.title("Cost function using Gradient Descent")<br/>        <br/>    return theta, J_history</span><span id="b237" class="jt ju hi lk b fi mu lp l lq lr">theta, J_history = gradientDescent(X, y, theta, alpha, iterations)<br/>print(f"h(x)= {round(theta[0, 0], 2)} + {round(theta[1, 0], 2)} x1")</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/8f7cf9625a50f9e9870308dfe360d6f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*qcGW55Zi4YCDVGx3N2p_qA.png"/></div></figure><p id="f142" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参数的初始值被设置为零。学习率设置为0.01。最多允许1400个重复或时期。相对于迭代次数绘制成本函数给出了良好的下降趋势，表明梯度下降实现在降低成本函数方面起作用。</p><p id="8e05" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，有了优化的θ值，我将把预测值(最佳拟合线)一起绘制成图</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/9508331402838ba40d2641875bc00959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*STuU0clw4YwOoiQ2JLGnqg.png"/></div></figure><h2 id="edb6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">预言</h2><p id="b946" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">要进行预测:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/42cbe126a0d60009671bdea6a136eead.png" data-original-src="https://miro.medium.com/v2/resize:fit:254/format:webp/1*v3X8pz2SEy3sGPW8ywGn1w.png"/></div></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="3855" class="jt ju hi lk b fi lo lp l lq lr">def predict(X, theta):<br/>    predictions = np.dot(theta.T, X)<br/>    return predictions[0]</span></pre></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="lj lk ll lm aw ln bi"><span id="0cbc" class="jt ju hi lk b fi ly lz ma mb mc lp l lq lr">predict1 = predict(np.array([1,3.5]),theta)*10000<br/>print(f'For population=35000, we predict a profit of ${round(predict1, 0)}')</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es my"><img src="../Images/3d7dbaf8b075b0be0707e0f29d973190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*NLCrAkEtnrI5lmSoJlszdw.png"/></div></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><pre class="ku kv kw kx fd lj lk ll lm aw ln bi"><span id="163f" class="jt ju hi lk b fi lo lp l lq lr">predict2 = predict(np.array([1,7]),theta)*10000<br/>print(f'For population=70000, we predict a profit of ${round(predict2, 0)}')</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/91acc6344411849cb38afa42b59f2076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*-MtFXkLgqQWXMTV9uqtyOw.png"/></div></figure><h2 id="c7eb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">结论</h2><p id="e9dd" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">今天，我们看到了假设、成本函数和单变量线性回归的梯度下降背后的概念，并使用上述概念在房价数据集的要素上构建了一条回归线。然后使用python的numpy、pandas和matplotlib从头开始创建它。数据集和最终代码上传到github。</p><p id="8262" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">点击这里查看<a class="ae iu" href="https://github.com/jagajith23/Andrew-Ng-s-Machine-Learning-in-Python/tree/gh-pages/Linear%20Regression" rel="noopener ugc nofollow" target="_blank">线性回归</a>。</p><h1 id="fc03" class="na ju hi bd jv nb nc nd jz ne nf ng kd nh ni nj kg nk nl nm kj nn no np km nq bi translated">如果你喜欢这篇文章，那么看看我在这个系列中的其他文章</h1><h2 id="d5df" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">1.<a class="ae iu" rel="noopener" href="/@jagajith23/what-is-machine-learning-daeac9a2ceca">什么是机器学习？</a></h2><h2 id="3220" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">2.<a class="ae iu" rel="noopener" href="/codex/what-are-the-types-of-machine-learning-53360b7db8b4">机器学习有哪些类型？</a></h2><h2 id="1ffb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">3.<a class="ae iu" rel="noopener" href="/@jagajith23/linear-regression-on-multiple-variables-1893e4d940b1">多元线性回归</a></h2><h2 id="9002" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">4.<a class="ae iu" rel="noopener" href="/@jagajith23/logistic-regression-eee2fd028ffd">逻辑回归</a></h2><h2 id="1559" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">5.<a class="ae iu" rel="noopener" href="/@jagajith23/what-are-neural-networks-3a0965e2ebfb">什么是神经网络？</a></h2><h2 id="fed2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">6.<a class="ae iu" rel="noopener" href="/@jagajith23/digit-classifier-using-neural-networks-ad17749a8f00">使用神经网络的数字分类器</a></h2><h2 id="60c0" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">7.<a class="ae iu" rel="noopener" href="/@jagajith23/image-compression-with-k-means-clustering-48e989055729">利用K均值聚类进行图像压缩</a></h2><h2 id="3177" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">8.<a class="ae iu" rel="noopener" href="/@jagajith23/dimensionality-reduction-on-face-using-pca-e3fec3bb4cee">使用PCA对人脸进行降维</a></h2><h2 id="3719" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">9.<a class="ae iu" href="https://jagajith23.medium.com/detect-failing-servers-on-a-network-using-anomaly-detection-1c447bc8a46a" rel="noopener">使用异常检测来检测网络上的故障服务器</a></h2><h1 id="5099" class="na ju hi bd jv nb nc nd jz ne nf ng kd nh ni nj kg nk nl nm kj nn no np km nq bi translated">最后做的事</h1><p id="85d9" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">如果你喜欢我的文章，请鼓掌👏一个追随者将会是惊人的和它有助于媒体推广这篇文章，以便其他人可以阅读它。我是Jagajith，我会在下一个里抓住你。</p></div></div>    
</body>
</html>