<html>
<head>
<title>A Probabilistic Approach to POS Tagging (HMM)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种基于概率的词性标注方法</h1>
<blockquote>原文：<a href="https://medium.com/codex/a-probabilistic-approach-to-pos-tagging-hmm-a557f963e159?source=collection_archive---------3-----------------------#2021-06-12">https://medium.com/codex/a-probabilistic-approach-to-pos-tagging-hmm-a557f963e159?source=collection_archive---------3-----------------------#2021-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/19cce65fea6d06761248e11c04f02211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HeN8TmS4nHgkKN3a-dQMuw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/photos/YLSwjSy7stw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank">阿尔方斯·莫拉莱斯</a>在<a class="ae iu" href="https://unsplash.com/s/photos/book" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure></div><div class="ab cl iv iw gp ix" role="separator"><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja"/></div><div class="hb hc hd he hf"><p id="68c2" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">简介</strong></p><p id="21c0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在早期学校的某个时候，当我们学习语法时，我们开始知道单词可以分成不同的类别，像名词、动词、形容词等等。这些类别有助于我们理解一个单词在句子中扮演的角色。<strong class="je hj">P</strong>art<strong class="je hj">o</strong>f<strong class="je hj">S</strong>peech或<strong class="je hj"> POS </strong> tagging就是将这些类别(或标签)分配给单词的过程。词性标注是自然语言处理(NLP)的基本构件之一，因为它是其他NLP过程的先决条件。</p><p id="c87a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们经常遇到的一些词类标记有单数名词(NN)、代词(PRP)、形容词(JJ)、动词(VB)等。而作为人类，我们可以看着一个句子，凭经验直观地将词性标签与单词联系起来。然而，如何训练一个算法来实现这个看似简单的任务呢？在解决词性标注问题的各种方法中，我们将在本文中研究一种基于隐马尔可夫模型(HMM)的概率方法。</p><p id="8fa2" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">关键问题是将一系列<em class="ka"> t </em>标签分配给一系列<em class="ka"> n </em>字。听起来很简单！！假设我们有三个单词，分别是w₁、w₂、w₃，还有一组六个标签，分别是t₁、t₂ …..t₆.我们需要给这三个单词分配任何一个标签。</p><p id="e92c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">但是，有一个问题。每个单词可以有6个标签中的任何一个。这意味着有6×6×6个可能的序列(6)，我们需要找出哪个是正确的标签序列。概括地说，我们可以说，如果我们有<em class="ka"> t </em>个标签要分配给n个单词，就有t^n的可能性。在这些序列中，我们需要选择最可能的标签序列。</p><p id="eb6c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们很快意识到，对于一个大文档来说，这可能会很快失去控制。在我们继续之前，让我们绕道，建立一些数学积木。</p></div><div class="ab cl iv iw gp ix" role="separator"><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja"/></div><div class="hb hc hd he hf"><p id="84eb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">马尔可夫过程</strong></p><p id="d1e1" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们从一个非常简单的例子开始。假设它们是一系列事件——x₁、x₂、x₃——以离散的时间步长发生——t₁、t₂、t₃.这一系列事件首先发生的概率有多大？如果我们想一想，我们会问以下问题:</p><p id="3393" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">给定下列概率，P(x₃、x₂、x₁是什么？</p><ol class=""><li id="2fb5" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz kg kh ki kj bi translated">x₁在t₁，即P(x₁的概率)</li><li id="e4e0" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj bi translated">x₂在t₂的概率，给定x₁发生在t₁，即P(x₂ | x₁)，</li><li id="d672" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj bi translated">概率x₃在t₃，鉴于x₁，x₂发生在t₁，t₂.形式上这是P(x₃ | x₂，x₁)</li></ol><p id="b27c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们可以将此改写为:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/f7b58e8893f7da6d983c960efd0bc4a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k3aFYdOKLqJS1N8WeoMLSA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。1连锁法则</figcaption></figure><p id="e2a1" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">Eqn.1就是著名的概率的<strong class="je hj"> <em class="ka">链式法则</em> </strong>。此规则模拟2个或更多事件的联合概率。你可以在这里找到更多关于<a class="ae iu" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)#:~:text=In%20probability%20theory%2C%20the%20chain,variables%20using%20only%20conditional%20probabilities." rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="6ffd" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">像这样的一个序列随机过程，如果具有马尔可夫性，就称之为马尔可夫过程。这意味着，给定一个连续随机过程的当前状态，我们不能通过收集更多关于过去的知识来获得任何关于未来的额外信息。数学上我们可以这样写:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/a685736d37efc9fcc0988242c182b812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IL7uR9gDfZ08IgQKFEsZkA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。2马尔可夫性质</figcaption></figure><p id="1c46" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这意味着，<em class="ka"> n </em>处的状态仅取决于<em class="ka"> n-1 </em>处的先前状态。这对等式有什么影响？1 ?假设我们有一个马尔可夫过程，我们可以将等式1改写为:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/e11bdac0000fa1110df5dba44e91f43c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPEk3D5PLnX_xFkXt8Ojcw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。3马尔可夫性在链式法则中的应用</figcaption></figure><p id="8eb2" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这也被称为<strong class="je hj"><em class="ka">1-马尔科夫</em> </strong>过程。如果一个状态依赖于过去的<em class="ka"> k </em>个状态，那么它将是一个<strong class="je hj">k马尔可夫T19】过程。</strong></p><p id="2112" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">条件概率和贝叶法则</strong></p><p id="27cf" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">条件概率给我们一个事件B的概率，给定A已经发生，表示为P(B|A)。要计算P(B|A)，我们需要求出P(A，B)给定的A和B的联合概率，以及P(A)给定的A的边际概率。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/970fac924318b86531dceab5450d83ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LdREpc2PI20cBiE8UQeQaQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。4给定A，B的条件概率</figcaption></figure><p id="8017" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们可以使用等式1中的链式法则来展开分子。这样我们就得到了方程。5.这意味着，在实验的所有结果中，方程5给出了事件B发生频率的比率，假设我们只限于A发生的那些观察结果。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/3099c59812b9dce4cc821ebdc9187e7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rAB9wTWfytLvRWL77OvBpQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。5贝叶法则</figcaption></figure><p id="8789" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们可以把这个公式推广到两个以上的变量。我们可能会问，给定观测值A，B，一个结果是C的概率是多少，数学上，我们会把这个写成P(C|A，B)。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/8b6411472dd4e2e7934a872a025ebaad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bYW0dQEeaJeCSA9xZYKV1Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。6贝叶法则适用于3个变量。</figcaption></figure><p id="daf7" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">关于方程的一个重要观察。5是，如果事件A和事件B相互独立呢。在这种情况下，P(B|A)=P(B)，如果你认为这是非常明显的。在等式中。6、若C是A的<strong class="je hj">独立</strong>，则Eqn。6简化为类似的等式。5用于事件C和b。</p><p id="9869" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">结合链式法则和贝叶法则</strong></p><p id="a1bb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们可以用一个更复杂的事件链，将链式法则应用于一个看起来可怕的条件概率。假设B₁,B₂,B₃发生了，A₁,A₂,A₃发生的概率是多少。我们怎么用贝叶法则来写这个呢？考虑下面的表达式。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/3ffcfb559b41c857d8afbee520d96481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xjXYkBkPK5gT1XRXVmNVOw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。7贝叶法则适用于更多的赛事。</figcaption></figure><p id="2484" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们简单地将贝叶法则用于LHS。但是，RHS看起来还是有点复杂，尤其是分子。首先，我们取分子中的第二个操作数，应用链式法则得到:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/95dd26a56847916a402d0aa68da2332a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79ALEZKpdcMdok3GyuJ34w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。8链式法则应用于等式分子中的第二个操作数。七</figcaption></figure><p id="68f6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">将链式法则应用于第一个操作数，我们得到:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/7f1d87ff97c264d0482ee019d66f11ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t5trKJ0_yX_qi6tOsPivUA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。9链式法则应用于等式分子中的第一个操作数。七</figcaption></figure><p id="709d" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">如果你想知道，为什么我们不扩大分母，坚持住。我们很快就会看到，我们不需要！！</p><p id="0132" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">最可能的标签序列</strong></p><p id="e386" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">将我们的注意力转向词性标注，我们现在正式宣布我们的问题陈述。对于单词序列w₁、w₂、w₃，我们打算找出最可能的标签序列。为了简单起见，让我们假设我们只有3个标签t₁，t₂，t₃.如果这三个标签是，DT，VB和NN，那么在这三个标签的所有可能组合中，我们需要计算最可能的一个。我们注意到这是从这六种可能性中选择一种的问题。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/5f84b040afe232d4829ebe0dbf884e11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ptTa3WNhMS8awJr5lLHQrg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">3个标签的所有可能标签序列</figcaption></figure><p id="6a4e" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">让我们选择一个这样的序列t₁-t₂-t₃(即DT-VB-NN)。我们可以用数学方法将其写成下面的等式10。这只是这个标签序列的概率。注意，对于剩余的序列，将有五个以上这样的等式。然而，对于那些序列之一，P将是最高:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/38eac49a31f8f070999d553771ad1f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WKdFSxKKFISo173xQ96x3g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式10给定单词序列，标签序列的概率。</figcaption></figure><p id="8b79" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">此时，我们注意到这与等式7相似。让我们简化等式分子中的两个操作数。10使用链式法则，就像我们在方程中做的那样。8和9。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/4666aab646e2e1474a179a07f0f1e453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qdyhHUQiBPdaiy6YPqFNUw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。11将链式法则应用于等式中分子的操作数。10</figcaption></figure><p id="3339" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在，我们做两个非常重要的假设，这是我们下一步计算的基础。</p><ul class=""><li id="ff70" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz le kh ki kj bi translated">一个词的概率只取决于那个位置的标签。意义，它独立于前面的标签或相邻的词。</li><li id="1a98" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">当前标签仅依赖于前一个标签。因此，假设标签序列具有如等式2所示的马尔可夫属性。2.这被称为<strong class="je hj">二元模型</strong>假设。</li></ul><blockquote class="lf lg lh"><p id="39d6" class="jc jd ka je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi translated">如果我们假设当前标签依赖于前两个标签，那么这将是一个<strong class="je hj">三元模型</strong>假设。一般来说，如果当前标签依赖于当前单词和前面的n-1个标签，我们就有一个n-gram标签问题。</p><p id="ddf7" class="jc jd ka je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi translated">对于本文，我们考虑n=2。因此，我们有一个二元或二元标记问题。</p></blockquote><p id="9a95" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">将这两个假设应用于方程。11，我们得到简化得多的操作数。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/476e029a9c048eed0265084fd27334ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Iw1PrSMDA_L_JtFXwQBug.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。12简化方程式中的分子。10</figcaption></figure><p id="e798" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">术语P(wᵢ|tᵢ)被称为<strong class="je hj"> <em class="ka">发射概率</em> </strong>即一个词wᵢ的概率，给定的标签是tᵢ.术语P(tᵢ|tᵢ₋₁)被称为<strong class="je hj"> <em class="ka">转移概率</em> </strong>，即标签T1出现的概率，假定前一个标签是tᵢ₋₁.</p><p id="3716" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在，我们把注意力放在等式的分母上。10.当我们替换不同的标签序列时，我们注意到单词的序列保持不变。只有分子会改变。因此，出于所有实际目的，当我们试图找到最可能的标签序列时，我们只需要找到最大化方程中分子的那个。10.因此，我们用比例符号代替等式10中的等号。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/f2dcbbc7185373aa1e2e21f04ec6ff3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89rZJk8X6rsS2BNeduxxRQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。13标签序列t1、t2、t3的概率</figcaption></figure><p id="6546" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们可以进一步分解最大化问题，通过询问，什么样的标签选择将最大化括号中的术语。为了保持一致，我们注意到P(t₁)实际上是指P(t₁|Start)，意思是“假设我们在句子的开头，标记t₁的概率是多少？”。</p><p id="e62f" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">为了计算出最大化Eqn的三个标签的顺序。13(记住，有6种可能的序列)，我们需要计算Eqn。13，并选择产生最高概率的一个。形式上，这意味着寻找最大化Eqn的“3”标签的“1”序列。13.它是这样写的:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/5950796657dc43b82fe01f01dde1c943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aj3xmeVoHw7kYOkvt5RKlg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。14最可能的标签序列，最大化方程。13.</figcaption></figure><p id="c96f" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">因此，如果我们有n个单词的序列，寻找n个标签的序列，我们简单地用“n”替换索引“3”:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/791dd62dd20a9d945aa0227726c6b4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YsBm44d53XTdz7SL-QvEg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">等式。15参考:语音和信号处理— Jurafsky和Martin</figcaption></figure><p id="8686" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">因此，我们将问题简化为寻找句子中每个单词的发射和<strong class="je hj">转移概率</strong>的序列乘积<strong class="je hj">。</strong></p><p id="c3b4" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">隐马尔可夫模型</strong></p><p id="4cd9" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">请注意某个位置的标签的两个具体特征。它<strong class="je hj">在其当前位置发出</strong>一个字，并且<strong class="je hj">将</strong>转换到下一个位置的标签。作为观察者，我们只能按顺序看到单词，但是标签是<strong class="je hj">隐藏</strong>。这些是一个<strong class="je hj">隐马尔可夫模型</strong>或<strong class="je hj"> HMM </strong>的特征。</p><p id="1ee7" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在这里详细解释HMMs超出了本文的范围，所以我们将简单地讨论一下。</p><blockquote class="lf lg lh"><p id="d51d" class="jc jd ka je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi translated">在HMM中，有一个马尔可夫过程T (t₁、t₂、t₃)which对观察者来说是<strong class="je hj">隐藏的</strong>，(本例中的标签)。然而，随着过程从一个状态过渡到下一个状态，它<strong class="je hj">以文字的形式发出</strong>某些观察W ( w₁、w₂、w₃)。HMM的目标是通过观察w来学习T。</p></blockquote><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/6f329125cc87a35fb272628fad505250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0QtcvPc9p6m_gtMDSCFmzw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图1隐马尔可夫模型(参考号:<a class="ae iu" href="https://en.wikipedia.org/wiki/Hidden_Markov_model#:~:text=Hidden%20Markov%20Model%20(HMM)%20is,whose%20behavior%20%22depends%22%20on%20." rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><p id="a2f9" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">t₁的隐藏过程t可以以概率p₁₂.转移到t₂它也可以用<strong class="je hj"> <em class="ka">跃迁</em> </strong>概率p₁₁.跃迁回自身在这一步，t₁可以分别以<strong class="je hj"> <em class="ka">发射</em> </strong>概率e₁₁,e₁₂和e₁₃发射w₁、w₂和w₃。在t₃没有进一步过渡的可能，因为这是该进程的最后一步。对于我们的问题陈述，我们不需要更深入地研究hmm。</p><p id="5c68" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">所有源于隐藏态的发射概率的总和必须是1。类似地，所有源自隐藏状态的转移概率也必须加到1。</p></div><div class="ab cl iv iw gp ix" role="separator"><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja"/></div><div class="hb hc hd he hf"><p id="ffb6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">一个例子</strong></p><p id="ea69" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们已经做好了所有的数学基础。现在让我们举一个例句“长城”。凭直觉，我们知道，最好的标签序列是DT-JJ-NN，但我们能确定第一个标签是DT，然后是JJ和NN吗？首先，我们被问及什么样标签选择将使P( t₁|"the").)最大化既然我们知道，p(t₁|"the“)<em class="ka">∝</em>p(“t₁)p(t₁|start”)，让我们来回答下面的问题。</p><ul class=""><li id="e399" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz le kh ki kj bi translated">最有可能的开始标签是什么？是NN，JJ还是DT？</li><li id="2dd8" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">如果我们有最可能的开始标记，最可能发出的单词是什么？</li></ul><p id="7b4a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这与问以下哪个概率最高是一样的:</p><ul class=""><li id="cb7e" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz le kh ki kj bi translated">P(DT | " the ")∧P(" the " | DT)* P(DT | Start)</li><li id="4ec1" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">P(NN | " the ")∝P(" the " | NN)* P(NN | Start)</li><li id="f9ba" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">P(JJ | " the ")∝P(" the " | JJ)* P(JJ | Start)</li></ul><p id="6fb4" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在让我们假设，不知何故，我们已经设法找出了下列跃迁和发射概率:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/d043f74d7482951c2eb9d6973f248734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7aEw5ykRgbcZjZ0snLYfPg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图2第一个标签的跃迁和发射概率</figcaption></figure><p id="2c72" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们可以清楚地看到，选择DT作为“the”的标签最大化了P(t₁|"the").</p><p id="01f9" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">既然我们已经找到了作为DT的第一个标签，我们问t₂的什么选择将最大化P(t₂|"great)？现在，我们知道我们必须为t₂选择一个标签，最大化P("great"|t₂)*P(t₂|t₁=DT).我们寻找三个发射和跃迁概率，注意到如果我们选择P(JJ|DT)*P(“大”| JJ)，P(t₂|"great”)最大。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/fe9c90de1204e05ab1e7b19f7513c98c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wcvyCY8R9K_2Tlc25CnVlQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图3第二个标签的跃迁和发射概率</figcaption></figure><p id="33ac" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">请注意，我们并不是一次性寻找完整的标签序列。相反，我们从一个单词到下一个单词依次寻找下一个标签。实际上，我们是在一个<strong class="je hj"> <em class="ka">维特比算法中遍历一个<strong class="je hj"> <em class="ka">格子图</em> </strong>。</em> </strong>解码hmm是一种常见的选择</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/acbb2e6cd30fc108fd9a64c43cfd4219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7J_BdDPVgXavJlYwktwAxA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图4寻找最佳序列的格子图。</figcaption></figure><p id="5c58" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们将单词和所有可能的标签分成三列。维特比算法计算格子图中的最佳路径，使得对于所选择的标签，发射和转移概率的乘积最大。</p><p id="4cdf" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">实施</strong></p><p id="679b" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">为了得到一个未标记句子的标记序列，我们必须有所有标记转换和所有单词发射的转换和发射概率。我们可以从带标签的文档中构建它们，并使用它来构建我们的维特比解码器。让我们开始编码吧！！(访问我的GitHub页面访问<a class="ae iu" href="https://github.com/Arindam75/HMM-Tagger/blob/main/Viterbi_HMM_POS_Tagger.ipynb" rel="noopener ugc nofollow" target="_blank">整个笔记本</a>)。</p><p id="4960" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">一个好的起点是寻找一个带标签的语料库。NLTK库有丰富的资源，这些资源已经被标记，可以用来构建一个解码器。NLTK的书有一章专门介绍了这个图书馆提供的所有词汇资源。</p><p id="f70e" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">下面的代码片段加载了一组华尔街日报，作为一个POS标记句子的列表。</p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="b38c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">文肯先生是荷兰出版集团爱思唯尔公司的董事长。”显示为如下元组列表。每个元组都有单词及其标签。</p><blockquote class="lf lg lh"><p id="ab30" class="jc jd ka je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi translated"><em class="hi">('先生'，'名词')，('文肯'，'名词')，('是'，'动词')，('主席'，'名词')，(' of '，' ADP ')，('爱思唯尔'，'名词'，(' N.V . '，'名词')，('，'，'.')、(' the '、' DET ')、('荷兰语'、'名词')、('出版'、'动词')、('集团'、'名词')、('.', '.')] </em></p></blockquote><p id="088a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们进一步研究训练/测试集，找出以下特征。</p><ul class=""><li id="79f8" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz le kh ki kj bi translated">训练-测试分离留给我们3718个训练和196个测试句子。</li><li id="ed30" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">标记的训练词的数量是95440，标记的测试词的数量是5236。</li><li id="c2c7" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">词汇长度为11017，有12个独特的标签。</li></ul><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="173f" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们定义了两个效用函数，帮助我们计算以下内容:</p><ul class=""><li id="e6db" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz le kh ki kj bi translated">给定一个单词和标签，返回一个元组的次数，这个单词从标签中发出的次数和标签出现的总次数。</li><li id="b041" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">给定两个标签t₁和t₂，返回一个数组，其中包含t₁后面跟着t₁的次数以及t₁出现的总次数。</li></ul><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="6382" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">数据帧<strong class="je hj"> tag_df </strong>给出了任何标签t₁(column和t₂(row).之间的所有转换可能性例如，名词后跟动词的概率是0.146889(第1列第5行)。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/24ed24d89c4afc8f926fddf83a3fee94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1rLr2ldrY8bs_LkMcp2Mw.png"/></div></div></figure><p id="7031" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">理论上，我们也可以建立一个排放概率矩阵。然而，我们需要两个嵌套循环来访问vocab中的所有单词和所有标签。对于11017个词汇表和12个标签，这意味着超过100K次迭代。有更好的方法来处理。注意，我们只需要计算我们将在测试集中遇到的那些单词的P(w|t)。因此，当我们遍历测试集中的单词时，我们可以即时计算P(w|t)。</p><p id="d8fb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">Viterbi函数获取一系列单词并预测一系列标签。</p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="05f6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在，我们可以遍历测试集中的每个句子，去掉标签，并将结果单词列表发送给Viterbi函数。该函数执行以下操作。</p><ul class=""><li id="5ca0" class="kb kc hi je b jf jg jj jk jn kd jr ke jv kf jz le kh ki kj bi translated">对于句子中的每个单词w，计算每个标签的P(w|ti)∗P(tᵢ|tᵢ-₁。我们使用训练集来计算这些概率。</li><li id="d9ef" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">选择最大乘积的索引并使用它指向<strong class="je hj">标签</strong>列表来预测单词w的标签。</li><li id="511c" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">预测标签存储在列表<strong class="je hj"> tag_seq </strong>中。这是用来获取前一个标签，除非我们是一个句子的开始。</li><li id="b7de" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">如果，我们是一个句子的开头，前面的标签是“.”(开始标签)。</li><li id="edd2" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">该函数返回一个元组列表，每个元组包含单词和预测的标签。</li><li id="e091" class="kb kc hi je b jf kk jj kl jn km jr kn jv ko jz le kh ki kj bi translated">如果我们在词汇表中找不到一个单词，我们只需使用具有最大转移概率的标签。</li></ul><p id="ffc2" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">最后，我们有一个列表pred_set，它是测试集的预测版本。</p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="57ea" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">当我们比较预测标签和真实标签时，我们得到以下结果。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/bf1acae9cee8c79389339a0762895d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*yvTJtB0ygZ2rmDohNCZCNg.png"/></div></figure><p id="e3ff" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">结论</strong></p><p id="b6ff" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们基于HMM建立了一个简单的概率二元词性标注器。我们可以通过对未知单词(即，测试集中不在训练集中的单词)使用最常见的标记来进一步提高标记器的性能。然而，同样的方法也可以用来为命名实体识别建立模型。然而，我们将在另一篇文章中解决这个问题。</p><p id="409f" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">敬请关注，享受学习的乐趣！！</p><p id="7caf" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="ka">参考文献</em> </strong></p><p id="dc39" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><a class="ae iu" href="https://www.nltk.org/book/" rel="noopener ugc nofollow" target="_blank"> <em class="ka">用Python进行自然语言处理</em> </a> <em class="ka"> : Bird、Klein和Loper </em></p><p id="2dbb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><a class="ae iu" href="https://web.stanford.edu/~jurafsky/slp3/" rel="noopener ugc nofollow" target="_blank"> <em class="ka">语音和语言处理</em> </a> <em class="ka">:茹拉夫斯基和马丁</em></p></div></div>    
</body>
</html>