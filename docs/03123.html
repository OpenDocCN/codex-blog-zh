<html>
<head>
<title>Faster Tape Emulation with SIMD</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SIMD实现更快的磁带仿真</h1>
<blockquote>原文：<a href="https://medium.com/codex/faster-tape-emulation-with-simd-49287d7b24cf?source=collection_archive---------6-----------------------#2021-08-19">https://medium.com/codex/faster-tape-emulation-with-simd-49287d7b24cf?source=collection_archive---------6-----------------------#2021-08-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a373" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在过去的几年里，我一直在半定期地开发一个名为<a class="ae jd" href="https://github.com/jatinchowdhury18/AnalogTapeModel" rel="noopener ugc nofollow" target="_blank"> CHOWTapeModel </a>的开源磁带仿真音频插件。在那段时间里，我收到了很多很棒的用户反馈，包括关于新DSP功能的想法，关于我自己可能没有发现的错误的报告，甚至有一个很棒的用户提供服务来帮助重新设计插件的GUI(感谢Margus！).</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/d6f00056cfd92e0910ce33156e5ff463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*g87R-3dhDy537B9Ir7tCTQ.png"/></div></figure><p id="1e42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，我一次又一次收到的反馈是，这个插件“计算开销很大”，也就是说，它消耗了大量的计算资源。在某种程度上，这一结果是可以预期的，因为模拟磁带磁化过程背后的物理过程肯定不是一项微不足道的任务(参见我的<a class="ae jd" href="https://dafx2019.bcu.ac.uk/papers/DAFx2019_paper_3.pdf" rel="noopener ugc nofollow" target="_blank"> 2019 DAFx论文</a>。但是作为一个可能想在我的一个会话中使用10-20个插件实例的用户(在我的所有其他插件之上)，CHOWTapeModel所需的计算能力可能足以成为切换到其他一些计算成本更低的插件来实现所需声音的理由。</p><p id="fddd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于我最近开始致力于发布2.9.0版本的CHOWTapeModel，我决定自己去寻找可以提高插件性能的方法。这一搜索以<a class="ae jd" href="https://github.com/jatinchowdhury18/AnalogTapeModel/commit/b5f38990ed07d2e751149ad7b6d2e5adbe148a27" rel="noopener ugc nofollow" target="_blank">最近的提交</a>而告终，该提交将性能(在大多数处理模式下)提高了30–60%。我想写下这一改进背后的思考过程，以帮助我自己更好地理解它们，并与其他任何可能感兴趣的人分享这些想法。</p><p id="44db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">警告:下面将是一个相当技术性的讨论，假设你对C++和计算机架构有一点背景知识。</p><h1 id="9ba4" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">插件真的有多快？</h1><p id="626c" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">在开始改进之前，重要的是要找到一种可靠的方法来衡量插件的性能。虽然这个问题引发了关于测量软件性能的更广泛的讨论，但我认为对于音频处理来说，考虑“实时”性能很重要:例如，我的插件处理一秒钟的音频需要多长时间？如果我的插件需要10秒(平均)，那么它显然不能实时运行。如果我的插件平均需要0.9秒，它可能可以实时运行，但你可能无法在一个线程上运行多个插件实例。另外，如果<em class="jm">平均</em>时间为0.9秒，则“最坏情况”时间可能会大于1秒，这可能会导致听觉故障。</p><p id="e246" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于我的插件，我试图将最大处理时间定为0.1秒，这意味着插件的10个实例可以在一个线程上实时运行。由于我的笔记本电脑一次最多可以使用8个线程，所以理论上我可以有一个包含80个音轨的DAW会话，每个音轨在处理能力耗尽之前运行一个插件实例(假设我不想使用任何其他插件)。在一个真实的会话中，我可能不需要80首曲目，但我会想使用其他插件，加上DAW需要一点计算能力来完成自己的操作。</p><h2 id="d1aa" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">CHOWTapeModel有多快？</h2><p id="90d2" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">对于CHOWTapeModel，性能在很大程度上取决于插件使用的“滞后模式”。在进行最近的改进之前，以下是CHOWTapeModel在44.1 kHz采样速率和8倍过采样(所有其他设置均为默认值)下，在每种模式下处理1秒音频所需的时间:</p><ul class=""><li id="6e56" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">RK2: 0.073秒</li><li id="8d1a" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">RK4: 0.132秒</li><li id="6e7d" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">NR4: 0.172秒</li><li id="6535" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">NR8: 0.306秒</li><li id="71e5" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">状态:0.066秒</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ls"><img src="../Images/670eaba4be2a9981c45828d0ea3578aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*JE63DDU6vzGFSUycT9N7bQ.png"/></div></figure><p id="154f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有几点需要注意。首先，我没有包括“V1”滞后模式，因为它在内部使用“RK4”处理。有关我如何生成这些性能度量的更多信息，请参见<a class="ae jd" href="https://github.com/jatinchowdhury18/AnalogTapeModel/blob/master/Plugin/Source/Headless/Benchmarks.cpp" rel="noopener ugc nofollow" target="_blank">基准测试工具</a>源代码。所有性能测量都是在一台配备英特尔酷睿i7–9750h CPU、主频为2.60GHz的MacBook上进行的。</p><h2 id="3256" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">先前的工作</h2><p id="503f" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">我应该在这里提到，我已经花了大量的时间来优化磁带仿真算法。事实上，回顾2019年12月的一些<a class="ae jd" href="https://www.kvraudio.com/forum/viewtopic.php?t=536112" rel="noopener ugc nofollow" target="_blank">论坛帖子，我记得在耗尽计算能力之前，我几乎无法运行一个插件实例。一路走来，我学到了很多优化技巧，包括如何缓存值，这样就不需要重新计算，</a><a class="ae jd" href="https://youtu.be/bVJ-mWWL7cE" rel="noopener ugc nofollow" target="_blank">无分支编程</a>，如何读取不同C++编译器生成的汇编代码。然而，有一个重要的优化技术我还没有能够应用到CHOWTapeModel: SIMD并行化。</p><h1 id="5583" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是SIMD？</h1><p id="72e1" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">SIMD是<a class="ae jd" href="https://en.wikipedia.org/wiki/SIMD" rel="noopener ugc nofollow" target="_blank">“单指令多数据”</a>的缩写。基本思路如下。如果您给计算机两个数字，并告诉它将它们相乘(即<em class="jm"> a * b = c </em>，它通常会经历以下步骤:</p><ul class=""><li id="4957" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">将第一个数字(<em class="jm"> a </em>)存储在寄存器中</li><li id="3b74" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">将第二个数字(<em class="jm"> b </em>)存储在寄存器中</li><li id="b8db" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">将两个寄存器的内容相乘，并将结果存储在第三个寄存器中(<em class="jm"> c) </em></li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/41c87ab37a69cd6feb339a0d0a91f39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcrtFOaED1J7WrpMKUyCSA.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">用于将两个浮点数相乘的生成的程序集</figcaption></figure><p id="0445" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们说，你有两组4个数字，你想让计算机将每组中的数字相乘。显而易见的方法是重复上述步骤4次，这自然需要4倍的时间来完成。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/854c7c430b09328c4d265d1dc7197ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkxG-kJqhFQ_pOJVNjlkbA.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">为4个浮点数相乘而生成的程序集</figcaption></figure><p id="1101" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或者，SIMD指令允许计算机在单个寄存器中存储多个值，从而实现以下方法:</p><ul class=""><li id="db74" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">将第一组中的四个数字存储在SIMD寄存器中</li><li id="8eed" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">将第二组中的四个数字存储在SIMD寄存器中</li><li id="4c62" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">将两个SIMD寄存器的内容相乘，并将结果存储在第三个SIMD寄存器中</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/6305b99effae6b413dfb1ba5bb5e8629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZSzR8FTjj6xDoGOmWvTQw.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">将四个浮点数与SIMD寄存器相乘的生成的程序集</figcaption></figure><p id="9360" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这使得计算机能够用相同数量的CPU指令将4个数字相乘，就像将单个数字相乘一样！这个过程通常被称为“矢量化”或“编写矢量化代码”。</p><h2 id="5c04" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">SIMD指令集</h2><p id="7226" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">据我所知，目前有三种常用的SIMD指令集。几乎所有的英特尔CPU都支持SSE指令集，该指令集支持128位SIMD寄存器:大到足以存储4个单精度浮点数(通常称为“浮点”)，或2个双精度浮点数(“双精度”)。AVX指令集支持256位SIMD寄存器，宽度足以容纳8个浮点数或4个双精度数，但一些较老的英特尔CPU不支持。最后，用于ARM CPUs的NEON指令集支持4浮点和2双精度的SIMD寄存器，但双精度支持仅在最近的版本中可用(稍后会有更多介绍……)。</p><h2 id="d755" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">SIMD并行化的极限</h2><p id="571f" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">虽然SIMD优化非常强大，但它的应用范围是有限的。一般来说，要并行完成两个操作，它们必须完全独立。例如，假设我有两个乘法运算，<em class="jm"> a * b = c </em>和<em class="jm"> c * d = e </em>。我不能并行执行这些操作，因为第二个操作取决于第一个操作的结果！</p><p id="2e9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑到这一点，音频处理中通常有两种情况可以进行SIMD优化。一个是如果你有一个“前馈”过程，这样输出只取决于当前和以前的输入。这种情况对于优化类似<a class="ae jd" href="https://github.com/hgomersall/SSE-convolution" rel="noopener ugc nofollow" target="_blank">卷积</a>、<a class="ae jd" href="https://github.com/Chowdhury-DSP/chowdsp_utils/blob/master/DSP/Delay/chowdsp_DelayInterpolation.h#L253" rel="noopener ugc nofollow" target="_blank">延迟线插值</a>或<a class="ae jd" rel="noopener" href="/mlearning-ai/real-time-neural-network-inferencing-for-audio-processing-857313fd84e1">神经网络</a>的事情非常有用。另一种情况是，如果您有两个并行的音频流，例如，一个带有4个并行声部的合成器，或者一个多声道音频流。第二种情况对优化CHOWTapeModel很有用。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mc md l"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">有趣的SIMD可视化</figcaption></figure><h1 id="8f89" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">优化CHOWTapeModel</h1><p id="0ed0" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">因为CHOWTapeModel是为立体声处理配置的，所以这种优化背后的基本策略是通过插件的“滞后”部分并行处理立体声通道。</p><h2 id="9b0d" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">为什么不把整个插件并行化呢？</h2><p id="bb60" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">尝试并行化整个插件没有意义有几个原因。首先，在插件的几个部分中，两个通道之间的处理不是独立的，这意味着并行化是不可能的。第二，并行处理需要在处理之前将立体声通道“交织”到SIMD寄存器中，然后在处理之后对立体声通道进行去交织。这个操作会产生一点开销，所以在插件的不同部分之间不断地交错/去交错实际上会使插件慢一点！</p><p id="c260" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">滞后处理器是并行化的良好候选，因为立体声通道是独立处理的，并且处理器在计算上非常昂贵。由于处理非常昂贵，SIMD并行化的好处远远超过交织/解交织通道的开销。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es me"><img src="../Images/fd9a904d166dcfb1c92ff70f872555e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NYs5ZMY7s2nOj9JQ.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">交错立体声音频</figcaption></figure><h2 id="cf04" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">正在优化…</h2><p id="d2c1" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">实现这种优化的实际工作需要几个步骤:</p><ul class=""><li id="82ae" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">重构</li><li id="c9dc" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">转换操作以使用SIMD</li><li id="09c6" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">寻找特殊功能的替代品</li><li id="ad3a" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">衡量绩效</li></ul><p id="1867" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不想太详细地讨论重构步骤(鼓励感兴趣的人阅读<a class="ae jd" href="https://github.com/jatinchowdhury18/AnalogTapeModel/commit/b5f38990ed07d2e751149ad7b6d2e5adbe148a27" rel="noopener ugc nofollow" target="_blank">提交</a>)，但是大量的跑腿工作集中在将类成员函数转换成“自由”函数，这可以更容易地配置成采用浮点寄存器或SIMD寄存器。我想保持与非矢量化实现的向后兼容性，以便用于测试和比较。</p><p id="b693" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将浮点运算转换为SIMD运算，在大多数情况下，用<code class="du mf mg mh mi b"><a class="ae jd" href="https://docs.juce.com/master/structdsp_1_1SIMDRegister.html" rel="noopener ugc nofollow" target="_blank">juce::dsp::SIMDRegister&lt;double&gt;</a></code>替换<code class="du mf mg mh mi b">double</code>是一种简单的替换，但是有一些地方需要更多的注意，特别是条件语句。比如说我有一个数<em class="jm"> x </em>，如果<em class="jm"> x &gt; 6我想加倍。</em>对于浮点数，我可以用三元运算符进行如下操作:</p><pre class="jf jg jh ji fd mj mi mk ml aw mm bi"><span id="2d31" class="kq jo hi mi b fi mn mo l mp mq">x = x &gt; 6.0 ? x * 2.0 : x;</span></pre><p id="80b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于SIMD寄存器，这种类型的事情有点困难:</p><pre class="jf jg jh ji fd mj mi mk ml aw mm bi"><span id="3131" class="kq jo hi mi b fi mn mo l mp mq">using Float = juce::dsp::SIMDRegister&lt;double&gt;;</span><span id="8e24" class="kq jo hi mi b fi mr mo l mp mq">x = (((Float) 2.0 * x) &amp; Float::greaterThan (x, (Float) 6.0)) — (x &amp; Float::lessThanOrEqual (x, (Float) 6.0));</span></pre><p id="11bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，滞后处理使用了几个特殊的数学函数，即<code class="du mf mg mh mi b">std::isnan()</code>和<code class="du mf mg mh mi b">std::tanh()</code>。为了让这些函数工作，我需要引入一个第三方库，<a class="ae jd" href="https://github.com/xtensor-stack/xsimd" rel="noopener ugc nofollow" target="_blank"> xsimd </a>，它包含这些操作的simd实现。</p><p id="eb01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在完成上述所有步骤后，我能够编译CHOWTapeModel的改进版本，并在我的计算机上进行测试。唷！</p><h2 id="7bba" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">STN模式呢？</h2><p id="0e92" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">有一种滞后模式，我必须作为一种特殊情况来处理。因为STN模式使用的神经推理引擎已经使用了SIMD优化，所以我不能再进一步优化它了。因此，使用该模式时的性能应该保持不变。</p><h2 id="c229" class="kq jo hi bd jp kr ks kt jt ku kv kw jx iq kx ky kb iu kz la kf iy lb lc kj ld bi translated">还有一个障碍…</h2><p id="0850" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">不幸的是，还有一个绊脚石需要一些时间去克服。还记得之前我提到过ARM NEON指令集的某些版本不包含双精度浮点寄存器吗？JUCE SIMDRegister实现就是在这种情况下开发的，目前不包含ARM NEON的双精度SIMD寄存器的矢量化实现。结果是，在配有ARM CPUs的设备上，包括iPad和新的Mac M1电脑，滞后处理的运行速度实际上会比非矢量化实现慢得多。</p><p id="6650" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终，我自己动手做了一个<a class="ae jd" href="https://github.com/Chowdhury-DSP/chowdsp_juce_dsp" rel="noopener ugc nofollow" target="_blank"> JUCE DSP模块</a>的分支，并自己为ARM NEON实现了双精度SIMD寄存器。希望JUCE的人能在模块的未来版本中更正式地加入这种支持。</p><h1 id="9d3a" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">全部完成！</h1><p id="96d0" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">就是这样！我们已经完成了CHOWTapeModel的迟滞处理器的矢量化。现在是时候看看插件的实际性能到底有多好了:</p><ul class=""><li id="1de5" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">RK2: 0.053秒(提高了38%)</li><li id="8fc9" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">RK4: 0.088秒(提高50%)</li><li id="aef8" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">NR4: 0.111秒(提高了55%)</li><li id="a8e5" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">NR8: 0.188秒(提高了63%)</li><li id="ab41" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">状态:0.066秒(无变化)</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ls"><img src="../Images/60cbfb3efeffbd4e066459e7e72996b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*M3iwqzI_b-3jBZcJmRuWbA.png"/></div></figure><p id="f8a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总的来说，这是一个非常显著的改进！特别是，“NR8”模式在这次改变之前对我来说几乎是不可用的，所以现在它快了1.5倍以上，我希望能多使用一点。</p><h1 id="0c15" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">最后…</h1><p id="9682" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">现在优化已经完成，在发布CHOWTapeModel 2 . 9 . 0版之前，我还想做一些事情。与此同时，如果你等不及了，可以尝试一下插件的<a class="ae jd" href="https://chowdsp.com/nightly.html" rel="noopener ugc nofollow" target="_blank">夜间版本</a>，尽管要注意它们可能不稳定。</p><p id="908e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我知道这篇文章已经深入到编写低级DSP代码的内部，但是我希望你会感兴趣，感谢你一直坚持到最后！向前…</p></div></div>    
</body>
</html>