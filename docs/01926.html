<html>
<head>
<title>Web Scraping to See Trends in Education</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">浏览网页，了解教育趋势</h1>
<blockquote>原文：<a href="https://medium.com/codex/web-scraping-to-see-trends-in-education-c18485260bad?source=collection_archive---------8-----------------------#2021-06-15">https://medium.com/codex/web-scraping-to-see-trends-in-education-c18485260bad?source=collection_archive---------8-----------------------#2021-06-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="eec8" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">用Scrapy提取芬兰教育数据</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/011cfc2c6c9c2e73509a368d9d597dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ggugH1b5luDVDLoZ-WFfrw.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><a class="ae jn" href="https://unsplash.com/@homajob?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae jn" href="https://unsplash.com/s/photos/education?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="5ebb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi kk translated">芬兰大学入学考试是高中学生(标准完成时间为15-19岁)参加的最后一次考试，包括一门学科的所有领域。这些考试的成绩被用来申请大学，你需要达到一定的标准才能通过高中。</p><p id="f64a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">分数是用所谓的分数限制来决定的。例如，一个等级的赞美诗的分数限制，可能是最好的，可能是120分。这意味着，如果你得到120或以上，你得到赞美。这些分数限制是根据高斯分布计算的。这意味着前5%的参与者得到赞美，然后15%得到Eximia(第二好)等等。<a class="ae jn" href="https://www.ylioppilastutkinto.fi/en/assessment-and-certificates/assessment-of-the-examination" rel="noopener ugc nofollow" target="_blank">你可以阅读更多关于这个过程和这里使用的确切公式</a>。</p><p id="1889" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因为分数限制与参与者的表现相关，所以它们可以用来比较每年学生的一般学术能力。这当然没有考虑到这样一个事实，即有时测试会稍微难一点或容易一点。</p><p id="6437" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">另一个要注意的重要事情是，随着时间的推移，考试通常会变得更难，以平衡教育越来越好和信息量越来越大的事实。</p><p id="e845" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这样一来，我们就可以真正进入项目了</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="3d60" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">目录</h2><p id="983c" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">1 — Scrapy <br/> 2 —在本地启动一个Scrapy项目<br/> 3 —在Jupyter上启动一个Scrapy项目<br/> 4 —配置您的蜘蛛<br/> 5 —使用LinkExtractor <br/> 6提取链接—抓取限制分数表<br/> 7 —规划我们的导出<br/> 8 —最终的蜘蛛<br/> 9 —在本地提取数据<br/> 10 —在Jupyter上提取数据<br/> 11 —生成洞察</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="a00a" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">Scrapy</h2><p id="4a95" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">这篇文章将主要处理这个项目的网页抓取部分，并可以作为一个很好的介绍像Scrapy和它提供的非常方便的功能。</p><p id="01b8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你对Scrapy完全陌生，我建议<a class="ae jn" href="https://docs.scrapy.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">通读文档</a>。与这个项目最相关的是<a class="ae jn" href="https://docs.scrapy.org/en/latest/topics/spiders.html" rel="noopener ugc nofollow" target="_blank">蜘蛛</a>和<a class="ae jn" href="https://docs.scrapy.org/en/latest/topics/link-extractors.html" rel="noopener ugc nofollow" target="_blank">链接提取器</a>。当然，我会解释整个项目中的所有新概念，并在需要时给出例子，但是浏览文档可以帮助你更好地理解项目。</p><p id="c75a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">此外，你还需要确保你已经安装了Scrapy。你可以使用pip安装Scrapy。</p><p id="6d73" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">要在windows上这样做，请打开cmd并键入</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="390f" class="la lb hi mb b fi mf mg l mh mi">pip install Scrapy</span></pre><p id="b532" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在linux上，您可以使用</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="8be8" class="la lb hi mb b fi mf mg l mh mi">#pip install Scrapy</span></pre><p id="532c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果您正在使用Anaconda，您可以简单地从navigator向您的环境添加Scrapy。</p><p id="dbec" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通常当你开始一个零碎的项目时，你首先创建项目文件。这种情况的主要例外是当你想在Jupyter笔记本上运行项目时(这也意味着通过Kaggle笔记本或Google Colab运行它)。我将在这里介绍这两种方法。</p><h2 id="7267" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">在本地开始一个零碎的项目</h2><p id="4d0f" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">要开始一个项目，你需要首先打开你的cmd。然后使用它导航到您的项目文件夹。我的项目文件夹在我的桌面上，所以这里是我如何导航到那里。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/de93365f6fa9878cb1f4df5ceede02ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*ilOh7PkD0qIaYpVIKYaw4w.png"/></div></figure><p id="15d4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果您不确定如何到达下一个路径，您可以使用dir命令来查看您可以移动到哪些文件夹。</p><p id="5da7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">导航到文件夹后，可以使用下面的命令创建项目。</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="e130" class="la lb hi mb b fi mf mg l mh mi">scrapy startproject &lt;project name&gt; </span></pre><p id="7435" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我建议给这个项目起一个相关的名字。我把我的名字命名为“matricular_scrape”。</p><p id="08ef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">运行此命令将生成一个项目文件夹，其中包含此项目所需的所有文件。其中最重要的是你的设置文件和蜘蛛文件夹。我们的下一步是在spiders文件夹中创建一个蜘蛛。</p><p id="80aa" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为此，我们运行以下命令:</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="95fc" class="la lb hi mb b fi mf mg l mh mi">scrapy genspider &lt;spider name&gt; &lt;starting link&gt;</span></pre><p id="31a6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，在我们生成蜘蛛之前，我们需要决定从哪一页开始抓取。对于这个项目，我们将使用这个页面:<a class="ae jn" href="https://www.ylioppilastutkinto.fi/ylioppilastutkinto/pisterajat" rel="noopener ugc nofollow" target="_blank">https://www . yliopilastutkinto . fi/yliopilastutkinto/pisterajat</a></p><p id="9e9a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">原因是，我们可以看到在右侧栏中有一个到每年分数限制的链接。每年的日期分为春季和秋季。这是因为大学入学考试每年在全国范围内举行两次。</p><p id="198d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从这一页开始，我们可以在以后利用链接提取器获得每年分数限制的链接。</p><p id="721d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你想完全跟随我，你应该给这个蜘蛛起名叫“分数限制”。当我们运行蜘蛛时，这个名字将是相关的。</p><p id="3eb4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这意味着现在要运行的命令应该是:</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="3bb9" class="la lb hi mb b fi mf mg l mh mi">scrapy genspider score_limits “<a class="ae jn" href="https://www.ylioppilastutkinto.fi/ylioppilastutkinto/pisterajat" rel="noopener ugc nofollow" target="_blank">https://www.ylioppilastutkinto.fi<br/>/ylioppilastutkinto/pisterajat</a>”</span></pre><h2 id="2baa" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">在Jupyter上开始了一个棘手的项目</h2><p id="83db" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">你不需要在Jupyter上创建一个项目文件夹，而是首先确保把Scrapy安装到那个笔记本上。大多数笔记本支持使用</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="82bf" class="la lb hi mb b fi mf mg l mh mi">!pip install Scrapy</span></pre><p id="ce94" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，您需要手动创建蜘蛛。你可以在<a class="ae jn" href="https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy-spider" rel="noopener ugc nofollow" target="_blank"> Scrapy文档</a>中找到创建通用蜘蛛的模板。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="2c97" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">配置您的蜘蛛</h2><p id="5f1d" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">现在你已经创建了蜘蛛，你可以打开它创建的模板，看起来应该是这样的:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="9c19" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们想对此做些改变。首先，我们可以把<code class="du mm mn mo mb b">allowed_domains</code>概括为仅仅是<code class="du mm mn mo mb b">‘<a class="ae jn" href="http://www.ylioppilastutkinto.fi'" rel="noopener ugc nofollow" target="_blank">www.ylioppilastutkinto.fi'</a></code>。这就把它变成了一个域名而不是一个url。</p><h2 id="c971" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">使用LinkExtractor提取链接</h2><p id="40d1" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">接下来，我们将开始构建解析函数。这是当你告诉你的蜘蛛抓取一个网站时将运行的功能。它将获取<code class="du mm mn mo mb b">start_urls</code>中给定的网站，并将获取的数据存储到响应对象中。</p><p id="98f9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们之前建立的那样，我们希望从侧栏中检索链接。为此，我们将创建一个链接提取器。一个链接提取器将允许我们从一个给定的网站提取任何链接。<br/>下面是设置链接提取器的代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="15c6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这里有几点需要注意:</p><ol class=""><li id="7dde" class="mp mq hi jq b jr js ju jv jx mr kb ms kf mt kj mu mv mw mx bi translated">我们需要在<code class="du mm mn mo mb b">LinkExtractor</code>类中导入，这是我们在第2行做的</li><li id="c48d" class="mp mq hi jq b jr my ju mz jx na kb nb kf nc kj mu mv mw mx bi translated">我们给了<code class="du mm mn mo mb b">LinkExtractor</code>和蜘蛛相同的允许域名</li><li id="4e06" class="mp mq hi jq b jr my ju mz jx na kb nb kf nc kj mu mv mw mx bi translated">我们只想要边栏中的链接。为此，我们需要检查网站并找出侧栏的xpath。然后通过给出<code class="du mm mn mo mb b">restrict_xpaths</code>参数，我们可以告诉<code class="du mm mn mo mb b">LinkExtractor</code>只在xpath中寻找链接。</li></ol><p id="bb2d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了实际获得链接，我们需要使用<code class="du mm mn mo mb b">le.extract_links(response)</code>调用<code class="du mm mn mo mb b">LinkExtractor </code></p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="c37c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们有了链接，我们需要一些方法来告诉蜘蛛去那些链接，并给它指示当它到达那些网站时该做什么。</p><p id="59b7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将蜘蛛发送到每个链接的完整代码如下:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="cd68" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">所以详细说明一下评论:<br/>我们首先调用<code class="du mm mn mo mb b">yield scrapy.Request</code>它的作用是告诉scrapy去获取另一个网站。<br/>然后我们通过调用<code class="du mm mn mo mb b">url = link.url</code>给出获取的url。<br/>我们设置了一个回调函数，让我们在每次发出请求时给出一个我们想要运行的函数。然后我们给出回调参数。这里我们给它<code class="du mm mn mo mb b">date</code>，这样我们可以在回调参数中给定的函数期间使用它。</p><p id="ae4d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们已经让蜘蛛先找到所有我们想浏览的链接，然后我们将蜘蛛发送到这些链接。现在我们需要构建一个函数，蜘蛛将使用它来抓取我们发送给它的每个链接。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="dc06" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">刮极限分数表</h2><p id="a35e" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">我们将要设置的函数将被称为<code class="du mm mn mo mb b">parse_table</code>。如果你想叫它别的名字，记得相应地更新回调参数。</p><p id="b1ce" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这个函数需要一些东西。因为我们在这个类中设置了一个函数，所以我们将<code class="du mm mn mo mb b">self </code>值传递给它，但是我们也需要传递<code class="du mm mn mo mb b">response</code>，然后我们传递之前给出的回调参数。在这种情况下，这意味着变量<code class="du mm mn mo mb b">date</code>。结果行应该是:</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="6522" class="la lb hi mb b fi mf mg l mh mi">def parse_table(self, response, date):</span></pre><p id="79b4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们需要开始思考我们将用来抓取网站的实际逻辑。如果我们看一下侧边栏中的第一个链接，我们可以看到这样一个表格:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/5c8d63078f3793b56facaea4f0e5af0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUW3-J9BlTAEoNyJeUh_Xg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">表格被剪短以保持图像足够大</figcaption></figure><p id="9b87" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们使用chrome/Firefox的检查工具来计算如何从网站上选择我们的数据。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ne"><img src="../Images/c30e601cc36f37cfd3ed1e29f17ef7e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RC8xofMJ53w_eeVyBAL-TA.png"/></div></div></figure><p id="bb5d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由此我们可以看到，表存储在内容类中。我们还可以看到，每个科目的分数限制存储为表格行。</p><p id="622a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有了这些信息，我们就可以开始构建抓取逻辑了。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="925e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们从抓取列标题开始(所以L，E，M，C…)。我们为每个链接单独抓取这些，因为它们会随着时间的推移而略有变化。这些类别位于表格的第一行。下面是完整的代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="8174" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们使用列表理解建立一个列表。逻辑基本上是:</p><p id="c042" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">1.我们首先得到每个类别的根值，从中我们可以得到纯文本，也就是类别本身。<br/> 2。我们通过使用css选择器选择表格，然后选择所述表格的第一行来获得每个类别。<br/> 3。我们从第二个值向前选择第一行的值。这是因为第一行的第一个值是空的。(你可以在截图中看到)</p><p id="d639" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">按照这个逻辑，我们可以得到网站上表格的类别。</p><p id="54d7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，有时每个网站的格式不尽相同。当处理跨越多年的数据时，这种情况经常发生。这里也是如此。</p><p id="5a2e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在一些网站上，表格数据只是简单的<code class="du mm mn mo mb b">td</code>，但是在另一些网站上，表格数据被附加了一个<code class="du mm mn mo mb b">strong</code>标签。这意味着我们需要使用<code class="du mm mn mo mb b">td strong</code>来清除它。为了涵盖这两种情况，我们可以使用if语句来检查当我们只使用<code class="du mm mn mo mb b">td</code>进行抓取时，类别是否有<code class="du mm mn mo mb b">None</code>值。</p><p id="4991" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">if语句的逻辑在这里。类别列表的一致性遵循我上面解释的逻辑。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="56a1" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">规划我们的出口</h2><p id="9ea6" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">现在我们可以开始实际刮每个科目的分数限制。在这一步，最好首先考虑如何导出数据。数据通常是表格形式的，这意味着您通常会输出csv文件。</p><p id="0dc1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于这个项目，我选择了以下类型的结构:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nf"><img src="../Images/a4f20794ad9a9a33df4e383b1ecedc5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0ULeIvFPA-u_-lEmZYK0w.png"/></div></div></figure><p id="79b6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">标题</strong>将是主题的名称。<br/> <strong class="jq hj">日期</strong>将是分数限制的起始年份和赛季。<br/> <strong class="jq hj">类别</strong>每个类别有一列，并且有该类别的分数限制。</p><p id="4518" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面是一个完整的示例:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/469573b2ee3688fcd1a7f8d9eff6e6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j8sbwAZZWylFqU2gFvVZLw.png"/></div></div></figure></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="ddcc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">既然我们已经决定了如何导出数据，我们实际上可以开始构建导出的字典了。</p><p id="ea9f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面是这段代码的第一部分:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="9a86" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">首先，我们开始遍历表中的每一行。我们得到包含以下内容的行:</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="b477" class="la lb hi mb b fi mf mg l mh mi">rows = response.css(‘#content table tbody tr’)</span></pre><p id="bf94" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">也就是说，我们选择内容包装器，然后选择其中的表，然后只选择表的主体，最后选择该表中的所有行。</p><ol class=""><li id="214c" class="mp mq hi jq b jr js ju jv jx mr kb ms kf mt kj mu mv mw mx bi translated"><code class="du mm mn mo mb b">cols</code>表示该行的所有数据(即每列的值)</li><li id="1c33" class="mp mq hi jq b jr my ju mz jx na kb nb kf nc kj mu mv mw mx bi translated">通过选择第一个值，我们得到了主题名，也称为标题</li><li id="153b" class="mp mq hi jq b jr my ju mz jx na kb nb kf nc kj mu mv mw mx bi translated">然后我们获取实际的分数限制。我们从第二个值开始前进。我们在这里也应用同样的<code class="du mm mn mo mb b">.root.text</code>来获得实际值。</li></ol><p id="d862" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们得到必要的数据后，我们为最终的词典建立一个基础。我们在这里设置标题和日期的值。</p><p id="5f78" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们需要将每个分数限制分配给相应的类别。<br/>为此，我们使用以下代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="c0ec" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">该代码利用了分数限制以与类别相同的顺序存储的知识。有了这些信息，我们浏览每个分数限制(<code class="du mm mn mo mb b">num</code>)并将其分配给相同位置的<code class="du mm mn mo mb b">category </code>。这意味着<code class="du mm mn mo mb b">nums</code>中的第一个分数限制被分配给<code class="du mm mn mo mb b">categories</code>中的第一个<code class="du mm mn mo mb b">category</code>。</p><p id="6a72" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">运行之后，我们已经构建了字典，并且拥有了我们想要的所有数据。</p><p id="8a09" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后一步我们调用<code class="du mm mn mo mb b">yield data</code>，当我们使用蜘蛛爬行时，它将输出字典。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="de82" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">最后的蜘蛛</h2><p id="6749" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">如果你在路上迷路了，或者只是想看看更大的图片，这里是整个蜘蛛的代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="c25f" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">在本地提取数据</h2><p id="1e80" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">现在，我们已经建立了一个功能蜘蛛，但我们如何实际使用它来抓取数据？我们要做到这一点，我们需要再次打开cmd。</p><p id="fbb9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">首先，再次导航到您的项目文件夹。您所在的文件夹是存储csv文件的文件夹，所以请记住这一点。要激活Scrapy spider，我们使用以下命令语法:</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="2e2a" class="la lb hi mb b fi mf mg l mh mi">scrapy crawl &lt;spider name&gt; -o &lt;file name&gt;</span></pre><p id="1079" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你一直跟着，那么蜘蛛的名字将是<code class="du mm mn mo mb b">score_limits</code>。我将使用“data.csv”作为文件名，但只需选择任何相关的内容。请记住在名称中包含文件扩展名，并用引号将名称括起来。</p><p id="862d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你想了解更多关于从scrapy导出数据的信息，我推荐<a class="ae jn" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html" rel="noopener ugc nofollow" target="_blank">饲料导出文档</a>。</p><p id="83c0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">运行此命令后，您应该有一个与您在项目文件中选择的名称相同的文件。该文件应该包含抓取的数据。例如，下面是我的csv文件的开头:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nh"><img src="../Images/a17d7899e1639697e55d978f3d150db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RKWwmEOlyRrJN1TbpFekFA.png"/></div></div></figure></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="2f67" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">在Jupyter上导出数据</h2><p id="2966" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">为了在Jupyter上抓取带有Scrapy的蜘蛛，你需要建立抓取<a class="ae jn" href="https://docs.scrapy.org/en/latest/topics/settings.html" rel="noopener ugc nofollow" target="_blank">设置</a>并设置一个<a class="ae jn" href="https://docs.scrapy.org/en/latest/topics/api.html#crawler-api" rel="noopener ugc nofollow" target="_blank">抓取进程</a>。如果你想深入了解这些，看看链接的文件。</p><p id="b16f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">首先，您应该使用以下命令导入<code class="du mm mn mo mb b">CrawlerProcess</code></p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="005a" class="la lb hi mb b fi mf mg l mh mi">from scrapy.crawler import CrawlerProcess</span></pre><p id="fb07" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">接下来你需要设置<code class="du mm mn mo mb b">CrawlerProcess</code>。有很多不同的东西你可以改变，但这里最重要的是<code class="du mm mn mo mb b">FEEDS</code>。这个设置告诉蜘蛛如何在爬行时导出数据。要设置输出csv，您可以执行以下操作:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="b602" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用这些设置，输出文件的名称是“scores.csv ”,它将被格式化为csv文件。</p><p id="9457" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，您只需要告诉进程开始爬行，并实际启动进程。你可以用</p><pre class="iy iz ja jb fd ma mb mc md aw me bi"><span id="2d05" class="la lb hi mb b fi mf mg l mh mi"># We tell the spider to crawl when process startsprocess.crawl(MainSpider)</span><span id="8904" class="la lb hi mb b fi ni mg l mh mi"># We start the process, <br/># and set it to end after we’ve crawled through all pages<br/>process.start(stop_after_crawl=True)</span></pre></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="f719" class="la lb hi bd lc ld le lf lg lh li lj lk jx ll lm ln kb lo lp lq kf lr ls lt lu bi translated">产生洞察力</h2><p id="5073" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">我们可以从这些数据中收集一些一般性的见解，如数学测试中赞美诗分数限制随时间的变化。</p><p id="0bc4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以用下面的代码做到这一点:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="cb40" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这将输出下图:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/03f689e6af7aed9e4ea83a15c17ce1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vL6leqL7vMt6o391jAJHjQ.png"/></div></div></figure><p id="b573" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从这张图中可以看出，在过去的几年里，数学水平相对较高。其中一些也可以归因于2019年发生的数学考试的数字化。</p><p id="fef2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们从中获得的另一个洞见也与我们的刮擦过程有关。例如，我们可以看到我们缺少“kevt 2017”和“kevt 2019”的数据。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="75e7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这个项目的范围到此为止。如果你很好奇，你肯定可以浏览这些数据，并获得一些非常有趣的见解，但这超出了这个项目的预期范围。</p><p id="028e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我希望这个项目向您展示了用Scrapy和它提供的一些更酷的功能抓取数据的方法。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="2914" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你可以在medium上关注我，查看我的新帖子<br/>你也可以在其他社交媒体上查看我:<br/><a class="ae jn" href="https://twitter.com/kaarlsamu" rel="noopener ugc nofollow" target="_blank">Twitter</a><br/>T5】LinkedIn</p></div></div>    
</body>
</html>