<html>
<head>
<title>Classification with Wise-SrNet instead of Global Average Pooling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Wise-SrNet代替全局平均池进行分类</h1>
<blockquote>原文：<a href="https://medium.com/codex/classification-with-wise-srnet-instead-of-global-average-pooling-ccdd7c37058d?source=collection_archive---------15-----------------------#2021-07-29">https://medium.com/codex/classification-with-wise-srnet-instead-of-global-average-pooling-ccdd7c37058d?source=collection_archive---------15-----------------------#2021-07-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="92bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用深度神经网络的图像分类有两个步骤:</p><ol class=""><li id="3acb" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj"> <em class="jm">从输入图像中生成特征图。</em>T3】</strong></li><li id="351d" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><strong class="ih hj"> <em class="jm">根据生成的特征图进行分类。</em> </strong></li></ol><p id="39b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然特征提取是最重要的部分，并且具有更高语义值的特征图导致更准确的分类，但是通过最后几层神经网络进行分类存在一些困难。</p><p id="e21e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主要问题是图像的特征图将具有很大的尺寸，例如，<a class="ae js" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> ResNet </strong> </a>模型从一个<strong class="ih hj"> <em class="jm"> 224*224 </em> </strong>图像产生一个<strong class="ih hj"> <em class="jm"> 7*7*2048 </em> </strong>特征图。因此，将具有此形状的要素地图提供给完全连接的图层以生成最终分类数组将显著增加模型权重的数量，尤其是当数据集中有许多类时。ImageNet数据集包括1000个图像类别，因此对来自<strong class="ih hj"> <em class="jm"> 7*7*2048 </em> </strong>特征地图的分类部分使用全连接图层将增加<strong class="ih hj"> <em class="jm"> 7*7*2048*1000=100，352，000 </em> </strong>权重的模型权重数！现在，如果图像更大，权重会更大！！</p><blockquote class="jt ju jv"><p id="f3f0" class="if ig jm ih b ii ij ik il im in io ip jw ir is it jx iv iw ix jy iz ja jb jc hb bi translated">像<a class="ae js" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">【VGG】</strong></a>这样的第一阶段模型使用完全连接的层来获得分类数组，这增加了几乎<strong class="ih hj"> 1亿个参数</strong>的模型权重。这是荒谬的，因为模型的主要部分(<strong class="ih hj">特征提取层</strong>)只包含<strong class="ih hj"> 14M </strong>参数，但是分类阶段(包含几层)包含<strong class="ih hj"> 100M </strong>参数！这种情况使得最初版本的VGG分类器未被优化并且难以训练。</p></blockquote><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es jz"><img src="../Images/2afa0eb13094ab159785578d8cbcc5e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T4rrHuEN0FfF9oeHwD2dkw.png"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">VGG架构(蓝框显示用于分类的完全连接的层)</figcaption></figure><p id="6aaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在VGG、ResNet和大多数即将出现的深度卷积模型意识到它们应该在将最终特征图馈送到分类全连接层之前压缩它之后。于是，他们决定使用<a class="ae js" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="jm">【全球平均池(GAP) </em> </strong> </a>图层对特征地图进行压缩。GAP通过在每个通道的内核值之间求平均，将一个<strong class="ih hj"> 7*7*2048 </strong>特征映射转换为一个<strong class="ih hj"> 1*1*2048 </strong>数组。然而，这种方式减少了训练权重的数量，但是由于大的平均核，也导致了空间信息的丢失。时至今日，最新推出的分类器如<a class="ae js" href="https://arxiv.org/abs/2104.00298" rel="noopener ugc nofollow" target="_blank"> EfficientNetV2 </a>仍在使用这一层进行分类。</p><p id="5efe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在只有很少类的数据集中，许多研究人员仍然使用经典技术，即将整个要素地图馈送到最终的分类全连接图层，而不对其进行压缩。他们不喜欢使用间隙图层，因为在某些情况下丢失空间数据(如医疗数据集)会显著降低分类精度。</p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="f6bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae js" href="https://arxiv.org/abs/2104.12294" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/>-<strong class="ih hj">SrNet</strong></a><strong class="ih hj"/>是<strong class="ih hj"> </strong>新推出的处理分类过程的方法。蒂耶方法像压缩间隙图层一样压缩要素地图，同时不会丢失数据，因此您可以在保留原始数据的同时训练模型，而不会面临额外的计算成本。</p><p id="e8a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Wise-SrNet背后的主要原理是让神经网络学习如何<strong class="ih hj">明智地将特征图压缩成一个更小的数组，而不删除重要的数据。</strong>换句话说，模型将在训练时学习一些权重，以用于压缩特征图。这类似于特征提取部分，模型学习如何从包含有用信息的输入图像中提取简短的特征图。</p><p id="baf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了Wise-SrNet的架构。它的主要核心是一个<strong class="ih hj">深度方向卷积层</strong>，其核的大小等于特征图的核，没有激活函数。作者设想，由于深度方向卷积层的大核尺寸，该模型可能面临过拟合。为了解决这个问题，他们在深度方向的卷积层上应用了一个<strong class="ih hj"> <em class="jm">非负约束</em> </strong>来限制权重为负。他们还研究了在深度方向卷积层之前放置一个<strong class="ih hj">小平均池层</strong>，以减小深度方向卷积层的内核大小并防止过拟合。</p><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es kw"><img src="../Images/a1011f19d47716a65c59b2fb71971dc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qjFhtmHKCnagB3Yd5_Xj4Q.jpeg"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">Wise-SrNet架构应用于使用224x224图像的深度神经网络。</figcaption></figure><p id="2c5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了全局平均池和深度卷积层如何压缩要素地图。(所有的数字都摘自Wise-SrNet的论文)</p><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es kx"><img src="../Images/c3f29e93f32a87c97a379059422d930a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LEVeFgzwPnkJxMIHQmT4LQ.jpeg"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">深度方向卷积层，明智地压缩特征图(不丢失重要数据)</figcaption></figure><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es ky"><img src="../Images/9bc7c2a32e6591ef922f5ef2bc13b319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qT5vu6rBXDx5-E6xumE8ng.jpeg"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">全局平均池，压缩特征图进行分类</figcaption></figure><p id="aae1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一个脚本展示了应用于Xception模型的Wise-SrNet代码。输入图像尺寸被设置为224x224。</p><figure class="ka kb kc kd fd ke"><div class="bz dy l di"><div class="kz la l"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">Wise-SrNet代码应用于224x224图像的异常模型。</figcaption></figure><p id="84a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者表示，使用他们的方法将提高分类精度，如下所示:</p><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es lb"><img src="../Images/6158e4ba38d32230123efe07eef6eaaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcZ6N98AgMQjIRDyzPohYw.png"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">Wise-SrNet对包含70个类的ImageNet数据集的选定部分的影响。图像尺寸调整为<strong class="bd lc"> 224x224 </strong>，并且<strong class="bd lc">没有使用预训练的权重</strong>来开始训练过程。</figcaption></figure><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es ld"><img src="../Images/c4e79219154f3dd5ce8dc505952cade7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RK54Jy770vuS850WvSGhVA.png"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">Wise-SrNet对使用512x512图像和迁移学习的麻省理工学院室内场景数据集的选定部分的影响。</figcaption></figure><p id="ec88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Wise-SrNet的作者还提出了一个有趣的结果，即在大图像上使用间隙层可能对某些模型根本不起作用。在这些情况下，唯一的选择是不使用压缩并将整个特征地图馈送到分类全连接层(显著增加模型权重的经典方法)，但现在Wise-SrNet通过压缩特征地图同时保留空间信息来解决这个问题。基于他们获得的结果，Wise-SrNet有时可能是快速准确地训练分类模型的唯一解决方案。</p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="ea81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Wise-SrNet论文:</strong><a class="ae js" href="https://arxiv.org/abs/2104.12294" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2104.12294</a></p><div class="le lf ez fb lg lh"><a href="https://arxiv.org/abs/2104.12294" rel="noopener  ugc nofollow" target="_blank"><div class="li ab dw"><div class="lj ab lk cl cj ll"><h2 class="bd hj fi z dy lm ea eb ln ed ef hh bi translated">Wise-SrNet:一种通过学习空间分辨率增强图像分类的新架构…</h2><div class="lo l"><h3 class="bd b fi z dy lm ea eb ln ed ef dx translated">卷积神经网络发展以来面临的主要挑战之一是如何连接提取的神经网络</h3></div><div class="lp l"><p class="bd b fp z dy lm ea eb ln ed ef dx translated">arxiv.org</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv kj lh"/></div></div></a></div><p id="bc96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">代号:</strong>【https://github.com/mr7495/image-classification-spatial】T2</p><div class="le lf ez fb lg lh"><a href="https://github.com/mr7495/image-classification-spatial" rel="noopener  ugc nofollow" target="_blank"><div class="li ab dw"><div class="lj ab lk cl cj ll"><h2 class="bd hj fi z dy lm ea eb ln ed ef hh bi translated">GitHub-Mr 7495/image-class ification-spatial:一种用于增强图像的新型架构…</h2><div class="lo l"><h3 class="bd b fi z dy lm ea eb ln ed ef dx translated">源论文:arxiv:2104.12294本文旨在解决全局平均导致的空间分辨率损失问题…</h3></div><div class="lp l"><p class="bd b fp z dy lm ea eb ln ed ef dx translated">github.com</p></div></div><div class="lq l"><div class="lw l ls lt lu lq lv kj lh"/></div></div></a></div></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><h1 id="ca26" class="lx ly hi bd lc lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">参考</h1><p id="84f5" class="pw-post-body-paragraph if ig hi ih b ii mu ik il im mv io ip iq mw is it iu mx iw ix iy my ja jb jc hb bi translated">1-Rahimzadeh，m .，帕尔文，s .，Safi，e .和Mohammadi，M.R .，2021。Wise-SrNet:一种通过学习特征图的空间分辨率来增强图像分类的新体系结构。<em class="jm"> arXiv预印本arXiv:2104.12294 </em>。</p><p id="6cc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2-2013年，林，硕士，陈，秦，闫。网络中的网络。<em class="jm"> arXiv预印本arXiv:1312.4400 </em>。</p><p id="079e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3-Chollet，f，2017。例外:具有深度可分卷积的深度学习。在<em class="jm">IEEE计算机视觉和模式识别会议论文集</em>(第1251-1258页)。</p></div></div>    
</body>
</html>