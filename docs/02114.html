<html>
<head>
<title>COVID-19: Lung CT scan detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新冠肺炎:肺部CT扫描检测</h1>
<blockquote>原文：<a href="https://medium.com/codex/covid-19-lung-ct-scan-detection-c7998b49266b?source=collection_archive---------9-----------------------#2021-07-01">https://medium.com/codex/covid-19-lung-ct-scan-detection-c7998b49266b?source=collection_archive---------9-----------------------#2021-07-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">这是一篇关于我最近使用CNN在ct扫描图像中进行新冠肺炎检测项目的短文。结果是相当令人满意的，因为该模型设法达到超过98%的准确度。您将在下面找到关于如何收集数据、构建模型和部署模型的所有必要信息。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/e0e71708d3920260b00a62cf254af3b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*M9st6JGN2PNa7gij"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">照片由<a class="ae kc" href="https://unsplash.com/@fusion_medical_animation?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">融合医学动画</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="016e" class="kd ke hi bd kf kg kh ki kj kk kl km kn iq ko kp kq iu kr ks kt iy ku kv kw kx bi translated">摘要:</h2><p id="7e0b" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在与病毒的长期斗争中，通过肺部ct扫描和胸部x光图像对新冠肺炎的诊断证明了其有效性。放射科医生每天分析数百张计算机断层摄影图像，以检测可能代表潜在COVID感染的异常。这是一项要求非常高且耗时的任务，可能会导致医院的延误。因此，目前的工作是试图在新冠肺炎病例迅速增加期间减轻医务人员的压力。随着人工智能的使用，深度学习模型已被训练为医院和实验室提供肺部CT切片的即时分析。该方法包括将这些图像分为三类:正常、Covid和CAP(社区获得性肺炎)。建议的工作使用ResNet-50预训练基础模型进行预测。使用迁移学习技术进一步训练，它能够达到98%以上的准确率。</p><h2 id="a698" class="kd ke hi bd kf kg kh ki kj kk kl km kn iq ko kp kq iu kr ks kt iy ku kv kw kx bi translated">1.简介:</h2><p id="9a03" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">自2019年首次在中国出现以来，世界一直面临着一种叫做新冠肺炎的全球性威胁。迄今为止，该病毒已经在各个方面造成了巨大的破坏，并严重改变了我们的日常生活方式。虽然一些国家通过实施严格的法规和为民众提供疫苗，成功地部分克服了病毒的巨大影响，但其他国家一直在努力寻找出路和拯救人们的生命。</p><p id="2788" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">医务人员已经筋疲力尽，并且由于他们与病人直接接触而暴露在高感染风险下。<a class="ae kc" href="https://www.sciencedirect.com/science/article/pii/S2211568420302977#!" rel="noopener ugc nofollow" target="_blank">文婧</a>等人【1】推荐胸部计算机断层扫描作为检测新冠肺炎肺炎的一线影像学检查。想法是在CT扫描结果之后立即过滤潜在的COVID病例。放射科医生的角色仍将像以前一样重要，但这一次他们的工作将更加集中在预测为阳性和具有更高置信度(模型输出)的病例上。此外，该应用程序使用更少的计算资源，这将适用于缺乏这些强大资源的第三世界国家的医院。[2]我们能够创建一个在低规格机器上工作的深度学习模型，但他们牺牲了准确率来实现这样的结果。当结合这两个指标时，我们的目标是最大限度地提高精度，最小化处理能力。该模型已经在raspberry pi 3上部署，并在很短的时间内取得了很好的效果。这样的结果是有希望的，尤其是当我们考虑到这种设备的有限规格及其便宜的价格时。最后，通过为放射科医生提供一种可以快速准确地对CT扫描进行分类的工具，我们可以在早期阶段限制病毒的传播，并在爆发期间节省精力。</p><h2 id="1c6b" class="kd ke hi bd kf kg kh ki kj kk kl km kn iq ko kp kq iu kr ks kt iy ku kv kw kx bi translated">2.方法:</h2><p id="82a3" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated"><strong class="ih hj"> 2.1数据集:</strong></p><p id="23c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于训练模型的数据集由参考文献中列出的7个公共数据集的数据组成。这些数据集被用于之前与新冠肺炎诊断相关的项目中，并且已经证明了它们的效率。因此，通过将它们融合在一起，我们有望提高深度学习方法的泛化能力。该数据集总共包含来自466名患者的7，593幅新冠肺炎图像，来自604名患者的6，893幅正常图像，以及来自60名患者的2，618幅CAP图像。图1显示了从使用的数据库中收集的样本CT扫描图像。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/2faa88828897167ace7102b08f4373f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNt-5j6NZZdAT_Rb_D08bg.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated"><strong class="bd kf">图一</strong></figcaption></figure><p id="7ebe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在目前的研究中，有必要使CT扫描图像与我们预先训练的迁移学习模型输入兼容。在我们的例子中，图像以<strong class="ih hj"> 512*512*1 </strong>格式出现。然而，<strong class="ih hj"> ResNet-50 </strong>型号需要不同的尺寸。为了保持一致性，输入图像被调整为224*224的格式。然后，使用OpenCV库将灰度图像转换为RGB图像。此外，我们对像素值进行归一化，以加快计算速度，并确保特征在相同的值范围[0，1]内。这是根据以下等式完成的:</p><blockquote class="le"><p id="449e" class="lf lg hi bd lh li lj lk ll lm ln jc dx">𝐼_𝑛𝑜𝑟𝑚=(𝐼𝑛−𝑚𝑖𝑛(𝐼𝑛))/(𝑚𝑎𝑥(𝐼𝑛)−𝑚𝑖𝑛(𝐼𝑛))</p></blockquote><figure class="lp lq lr ls lt jr er es paragraph-image"><div class="er es lo"><img src="../Images/addea179bb99c110d47aea73d7214409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*R65h6eIVUnMRmHSQhbo42g.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated"><strong class="bd kf">图2 </strong></figcaption></figure><p id="337d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以注意到，每一类案例的数量比例是不同的。最后一类，CAP，只有2618个样本，是COVID病例数的一半。因此，这种不平衡会导致有偏差的分类结果。由于其增加的先验概率，这将导致多数组的过度分类。</p><p id="fe6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了避免类别敏感性，进行了数据扩充。我们将利用增强器库将第三类中的样本数量增加一倍。该库包含基本的图像预处理功能，如旋转、裁剪和缩放。我们添加了一个<code class="du lu lv lw lx b"><a class="ae kc" href="https://augmentor.readthedocs.io/en/master/code.html#Augmentor.Pipeline.Pipeline.rotate" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">rotate()</strong></a></code>操作，它将以80%的概率执行，并定义了图像旋转的最大范围，从-10度到10度。此外，以50%的概率执行了一次<code class="du lu lv lw lx b"><a class="ae kc" href="https://augmentor.readthedocs.io/en/master/code.html#Augmentor.Pipeline.Pipeline.zoom" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">zoom()</strong></a></code>操作。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ly"><img src="../Images/a350da728eaad576b165af28df19bc38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*Q6T4SvULBMzACFKjzW0y1Q.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated"><strong class="bd kf">图三</strong></figcaption></figure><p id="69d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在执行数据扩充之前，我们将数据分为训练集(80%)和测试集(20%)。我们保留了20%的训练集来创建验证集，以便调整模型的参数并避免过度拟合。只有在为模型部署的主要阶段准备好不同的集合之后，才执行数据预处理是至关重要的。</p><p id="559a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.2迁移学习</strong></p><p id="96ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴于在大型数据集上从头训练一个深度学习模型需要巨大的计算资源，我使用了深度学习领域一种著名的技术，称为迁移学习。它包括使用基础数据集上的预训练模型作为第二个感兴趣的任务上的模型的起点。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es lz"><img src="../Images/324e0c7d8c6550e25d7c7d249d1039c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2K6_glso4RNRZHO02Tk43g.jpeg"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated"><strong class="bd kf">图4来源:</strong> <a class="ae kc" href="https://builtin.com/sites/default/files/styles/ckeditor_optimize/public/inline-images/classifiers-transfer-learning.jpeg" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kf">内置</strong> </a></figcaption></figure><p id="aaf0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ResNet50是一组微软研究人员在2015年提出的最受欢迎的基于预训练迁移学习的CNN模型之一。其架构由5个阶段组成，每个阶段都有一个卷积和标识模块。每个卷积块有3个卷积<strong class="ih hj">层</strong>，每个标识块也有3个卷积<strong class="ih hj">层</strong>。<strong class="ih hj"> ResNet </strong> - <strong class="ih hj"> 50 </strong>拥有超过2300万个可训练参数。[3].</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ma"><img src="../Images/7c833fc0a896128ac3938a10f6128dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PwXnnjns8AoHQeDECTVe9A.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated"><strong class="bd kf">图5</strong><strong class="bd kf">【4】</strong></figcaption></figure><p id="58fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网络可以按照格式<strong class="ih hj">高度</strong> * <strong class="ih hj">宽度</strong> * <strong class="ih hj"> 3取一个输入。</strong>其中高度和宽度值必须是<strong class="ih hj"> 224*224 </strong>并且<strong class="ih hj"> 3 </strong>是指RGB图像中的通道数。此外，我们使用了辍学技术，以避免过度拟合和批量标准化，以稳定和加快学习过程。</p><pre class="jn jo jp jq fd mb lx mc md aw me bi"><span id="b08c" class="kd ke hi lx b fi mf mg l mh mi">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>lambda (Lambda)              (None, 224, 224, 3)       0         <br/>_________________________________________________________________<br/>resnet50 (Functional)        (None, 7, 7, 2048)        23587712  <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 100352)            0         <br/>_________________________________________________________________<br/>batch_normalization (BatchNo (None, 100352)            401408    <br/>_________________________________________________________________<br/>dense (Dense)                (None, 256)               25690368  <br/>_________________________________________________________________<br/>dropout (Dropout)            (None, 256)               0         <br/>_________________________________________________________________<br/>batch_normalization_1 (Batch (None, 256)               1024      <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 128)               32896     <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 128)               0         <br/>_________________________________________________________________<br/>batch_normalization_2 (Batch (None, 128)               512       <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 64)                8256      <br/>_________________________________________________________________<br/>dropout_2 (Dropout)          (None, 64)                0         <br/>_________________________________________________________________<br/>batch_normalization_3 (Batch (None, 64)                256       <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 3)                 195       <br/>=================================================================<br/>Total params: 49,722,627<br/>Trainable params: 40,909,315<br/>Non-trainable params: 8,813,312<br/>_________________________________________________________________</span></pre><p id="910d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.3结果</strong></p><p id="c7e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果总的来说令人满意。在使用的CT扫描数据集上，使用ResNet15模型获得的最佳分类准确度得分为98.94%的训练准确度和98.17%的验证准确度。当应用数据扩充技术时，性能显著提高。此外，数据扩充允许我们克服由有限数量的CT扫描切片引起的过拟合问题。然而，可以通过尝试改变网络的架构并相应地实施新技术来进一步更新模型的鲁棒性。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mj mk l"/></div></figure><h2 id="c093" class="kd ke hi bd kf kg kh ki kj kk kl km kn iq ko kp kq iu kr ks kt iy ku kv kw kx bi translated"><strong class="ak"> 3。结论:</strong></h2><p id="7071" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">本项目提出深度学习解决方案，将肺部ct扫描切片分为3类。最初，对使用的数据集执行数据预处理。这涉及到调整大小和旋转等技术。然后，我们导入迁移学习基础模型ResNet50，并在收集的切片上训练它。结果是非常有希望的，特别是当我们考虑到每个类的样本数量有限时。因此，这项工作很可能在未来得到进一步的改进。</p><h2 id="28a1" class="kd ke hi bd kf kg kh ki kj kk kl km kn iq ko kp kq iu kr ks kt iy ku kv kw kx bi translated">参考资料:</h2><ol class=""><li id="69c0" class="ml mm hi ih b ii ky im kz iq mn iu mo iy mp jc mq mr ms mt bi translated">、龙、、、方芳、、吕、、、等。放射学不可或缺的跟踪新冠肺炎，2021；。</li></ol><p id="5a55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.朱敏，陈B，卡列尼琴科D，王W，韦延德，等。移动神经网络:用于移动视觉应用的高效卷积神经网络。arXiv预印本arXiv:170404861。2017;。</p><p id="0319" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.ResNet50架构的Mathworks文档。</p><p id="5bb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.巴尔特鲁沙特，伊沃&amp;尼基施，汉尼斯&amp;格拉斯，迈克尔&amp;克诺普，托比亚斯&amp;萨尔巴赫，阿克塞尔。(2019).多标签胸片分类的深度学习方法比较。科学报告。10.1038/s 41598–019–42294–8。</p></div></div>    
</body>
</html>