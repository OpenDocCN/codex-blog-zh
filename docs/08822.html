<html>
<head>
<title>Vol 2A: Siamese Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2A卷:连体神经网络</h1>
<blockquote>原文：<a href="https://medium.com/codex/vol-2a-siamese-neural-networks-6df66d33180e?source=collection_archive---------4-----------------------#2022-09-05">https://medium.com/codex/vol-2a-siamese-neural-networks-6df66d33180e?source=collection_archive---------4-----------------------#2022-09-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/fbe96363d9288bd2fe28c38f3142b061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A7SsbqVCuTnSLmz0.jpg"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">暹罗神经网络(来源:GreatLearning)</figcaption></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h2 id="3615" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">TL；博士:</h2><p id="5270" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku hb bi translated">暹罗神经网络(SNN)是一种相似性分类器，它使用区别性特征来概括给定分布中的未知类别。SNN可以用作<em class="kv">特征提取器</em>，并且可以在其后安装其他ML机制，以便产生概率和/或类别标签。该网络的架构受到连体双胞胎的启发，拥有多个相同的卷积神经子网络(CNN ),具有相同的权重&amp;偏差。在训练期间，CNN产生由距离层处理的<em class="kv">嵌入</em>。然后使用<em class="kv">距离嵌入</em>计算损失，并通过<em class="kv">随机梯度下降</em>和<em class="kv">反向传播</em>进行更新。在推理过程中，CNN产生可被支持向量机(SVM)使用的<em class="kv">嵌入</em>。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="2519" class="pw-post-body-paragraph ka kb hi kc b kd kw kf kg kh kx kj kk jn ky km kn jr kz kp kq jv la ks kt ku hb bi translated">本文是由两部分组成的系列文章的第一部分，重点是为读者提供如何将SNN用作<em class="kv">特征提取器的高级概述。</em>本系列的第二篇文章将为读者提供一个python教程，解释如何使用在<em class="kv"> Omniglot </em>数据集上训练过的预训练SNN对来自<em class="kv"> MNIST </em>数据集的图像样本进行精确分类。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="2afd" class="lb jd hi bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">什么是连体神经网络？</h1><p id="44d4" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku hb bi translated">SNN是一种相似性分类器，它使用区别性特征来归纳给定分布中的未知类别。它的架构受连体双胞胎的启发，拥有多个相同的卷积神经子网络(CNN ),具有相同的权重和偏差。子网络在不同的输入图像上协同工作，以产生可比较的输出向量，称为<em class="kv">嵌入</em>。使用为每个相应图像计算的<em class="kv">嵌入</em>来计算损失值。最后，损失值用于同时更新CNN子网络权重&amp;偏差，使得子网络保持相同。与大多数传统的深度学习模型一样，该模型通过<em class="kv">随机梯度下降</em>和<em class="kv">反向传播</em>进行优化。</p><h2 id="3747" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">SNN专业</h2><ul class=""><li id="1746" class="ls lt hi kc b kd ke kh ki jn lu jr lv jv lw ku lx ly lz ma bi translated">SNNs学习相似性函数，并可用于区分两个图像是否属于同一类。因此，这种类型的神经网络可以用于<em class="kv">图像分类</em>任务</li><li id="e146" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">传统的神经网络学习预测类；当需要添加/删除类时，这是一个问题。一旦训练好SNN，它就可以用来将数据分类到模型从未“见过”的类别</li><li id="582c" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">SNNs可用于<em class="kv"> K-Shot分类- </em>一般来说，k-shot <em class="kv">图像分类</em>旨在每类仅用k-image(s)训练分类器。此外，与传统的<em class="kv">深度学习</em>技术相比，snn对类别不平衡更加鲁棒</li></ul><h2 id="e717" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">SNN骗局</h2><ul class=""><li id="9075" class="ls lt hi kc b kd ke kh ki jn lu jr lv jv lw ku lx ly lz ma bi translated">SNN的最终输出是相似性值，而不是概率。如果需要一个概率，SNN可以作为一个<em class="kv">特征提取器</em>来实现，其他的ML机制可以安装到神经网络上</li><li id="a7e6" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">神经网络的架构更加复杂。根据所使用的损失函数，可能需要创建一个定制的训练循环(假设没有可以利用的代码库)来计算损失并<em class="kv">反向传播。</em>如果SNN被视为<em class="kv">特征提取器</em>，则需要添加额外的最大似然机制，例如，完全/密集连接层、硬/软支持向量机等。</li><li id="5e89" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">与传统的神经网络结构相比，需要更多的训练时间，因为SNN学习机制需要大量的训练样本组合来产生精确的模型</li></ul><h2 id="a3ff" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">社交网络的现实应用</h2><p id="530d" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku hb bi translated">示例包括但不限于:</p><ul class=""><li id="2c50" class="ls lt hi kc b kd kw kh kx jn mg jr mh jv mi ku lx ly lz ma bi translated">面部识别</li><li id="4ed1" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">签名验证</li><li id="c790" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">钞票欺诈检测</li><li id="069e" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">音频分类</li></ul><p id="4938" class="pw-post-body-paragraph ka kb hi kc b kd kw kf kg kh kx kj kk jn ky km kn jr kz kp kq jv la ks kt ku hb bi translated">让我们以钞票欺诈检测为例。现在一种货币有许多不同的面值。同样，对于一种给定的货币，也有许多伪钞面额。训练传统的<em class="kv">图像分类</em>神经网络将需要大量的真钞和伪钞面额，以便产生准确的钞票欺诈检测。事实上，传统的神经网络需要看到每种货币的每一张真钞面额以及大量相关的假钞。相比之下，SNN可用于此任务，需要的数据较少。以下是自动SNN用于钞票欺诈检测的一种方法:</p><ol class=""><li id="517f" class="ls lt hi kc b kd kw kh kx jn mg jr mh jv mi ku mj ly lz ma bi translated">从每种货币中取出一些面值的钞票——不需要全部都是</li><li id="e224" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku mj ly lz ma bi translated">训练* SNN对每种货币的所选钞票面额及其相关伪钞的组合</li><li id="b8c4" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku mj ly lz ma bi translated">取每种货币剩余的纸币面额，并推动它们通过SNN，得到<em class="kv">嵌入物</em></li><li id="e280" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku mj ly lz ma bi translated">找到并记录每种货币的每种面额聚类的质心(定义给定聚类的所有<em class="kv">嵌入</em>的平均值的向量)。可以使用多个软支持向量机来产生类别标签</li><li id="0cf1" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku mj ly lz ma bi translated">将钞票面额的图像推过经过训练的SNN，并评估返回到每个质心的<em class="kv">嵌入</em>的距离</li><li id="ea2a" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku mj ly lz ma bi translated">如果钞票是真的，则其相关联的真实面额质心之间的距离应该很小。货币的其他真实面额质心之间也应该有很大的距离</li><li id="7e29" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku mj ly lz ma bi translated">如果钞票是假的，那么在它相关的真实面额质心之间应该有很大的距离。货币的其他真实面额质心之间也应该有很大的距离</li></ol><h1 id="aeaa" class="lb jd hi bd je lc mk le ji lf ml lh jm li mm lk jq ll mn ln ju lo mo lq jy lr bi translated">SNN建筑看起来像什么？</h1><p id="497c" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku hb bi translated">如前所述，SNN可以用作<em class="kv">特征提取器</em>，并且可以在其后安装其他ML机制，以便产生概率和/或类别标签。在本文中，SNN将被解释为一个<em class="kv">特征提取器</em>，并且一个单独的硬SVM将被添加以产生一个分类标签。本文中描述的SNN <em class="kv">特征提取器</em>展示了一个三元组网络——也就是说它有三个相同的CNN子网络。</p><p id="148a" class="pw-post-body-paragraph ka kb hi kc b kd kw kf kg kh kx kj kk jn ky km kn jr kz kp kq jv la ks kt ku hb bi translated">值得注意的是，SNN实际上并没有将多个CNN子网络加载到GPU内存中。相反，根据所采用的损失函数的类型，图像的成对/三对/四对都被通过。然后使用输出的<em class="kv">距离嵌入</em>计算损失，并且通过<em class="kv">反向传播更新子网络的权重&amp;偏差。重复这一过程，直到收敛。</em></p><h2 id="84d2" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">SNN作为特征提取器；</h2><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mp"><img src="../Images/394931f396288c1cf38c2115a72309bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mRmGuKgQ5QVHNRzUAaCZjA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">图1: SNN特征提取器(来源:王书申，YouTube——但由作者编辑)</figcaption></figure><h2 id="9764" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">卷积神经网络(CNN)</h2><ul class=""><li id="64bc" class="ls lt hi kc b kd ke kh ki jn lu jr lv jv lw ku lx ly lz ma bi translated">生成<em class="kv">嵌入</em>,这些嵌入实际上只是拼合的1D要素地图</li><li id="b57c" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">在<em class="kv">训练</em>模式中，<em class="kv">嵌入</em>被传递到距离层</li><li id="5cba" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">在<em class="kv">推理</em>模式中，<em class="kv">嵌入</em>被传递到SVM上</li><li id="6970" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">对于给定的应用，可以从预先建立的“主干工厂”中选择CNN(通常称为嵌入模型、编码器或主干)，因此，可以利用<em class="kv">迁移学习</em>，例如，在<em class="kv"> ImageNet </em>数据集上训练的VGG16/Resnet50/InceptionV3</li></ul><h2 id="28e8" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">距离层</h2><ul class=""><li id="459e" class="ls lt hi kc b kd ke kh ki jn lu jr lv jv lw ku lx ly lz ma bi translated">它计算<em class="kv">嵌入</em>之间的距离。对于三元组网络(由三元组损耗定义)<em class="kv">距离嵌入</em>是:<br/> -正<em class="kv">距离嵌入</em>(锚&amp;正<em class="kv">嵌入</em> ) <br/> -负<em class="kv">距离嵌入</em>(锚&amp;负<em class="kv">嵌入</em>)</li><li id="d5e6" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">使用欧几里得的平方(也称为L2范数)来计算距离</li></ul><h2 id="4731" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">损失函数</h2><ul class=""><li id="e83d" class="ls lt hi kc b kd ke kh ki jn lu jr lv jv lw ku lx ly lz ma bi translated">使用从<em class="kv">嵌入</em>计算的距离计算损耗</li><li id="ed8f" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">为了防止平凡解，使用了一个称为余量的超参数，以确保负距离嵌入<em class="kv">比正距离嵌入</em>大得多<em class="kv"/></li><li id="d00b" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">有几个可用的损失函数:<br/> -对比损失(双网络架构)<br/> -三重损失(三重网络架构)<br/> -四重损失(四重网络架构)</li></ul><p id="3697" class="pw-post-body-paragraph ka kb hi kc b kd kw kf kg kh kx kj kk jn ky km kn jr kz kp kq jv la ks kt ku hb bi translated">*作者怀疑四联丢失对于上面概述的钞票欺诈检测任务是理想的。与三重损失相比，四重损失会导致模型输出产生较大的类间变化和较小的类内变化。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mq"><img src="../Images/d3ea74f6804f9abe2c58f5d9606c5b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2TvU7JZ9ZlzEbQ013AnYaw.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">图2:距离层和损失函数逻辑(来源:王书申，YouTube——但由作者编辑)</figcaption></figure><h2 id="a444" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">作为量词的SVM</h2><p id="0c79" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku hb bi translated">线性SVM是一种监督学习技术，它能够通过线性超平面(如果数据是2D，则为直线)来分离数据，从而对数据进行分类。如果数据不是线性可分的，则数据点可以被映射到更高维的特征空间，直到SVM能够分离类别。SVM试图优化超平面的姿态(位置和方向),以确保不同类别的数据点之间的最大余量。对于每个类别，位于最大边缘(定义为不同类别的数据点之间的垂直距离)的数据点被称为支持向量。SVM的一些关键特征包括但不限于:</p><ul class=""><li id="5d87" class="ls lt hi kc b kd kw kh kx jn mg jr mh jv mi ku lx ly lz ma bi translated">适合于训练数据(可以使用验证子集来代替训练子集，以便增加另一个正则化级别)<em class="kv">嵌入</em>，其从CNN产生(距离层和三元组损失函数在训练之后是不必要的，因此被移除)</li><li id="c7d7" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">可以实现不同的内核，例如线性、高斯、Sigmoid、多项式等。，以便分离具有不同概率分布的数据点</li><li id="b99b" class="ls lt hi kc b kd mb kh mc jn md jr me jv mf ku lx ly lz ma bi translated">生成类别标签</li></ul><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mr"><img src="../Images/4a8ea8e821f20fb5864780d906faa03f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*93BxR2gIStbRrUMG_DXQSg.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">图3:可视化的SVM分类(来源:KDnuggets)</figcaption></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="896e" class="pw-post-body-paragraph ka kb hi kc b kd kw kf kg kh kx kj kk jn ky km kn jr kz kp kq jv la ks kt ku hb bi translated"><strong class="kc hj">感谢阅读。请考虑订阅和/或资助我</strong><a class="ae ms" href="https://gofund.me/c397684d" rel="noopener ugc nofollow" target="_blank">https://gofund.me/c397684d</a></p></div></div>    
</body>
</html>