<html>
<head>
<title>Using the Web Audio API: Where Programming meets Sound Engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用网络音频API:编程遇到声音工程</h1>
<blockquote>原文：<a href="https://medium.com/codex/using-the-web-audio-api-where-programming-meets-sound-engineering-b3a1e0e64a44?source=collection_archive---------18-----------------------#2021-07-29">https://medium.com/codex/using-the-web-audio-api-where-programming-meets-sound-engineering-b3a1e0e64a44?source=collection_archive---------18-----------------------#2021-07-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/a583c6bf608face7e5bcbf023b8dd045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AEbQcQ9fDMxFty01r-4sxQ.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">安迪·马克里在<a class="ae hv" href="https://unsplash.com/s/photos/audio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><div class=""/><p id="906d" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我发现自己对编程的热爱之前，我去学校学过音乐录制，学到了很多音频处理的知识。当我第一次开始学习编码时，我真的想在一个项目中结合我的两个兴趣。我最近一直在用React构建一个鼓音序器，并对Web音频API有所了解。在为这个项目做研究的时候，我发现在这个项目中有很多地方，我很高兴有音频方面的背景。</p><h1 id="243b" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">入门指南</h1><p id="5b12" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">要开始使用Web音频API，您需要初始化一个<code class="du kw kx ky kz b">AudioContext</code>。<code class="du kw kx ky kz b">AudioContext</code>是一个对象，它将包含使用Web音频API所需的一切。这将为我们提供解码、处理和播放声音所需的所有特性和功能。要设置一个<code class="du kw kx ky kz b">AudioContext</code>，使用下面的代码。第一行是允许更广泛的浏览器支持。</p><figure class="la lb lc ld fd hk"><div class="bz dy l di"><div class="le lf l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">设置音频上下文</figcaption></figure><h1 id="4163" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">加载预先录制的声音</h1><p id="edbe" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">在web浏览器中播放预先录制的声音有两种主要方式。最简单的方法是使用<code class="du kw kx ky kz b">&lt;audio&gt;</code>标签。如果您只需要对正在回放的音频进行基本控制，这种方法最有效。如果你想在音频播放前对其进行处理，或者播放的精确度对你的应用很重要，那么<code class="du kw kx ky kz b">&lt;audio&gt;</code>标签不是你想要的路线。</p><p id="9dc2" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当从<code class="du kw kx ky kz b">&lt;audio&gt;</code>标签播放音频文件时，浏览器必须向音频文件的来源发送请求，检索和解码数据并缓冲音频，然后才能播放音频文件。虽然你的浏览器可以很快做到这一点，但如果用户想在点击按钮时听到声音，那么在点击和播放之间可能会有明显的延迟。</p><p id="10be" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">播放预先录制的声音的另一个选项是预先缓冲音频，并将缓冲的音频存储在一个变量中，以便在需要时播放。为此，您需要使用<code class="du kw kx ky kz b">fetch()</code>或<code class="du kw kx ky kz b">XMLHttpRequest()</code>提前检索数据。(我更喜欢使用<code class="du kw kx ky kz b">fetch()</code>，所以我将详细介绍这个过程，但是<code class="du kw kx ky kz b">XMLHttpRequest()</code>过程是相似的，如果你愿意，我将在下面提供一个例子。)对来自<code class="du kw kx ky kz b">fetch()</code>的响应，调用<code class="du kw kx ky kz b">arrayBuffer()</code>将响应放入arrayBuffer中。在arrayBuffer上，可以使用<code class="du kw kx ky kz b">audioContext</code>提供的<code class="du kw kx ky kz b">decodeAudioData()</code>对数据进行解码。然后，您可以将这些数据保存到一个变量中供以后使用。使用<code class="du kw kx ky kz b">fetch()</code>或<code class="du kw kx ky kz b">XMLHttpRequest()</code>的示例见下文:</p><figure class="la lb lc ld fd hk"><div class="bz dy l di"><div class="le lf l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">将音频文件加载到音频缓冲区</figcaption></figure><h1 id="cdf8" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">播放声音</h1><p id="f25b" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">现在我们已经缓冲了我们的音频，我们可能想要播放它，这样用户就可以听到音频。为此，我们需要创建一个缓冲源，并将其连接到用户的扬声器。我们可以使用<code class="du kw kx ky kz b">audioContext</code>提供的<code class="du kw kx ky kz b">createBufferSource()</code>函数来创建缓冲源。这创建了一个<code class="du kw kx ky kz b">audioNode</code>，我们可以使用不同的音频效果来操纵它，或者我们可以连接到用户的扬声器来播放声音。现在，我们将使用<code class="du kw kx ky kz b">connect()</code>功能将<code class="du kw kx ky kz b">audioNode</code>连接到用户的扬声器，而不进行任何音频操作。请参见下面的示例:</p><figure class="la lb lc ld fd hk"><div class="bz dy l di"><div class="le lf l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">播放音频缓冲区中的声音</figcaption></figure><h1 id="e96e" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">建立联系</h1><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/acd10ea164d5dd5d6103a25f9d698d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gDT6QXLjaP7v981TdIyvUQ.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">米歇尔·迪迪埃·朱蒙在<a class="ae hv" href="https://unsplash.com/s/photos/audio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="97c0" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在声音工程中，有一个概念叫做信号流。这是一种想法，即声音信号从其来源(乐器、麦克风、合成器等)开始，经过多个音频处理器(麦克风前置放大器、均衡、混响等)，最终到达扬声器。源必须连接到音频处理器的输入端，然后音频处理器的输出被路由到下一个处理器或扬声器。网络音频API以类似的方式工作。音频源(音频缓冲器、振荡器或流式音频)连接到各种音频处理器(增益、声相、滤波器、混响)，并从这些音频处理器连接到用户扬声器(<code class="du kw kx ky kz b">audioContext.destination</code>)。</p><p id="287c" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在现实世界中，这些连接是通过电缆实现的。在Web Audio API中，我们使用了<code class="du kw kx ky kz b">connect()</code>函数。多个<code class="du kw kx ky kz b">connect()</code>功能可以链接在一起，在声音传送到扬声器之前，将多种效果应用到声音中。文档将这种路由称为音频路由图。</p><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/75640ecf5e2eb70da5d20df7ab2f6bec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVyR2QwOfkBILdJ67TLfLA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">音频路由图表(来自MDN文档)</figcaption></figure><blockquote class="li lj lk"><p id="71b2" class="iv iw ll ix b iy iz ja jb jc jd je jf lm jh ji jj ln jl jm jn lo jp jq jr js hb bi translated">在现实世界和网络音频API中路由信号的一个很好的故障排除技巧是:如果声音没有按预期播放，请跟随信号流。从信号源开始，直接连接到扬声器。逐一重新连接音频处理器，直到问题重现。然后你就会发现是什么因素导致了这个问题，并能够集中精力解决问题的根源。</p></blockquote><h1 id="6858" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">声音处理</h1><p id="1184" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">恭喜你。您现在可以在网络浏览器中播放声音。现在让我们在用户听到这些声音之前操纵它们。您想要使用的最常见的声音处理是增益。增益是音量的音频术语。为了给你的声音增加音量控制，你需要创建一个增益节点并将你的<code class="du kw kx ky kz b">audioBuffer</code>连接到它，然后将<code class="du kw kx ky kz b">gainNode</code>连接到<code class="du kw kx ky kz b">audioContext.destination</code>。</p><h2 id="be73" class="lp ju hy bd jv lq lr ls jz lt lu lv kd jg lw lx kh jk ly lz kl jo ma mb kp mc bi translated">开大声点</h2><p id="dcca" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">要添加增益节点，使用<code class="du kw kx ky kz b">audioContext</code>提供的<code class="du kw kx ky kz b">createGain()</code>函数，并将其保存到变量中。然后使用<code class="du kw kx ky kz b">gain.value</code>设置增益节点的值，并给它一个值。值为1不会改变声音。任何低于1的值都会降低音量，0表示没有声音。上限在3到4之间，但我不建议超过1.5太多，以避免削波和失真(除非声源的音量特别低)。我们更新后的<code class="du kw kx ky kz b">playSample()</code>功能如下:</p><figure class="la lb lc ld fd hk"><div class="bz dy l di"><div class="le lf l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">向playSample()函数添加GainNode</figcaption></figure><h2 id="6cbe" class="lp ju hy bd jv lq lr ls jz lt lu lv kd jg lw lx kh jk ly lz kl jo ma mb kp mc bi translated">声音空间化</h2><p id="f05c" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">在web浏览器中操纵声音的另一种方法是通过声音空间化。声音空间化为您的声音提供了一个位置。一个简单的实现方法是将声音放在左边或右边。根据您放置声音的位置，一个扬声器播放的声音会比另一个多。听众会感觉到声音在空间中有特定的位置。</p><p id="ae2f" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Web Audio API有两种处理声音空间化的方式:<code class="du kw kx ky kz b">PannerNode</code>和<code class="du kw kx ky kz b">StereoPannerNode</code>。平移是声音空间化的音频术语。对于大多数需要定位声音的情况来说，<code class="du kw kx ky kz b">StereoPannerNode</code>已经足够好了。它仅限于立体声定位(双扬声器设置)。<code class="du kw kx ky kz b">PannerNode</code>允许更复杂的空间化，例如在更大的扬声器设置(quad，5.1)中定位，定位随时间移动的声音，相对于声音移动听众，添加多普勒效应(想象消防车开着警报器经过你身边的声音)，等等。</p><p id="004c" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于这篇文章是针对网络音频API的新手，我将只解释更基本的<code class="du kw kx ky kz b">StereoPannerNode</code>。<code class="du kw kx ky kz b">StereoPannerNode</code>的设置与<code class="du kw kx ky kz b">GainNode</code>的设置非常相似。<code class="du kw kx ky kz b">AudioContext</code>给出了另一个创建立体声声相器的函数<code class="du kw kx ky kz b">createStereoPanner()</code>。将其保存到一个变量，然后通过给<code class="du kw kx ky kz b">pan.value</code>您想要的值来设置平移值。该值可以介于-1和1之间，其中-1表示向左倾斜，1表示向右倾斜，0表示居中定位。一旦<code class="du kw kx ky kz b">StereoPannerNode</code>被创建并赋予一个值，您就可以使用<code class="du kw kx ky kz b">connect()</code>功能将其连接到您的声源。我在前面的<code class="du kw kx ky kz b">playSample()</code>函数中添加了平移功能:</p><figure class="la lb lc ld fd hk"><div class="bz dy l di"><div class="le lf l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">向playSample()函数添加StereoPannerNode</figcaption></figure><h2 id="86ae" class="lp ju hy bd jv lq lr ls jz lt lu lv kd jg lw lx kh jk ly lz kl jo ma mb kp mc bi translated">更多音频探索</h2><p id="9e6f" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">Web Audio API还有许多其他功能，但是要深入了解所有功能，需要的不仅仅是一本书，而是一个博客。一旦掌握了本文中的概念，就可以探索其他一些特性。您可以添加混响，过滤器，延迟，失真或压缩到您的音频源。您也可以尝试使用麦克风和MediaStreamAudioSourceNode生成自己的声音，或者使用振荡器合成自己的声音。也有许多方法来可视化包含在Web Audio API中的音频。</p><p id="a4e3" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这应该足以让你开始添加声音到你的网络应用程序。网络音频API非常强大，提供了许多通常只有专业音频软件才有的功能。事实上，这一切在大多数浏览器中都是现成的，这很棒，我期待着探索它的更多功能。编码快乐！</p></div></div>    
</body>
</html>