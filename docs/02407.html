<html>
<head>
<title>K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k均值聚类</h1>
<blockquote>原文：<a href="https://medium.com/codex/k-means-clustering-7b08ed4b303e?source=collection_archive---------5-----------------------#2021-07-19">https://medium.com/codex/k-means-clustering-7b08ed4b303e?source=collection_archive---------5-----------------------#2021-07-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f2833c2b4bdc36c7557708856e7a8b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oUPpkrCyXQklkAjO"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Billy Huynh 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="4bba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以应用k均值聚类将数据点划分为k个不同的组。与数据一起，聚类数“k”是算法的输入。</p><h2 id="0521" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">什么是K-Means算法？</h2><p id="15e9" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">K-Means聚类是一种无监督学习算法，它将未标记的数据集分组到不同的簇中。这里K定义了在该过程中需要创建的预定义聚类的数量。它是一种迭代算法，将未标记的数据集划分为k个不同的聚类，使得每个数据集只属于一个具有相似属性的组。</p><h2 id="cbe8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">什么是无监督学习？</h2><p id="9200" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">顾名思义，无监督学习是一种机器学习技术，其中模型不使用训练数据集进行监督。相反，模型本身从给定的数据中发现隐藏的模式和见解。可以把它比作在学习新事物时发生在人脑中的学习。它可以定义为:</p><p id="9553" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">无监督学习是一种机器学习，其中模型使用未标记的数据集进行训练，并允许在没有任何监督的情况下对该数据进行操作。</p><p id="ae0c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">非监督学习不能直接应用于回归或分类问题，因为与监督学习不同，我们有输入数据，但没有相应的输出数据。</p><p id="835e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">无监督学习的目标是找到数据集的底层结构，根据相似性对数据进行分组，并以压缩格式表示数据集。</p><ul class=""><li id="0e9e" class="kt ku hi ix b iy iz jc jd jg kv jk kw jo kx js ky kz la lb bi translated">示例:假设给定无监督学习算法一个包含不同类型的猫和狗的图像的输入数据集。该算法从未在给定的数据集上训练过，这意味着它对数据集的特征没有任何概念。无监督学习算法的任务是自己识别图像特征。无监督学习算法将通过根据图像之间的相似性将图像数据集聚类成组来执行这项任务。</li></ul><p id="2dea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">无监督学习算法可以进一步分为两类问题:</p><p id="bfa9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">聚类</strong>:聚类是一种将对象分组为簇的方法，使得具有最多相似性的对象保留在一个组中，而与另一个组的对象具有较少或没有相似性。聚类分析发现数据对象之间的共性，并根据这些共性的存在与否对它们进行分类。</p><p id="3773" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">关联</strong>:关联规则是一种无监督的学习方法，用于发现大型数据库中变量之间的关系。它确定在数据集中一起出现的项目集。关联规则使营销策略更加有效。比如购买X物品(假设一个面包)的人也倾向于购买Y(黄油/果酱)物品。关联规则的一个典型例子是购物篮分析。</p><p id="df1d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">下面是一些流行的无监督学习的列表</strong></p><ul class=""><li id="6fbc" class="kt ku hi ix b iy iz jc jd jg kv jk kw jo kx js ky kz la lb bi translated">k均值聚类</li><li id="af98" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">KNN(k-最近邻)</li><li id="e9d7" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">分层聚类</li><li id="914e" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">异常检测</li><li id="97b5" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">神经网络</li><li id="8b51" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">主成分分析</li><li id="71c6" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">独立成分分析</li><li id="63ee" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">Apriori算法</li><li id="a874" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">奇异值分解</li></ul><h2 id="1d5d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">k均值聚类</h2><p id="d8d6" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">“k-means”这个术语是由James MacQueen在1967年首次使用的，作为他的论文“多元观测值的一些分类和分析方法”的一部分。1957年，贝尔实验室也将该标准算法作为脉冲编码调制技术的一部分。E. W. Forgy也于1965年发表了该方法，通常也被称为劳埃德-Forgy法。</p><p id="b9da" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">k-means允许我们将数据聚类到不同的组中，这是一种无需任何训练就可以自行发现未标记数据集中的组类别的便捷方法。</p><p id="c12c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是一种基于质心的算法，其中每个聚类都与一个质心相关联。该算法的主要目标是最小化数据点和它们对应的聚类之间的距离之和。</p><p id="3fb9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该算法将未标记的数据集作为输入，将数据集划分为k个聚类，并重复该过程，直到没有找到最佳聚类。在这个算法中，k的值应该是预先确定的。</p><p id="64db" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">k-means聚类算法主要执行两项任务:</p><ul class=""><li id="b9fe" class="kt ku hi ix b iy iz jc jd jg kv jk kw jo kx js ky kz la lb bi translated">通过迭代过程确定K个中心点或质心的最佳值。</li><li id="d0e7" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">将每个数据点分配到其最近的k中心。靠近特定k中心的那些数据点创建一个聚类。</li></ul><p id="8057" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，每个聚类都有一些具有共性的数据点，并且远离其他聚类。</p><p id="2071" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下图解释了K均值聚类算法的工作原理:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/6c8e502a77553f2be083617b5525ee3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/0*1FMgK7rm3Z8zD0Lj.png"/></div></figure><h2 id="ce65" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">K-Means算法是如何工作的？</h2><p id="0fa2" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">K-Means算法的工作原理在下面的步骤中解释:</p><p id="2b8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第0步:</strong>获取数据集</p><p id="432a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第一步:</strong>选择数字K决定聚类数。</p><p id="bfc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步:</strong>随机选择K个点或质心。(它可以是输入数据集中的其他数据)。</p><p id="df8c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤3: </strong>将每个数据点分配给它们最近的质心，这将形成预定义的K个聚类。</p><p id="8d29" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤4: </strong>计算方差，放置每个聚类的新质心。</p><p id="7379" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤5: </strong>重复第三步，这意味着将每个数据点重新分配给每个聚类的新的最近质心。</p><p id="8d25" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤6: </strong>如果发生任何重新分配，则转到步骤4，否则转到结束。</p><p id="0bea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第七步</strong>:模型做好了。</p><h2 id="7295" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">不知道K的值</h2><p id="72e3" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">没有办法知道K-means的聚类数。所以你能做的就是从K=1开始。然后增加K的值(达到某个上限)。通常情况下，<strong class="ix hj">方差</strong>(每个点距离“主人”中心的距离的平方之和)会迅速减小。过了某个点，会慢慢减少。当你看到这样的行为，你知道你已经超过了K值。</p><h2 id="e758" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">错误的初始猜测</h2><p id="5a42" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">如果你最初的猜测是错误的，你就不能指望算法能很好地工作。</p><p id="99e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最好的方法是对几次随机的初始猜测运行K-means。然后，选择方差最小的最终中心。</p><p id="8352" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个诀窍是以某种方式选择中心:</p><ol class=""><li id="7ffe" class="kt ku hi ix b iy iz jc jd jg kv jk kw jo kx js lm kz la lb bi translated">将第一个中心放置在数据点上</li><li id="83d8" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js lm kz la lb bi translated">将第二个中心放在离第一个中心最远的数据点上</li><li id="524d" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js lm kz la lb bi translated">将第三个中心放在距离第一个和第二个中心最远的数据点上</li><li id="3af8" class="kt ku hi ix b iy lc jc ld jg le jk lf jo lg js lm kz la lb bi translated">诸如此类。</li></ol><h1 id="8e49" class="ln ju hi bd jv lo lp lq jz lr ls lt kd lu lv lw kg lx ly lz kj ma mb mc km md bi translated">哪里可以应用K-means？</h1><p id="3754" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">K-means算法通常适用于维数较少、数值型且连续的数据。想象一个场景，我们想要从随机分布的事物集合中制造相似事物的组；k-means非常适合这样的场景。</p><p id="0cae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里是K-means的一些有趣的用例，</p><p id="5452" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 1。文档分类</strong>:根据标签、主题和文档内容，将文档分成多个类别。这是一个非常标准的分类问题，k-means是一个非常适合这个目的的算法。文档的初始处理需要将每个文档表示为一个向量，并使用术语频率来识别常用术语，以帮助对文档进行分类。然后对文档向量进行聚类，以帮助识别文档组中的相似性。</p><p id="63bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。配送商店优化:</strong>通过使用k-means的组合来寻找最佳的发射位置数量，并使用遗传算法来解决作为旅行推销员问题的卡车路线，来优化使用卡车无人机交付货物的过程。</p><p id="dbdf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 3。确定犯罪地点:</strong>利用城市中特定地点的犯罪相关数据、犯罪类别、犯罪区域以及两者之间的关联，可以对城市或地区内的犯罪易发区提供高质量的洞察。有了与城市中特定地点的犯罪相关的数据，犯罪的类别、犯罪的区域以及两者之间的关联可以提供对城市或地点内犯罪易发区域的高质量洞察。</p><p id="2f31" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 4。客户/市场细分:</strong>聚类有助于营销人员改善他们的客户群，致力于目标领域，并根据购买历史、兴趣或活动监控对客户进行细分。这种分类将有助于公司针对特定的客户群开展特定的活动。</p><p id="5bf1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 5。梦幻联盟统计数据分析:</strong>分析球员统计数据一直是体育界的一个关键元素，随着竞争的加剧，机器学习在这里发挥着至关重要的作用。作为一个有趣的练习，如果你想创建一个梦幻选秀队，并想根据球员统计数据来识别相似的球员，k-means可以是一个方便的选择。</p><p id="fa93" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 6。保险欺诈检测:</strong>机器学习在欺诈检测中起着至关重要的作用，并在汽车、医疗保健和保险欺诈检测中有许多应用。利用欺诈性索赔的过去历史数据，可以根据其与陈述欺诈模式的聚类的接近程度来隔离新的索赔。由于保险欺诈会给公司带来数百万美元的损失，因此检测欺诈的能力至关重要。</p><p id="cf7c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 7。乘车共享数据分析:</strong>公共可用的优步乘车信息数据集提供了大量关于交通、通行时间、高峰乘车地点等有价值的数据。分析这些数据不仅有助于优步，也有助于洞察城市交通模式，帮助我们规划未来的城市。</p><p id="caf6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 8。网络特征分析罪犯:</strong>网络特征分析是从个人和群体中收集数据以确定显著相关性的过程。网络特征分析的想法来自于犯罪特征分析，犯罪特征分析提供了调查部门对犯罪现场的罪犯类型进行分类的信息。</p><p id="4a75" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 9。通话记录详细分析:</strong>通话详细记录是电信公司在客户的通话、短信和互联网活动中捕获的一条信息。当与客户人口统计结合使用时，这些信息提供了关于客户需求的更深入的见解。我们可以使用无监督的k-means聚类算法对24小时的客户活动进行聚类。它用于按小时了解客户群的使用情况。</p><p id="5ab4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 10。IT警报的自动群集:</strong>网络、存储或数据库等大型企业IT基础架构技术组件会生成大量警报消息。由于警报消息可能指向操作问题，因此必须对其进行手动筛选，以确定下游流程的优先级。</p></div></div>    
</body>
</html>