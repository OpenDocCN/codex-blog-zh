<html>
<head>
<title>Image Recognition with America’s Favorite Animated TV Family</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">美国最受欢迎的动画电视家庭的图像识别</h1>
<blockquote>原文：<a href="https://medium.com/codex/image-recognition-with-americas-favorite-animated-tv-family-95274b45c610?source=collection_archive---------14-----------------------#2021-08-26">https://medium.com/codex/image-recognition-with-americas-favorite-animated-tv-family-95274b45c610?source=collection_archive---------14-----------------------#2021-08-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="f7d8" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在Alteryx Designer中构建图像分类模型</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/8d03ed36dab9294ba34de45c88b35bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w0vhC9Rh7v8yOsFf"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">斯蒂芬·格雷奇在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="e9cc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你对美国流行文化有一点了解，你大概能说出上图中的人物。《辛普森一家》已经在电视上播了30多年了，它提供了大量的“训练数据”,所以我们可以认出剧中的所有或许多角色。另外，作为人类，我们非常擅长解读图像。</p><p id="3f5b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">但是为了识别图像，计算机不仅需要训练数据，还需要一种理解图像并预测图像中的人或物的方法。幸运的是，随着Alteryx Designer 21.3的发布，智能套件中的新<a class="ae jn" href="https://help.alteryx.com/20213/designer/image-recognition" rel="noopener ugc nofollow" target="_blank">图像识别工具</a>正好提供了这一点。此工具可帮助您构建一个影像分类模型，该模型针对一组带有两个或更多类别的已标记影像进行训练(多类别分类)。然后，您可以使用机器学习工具组中的<a class="ae jn" href="https://help.alteryx.com/20213/designer/predict-tool" rel="noopener ugc nofollow" target="_blank">预测工具</a>来标记新图像。</p><p id="8794" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们看看如何使用图像识别来训练一个模型，它可以像你和我一样识别辛普森一家的成员。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kl"><img src="../Images/4effe75a44b830c3951a7710b0874c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*Fq_A_KKBIJyx9TK8"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="km">图像通过</em> <a class="ae jn" href="https://media.giphy.com/media/Sbq7EL4jPZlbj9wUKD/giphy.gif" rel="noopener ugc nofollow" target="_blank"> <em class="km"> GIPHY </em> </a></figcaption></figure><h1 id="20d4" class="kn ko hi bd kp kq kr ks kt ku kv kw kx io ky ip kz ir la is lb iu lc iv ld le bi translated">不要大惊小怪，伙计:准备和输入图像</h1><p id="5df6" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">《辛普森一家》中的这个<a class="ae jn" href="https://www.kaggle.com/mathurinache/simpsons-images" rel="noopener ugc nofollow" target="_blank">图像数据集</a>可以在Kaggle上获得，它包括该剧的16，000多张静止图像，组织成代表19个不同角色的训练和测试目录。为了简单起见，我使用了5637张图片，每张图片只显示了四个角色中的一个:荷马、玛吉、巴特和丽莎。该模型将尝试按照它认为显示的字符“分类”每个图像，本质上是“识别”该字符。</p><p id="8c63" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我将70%的图像放入训练数据集中，20%放入验证集中，10%放入维持集中。(要了解为什么这种划分如此重要，请看<a class="ae jn" href="https://community.alteryx.com/t5/Data-Science/Holdouts-and-Cross-Validation-Why-the-Data-Used-to-Evaluate-your/ba-p/448982?utm_content=802313&amp;utm_source=tds" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。)目录工具使得引入完整的训练和验证目录变得容易，加上由四个Simpsons角色中的每一个组织的子目录。我使用公式工具从每个子目录的名称中提取标签名称(图中显示的Simpsons字符)，并将其放入一个名为“Class”的新字段中。组织好图像并建立标签后，图像输入工具就可以输入实际的图像文件了。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lk"><img src="../Images/8e794e9e50ec010259802a2682d2f271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tYPYlP9Io5zDp08i"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="2a1d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">但是——“哦！”正如荷马所说——我们还没有准备好建立模型。为了一致性和与模型建立过程的兼容性，首先处理图像是很重要的。特别是，你可能需要使用<a class="ae jn" href="https://help.alteryx.com/20212/designer/image-processing" rel="noopener ugc nofollow" target="_blank">图像处理工具</a>——在<a class="ae jn" href="https://community.alteryx.com/t5/Data-Science/Picture-Perfect-Inside-Image-Processing/ba-p/767828?utm_content=802313&amp;utm_source=tds" rel="noopener ugc nofollow" target="_blank">这篇博文</a>中讨论过——来使图像大小一致，并应用他们可能需要的其他变换。(但是，不要将其转换为灰度，因为这与图像识别工具不兼容。)为图像选择统一的大小；您的图像越小，您的模型将越快，但它可能有较低的准确性。图像的最小尺寸取决于您选择的预训练模型(稍后将详细介绍)。一个好的起点是128 x 128，这就是我在这里使用的。你可以试验一下，看看哪个维度能给你最好的结果。对训练、验证和测试图像应用相同的处理很重要。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kl"><img src="../Images/f2a5f4935ebb2a4f614ff456b91e4116.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*EUCWjJRoZtWH9DTU"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="km">图像通过</em> <a class="ae jn" href="https://media.giphy.com/media/26BGIqWh2R1fi6JDa/giphy.gif" rel="noopener ugc nofollow" target="_blank"> <em class="km"> GIPHY </em> </a></figcaption></figure><h1 id="4b5c" class="kn ko hi bd kp kq kr ks kt ku kv kw kx io ky ip kz ir la is lb iu lc iv ld le bi translated">呜-呼！配置图像识别</h1><p id="422e" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">图像识别工具是工作流程中的下一步，如下所示，它需要一些配置选择。我们需要指定训练和验证图像来自哪里，以及每个数据流中的哪个字段包含图像的标签。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ll"><img src="../Images/98631325a40a9e0578c151c0b4e33211.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/0*J5fpa4EiccbVKlKI"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="fa8b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们还可以选择时期和批量大小。这里的一个<em class="kk">批次</em>是我们训练数据的子集，工具中的默认是32张图像。这32幅图像是通过正在构建的神经网络发送的；基于该组计算误差，并且更新模型参数以尝试减少误差。</p><p id="651b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">epochs的数量表示您希望<em class="kk">所有</em>训练数据(在一个或多个批次中)通过进行中的模型发送的次数。这里的默认值是10，但是您可以尝试不同的值，看看哪一个最适合您的数据集。这个想法是让数据在模型中运行足够长的时间，以找到最小化误差的参数。</p><p id="09f8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">32个批次，10个历元，你的模型的参数会更新320次；因此，请记住，如果增加这些数字，您的工作流将需要更长的时间。添加更多的纪元<a class="ae jn" href="https://datascience.stackexchange.com/questions/46523/is-a-large-number-of-epochs-good-or-bad-idea-in-cnn/46534" rel="noopener ugc nofollow" target="_blank">也会导致</a>过度拟合你的模型。同样，您可以尝试这些选项，看看哪种组合会产生最好的结果。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kl"><img src="../Images/2e4ebb53fef6bf8972090dc2c822746e.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*Ii9NKxHOdG04fW7_"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="km">图片via </em> <a class="ae jn" href="https://media.giphy.com/media/3orif8Epddpd8KSELe/giphy.gif" rel="noopener ugc nofollow" target="_blank"> <em class="km"> GIPHY </em> </a></figcaption></figure><h1 id="7898" class="kn ko hi bd kp kq kr ks kt ku kv kw kx io ky ip kz ir la is lb iu lc iv ld le bi translated">嗯，模型:选择预训练模型</h1><p id="0f5b" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">最后，您有一个预训练模型的选择列表。图像识别工具并没有完全从零开始建立一个用于图像分类的深度<a class="ae jn" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>模型。你可能不希望这样，除非你有大量的计算能力和时间！相反，它使用由拥有这些资源的专家建立的预训练模型，加上数百万张图像来训练和完善他们的模型。可以说，预先训练的模型包含关于图像特征的现有“知识”，并且它们可以将该知识“转移”到分析您的图像(因此有术语“<a class="ae jn" href="https://builtin.com/data-science/transfer-learning" rel="noopener ugc nofollow" target="_blank">转移学习</a>”，这是一种也用于其他类型的数据的方法，例如在自然语言处理中)。</p><p id="ab38" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这里的默认值是InceptionV3，但是您也可以选择VGG16、InceptionResNetV2或Resnet50V2。正如图像识别工具<a class="ae jn" href="https://help.alteryx.com/20213/designer/image-recognition" rel="noopener ugc nofollow" target="_blank">文档</a>所解释的，每种工具在准确性、速度和计算费用方面都有自己的优势和劣势，您需要根据您的使用情况对这些标准进行优先排序。同样，您可以在这里轻松地尝试多个选项，并查看您的模型的每个版本的执行情况。如果您的图像很小，请务必记下预训练模型所需的最小尺寸；VGG16和ResNet50V2需要32 x 32，InceptionV3和InceptionResNetV2需要75 x 75。</p><p id="ac70" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后，为了使用训练好的模型对新的、未标记的图像进行预测，您可以将新数据和预测过程包含在同一个工作流中，也许可以使用容器来分隔过程的各个部分。或者，您可以保存模型以供以后在单独的工作流中使用。要保存模型，请在图像识别工具之后添加一个输出工具，将模型放入一个. yxdb文件中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kl"><img src="../Images/c103846dc77f8e7c702ad6ed99315dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*TRlemkqmVm9Jk348"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="km">图片经由</em> <a class="ae jn" href="https://media.giphy.com/media/3orieR4zl3zCoNhGV2/giphy.gif" rel="noopener ugc nofollow" target="_blank"> <em class="km"> GIPHY </em> </a></figcaption></figure><h1 id="de29" class="kn ko hi bd kp kq kr ks kt ku kv kw kx io ky ip kz ir la is lb iu lc iv ld le bi translated">科瓦邦加！训练模型并进行预测</h1><p id="f6f2" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">当您运行工作流时，您可以在结果窗口中观看您的纪元。您将看到进度，以及每个时期中，模型在训练和验证数据上的表现。通常，尽管不总是如此，随着时代的发展，你会看到准确性大部分增加，而损失大部分减少。这种模式表明，随着模型反复查看数据并对其自身参数进行调整，其预测图像标签的能力正在提高。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lm"><img src="../Images/ada802ce92a57175f8179d7f1b22821d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EO9cQu23QDrde-m2"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="1d78" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">(想看看所有预训练的模型选项表现如何？详细内容见本帖</em>  <em class="kk">中的</em> <a class="ae jn" href="https://community.alteryx.com/t5/Data-Science/Image-Recognition-Classification-Models-Made-Simple/ba-p/802313?utm_content=802313&amp;utm_source=tds" rel="noopener ugc nofollow" target="_blank"> <em class="kk">。)</em></a></p><p id="63dc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，您可以直接在同一工作流中或在单独的工作流中使用您的模型进行预测。无论您选择哪个选项，在预测它们的标签之前，您的用于分类的新图像应该以与您的原始图像相同的方式进行处理；在我的工作流程中，我把新的无标签图像的尺寸也调整为128 x 128。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ln"><img src="../Images/ef8562dae570a7773882a98494792e19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*74gBaGy_hX6xf-ct"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="42ee" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我设置了工作流的第二部分，通过输入工具引入保存的图像识别模型。在预测工具上，我将模型连接到M输入锚，将我的维持数据连接到D锚。</p><p id="8d81" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我还在Predict工具之后添加了一些数据整理和分析，以评估我的模型在维持图像上的表现如何。我添加了一个变量来标记预测是否与图像上的原始标签匹配，这让我可以使用过滤工具快速查看哪些图像的标签预测正确，哪些预测不正确。</p><p id="3610" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后，我使用列联表工具来显示本质上的混淆矩阵，比较图像的实际标签和预测标签。这种可视化可以让您快速了解您的模型正在学习什么以及它在哪里出错。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ln"><img src="../Images/e65eac0ef5c6870a6c5339e6f11da0fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UnPuDvPfyn3mn11J"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="5df1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我的表现最好的模型使用了ResNet50V2预训练模型，它在所有类(在本例中是字符)上实现了90%的整体准确性。与巴特和荷马相比，它在辨认丽莎和玛吉方面做得稍好一些。我可以进一步试验图像和批次大小，以及时期的数量，看看是否能得到更好的结果。干得好，图像识别！</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lo"><img src="../Images/d8c8d9a22cc7ffbcfb7a4b3101dafe39.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/0*ATerf6VYX-FYkcZg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="km">图片经由</em> <a class="ae jn" href="https://media.giphy.com/media/3orifhaiBq26JjDbsQ/giphy-downsized.gif" rel="noopener ugc nofollow" target="_blank"> <em class="km"> GIPHY </em> </a></figcaption></figure><h1 id="a41a" class="kn ko hi bd kp kq kr ks kt ku kv kw kx io ky ip kz ir la is lb iu lc iv ld le bi translated">真人表演:图像分类应用</h1><p id="2c1e" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">在你收集的有趣数据中，有哪些图像？您可能需要手动标记一些图像来开始，但是有了足够的准备好的示例，您可以根据新数据生成预测。还要记住，在使用图像，尤其是人的图像时，有一些重要的伦理考虑要牢记在心；这里有一些要考虑的问题的简要概述，还有更多的资源。</p><p id="e118" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">像往常一样，从您的图像生成的数据可以在您的工作流程中与其他数据源混合，这意味着您再次扩展了数据的可能性。或者，就像他们在斯普林菲尔德说的，“孕育”了他们。</p></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="4179" class="kn ko hi bd kp kq lw ks kt ku lx kw kx io ly ip kz ir lz is lb iu ma iv ld le bi translated">推荐阅读</h1><ul class=""><li id="2161" class="mb mc hi jq b jr lf ju lg jx md kb me kf mf kj mg mh mi mj bi translated"><a class="ae jn" href="https://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank">用于视觉识别的卷积神经网络:图像分类</a></li><li id="e03b" class="mb mc hi jq b jr mk ju ml jx mm kb mn kf mo kj mg mh mi mj bi translated"><a class="ae jn" href="https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/" rel="noopener ugc nofollow" target="_blank">神经网络中批次和时期之间的差异</a></li><li id="16f5" class="mb mc hi jq b jr mk ju ml jx mm kb mn kf mo kj mg mh mi mj bi translated"><a class="ae jn" href="https://docs.paperspace.com/machine-learning/wiki/accuracy-and-loss" rel="noopener ugc nofollow" target="_blank">精度和损耗</a></li></ul></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><p id="19d9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">原载于</em> <a class="ae jn" href="https://community.alteryx.com/t5/Data-Science/Image-Recognition-Classification-Models-Made-Simple/ba-p/802313?utm_content=802313&amp;utm_source=tds" rel="noopener ugc nofollow" target="_blank"> <em class="kk"> Alteryx社区数据科学博客</em> </a> <em class="kk">。</em></p></div></div>    
</body>
</html>