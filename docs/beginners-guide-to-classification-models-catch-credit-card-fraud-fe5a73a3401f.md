# åˆ†ç±»æ¨¡å‹åˆå­¦è€…æŒ‡å—(æ•æ‰ä¿¡ç”¨å¡æ¬ºè¯ˆ)

> åŸæ–‡ï¼š<https://medium.com/codex/beginners-guide-to-classification-models-catch-credit-card-fraud-fe5a73a3401f?source=collection_archive---------2----------------------->

## å¼‚å¸¸æ£€æµ‹

![](img/146dc0e5200df1d57f485252601decf8.png)

æ‚¨æ˜¯å¦çŸ¥é“ï¼Œä¸€ä¸ªå…¸å‹çš„ç»„ç»‡æ¯å¹´å› æ¬ºè¯ˆè€ŒæŸå¤±çº¦ 5%çš„æ”¶å…¥ï¼Ÿç„¶è€Œï¼Œç”¨æˆ·è¡Œä¸ºä¸­ä¹Ÿæœ‰å¾®å¦™å’Œéšè—çš„äº‹ä»¶ï¼Œè¿™äº›äº‹ä»¶å¯èƒ½ä¸æ˜æ˜¾ï¼Œä½†ä»ç„¶é¢„ç¤ºç€å¯èƒ½çš„æ¬ºè¯ˆã€‚æœºå™¨å­¦ä¹ å…è®¸åˆ›å»ºå¤„ç†å…·æœ‰è®¸å¤šå˜é‡çš„å¤§å‹æ•°æ®é›†çš„ç®—æ³•ï¼Œå¹¶å¸®åŠ©æ‰¾åˆ°ç”¨æˆ·è¡Œä¸ºå’Œæ¬ºè¯ˆè¡Œä¸ºå¯èƒ½æ€§ä¹‹é—´çš„éšè—ç›¸å…³æ€§ã€‚ä¸åŸºäºè§„åˆ™çš„ç³»ç»Ÿç›¸æ¯”ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿçš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯æ›´å¿«çš„æ•°æ®å¤„ç†å’Œæ›´å°‘çš„äººå·¥å·¥ä½œã€‚ä¾‹å¦‚ï¼Œæ™ºèƒ½ç®—æ³•éå¸¸é€‚åˆè¡Œä¸ºåˆ†æï¼Œæœ‰åŠ©äºå‡å°‘éªŒè¯æ­¥éª¤çš„æ•°é‡ã€‚

## æœ¬æ–‡çš„ç›®çš„:

> æœ¬æ–‡é¢å‘æ•°æ®ç§‘å­¦é¢†åŸŸçš„åˆå­¦è€…&æ—¨åœ¨æ¼”ç¤ºå¦‚ä½•ç³»ç»Ÿåœ°è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¹¶å¼€å§‹ä½¿ç”¨ä¸ºæ¬ºè¯ˆæ£€æµ‹ç›¸å…³çš„ä¸å¹³è¡¡åˆ†ç±»é—®é¢˜è€Œè®¾è®¡çš„æŠ€æœ¯ã€‚**å½“ç±»åˆ«ä¸å¹³è¡¡æ—¶ï¼Œæˆ‘ä»¬å°†ç€é‡äºé€‰æ‹©åˆé€‚çš„æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ã€‚æˆ‘ä¼šå°è¯•è§¦åŠå„ç§å¸¸è§çš„è¯é¢˜ï¼Œä½†ä¹Ÿä¼šå°½å¯èƒ½åœ°ç®€åŒ–æ¦‚å¿µã€‚**

# æ•°æ®é›†æè¿°:

> æ•°æ®é›† fraud_data.csv æ˜¯ä» Coursera ç½‘ç«™ä¸‹è½½çš„ã€‚fraud_data.csv ä¸­çš„æ¯ä¸€è¡Œéƒ½å¯¹åº”äºä¸€ç¬”ä¿¡ç”¨å¡äº¤æ˜“ã€‚
> 
> 2.åŠŸèƒ½åŒ…æ‹¬æœºå¯†å˜é‡ V1 åˆ° V28 ä»¥åŠäº¤æ˜“é‡‘é¢ã€‚
> 
> 3.ç›®æ ‡å­˜å‚¨åœ¨â€œclassâ€åˆ—ä¸­ï¼Œå¯¹äºæ¬ºè¯ˆæ€§äº¤æ˜“ï¼Œè¯¥åˆ—çš„å€¼ä¸º 1ï¼Œå¦åˆ™ä¸º 0ã€‚

![](img/4e360cf47dae0a15eaa19814921d7f02.png)

å–æ ·å‰å‡ è¡Œ

> 4.æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç¬¬ä¸€åˆ—æ˜¯æ—¶é—´ï¼Œæ˜¯æ•´æ•°ï¼Œå€’æ•°ç¬¬äºŒåˆ—æ˜¯è´­ä¹°é‡‘é¢ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ° PCA å˜æ¢åçš„ç‰¹å¾æ˜¯æ­£è´Ÿçš„ï¼ŒåŒ…å«äº†å¾ˆå¤šæµ®ç‚¹ç²¾åº¦ã€‚
> 
> 5.æ—¶é—´åˆ—ä¸å¤ªå¯èƒ½æœ‰ç”¨ï¼Œå¯èƒ½ä¼šè¢«åˆ é™¤ã€‚PCA å˜é‡å’Œç¾å…ƒæ•°é‡ä¹‹é—´çš„æ¯”ä¾‹å·®å¼‚è¡¨æ˜ï¼Œæ•°æ®ç¼©æ”¾åº”è¯¥ç”¨äºé‚£äº›å¯¹è¾“å…¥å˜é‡çš„æ¯”ä¾‹æ•æ„Ÿçš„ç®—æ³•ã€‚

![](img/2928e61a75220a084710d3fafc5f26d8.png)

# **æ•°æ®æ¢ç´¢**

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ£€æŸ¥ fraud_data.csv æ•°æ®é›†çš„æ±‡æ€»ç»Ÿè®¡æ•°æ®&æˆ‘ä»¬å°†åœ¨è¿™ä¸€éƒ¨åˆ†èŠ±å¾ˆå¤šæ—¶é—´ã€‚åœ¨æ„å»ºä»»ä½•ä¸œè¥¿ä¹‹å‰ï¼Œäº†è§£æ•°æ®æ˜¯å¾ˆé‡è¦çš„ã€‚

ç¨åï¼Œæˆ‘ä»¬å°†æŠŠæ•°æ®é›†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†æ¥è®­ç»ƒå‡ ä¸ªæ¨¡å‹ï¼Œåœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è¯„ä¼°å®ƒä»¬åœ¨æ£€æµ‹ä¿¡ç”¨å¡äº¤æ˜“æ¬ºè¯ˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

```
df **=** read_transactions_data()

**print**(round(df**.**describe()**.**transpose(), 3))
**print**('\nThe number of missing values across all attributes and samples: ', df**.**isnull()**.**sum()**.**sum())
```

![](img/660520f109b51e403100e765b1746eda.png)

**è§‚å¯Ÿç»“æœ 1:** ä¸‹é¢çš„æ±‡æ€»ç»Ÿè®¡æ˜¾ç¤ºï¼Œæ•°æ®ä¸­æœ‰ 284806 ç¬”äº¤æ˜“ï¼Œå…¶ä¸­ 0.17%æ˜¯æ¬ºè¯ˆæ€§çš„(å³æ¬ºè¯ˆç±»ä»…ä»£è¡¨è§‚å¯Ÿç»“æœçš„ä¸€å°éƒ¨åˆ†)ã€‚

```
#This code is for the bar graph above
ax = df[â€˜Classâ€™].value_counts().plot(kind=â€™barâ€™, figsize=(10, 6), fontsize=13, color=â€™#087E8Bâ€™)
ax.set_title(â€˜Count of Valid vs Fraud Transactionsâ€™, size=20, pad=30)
ax.set_ylabel(â€˜Countâ€™, fontsize=14)
```

![](img/e998c39daffa56451c02d2845473d2c3.png)

**ä¸ºä»€ä¹ˆä¸å¹³è¡¡æ•°æ®ä¼šå¼•èµ·å…³æ³¨ï¼Ÿ**

> å¦‚æœç›®æ ‡å˜é‡çš„è‡³å°‘ä¸€ä¸ªç±»ä»…æ„æˆéå¸¸å°çš„å°‘æ•°ï¼Œåˆ™æ•°æ®é›†æ˜¯ä¸å¹³è¡¡çš„ã€‚åœ¨ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œç›®æ ‡å˜é‡ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡ä¼šå¯¼è‡´ä¸¥é‡åå‘å¤šæ•°ç±»åˆ«ï¼Œå¹¶é™ä½å¯é¢„æµ‹æ€§ã€‚ä¸å¹³è¡¡æ•°æ®åœ¨é“¶è¡Œã€ä¿é™©ã€å·¥ç¨‹å’Œè®¸å¤šå…¶ä»–é¢†åŸŸæ™®éå­˜åœ¨ã€‚åªéœ€çŸ¥é“ï¼Œåœ¨æ¬ºè¯ˆæ£€æµ‹ä¸­ï¼Œä¸å¹³è¡¡çš„æ¯”ä¾‹é€šå¸¸ä¸º 100:1ã€‚

**è§‚å¯Ÿç»“æœ 2:** å¹³å‡äº¤æ˜“é‡‘é¢å¤§å¤§é«˜äºä¸­ä½æ•°ï¼Œè¡¨æ˜æœ‰ç›¸å¯¹å°‘é‡çš„éå¸¸å¤§çš„äº¤æ˜“æ¨åŠ¨å¹³å‡å€¼ä¸Šå‡ã€‚æ•°æ®é›†æ²¡æœ‰ç¼ºå¤±å€¼ã€‚

![](img/d78a1bf8387b1a6707e2751df3943489.png)

æ±‡æ€»ç»Ÿè®¡

**è§‚å¯Ÿä¸‰:**

åœ¨â€œæ•°é‡â€åˆ—ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤§å¤šæ•°æ•°é‡éƒ½å¾ˆå°ï¼Œå¹³å‡å€¼çº¦ä¸º 88ï¼Œä¸­é—´ 50%çš„è§‚å¯Ÿå€¼ä»‹äº 5 å’Œ 77 ä¹‹é—´ã€‚æœ€å¤§å€¼çº¦ä¸º 25ï¼Œ691ï¼Œè¿™ä¼¼ä¹æ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ï¼Œå½“ç„¶ä¼šæé«˜åˆ†å¸ƒã€‚

**è§‚å¯Ÿå››:**

å¤§å¤šæ•° PCA åˆ†é‡çš„åˆ†å¸ƒæ˜¯é«˜æ–¯å‹çš„ï¼Œå¹¶ä¸”è®¸å¤šå¯èƒ½ä»¥é›¶ä¸ºä¸­å¿ƒï¼Œè¿™è¡¨æ˜å˜é‡è¢«æ ‡å‡†åŒ–ä¸º PCA å˜æ¢çš„ä¸€éƒ¨åˆ†ã€‚

![](img/e5ded78e574536e811a7845c3957b09d.png)

**é‡è¦æ³¨æ„äº‹é¡¹:**

1.  åœ¨æˆ‘ä»¬è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œéœ€è¦å¯¹ç‰¹å¾è¿›è¡Œç¼©æ”¾ã€‚

```
*# Split the data into X_train, X_test, y_train, y_test*
X **=** df**.**iloc[:,:**-**1]
y **=** df**.**iloc[:,**-**1]

X_train, X_test, y_train, y_test **=** train_test_split(X, y, random_state **=** 0)
```

2.è¯¥ä»£ç å°†ä½¿ä¸€ä¸ªå®šæ ‡å™¨é€‚åˆè®­ç»ƒæ•°æ®ï¼Œå¹¶ä½¿ç”¨é€‚åˆçš„å®šæ ‡å™¨è½¬æ¢è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ã€‚(æ³¨:å®šæ ‡å™¨åº”ä»…é€‚ç”¨äºè®­ç»ƒæ•°æ®ï¼Œä»¥é˜²æ­¢æµ‹è¯•æ•°æ®ä¸­çš„ä¿¡æ¯æ³„æ¼ã€‚)

```
scaler **=** StandardScaler()**.**fit(X_train)
X_train **=** scaler**.**transform(X_train)
X_test **=** scaler**.**transform(X_test)
```

## ä½ ä¸ºä»€ä¹ˆè¦å…³å¿ƒé˜¶çº§ä¸å¹³è¡¡åŠå…¶åœ¨é€‰æ‹©åº¦é‡æ ‡å‡†ä¸­çš„ä½œç”¨ï¼Ÿ

åªæœ‰ä¸€å°éƒ¨åˆ†äº¤æ˜“æ˜¯æ¬ºè¯ˆæ€§çš„ï¼Œé¢„æµ‹æ¯ä¸ªäº¤æ˜“ä¸æ˜¯æ¬ºè¯ˆæ€§çš„åˆ†ç±»å™¨å°†è¾¾åˆ° 99%çš„å‡†ç¡®åº¦åˆ†æ•°ã€‚è¿™æ ·çš„åˆ†ç±»å™¨å¯¹æˆ‘ä»¬æ²¡æœ‰ä»·å€¼ã€‚å› æ­¤ï¼Œåœ¨ç±»åˆ«ä¸å¹³è¡¡çš„æƒ…å†µä¸‹ï¼Œåº”è¯¥è€ƒè™‘å‡†ç¡®æ€§ä»¥å¤–çš„åº¦é‡ã€‚è¿™äº›åº¦é‡åŒ…æ‹¬ç²¾ç¡®åº¦ã€å¬å›ç‡ä»¥åŠè¿™ä¸¤ä¸ªåº¦é‡çš„ç»„åˆ(F2)ã€‚

# æ‹Ÿåˆå’Œè¯„ä¼° ML æ¨¡å‹ä¸€èˆ¬

è¿™æ˜¯å¯¹æˆ‘ä»¬åˆçœ‹æ—¶å¦‚ä½•å¤„ç†è¿™ä¸ªé—®é¢˜çš„å›é¡¾

**æ­¥éª¤ 1** :æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªè™šæ‹Ÿåˆ†ç±»å™¨ï¼Œå°†æ‰€æœ‰äº‹ç‰©åˆ†ç±»ä¸ºè®­ç»ƒæ•°æ®çš„ä¸»è¦ç±»åˆ«(å³ï¼Œæ‰€æœ‰äº¤æ˜“éƒ½ä¸æ˜¯æ¬ºè¯ˆæ€§çš„)

```
**def** **dummy_classifier**():

    dummy_majority **=** DummyClassifier(strategy **=** 'most_frequent')**.**fit(X_train, y_train)
    accuracy **=** dummy_majority**.**score(X_test, y_test)

    **return** accuracy
```

**è™šæ‹Ÿåˆ†ç±»å™¨ç»ƒä¹ çš„ä¸»è¦æ”¶è·**

> 1)æ­£å¦‚æ‰€è®¨è®ºçš„ï¼Œè¯¥å‡½æ•°è¿”å›è¶…è¿‡ 99%çš„å‡†ç¡®åº¦åˆ†æ•°ã€‚
> 
> 2)åŒæ—¶ï¼Œå¬å›ç‡(æ¢å¥è¯è¯´ï¼Œæ‰€æœ‰æ¬ºè¯ˆäº¤æ˜“ä¸­è¢«æ­£ç¡®é¢„æµ‹ä¸ºæ¬ºè¯ˆçš„éƒ¨åˆ†)æ˜¯ 0%ã€‚è¿™æ˜¯å› ä¸ºè¯¥æ¨¡å‹ä¸æ˜¯ä¸ºäº†å°†ä»»ä½•äº¤æ˜“å½’ç±»ä¸ºæ¬ºè¯ˆè€Œè®¾è®¡çš„ã€‚å› æ­¤ï¼Œå°½ç®¡å‡†ç¡®åº¦åˆ†æ•°å¾ˆé«˜ï¼Œä½†æ¨¡å‹è¡¨ç°ä¸ä½³ã€‚

![](img/9265f548afbd56db0a0900f24a93b482.png)

è™šæ‹Ÿåˆ†æ•°

**æ­¥éª¤ 2 SVC â†’** æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒæ”¯æŒå‘é‡åˆ†ç±»å™¨(SVC ):

```
**def** **SVC_classifier**():

    svm **=** SVC()**.**fit(X_train, y_train)
    y_pred **=** svm**.**predict(X_test)
    accuracy **=** svm**.**score(X_test, y_test)
    precision **=** precision_score(y_test, y_pred)
    recall **=** recall_score(y_test, y_pred)

    **return** (accuracy, recall, precision)
```

å‡†ç¡®åº¦ã€å¬å›ç‡å’Œç²¾ç¡®åº¦ç°åœ¨åˆ†åˆ«æ˜¯ 0.995ã€0.67 å’Œ 0.96ã€‚å¬å›ç‡ä»é›¶å¢åŠ åˆ° 0.67 è¡¨æ˜ SVC æ¯”ç®€å•çš„å¤šæ•°ç±»è§„åˆ™æ‰§è¡Œå¾—å¥½å¾—å¤šã€‚

![](img/ef4df009899ac35d72d32eee53c7797a.png)

**æ­¥éª¤ 3 - >æ··æ·†çŸ©é˜µ**

```
**def** **confusion_mtrx**():

    svm **=** SVC()**.**fit(X_train, y_train)
    y_pred **=** svm**.**predict(X_test)
    confusion **=** confusion_matrix(y_test, y_pred)

    **return** confusion

**print**(confusion_mtrx())
```

ä¸€å¼ å›¾èƒœè¿‡åƒè¨€ä¸‡è¯­ï¼Œä½ å¯ä»¥è¿™æ ·è§£é‡Š:

ä¸‰ä¸ªå‡é˜³æ€§ä¸æ„æˆå¨èƒï¼Œä½† 33 ä¸ªå‡é˜´æ€§æ˜¯ç®—æ³•æ— æ³•å‡†ç¡®åˆ†ç±»çš„æ¬ºè¯ˆæ¡ˆä»¶ã€‚

![](img/07571f1d4b13aeb01736e0acd0c3719d.png)![](img/5690aa9d590b96cf2c41b5901ee29f6e.png)

**æ­¥éª¤ 4 - >** è®©æˆ‘ä»¬è¯•ç€è·³è¿‡ SVC &ä»£ä¹‹ä»¥ç”¨é»˜è®¤å‚æ•°è®­ç»ƒé€»è¾‘å›å½’åˆ†ç±»å™¨ã€‚å¯¹äºè¿™ä¸ªåˆ†ç±»å™¨ï¼Œæˆ‘ä»¬ç„¶åä½¿ç”¨æµ‹è¯•æ•°æ®åˆ›å»ºä¸€ä¸ªç²¾ç¡®å¬å›æ›²çº¿å’Œä¸€ä¸ª ROC æ›²çº¿ã€‚ä½†æ˜¯ï¼Œåœ¨æˆ‘ä»¬å¼€å§‹æ·±å…¥ç ”ç©¶ä»£ç ä¹‹å‰ï¼Œæ‚¨éœ€è¦äº†è§£ä¸€äº›äº‹æƒ…:

> æ³¨æ„:ä¸€æ¡**ç²¾ç¡®-å¬å›æ›²çº¿**æ˜¾ç¤ºäº†å¬å›å’Œç²¾ç¡®ä¹‹é—´çš„æƒè¡¡ã€‚
> 
> æ³¨: **ROC æ›²çº¿**å½“çœŸé˜³æ€§ç‡å¢åŠ æ—¶ï¼Œä»¥å‡é˜³æ€§ç‡è¡¡é‡æˆæœ¬ã€‚
> 
> æ³¨æ„:ä¿¡ç”¨å¡å…¬å¸æ—¨åœ¨ä¼˜åŒ–å¬å›ã€‚å½“æˆ‘åœ¨ä¸€å®¶ä¿é™©å…¬å¸å·¥ä½œæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä¼˜åŒ–ç²¾ç¡®åº¦ã€‚å¬å›åªæ˜¯æ‰€æœ‰å®é™…æ¬ºè¯ˆæ¡ˆä¾‹ä¸­é¢„æµ‹æ¬ºè¯ˆæ¡ˆä¾‹çš„ä¸€å°éƒ¨åˆ†ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æŠ“åˆ°äº†å¤šå°‘è¯ˆéª—æ¡ˆï¼Ÿè¿™å°±è½¬åŒ–æˆäº†ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™=ğ‘‡ğ‘Ÿğ‘¢ğ‘’ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘ /ğ‘‡ğ‘Ÿğ‘¢ğ‘’ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘ +ğ¹ğ‘ğ‘™ğ‘ ğ‘’ğ‘ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘ å…¬å¼
> 
> Davis å’Œ Goadrich åœ¨è¿™ç¯‡[è®ºæ–‡](http://ftp.cs.wisc.edu/machine-learning/shavlik-group/davis.icml06.pdf)ä¸­æå‡ºï¼Œåœ¨å¤„ç†é«˜åº¦å€¾æ–œçš„æ•°æ®é›†æ—¶ï¼Œç²¾ç¡®å¬å›(PR)æ›²çº¿å°†æ¯” ROC æä¾›æ›´å¤šä¿¡æ¯ã€‚PR æ›²çº¿æç»˜äº†ç²¾ç¡®åº¦ä¸å¬å›ç‡çš„å…³ç³»(FPR)ã€‚å› ä¸ºç²¾åº¦ç›´æ¥å—åˆ°ç±»åˆ«ä¸å¹³è¡¡çš„å½±å“ï¼Œæ‰€ä»¥ç²¾åº¦-å¬å›æ›²çº¿æ›´å¥½åœ°çªå‡ºäº†é«˜åº¦ä¸å¹³è¡¡æ•°æ®é›†çš„æ¨¡å‹ä¹‹é—´çš„å·®å¼‚ã€‚å½“æ‚¨æ¯”è¾ƒå…·æœ‰ä¸å¹³è¡¡è®¾ç½®çš„ä¸åŒæ¨¡å‹æ—¶ï¼Œç²¾ç¡®åº¦-å¬å›æ›²çº¿ä¸‹çš„åŒºåŸŸå°†æ¯” ROC æ›²çº¿ä¸‹çš„åŒºåŸŸæ›´æ•æ„Ÿã€‚

åœ¨æˆ‘è°ˆè®ºæ›´å¤šçš„ PR æ›²çº¿ä¹‹å‰ï¼Œè®©æˆ‘å…ˆè°ˆè°ˆé˜ˆå€¼çš„æ¦‚å¿µã€‚

## PR æ›²çº¿çš„é˜ˆå€¼è®¾ç½®

é€šå¸¸ï¼Œåˆ†ç±»æ¨¡å‹é¢„æµ‹æ¦‚ç‡ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ­£åœ¨å¯»æ‰¾ç»™å®šè®°å½•çš„æ¬ºè¯ˆæ¦‚ç‡ã€‚é€šè¿‡å°†æ¦‚ç‡å€¼ä¸é˜ˆå€¼è¿›è¡Œæ¯”è¾ƒ(ä¾‹å¦‚ï¼Œå¦‚æœæ¦‚ç‡è¶…è¿‡ 80%ï¼Œåˆ™æ ‡è®°ä¸ºæ¬ºè¯ˆ)ï¼Œæˆ‘ä»¬å¯ä»¥å°†è®°å½•åˆ†ç±»ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦é¦–å…ˆå®šä¹‰è§„åˆ™ã€‚

**ä¸ºä»€ä¹ˆä¼šåœ¨æ„é—¨æ§›å’ŒèŒä¸šï¼Ÿ**

> å½“æ„å»ºæ··æ·†çŸ©é˜µå’Œè®¡ç®—å‡†ç¡®ç‡å’Œå¬å›ç‡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é¢„æµ‹çš„ç±»åˆ«è€Œä¸æ˜¯æ¦‚ç‡åˆ†æ•°ã€‚è¿™å°±æ˜¯åŸå› ã€‚

æ‚¨åº”è¯¥åœ¨ä»»ä½•æƒ³è¦å¯è§†åŒ–å‡é˜³æ€§å’Œå‡é˜´æ€§ä¹‹é—´çš„æƒè¡¡çš„æ—¶å€™å¯è§†åŒ–ç²¾åº¦-å¬å›æ›²çº¿ã€‚å¤§é‡çš„å‡é˜³æ€§å¯¼è‡´ä½ç²¾åº¦ï¼Œå¤§é‡çš„å‡é˜´æ€§å¯¼è‡´ä½å¬å›ç‡ã€‚

æ‚¨åº”è¯¥ä»¥é«˜ç²¾åº¦å’Œé«˜å¬å›æ¨¡å‹ä¸ºç›®æ ‡ï¼Œä½†åœ¨ç°å®ä¸­ï¼Œä¸€ä¸ªæŒ‡æ ‡æ›´é‡è¦(åœ¨è¿™ç§æƒ…å†µä¸‹å¬å›ï¼Œæˆ‘ä»¬ä¸æƒ³å¿½ç•¥ä»»ä½•æ¬ºè¯ˆè€…)ï¼Œå› æ­¤æ‚¨å¯ä»¥éšæ—¶ä¸ºå®ƒè¿›è¡Œä¼˜åŒ–ã€‚ä¼˜åŒ–åï¼Œç›¸åº”è°ƒæ•´åˆ†ç±»é˜ˆå€¼ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨æ¨èçš„ç²¾ç¡®å¬å›æ›²çº¿ä¸‹é¢ç§¯æŒ‡æ ‡æˆ– PR AUCã€‚ä»¥ä¸‹æ˜¯ä½ å¦‚ä½•åœ¨è„‘æµ·ä¸­å½¢è±¡åŒ–å’Œåˆç†åŒ–è¿™ä¸ªæ–¹æ³•:

> è®©æˆ‘ä»¬å¼€å§‹å†™ä¸€äº›ä»£ç :

ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†ä»€ä¹ˆæ˜¯ç²¾åº¦ã€å¬å›ç‡å’Œé˜ˆå€¼ï¼Œä¸€æ—¦æˆ‘ä»¬è®¡ç®—äº†å¤šä¸ªé˜ˆå€¼çš„ç²¾åº¦å’Œå¬å›ç‡ï¼Œæˆ‘ä»¬å°±åœ¨ x è½´ä¸Šç»˜åˆ¶å¬å›ç‡ï¼Œåœ¨ y è½´ä¸Šç»˜åˆ¶ç²¾åº¦-å¬å›ç‡æ›²çº¿ã€‚

```
lr = LogisticRegression().fit(X_train, y_train)
#use logistic regression model to make predictions
y_score = lr.decision_function(X_test)
precision, recall, thresholds = precision_recall_curve(y_test, y_score)
#create precision recall curve
fig, ax = plt.subplots()
ax.plot(recall, precision, color='purple')#add axis labels to plot
ax.set_title('Precision-Recall Curve')
ax.set_ylabel('Precision')
ax.set_xlabel('Recall')#display plot
plt.show()
```

![](img/093be7a3989dc66e24efeabc4a51ba28.png)

è¿™è¡¨æ˜å¬å›ç‡ä¸º 0.82(82%çš„æ¬ºè¯ˆäº¤æ˜“åœ¨æµ‹è¯•æ•°æ®ä¸­è¢«è¯†åˆ«ä¸ºæ¬ºè¯ˆäº¤æ˜“)ï¼Œå…¶ä¸­ 20%è¢«é¢„æµ‹ä¸ºæ¬ºè¯ˆçš„äº¤æ˜“è¢«é”™è¯¯åœ°é¢„æµ‹)

## è®©æˆ‘ä»¬ä»ä¸åŒçš„è§’åº¦æ¥çœ‹è¿™ä¸ªé—®é¢˜ã€‚

> ç¬¬ä¸€æ­¥:æˆ‘ä»¬å°†è®©ç®—æ³•é¦–å…ˆé¢„æµ‹ä¸€ä¸ªæ¦‚ç‡æˆ–ç±»ä¼¼æ¦‚ç‡çš„åº¦é‡ã€‚
> 
> æ­¥éª¤ 2:ç„¶ååœ¨ä¸åŒçš„é˜ˆå€¼èŒƒå›´å†…ä½¿ç”¨ç²¾åº¦å’Œå¬å›ç‡æ¥è¯„ä¼°é¢„æµ‹çš„æ¦‚ç‡ï¼Œä»¥å°†æ¦‚ç‡æ˜ å°„åˆ°ç±»åˆ«æ ‡ç­¾ï¼Œå¹¶ä¸”ä½œä¸ºæœ€åä¸€æ­¥
> 
> æ­¥éª¤ 3:è¿™äº›é˜ˆå€¼æ›²çº¿ä¸‹çš„é¢ç§¯è¢«æŠ¥å‘Šä¸ºæ¨¡å‹çš„æ€§èƒ½ã€‚
> 
> æœ€ç»ˆç»“æœ:è¿™å…è®¸æœ€ç»ˆæ¨¡å‹çš„æ“ä½œè€…é€‰æ‹©å°†æ¦‚ç‡æ˜ å°„åˆ°ç±»åˆ«æ ‡ç­¾(æ¬ºè¯ˆæˆ–éæ¬ºè¯ˆäº¤æ˜“)çš„é˜ˆå€¼ï¼Œè¯¥é˜ˆå€¼æœ€å¥½åœ°å¹³è¡¡æœ€ç»ˆæ¨¡å‹çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡ã€‚
> 
> æˆ‘ä»¬å°†å¦‚ä½•åšç¬¬ä¸€æ­¥:å½“æ¶‰åŠåˆ°è¯„ä¼°æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**é‡å¤ k-fold äº¤å‰éªŒè¯å’Œåˆ†å±‚**ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦è¿™æ ·åšï¼Ÿåœ¨ k æŠ˜å ä¸­å…·æœ‰å¤§çº¦åä¸ªæŠ˜å ï¼Œå…¶ä¸­æ¯ä¸ªæŠ˜å åŒ…å« 284807/10 = 28480 ä¸ªç¤ºä¾‹ï¼Œè¿™å°†æ¯”å•ä¸ªè®­ç»ƒæµ‹è¯•åˆ†å‰²åšå¾—å¥½å¾—å¤šã€‚è¿™å°†ç¡®ä¿æ¨¡å‹æ€§èƒ½ä¸ä¼šåå‘äºéæ¬ºè¯ˆæ¡ˆä¾‹ã€‚**ä½¿ç”¨åˆ†å±‚**å°±åƒé”¦ä¸Šæ·»èŠ±ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿä¿æŠ¤ 99.8%åˆ° 0.2%çš„æ­£å¸¸å’Œæ¬ºè¯ˆäº¤æ˜“ã€‚**ç®€å•åœ°è¯´ï¼Œé‡å¤ 3 æ¬¡**æ„å‘³ç€è¯„ä¼°è¿‡ç¨‹å°†è¢«å¤šæ¬¡æ‰§è¡Œï¼Œä»¥é¿å…ç»“æœçš„å¶ç„¶æ€§ï¼Œå¹¶æ›´å¥½åœ°æ•æ‰æ‰€é€‰æ¨¡å‹çš„å˜åŒ–ã€‚

**ç¬¬ä¸€æ­¥:è®©ç®—æ³•é¢„æµ‹**

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä¾æ¬¡å®šä¹‰æ¯ä¸ªæ¨¡å‹ï¼Œå¹¶å°†å®ƒä»¬æ·»åŠ åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æŒ‰é¡ºåºå¯¹å®ƒä»¬è¿›è¡Œè¯„ä¼°ã€‚ä¸‹é¢çš„ *get_models()* å‡½æ•°å®šä¹‰äº†ç”¨äºè¯„ä¼°çš„æ¨¡å‹åˆ—è¡¨ï¼Œä»¥åŠç”¨äºç¨åç»˜åˆ¶ç»“æœçš„æ¨¡å‹ç®€ç§°åˆ—è¡¨ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ‰€æœ‰æµ‹è¯•çš„ç®—æ³•éƒ½å…·æœ‰è¿™ç§æŠ€èƒ½ï¼Œå®ç°äº†é«˜äºé»˜è®¤å€¼ 0.5 çš„ PR AUCã€‚ç»“æœè¡¨æ˜ï¼Œå†³ç­–æ ‘ç®—æ³•çš„é›†æˆåœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šéƒ½åšå¾—å¾ˆå¥½ã€‚

åˆ›å»ºä¸€ä¸ªå›¾å½¢ï¼Œæ˜¾ç¤ºæ¯ä¸ªç®—æ³•çš„ä¸€ä¸ªæ–¹æ¡†å’Œé¡»çŠ¶å›¾ã€‚è¯¥æ¡†æ˜¾ç¤ºä¸­é—´çš„ 50%æ•°æ®ï¼Œæ¯ä¸ªæ¡†ä¸­é—´çš„æ©™è‰²çº¿æ˜¾ç¤ºæ ·æœ¬çš„ä¸­å€¼ï¼Œæ¯ä¸ªæ¡†ä¸­çš„ç»¿è‰²ä¸‰è§’å½¢æ˜¾ç¤ºæ ·æœ¬çš„å¹³å‡å€¼ã€‚

![](img/c1268c16750166c0b444c26006616a2e.png)

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå†³ç­–æ ‘çš„ RF å’Œç³»ç»¼çš„åˆ†æ•°åˆ†å¸ƒæ˜¯ç´§å¯†çš„ï¼Œå¹¶ä¸”å¹³å‡å€¼ä¼¼ä¹ä¸ä¸­ä½æ•°ä¸€è‡´ï¼Œè¿™è¡¨æ˜åˆ†å¸ƒå¯èƒ½æ˜¯å¯¹ç§°çš„ï¼Œå¹¶ä¸”å¯èƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶ä¸”åˆ†æ•°å¯èƒ½æ˜¯ç›¸å½“ç¨³å®šçš„ã€‚ä¸Šè¿°ä»£ç å¦‚ä¸‹æ‰€ç¤º:

```
# spot check machine learning algorithms on the credit card fraud dataset
from numpy import mean
from numpy import std
from pandas import read_csv
from matplotlib import pyplot
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import auc
from sklearn.metrics import make_scorer
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import BaggingClassifier

# load the dataset
def load_dataset(full_path):
 # load the dataset as a numpy array
 data  = pd.read_excel(full_path,index_col= None, header= 0)
 # retrieve numpy array
 data = data.values
 # split into input and output elements
 X, y = data[:, :-1], data[:, -1]
 return X, y

# calculate precision-recall area under curve
def pr_auc(y_true, probas_pred):
 # calculate precision-recall curve
 p, r, _ = precision_recall_curve(y_true, probas_pred)
 # calculate area under curve
 return auc(r, p)# evaluate a model
def evaluate_model(X, y, model):
 # define evaluation procedure
 cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
 # define the model evaluation the metric
 metric = make_scorer(pr_auc, needs_proba=True)
 # evaluate model
 scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)
 return scoresdef get_models():
 models, names = list(), list()
 # CART
 models.append(DecisionTreeClassifier())
 names.append('CART')models.append( LogisticRegression())
 names.append('LR')
 # RF
 models.append(RandomForestClassifier(n_estimators=100))
 names.append('RF')return models, names# define the location of the dataset
full_path = 'creditcard.xlsx'
# load the dataset
X, y = load_dataset(full_path)
# define models
models, names = get_models()
results = list()
# evaluate each model
for i in range(len(models)):
 # evaluate the model and store results
 scores = evaluate_model(X, y, models[i])
 results.append(scores)
 # summarize performance
 print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))
# plot the results
pyplot.boxplot(results, labels=names, showmeans=True)
pyplot.show()
```

æˆ‘ä»¬å°†ä½¿ç”¨ RF æ¨¡å‹ä½œä¸ºæˆ‘ä»¬çš„æœ€ç»ˆæ¨¡å‹ï¼Œå› ä¸ºå®ƒå®ç°äº†é«˜ PR AUCã€‚

æ­£å¦‚æˆ‘ä»¬å¯èƒ½å¸Œæœ›çš„é‚£æ ·ï¼Œä½¿ç”¨ F åˆ†æ•°ä½œä¸ºåº¦é‡æ ‡å‡†ï¼Œå¤§å¤šæ•°ç¤ºä¾‹éƒ½å¯ä»¥é€šè¿‡é»˜è®¤é˜ˆå€¼ 0.5 æ­£ç¡®é¢„æµ‹ã€‚

```
 model = RandomForestClassifier(n_estimators=100)
model.fit(trainX, trainy)
# predict probabilities
yhat = model.predict_proba(testX)
# keep probabilities for the positive outcome only
yhat = yhat[:, 1]
# calculate roc curves
precision, recall, thresholds = precision_recall_curve(testy, yhat)
# convert to f score
fscore = (2 * precision * recall) / (precision + recall)
# locate the index of the largest f score
ix = argmax(fscore)
print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))
# plot the roc curve for the model
no_skill = len(testy[testy==1]) / len(testy)
pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')
pyplot.plot(recall, precision, marker='.', label='RF')
pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')
# axis labels
pyplot.xlabel('Recall')
pyplot.ylabel('Precision')
pyplot.legend()
# show the plot
pyplot.show()
```

![](img/6724f2f1890c02be1143c6d5dba9f22e.png)

æ‹Ÿåˆæœ€ç»ˆæ¨¡å‹åŒ…æ‹¬åœ¨æ‹Ÿåˆæ¨¡å‹ä¹‹å‰å®šä¹‰ç®¡é“æ¥ç¼©æ”¾æ•°å€¼å˜é‡ã€‚

ç„¶åï¼Œå¯ä»¥ä½¿ç”¨ç®¡é“ç›´æ¥å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä½¿ç”¨ä¸å¯¹è®­ç»ƒæ•°æ®é›†æ‰§è¡Œçš„æ“ä½œç›¸åŒçš„æ“ä½œæ¥è‡ªåŠ¨ç¼©æ”¾æ–°æ•°æ®ã€‚

# **ç»“è®º**

æ€»ä¹‹ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•ç”¨å¼ºå¤§çš„æµ‹è¯•å·¥å…·ç³»ç»Ÿåœ°è¯„ä¼°ä¸€å¥—æœºå™¨å­¦ä¹ æ¨¡å‹&å¦‚ä½•æ‹Ÿåˆæœ€ç»ˆæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥é¢„æµ‹ç‰¹å®šæ¡ˆä¾‹ä¸­çš„æ¬ºè¯ˆæ¦‚ç‡ã€‚