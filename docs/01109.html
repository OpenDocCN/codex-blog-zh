<html>
<head>
<title>Apache Spark Optimization Techniques and Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark优化技术和调优</h1>
<blockquote>原文：<a href="https://medium.com/codex/apache-spark-optimization-techniques-and-tuning-52cc446c07f5?source=collection_archive---------1-----------------------#2021-04-05">https://medium.com/codex/apache-spark-optimization-techniques-and-tuning-52cc446c07f5?source=collection_archive---------1-----------------------#2021-04-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/27bffe9b64271cd0a04d6851c3efb01a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*wUGg1qzXT---UWWQ4VcomQ.jpeg"/></div></figure><h1 id="ef9e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">简介</strong></h1><p id="8c09" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">众所周知，数据是新的石油。数据呈指数级增长；随着时间的推移，数据分析和客户预测方法一直在变化，现在有些技术已经过时，有些技术即将过时。大多数组织都在向微服务和大数据处理和处理机制发展。</p><p id="6d17" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">架构正朝着快速可靠的技术和工具发展。在开始优化技术和Spark架构之前，让我们了解什么是大数据，以及Apache spark与大数据的关系。</p><h1 id="fbdf" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">大数据</h1><p id="dce1" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">传统工具和技术无法存储和处理的大量数据的集合被称为大数据。</p><p id="d7a8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">谷歌迈出了解决这个问题的第一步。他们在2006年发布了一个框架，命名为<a class="ae kn" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank"> <em class="ko"> Hadoop </em> </a>，后来捐赠给了阿帕奇基金会。该框架使用map-reduce编程范式，能够分别存储和处理大量数据(HDFS)和(蜂巢、猪等)。但是，由于Hadoop运行在商用硬件上，大多数处理都是在存储级别完成的，这最终会增加读写操作，从而导致更多的处理时间。这个后来被阿帕奇Spark解决了。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kp"><img src="../Images/df3e43c2fbefbe65c1474afec1f5730d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_GlZzoLsTnZvjZhCfwgBYg.png"/></div></div></figure><h1 id="abf7" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">阿帕奇火花</h1><p id="e731" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">Apache Spark是一个用于大规模数据处理的统一分析引擎。你可以把它想象成一个处理引擎，与Hadoop相比，它可以更快地处理你的数据(无论大小)。</p><h1 id="d783" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">是什么让阿帕奇火花更快</h1><h2 id="9811" class="ky in hi bd io kz la lb is lc ld le iw jv lf lg ja jz lh li je kd lj lk ji ll bi translated">1.内存计算</h2><p id="5f78" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">Spark将大部分内容存储在RAM中，这减少了磁盘IO。类似的处理在其他技术中需要更多的时间。</p><h2 id="6948" class="ky in hi bd io kz la lb is lc ld le iw jv lf lg ja jz lh li je kd lj lk ji ll bi translated">2.懒惰评估</h2><p id="3f14" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">一旦一个语句被执行，Spark就创建一个RDD的DAG(有向无环图)。只有当一个动作语句被执行时，处理才开始。我们将在spark架构中看到这一点。</p><p id="6039" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们举一个例子，惰性评估会影响执行时间和处理时间。</p><p id="c26e" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">假设我们有一个包含考试分数的表，我们需要过滤掉分数在90%以上和91%以下的学生(学生人数大约为1000万)。</p><p id="01db" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">然后我们写一个这样的代码。</p><p id="e4ff" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><em class="ko">df = spark . read . parquet(" some location ")<br/>df = df . filter((col(marks)&gt;90)&amp;(col(marks)&lt;91)<br/>df . show()</em></p><p id="f29c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">一个传统的工具首先试图读取所有的数据，将其存储在某个位置然后根据条件过滤出来并显示数据，而Spark会取满足上述条件的记录，然后开始其他操作。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/c7ce41d4a1663f6ff8d2a15f22fe547c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*WR20k1gVq1bx9r4Lv6caTg.jpeg"/></div></figure><h2 id="fa2d" class="ky in hi bd io kz la lb is lc ld le iw jv lf lg ja jz lh li je kd lj lk ji ll bi translated">Apache Spark架构(用简单的语言)</h2><p id="8704" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">Spark基于主从架构，其中在连接到集群管理器的主节点上将有一个驱动程序，集群管理器将任务分配给工作器。接下来，任务的执行完成，工作者将结果发送到主节点。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/2ac59def3b4fe4cc312c64ec827e21d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/0*_hhVjAihfqL9jVti.png"/></div></figure><h1 id="48f6" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">优点和局限性</h1><p id="f5ab" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">尽管有很多好处，Spark仍然有一些局限性。让我们一个一个来看。</p><h2 id="c04e" class="ky in hi bd io kz la lb is lc ld le iw jv lf lg ja jz lh li je kd lj lk ji ll bi translated">利益</h2><ol class=""><li id="c616" class="lo lp hi jm b jn jo jr js jv lq jz lr kd ls kh lt lu lv lw bi translated">内存计算——这意味着更少的IO、更少的执行和处理时间。</li><li id="8d81" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">容错-基本数据结构是RDD(弹性分布式数据集)。一旦将程序提交给驱动程序，DAG调度程序就会在工作线程上调度作业和任务。如果在某个时刻，任何RDD变换/操作失败，则调度器检查DAG，并且它可以再次重新处理失败的RDD。</li><li id="d23d" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">实时流处理——使用Spark流，我们可以轻松处理流数据。在数据帧添加到Spark流之后，它变得非常好用。</li><li id="a02e" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">多语言支持——我们可以用Python、Java、Scala和r编写spark代码。</li><li id="034a" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">兼容Hadoop和各种对象存储。</li></ol><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mc"><img src="../Images/4c506903faea84d175796999d7dafc7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n4Z9qdvE9cg4Plgw-vrZtQ.jpeg"/></div></div></figure><p id="793c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">限制</strong></p><ol class=""><li id="7f09" class="lo lp hi jm b jn ki jr kj jv md jz me kd mf kh lt lu lv lw bi translated">没有文件管理系统Spark没有提供文件系统，我们需要将数据存储在hdfs/s3/local文件系统中。</li><li id="7548" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">实时数据处理——尽管Spark提供了一个流特性，但它在内部将数据转换为分区，将分区转换为微批处理，并一次处理一个微批处理。所以没有实时处理。</li><li id="32dc" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">昂贵——因为主存储(RAM)总是比辅助存储(硬盘)昂贵，并且Spark在主存储器中完成大部分操作，所以这是一个昂贵的工具。</li><li id="f066" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">内存不足问题——有时，您的数据消耗的内存比可用的RAM多，在这种情况下，就会出现内存不足问题。</li></ol><p id="4240" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">尽管存在这些问题，但有一些技术可以减少处理时间和内存问题。我会试着在博客中列出一些我知道并实现的。</p><h1 id="7d51" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">优化技术</h1><ol class=""><li id="cce0" class="lo lp hi jm b jn jo jr js jv lq jz lr kd ls kh lt lu lv lw bi translated"><strong class="jm hj">尽早过滤数据</strong>:这是我们在数据处理中可以运用的最有效、最简单的技术。我们可以应用两种类型的过滤。<br/> <em class="ko"> a .列级过滤</em>——只选择那些需要进一步处理和执行的列。<br/>示例:df.select (col("col1 ")，col("col2 ")，col("col3 ")，col(" col 4 ")<br/><em class="ko">b .行级过滤</em>:过滤掉不需要进一步处理的数据。<br/>Example-df . filter(some condition)<br/>当你尽可能早地过滤掉数据，那么有效地处理数据所花费的时间就更少，最终导致处理时间更少。</li><li id="a8da" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated"><strong class="jm hj">文件格式选择:</strong>文件格式对处理时间起着重要的作用。由于读取时间和写入时间也计算在处理中，我们需要在选择文件格式时记住这些指针。<br/>我<em class="ko">。</em> <strong class="jm hj"> <em class="ko">拼花</em></strong>——拼花是一种柱状格式。将拼花作为一种文件格式的好处是——它占用的空间更少:拼花存储提供了更好的汇总数据，并遵循特定类型的编码。Parquet支持压缩——比如snappy、gzip、lzo。Parquet的限制:当我们试图从Parquet中读取一个记录时，这是一个开销很大的操作，因为这是一个列文件格式。与Avro等其他二进制文件格式相比，编写一个Parquet文件需要更多的时间。<br/>二。<strong class="jm hj"> Avro </strong> — Apache Avro是一个语言中立的数据序列化系统。Avro有一个基于模式的系统。Avro有两个组成部分:a)二进制数据:数据以二进制格式存储，并用Avro模式序列化数据。b)Avro模式是json格式的字符串/文件，用于序列化/反序列化数据。<br/>三。<strong class="jm hj">CSV/TSV/分隔文件</strong> —数据以明文和表格格式存储。<strong class="jm hj">优点</strong> -这种文件格式是人类可读的，可能在标题中包含列信息。数据解析非常简单，因为CSV可以被视为2D数组。<strong class="jm hj">限制</strong> -需要更多存储空间来存储数据(最高)。结构和数组数据类型的实现可能有点麻烦，因为它不太支持特殊字符，不支持列类型，而且文本列和数字列之间没有区别。<br/>四<strong class="jm hj">。JSON/XML</strong>——这些是以键值模式表示的半结构化数据文件类型。JSON现在被更广泛地使用，因为它比XML使用更少的内存。<strong class="jm hj">优势</strong> - JSON支持复杂的数据结构。用JSON处理数据非常简单，因为JSON解析器在所有主流编程语言中都可用。</li><li id="70a6" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated"><strong class="jm hj"> API选择- </strong> Spark提供了三种类型的API来处理数据，即RDD(弹性分布式数据集)、数据帧和数据集。为了获得最佳性能，我们应该通过观察用例来使用上述三个API。<br/> 1。<strong class="jm hj">RDD</strong>——RDD是Spark工作的基本数据结构。当用例要求低层次的计算和操作，如文本提取时，这将是有用的。Spark中没有默认提供的优化，因此我们必须非常精确地应用逻辑并自行优化代码。这里的数据过滤在早期阶段是非常重要的。<br/> 2。<strong class="jm hj"> DataFrame - </strong>你可以把数据帧想象成一个SQL表或者二维数组，能够存储复杂的数据类型，比如结构/数组。对于我们必须处理表格数据的用例，这是最好的选择。DataFrame使用catalyst优化器创建查询计划，并有一个优化流程，即分析- &gt;逻辑优化计划- &gt;物理计划- &gt;代码生成(如下图所示)。<br/> 3。数据集是高度类型安全的，并使用编码器作为其序列化的一部分。他们还使用钨作为二进制格式的串行器。因为数据集是类型安全的，所以您需要在使用数据之前定义一个模式。使用数据集的主要优点是编译时错误分析和数据类型修正，这样，在数据读取/转换时，您就不会面临数据类型的问题。与数据帧相比，它需要更少的内存。因此，在我们必须坚持使用模式，而不想在阅读时生成模式的用例中，我们应该选择数据集。</li></ol><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mg"><img src="../Images/33c097ae82776e93d503c451a0c72f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IsOMq0iHwo5J2XkjNLdoeQ.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">催化剂优化器</figcaption></figure><p id="1aaf" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">5.<strong class="jm hj">提前变量的使用- </strong> Spark提供两个提前变量:累加器和广播变量。<br/>累加器是仅通过关联操作“添加”到Spark的变量，因此可以有效地并行支持。它们可以用来实现计数器(作为Hadoop中的计数器)。<br/>广播变量是在作业/程序执行时存储在集群中每个节点的变量。同时处理大数据和小数据可以节省大量时间。它将小数据集发送到所有节点，因此Jon在执行作业时花费的时间更少。</p><p id="4843" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">6.<strong class="jm hj">使用Coalesce/Repartition的并行性</strong> -并行性是大数据中数据处理的核心。当您在Spark上的console/submit中创建代码时，它会创建一个操作符图。当我们调用action时，这个操作符图被提交给DAG调度程序。DAG调度程序将操作员分成不同的任务阶段。一个阶段包含一个基于数据分区数量的任务。这些阶段将被传递给任务调度程序。通过集群管理器，这些任务在工作节点(执行器)上执行。玩分区是一把<strong class="jm hj">双刃剑</strong>，因为当我们增加代码中的分区数量时，执行器级别的并行性会增加，但与此同时，执行器会将其执行结果传递给驱动节点。然后，驱动程序节点需要组合所有结果，这又需要时间，这会影响执行的总体时间。所以要小心玩转排比。</p><p id="35ec" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">7.<strong class="jm hj">数据串行化- </strong>串行化有助于将对象转换成字节流，反之亦然。当我们进行任何类型的计算时，我们的数据都会被转换成字节并通过网络传输。如果通过网络传输的数据越少，作业执行所需的时间就越少。Spark提供了两种类型的序列化。</p><ol class=""><li id="8f87" class="lo lp hi jm b jn ki jr kj jv md jz me kd mf kh lt lu lv lw bi translated"><strong class="jm hj"> Java序列化</strong>——Object output stream在spark中序列化对象。由java.io.Externalizable控制的序列化的性能很灵活，但非常慢。相反，我们可以使用Kyro序列化。</li><li id="b785" class="lo lp hi jm b jn lx jr ly jv lz jz ma kd mb kh lt lu lv lw bi translated">Kyro序列化是一个快速高效的Java二进制对象图序列化框架。它对字段使用直接字节码级别的访问。要使用Kyro，首先我们需要注册一个类。否则，它将从50多个默认类别中选择。如果仍然没有找到任何类，那么它将选择fieldserializer。Kyro序列化比Java序列化快。你可以在这里 阅读关于连载<a class="ae kn" href="https://github.com/EsotericSoftware/kryo" rel="noopener ugc nofollow" target="_blank"> <em class="ko">。<br/>登记一个班级-<br/>-<em class="ko">。registerKryoClasses(Array(class of[employee]，class of[class])</em><br/>在定义spark session时，我们需要将序列化设置为kyro<br/><em class="ko">spark _ session = spark session \<br/>。构建器\ <br/>。config("spark.serializer "，" org . Apache . spark . serializer . kryoserializer ")\<br/>。config(" spark . kryo . registration required "，" false")\ <br/>。appName("appname")\ <br/>。主人('纱')\ <br/>。getOrCreate() </em></em></a></li></ol><p id="ea51" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">8.<strong class="jm hj">缓存和解析</strong> —正如我们所知，spark有一个惰性评估，即它不会开始处理数据，直到一个动作被调用。每次调用一个动作，你的RDD dag就会被调用。每当这种情况发生时，所有的进程都会被调用，数据会从头开始处理。让我们举一个例子</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ml"><img src="../Images/00584a1be91f9ef064522acc4ebdda22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZIWqmU5Vwj7YXdxUZjCxZg.png"/></div></div></figure><p id="753c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们有2个数据帧:DF1和DF2，通过连接它们我们得到DF12的结果，然后我们需要连接DF12和DF3，得到结果数据帧DF123。<br/>所以如果我们运行下面的代码:</p><p id="22b8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><em class="ko"> df12=df1.join(df2，on =[df1[" some key "]= = df2[" some key "]，how = " inner ")<br/>df12 . write . parquet(" some _ location _ 1 ")<br/>df 123 = df12 . join(df3，on=["somekey"]，how = " inner ")<br/>df12 . write . parquet(" some _ location _ 2 ")</em></p><p id="1566" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在这种情况下，首先调用df12操作，第2行和第2行将保存在some_location_1，一旦调用df123操作和第4行，spark将再次读取df1和df2，并将连接此数据帧并计算已经计算的数据。因此，为了节省时间，我们可以使用cache/persist将df12保存在内存/磁盘上。所以，上面的程序可以这样写。</p><p id="a304" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><em class="ko"> df12=df1.join(df2，on =[df1[" some key "]= = df2[" some key "]，how = " inner ")<br/></em><strong class="jm hj"><em class="ko">df12 . cache()</em></strong><em class="ko"><br/>df12 . write . parquet(" some _ location _ 1 ")<br/>df 123 = df12 . join(df3，on=["somekey"]，how = " inner))<br/></em></p><p id="f578" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">何时不使用缓存/持久化</strong> -当数据的大小很大并且有多个dfs可用于缓存时。</p><p id="b6e9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">9.<strong class="jm hj">减少混洗操作</strong>——混洗是Spark中开销最大的操作，因为它在网络和磁盘上移动数据。所以洗牌越少，你的操作执行时间就越少。由于现在我们大多使用df，所以我不会建议你使用reduceByKey或groupByKey。过一会儿我们将学会如何做那件事。<br/>通过设置<strong class="jm hj"> </strong> <code class="du mm mn mo mp b"><strong class="jm hj">sparkSession.conf.set("spark.sql.shuffle.partitions",x), <br/></strong></code> <strong class="jm hj"> </strong>我们可以启用洗牌分区。<br/>理想情况下，每个分区的一个任务应该是100-200 MB。</p><p id="1d69" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最佳结果的公式是<br/> <code class="du mm mn mo mp b">spark.sql.shuffle.partitions</code> =(洗牌阶段输入大小/目标大小)/核心总数)*核心总数。</p><p id="7865" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在Spark 3.x中，我们新增了一个自适应查询执行的特性。当<strong class="jm hj">spark . SQL . adaptive . enabled</strong>置为真并且<strong class="jm hj">spark . SQL . adaptive . coalesce partitions . enabled</strong>置为真时，那么洗牌分区的数量可以由spark动态更新。为了获得更好的效果，您可以在默认大小为64mb的<strong class="jm hj">spark . SQL . adaptive . advisorypartitionsizeinbytes</strong>附近玩。</p><p id="484a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">10.<strong class="jm hj">设置广播加入的限制</strong> —当我们在Spark中广播一个表时，该表将被分发给所有工作人员，执行时间将会更短，但有一个默认值设置为10MB。我们可以通过设置<strong class="jm hj">spark . SQL . autobroadcastjointhreshold .</strong>来增加</p><p id="67e0" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">11.<strong class="jm hj">SQL执行时压缩数据- </strong>虽然这不会显著减少执行时间，但它将:a)防止内存不足问题，b)在执行时压缩数据。这可以通过将一个参数<code class="du mm mn mo mp b"><strong class="jm hj">spark.sql.inMemoryColumnarStorage.compressed</strong></code>设置为真来轻松完成。</p><p id="9159" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">12.<strong class="jm hj">内存和资源分配- </strong>当我们在集群或本地运行Spark作业时，最重要的事情是只为应用程序分配所需数量的内存和内核。如果操作不正确，您将无法并行运行作业，并且大多数作业将会失败。所以回到基础。</p><p id="f2a7" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">Spark有驱动者、执行者和我们(我们的spark集群；可以是独立的)具有用于工作人员和驱动程序的内核和内存。让我们举一个例子来理解其中涉及的数学，然后我们将根据它来设置属性。<br/>假设我们有128 GB内存和32个内核用于驱动程序(主节点), 64GB内存和16个内核用于4个工作节点。因此，总内存为384GB (4*64 +1*128)，总共有96个内核(16*4 + 1*32)。</p><p id="3417" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，如果我们想要运行200GB的作业。假设数据计算会有一些分组和计数操作，所以驱动程序也需要一些内存。</p><p id="e469" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">每个节点的执行器数量=每个执行器4个<br/>内存=每个执行器15GB <br/>内核=3个<br/>执行器总数= 15个<br/>驱动程序内存=20GB</p><p id="ba41" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在让我们来看看计算。<br/>每个节点的执行器数量将=15/4 ≈ 4，这意味着在3个工作线程上将产生4个执行器，在第4个节点上将产生3个执行器。<br/>分配的总内存将=执行器的总数量*每个执行器的内存= 15*15= 225GB，这大于数据大小(开销和中间输出应分配一些内存)。</p><p id="4ae1" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们看看Spark提交命令。我将使用<strong class="jm hj"> pyspark提交。</strong></p><blockquote class="mq mr ms"><p id="a6f5" class="jk jl ko jm b jn ki jp jq jr kj jt ju mt kk jx jy mu kl kb kc mv km kf kg kh hb bi translated">spark-submit—master local—conf "<strong class="jm hj">spark . executor . cores = 45</strong>"—conf "<strong class="jm hj">spark . cores . max = 3</strong>"—executor-memory<strong class="jm hj">15g</strong>—driver-memory<strong class="jm hj">20g</strong>—py-files " some _ py _ files " " python _ file _ to _ be _ executed . py "</p></blockquote><h1 id="083c" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">结论</h1><p id="7e6d" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">通过这篇文章，我们看到了Spark是如何帮助处理数据的。我们也看到了spark的局限性，然后我们了解了如何优化执行时间和空间管理。我希望这能对你在Spark上的工作有所帮助。如果我需要增加更多的分数，请告诉我。建设性的反馈总是令人感激的！</p></div></div>    
</body>
</html>