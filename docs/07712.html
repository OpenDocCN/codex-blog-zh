<html>
<head>
<title>Gradient Descent Math Over Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">过度简化的梯度下降数学</h1>
<blockquote>原文：<a href="https://medium.com/codex/gradient-descent-math-over-simplified-e2b38fddfaa0?source=collection_archive---------6-----------------------#2022-06-23">https://medium.com/codex/gradient-descent-math-over-simplified-e2b38fddfaa0?source=collection_archive---------6-----------------------#2022-06-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="83f4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">梯度下降</h1><p id="ac78" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">梯度下降是大多数机器学习背后的支柱。当您将机器学习方法用于训练数据集时，您可能会使用梯度下降。在这篇文章中，我决定向你展示它是如何工作的，所以如果你想知道这背后的数学原理，请继续关注。我会试着用简单的术语来描述一切。这篇文章假设你已经知道最小二乘法和线性回归的基础知识，如果你还不了解，你可以参考我以前的文章，熟悉这些概念。</p><h1 id="52a0" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">使用</h1><p id="d761" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在统计学、机器学习和其他数据科学领域，我们优化了很多东西。当我们用线性回归拟合一条线时，我们优化了截距和斜率。</p><div class="kb kc kd ke fd ab cb"><figure class="kf kg kh ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/2cf22b08915e5366d9a3deba90bf4713.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/0*3VbU5dNwhNIUrbub"/></div></figure><figure class="kf kg ks ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/59c8107e0b832c19e463954b9e1acdab.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/0*h0-H9q8ldBmWx7AC"/></div></figure></div><p id="879e" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">当我们使用逻辑回归时，我们优化了曲线。当我们使用t-sne时，我们优化了集群。梯度下降很酷的一点是，它可以优化这一点，甚至更多。如果你学会了优化线的策略，你可以很容易地优化曲线，也可以在以后的时间点优化簇。不仅如此，你将能够看到统计学、ML和数据科学中更多的优化问题。</p><h1 id="89e5" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">到底是什么？</h1><blockquote class="ky kz la"><p id="41a5" class="jd je lb jf b jg kt ji jj jk ku jm jn lc kv jq jr ld kw ju jv le kx jy jz ka hb bi translated">梯度下降是一种使用一阶迭代来解决优化问题的算法。由于梯度下降被设计成寻找微分函数的局部最小值，所以它被广泛用于机器学习模型<strong class="jf hj">中，以寻找使模型的成本函数最小化的最佳参数</strong></p></blockquote><div class="kb kc kd ke fd ab cb"><figure class="kf kg lf ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/721dd2e55756b8e0377c205672f28786.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*sjC3ZMvpRW65Ob_KuqoHGg.png"/></div></figure><figure class="kf kg lg ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/05724c496129a6c5eedcdef7cec13505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*uGrT1i-FAlF79YRNVngnqQ.png"/></div></figure></div><p id="830e" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">让我们先想一个例子。我将从非常著名的《猫和老鼠》系列中挑选最受欢迎的杰里</p><p id="7f00" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">如果我们拟合这个数据，有人告诉我杰里的体重是1.5，我可以用直线预测杰里的身高将是1.9(见下图截图)。</p><p id="52be" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">换句话说，给定Jerry &amp; a线的重量→我可以预测Jerry的高度。</p><ul class=""><li id="c96a" class="lh li hi jf b jg kt jk ku jo lj js lk jw ll ka lm ln lo lp bi translated">因此，让我们来了解一下梯度下降是如何帮助拟合数据的。</li><li id="4106" class="lh li hi jf b jg lq jk lr jo ls js lt jw lu ka lm ln lo lp bi translated">为了拟合数据，我们需要<strong class="jf hj">找到截距和斜率的最佳值，这就是我们将在本文中讨论的内容。</strong></li></ul><h1 id="89f6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目标</h1><p id="339a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">整篇文章将围绕我们如何使用梯度下降通过寻找斜率和截距的最佳值来拟合直线。</p><p id="bf2b" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">第1部分目的:我们从使用梯度下降法寻找斜率开始。</strong></p><p id="7dff" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">第2部分目的:稍后使用梯度下降来解决截距和斜率。</p><h1 id="e8d2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">第1部分的步骤1 Aim →找到截距为0的最小二乘</h1><p id="2f1e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">最小二乘法<strong class="jf hj">是一种统计程序，通过最小化绘制曲线</strong>中各点的偏移或残差的总和，找到一组数据点的最佳拟合。</p><p id="699c" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们首先插入斜率的最小二乘估计值0.64，并描绘截距的随机值。让我们选择0，只是一些开始。这只是给了GD一些开始的东西，让梯度下降得到改善。我们有3个坐标(0.5，1.4)，(2.3，1.9)，和(2.9，3.2)表示体重和身高。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lv"><img src="../Images/d8761fc834433ba19f2fb0ffa262fd33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6kGZF95829on7_-P"/></div></div></figure><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lw"><img src="../Images/f4d14749196a9c3cf075e96023a50049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6apVq42uuRbEST0S"/></div></div></figure><h2 id="1bbd" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">公式为观测高度-预测高度=残差</h2><h2 id="c712" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">1.4(这是我们给定的实际高度)—预测高度</h2><p id="be3e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这种情况下，我们将使用intercept作为0，但任何数字都可以。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lw"><img src="../Images/188ca26a6db95bba506393204e642b37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iHM15olvwKH_GMTI"/></div></div></figure><p id="dcfb" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">在这种情况下，我们将使用截距作为0，但任何数字都可以。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lw"><img src="../Images/40f47b40ec4ffa4ae0223927a6063e9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-FsrW4WaFZ6uucXg"/></div></div></figure><h1 id="6aeb" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">预测身高= 0 +0.64 * 0.5给定体重</h1><p id="0a91" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这就给出了这条线的方程。</p><h2 id="8a7d" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">1.4(这是我们的实际身高)-0.32(这是预测身高)</h2><h2 id="a499" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">= 1.1(四舍五入)</h2><p id="f0f4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">使用残差平方和/损失函数，让我们看看这条线是如何拟合数据的。</p><p id="78f2" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">让我们计算所有值的残差平方和。请参考下面的截图。我们有体重和身高的3个坐标(0.5，1.4)，(2.3，1.9)，(2.9，3.2)。</p><div class="kb kc kd ke fd ab cb"><figure class="kf kg ml ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/b78e35f010910c57a0c7876415fdcc6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1542/0*yd9RTh7HNkxiNgch"/></div></figure><figure class="kf kg mm ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/19f6ef75599a6c8b07af9a0957e24b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/0*EJDFeOEgwSEdJSpu"/></div></figure></div><blockquote class="ky kz la"><p id="de15" class="jd je lb jf b jg kt ji jj jk ku jm jn lc kv jq jr ld kw ju jv le kx jy jz ka hb bi translated"><strong class="jf hj">回答:我们现在得出截距为0的残差平方和为3.1。</strong></p></blockquote><h2 id="bd12" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">第二步:我们将在y轴上绘制3.1的残差，在x轴上绘制0的截距。</h2><p id="2a69" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">换句话说，第一个点是图中截距为0且残差平方和为3.1的点。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div class="er es mn"><img src="../Images/45f3f86219ea3684e8f0f3e090ffadeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*aNykm5mwdwJHsrOBuQf4Jg.png"/></div></figure><h2 id="1e70" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">第三步:重复第一步和第二步，取截距为0.25和0.5，而不是0</h2><p id="7d79" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">如果截距是0.25而不是0，那么使用上面相同的计算，你将得到图中的第二个红点。类似地，当截距为0.5时，你会得到右边图中的第三个点，我们继续猜测截距..我们得到了这条U形曲线和残差平方和的方程。</p><p id="5ff9" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">现在我们在寻找截距，我们分别尝试了0，0.25，0.5的值，你开始怀疑..</p><p id="63f2" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><em class="lb">“如果截距的最佳值介于右图中的值之间，会怎么样？”如果您查看下面的右图，当截距值= 1时，残差平方和最低。如果残差平方和是圆之间某处的一点呢？</em></p><p id="b41f" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">为了找到答案，我们必须经历使用更多值的痛苦过程。这是一个痛苦的过程。想想在超人故事的背景下，哥谭市受到坏人的攻击，当地警察很难找到坏人，我们有很多嫌疑人。</p><div class="kb kc kd ke fd ab cb"><figure class="kf kg mo ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/f94c2be73239d17b4a621bbbb8d8ed5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*Xf3a5aOfq3SZ1AzcYDel8w.png"/></div></figure><figure class="kf kg mp ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/d94d147e9e7f58a9f9ea5b20b24cbf32.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*4xFP5RwT0obChJXQxs20qA.png"/></div></figure></div><p id="dc2d" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">当蝙蝠女(梯度下降)介入，故事情节发生变化。利用她的超能力和她的速度，她匹配了恶棍的照片，很快扫描了所有的嫌疑人，并给恶棍戴上了手铐。梯度下降就像一个蝙蝠女侠！你可以把梯度下降想成一个大飞跃跳下高楼，不需要打车的超级英雄哈哈。与此同时，当她接近恶棍时，改变她的姿态，用小而多的步子慢慢踮着脚。<br/>类似地，梯度下降做一些距离很远的计算&amp;跳跃很大，但是当她接近最佳值时做更多的计算，并且以最小化最小平方和的方式做它。请注意，当远离恶棍时，步长必须足够大，但不能大到错过恶棍，并最终使最小平方和最大化。当她爬向恶棍时，脚步必须很小。<br/>查看下面的图示，您可以看到数字1周围的红点数量增加。</p><div class="kb kc kd ke fd ab cb"><figure class="kf kg mq ki kj kk kl paragraph-image"><img src="../Images/ba8cc045ad31f47c3d1c4d80dc45123d.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/0*G4wuGNjQcd7aNJtt"/></figure><figure class="kf kg mr ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/148c7e046d27b52cef3435292bd51f6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/0*M-tE1KSqDhOC6NmS"/></div></figure></div><div class="ab cb"><figure class="kf kg ms ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/4c1fae4e64a59916c98487b0b62f7476.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*gnRFT-ACnLbDdbKH1uITyA.png"/></div></figure><figure class="kf kg mt ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/ffa276128d39a6b023988bb64e9c1403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*T2-e1eqDTEmahYvMnxGsrA.png"/></div></figure></div><h1 id="0415" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">进近解释后面的梯度下降数学</h1><h1 id="e205" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">进近解释后面的梯度下降数学</h1><p id="cc5b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">梯度下降使用导数来寻找残差平方和最低的地方。</p><p id="ff5d" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们现在有了这条曲线的方程式(见上图)。这是当我们绘制所有残差3.1的截距为0，xxx残差的截距为0.25，yyy残差的截距为0.5，等等，我们得到了这个U形图。</p><p id="b2c6" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们可以用该函数的导数来确定截距任意值的斜率。以下是步骤:</p><p id="d0e5" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">第一步:对每个参数的损失函数求导。</strong></p><p id="682d" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">第二步:为参数选择一个随机值</strong></p><p id="0228" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">第三步:将参数值代入导数</strong></p><p id="b937" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">步骤4:计算步长{步长=斜率*学习率</strong></p><p id="591a" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">步骤5:计算新参数，即旧参数减去步长</strong></p><p id="2ad2" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">重复第3步，直到步长太小或用尽最大步长1000。</strong></p><p id="ea14" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">视觉上，在宏观层面上，Bat-Woman(梯度下降)从最初的猜测到最佳值采取步骤。现在让我们进入细节。</p><h2 id="dce7" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated"><strong class="ak"> <em class="mu">第一步:求导得到斜率</em> </strong></h2><p id="eb85" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">所以我们可以把它分解成，对这三部分逐一求导。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/828a9bf5eb252ade00e1728bd9bd7aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mId7in9FYqP7tFAB"/></div></div></figure><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mw"><img src="../Images/c03433f13aa84b7e80459238c31cc112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uPvxQQ2vpcY4XaNe"/></div></div></figure><h2 id="3da3" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated"><strong class="ak">第二步:在导函数中输入截距为0的随机值</strong></h2><div class="kb kc kd ke fd ab cb"><figure class="kf kg mx ki kj kk kl paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><img src="../Images/0d54534fa62bc2bde92b957b9c1c1ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/0*96Ri2bSeRdd6vR-V"/></div></figure><figure class="kf kg my ki kj kk kl paragraph-image"><img src="../Images/f7e6a637c7f72aa4c977e75b3016066b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/0*MxZB2KwTii6xtyPc"/></figure></div><p id="db69" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">概括一下，我们从一个0作为截距的随机数开始。我们将0代入导数，得到斜率为-5.7。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/b8377de0d7107e7b4ea2807ab828ec54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VQ92D4v0lCxog1qE"/></div></div></figure><p id="1373" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">斜率的答案是-5.7。</p><p id="b9bf" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">请注意，当截距为0时，斜率为-5.7。</p><p id="509e" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">您是否注意到，当我们接近截距的最佳值时，斜率会自动接近0？超级爽！见下文。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mz"><img src="../Images/e12df0de3f385c3826e39d25c7956eec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SDtee0NAAa6vtvz3"/></div></div></figure><p id="f137" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">这就是我们故事中的一点，蝙蝠女侠观察到她快要抓住坏人了，也就是找到了最佳价值，然后改变了姿态，迈出了小步。相比之下，当斜率远离零时，蝙蝠女侠知道她必须迈出大步，从高楼上跳下，迈出巨大的步伐。她根据坡度测量每一步的大小。接下来，我们将讨论我们的梯度下降/蝙蝠女侠中存在的超能力，以及她后脑勺发生的计算，以确定下一步的大小以及她将采取的下一步行动。让我们对此进行深入研究。</p><h2 id="8dbd" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">步骤4:现在我们有了斜率，使用斜率来计算步长，这将决定我们的下一步应该是多大(大，小还是中等大小？)</h2><p id="caa0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">秘方是梯度下降用一个叫做学习率的小数字乘以斜率(我们从导数函数中得到)。这种情况下的学习率是0.1，这决定了步长-0.57 (-5.7*0.1)。我们的步长是-0.57。</p><h2 id="f350" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">步骤5:根据步长找到下一步的值</h2><h2 id="516e" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">计算旧参数或步长的新参数</h2><p id="13c0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们需要从旧截距中减去这个步长来得到新截距。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es na"><img src="../Images/fca2dc7becc2a5235241bfe3c8391658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eUnOSZ5zCiFRZoof"/></div></div></figure><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/6661d90cb1a075ce0a7a2423f46243d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cmB4ib-puZV07QJQ"/></div></div></figure><p id="f7b0" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">所以用这个，蝙蝠女侠从0开始下一步，移动到0.57。这是一个巨大的举动！<br/>接下来呢？蝙蝠女侠需要再走一步。我们有一个新的截距0.57，我们把它放回导数方程，得到斜率-2.3。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/6539bb5231b3744836b9def38e368e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*suYZBhpAGLBjOo5Q"/></div></div></figure><p id="3330" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">按照规则，我们用学习率0.1乘以-2.3，得到步长-0.23。<br/>这个步长需要从旧截距中减去0.57 -(0.23) = 0.8。与之前的步骤相比，现在梯度下降需要相对较小的步骤。正如预测的那样，当我们接近曲线底部时，台阶会越来越小。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es nb"><img src="../Images/2c6951c4b3db21501425d4f25591f56b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VJBQf9lEPqCIDf_q"/></div></div></figure><p id="a585" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">这说明了batwoman是如何利用这种计算向截距的最佳值迈进一步的。</p><h2 id="6d94" class="lx ig hi bd ih ly lz ma il mb mc md ip jo me mf it js mg mh ix jw mi mj jb mk bi translated">结果</h2><p id="3cd4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">6步之后，梯度下降截距为0.95，最小二乘估计也是如此。</p><p id="fe6f" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">请注意，当这些条件中的任何一个满足时，梯度下降停止。</p><p id="d6c5" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">条件1: T </strong>步长(斜率*学习率)接近于零。(假设值为0.0009)。<strong class="jf hj">或</strong></p><p id="a30d" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">条件2: </strong>梯度下降停止的另一个标准是当最大步数接近1000时。在这一点上，梯度下降停止。</p><p id="7e58" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">现在，我们已经学会了如何使用梯度下降来估计截距的大小，我们可以毕业并进入下一阶段，了解梯度下降如何估计斜率和截距。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/4c0d6ea8eb5120c69fb0903c11c13ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*x8QNxaoXu0hp-AyV"/></div></div></figure><p id="caa7" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">注意:当同一个函数有两个或更多的导数时，它们叫做梯度。我们将使用这个梯度下降到最低的损失函数，在我们的情况下是最小二乘法。这就是为什么该算法被称为梯度下降。啊哈！！</p><p id="213a" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">继续下一节，讲述如何使用GD求解截距和斜率。</p><p id="cf64" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">第1部分目的:我们从使用梯度下降来寻找斜率开始。-完成了</p><p id="ee93" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">第二部分目的:后面用梯度下降法求解截距和斜率。-让我们开始</strong></p><p id="ddc4" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">现在让我们从截距0和斜率=1开始</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es nc"><img src="../Images/46512a095c987b0b87b83eee374499fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*29u69w9HL920l_VY"/></div></div></figure><p id="8fbc" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">把这个代入方程；</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/926cddcb8b5adffbb897ce3deb812977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*g7SNeBDcI6ms2FKl"/></div></div></figure><p id="ad24" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">乘以这次0.01的学习率。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es nd"><img src="../Images/7477f6167443dae8130edacb936c5faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vygPbieKXutpt45A"/></div></div></figure><p id="d57d" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">现在我们通过插入旧截距和旧斜率来计算新截距和新斜率。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ne"><img src="../Images/61dbfca626a08afe3a764a41ed90752d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ny2gvGLhL9PiO4Kz"/></div></div></figure><p id="1479" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">我们将不断重复这些，直到步长变得接近0。</p><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/ded78ba7aafd6364ba661483e3f906cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mJt_Xvy-2UhomW4A"/></div></div></figure><figure class="kb kc kd ke fd kg er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es mv"><img src="../Images/845f876c8dbd90eb9cfde94800e7b382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*92BCZnnQwp9JD0oX"/></div></div></figure><h1 id="db9b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">最后的话</h1><p id="dc9c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们现在知道梯度下降如何优化斜率和截距。注意，最小二乘法只是损失函数的一种类型。不管损失函数的类型如何，我们的梯度下降法都是一样的。</p><p id="e8d8" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated">在我离开之前，有个东西叫随机梯度下降。总而言之，这是一个我们随机选择数据子集而不是整个数据集的场景。这减少了对损失函数求导的时间。稍后会有更多关于随机下降的内容！</p><p id="5c27" class="pw-post-body-paragraph jd je hi jf b jg kt ji jj jk ku jm jn jo kv jq jr js kw ju jv jw kx jy jz ka hb bi translated"><strong class="jf hj">参考文献</strong></p><ol class=""><li id="b3d4" class="lh li hi jf b jg kt jk ku jo lj js lk jw ll ka nf ln lo lp bi translated"><a class="ae ng" href="https://machinelearningmastery.com/gradient-descent-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/gradient-descent-for-machine-learning/</a></li><li id="7657" class="lh li hi jf b jg lq jk lr jo ls js lt jw lu ka nf ln lo lp bi translated">乔希·斯塔默的任务</li><li id="9a75" class="lh li hi jf b jg lq jk lr jo ls js lt jw lu ka nf ln lo lp bi translated"><a class="ae ng" href="https://irosyadi.github.io/course/machine-learning-andrewng.html" rel="noopener ugc nofollow" target="_blank">https://irosyadi . github . io/course/machine-learning-Andrew ng . html</a></li></ol></div></div>    
</body>
</html>