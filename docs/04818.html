<html>
<head>
<title>Parallelizing ML/DL Model’s Inference on Both CPU and GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在CPU和GPU上并行化ML/DL模型推理</h1>
<blockquote>原文：<a href="https://medium.com/codex/parallelizing-ml-dl-models-inference-on-both-cpu-and-gpu-bdc3d0d2e2ad?source=collection_archive---------0-----------------------#2022-01-09">https://medium.com/codex/parallelizing-ml-dl-models-inference-on-both-cpu-and-gpu-bdc3d0d2e2ad?source=collection_archive---------0-----------------------#2022-01-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="82e3" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在生产环境中使用GPU推理深度学习模型时，如何利用未使用的CPU计算。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/c235a586f4209cdb0197dca9bf50a3a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7xQ_JCyYZsS8wU51mMtug.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">通过一个四臂卡通人物来说明多重处理。[ <a class="ae jn" href="https://blackgladiatoarswa.blogspot.com/2015/03/pokemon-x-and-y-machamp.html" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="d4f2" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">问题陈述:</strong></h2><p id="4589" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">你必须在计算机视觉中训练过各种机器学习(ML)或深度学习(DL)模型，使用BERT和Transformers解决物体检测、物体分割、物体定位和自然语言处理(NLP)任务等问题。在训练完模型之后，我们将它们推到生产环境中，在那里我们实时地进行推理。获得快速响应总是可取的，这增强了消费者的体验。未能最佳利用所提供的资源可能会导致延迟或金钱损失，甚至在我们不知情的情况下。因此，我们应该利用机器上未消耗的资源。</p><p id="0359" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">当我们通过GPU使用DL模型进行推理时，CPU仍然剩余，可以用来执行特定的并行任务，或者可以用来并行运行一些轻量级模型。例如，我们有一个由各种模型组成的管道，包括传统的ML模型或DL模型。我们的DL模型很少在CPU上慢那么多，并且可以在CPU上运行。在上述场景中，我们可以通过运行一些模型来利用机器未使用的CPU能力。有人可能会说，我们可以为每种CPU和GPU模型类型创建两个独立的API。然而，在这种情况下，GPU实例的CPU计算仍将保持未消耗状态。</p><p id="25c5" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">本文将讨论如何利用实例中未使用的CPU计算。</p><h2 id="f13f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">方法:</strong></h2><p id="5c94" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">目标是在CPU和GPU上分别运行代码库的一部分，而不影响彼此的性能。我们可以使用多重处理，通过双向方法来解决这个问题。首先，我们将首先用主流程运行我们的python脚本。此外，我们将在主流程下创建两个单独的流程。每个进程将调用单独的类文件，每个类文件将包含在它们的'<em class="lk"> __init__' </em>方法中进行推理时要使用的机器类型。</p><h2 id="6b4f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">为什么不是多线程？</strong></h2><p id="5a36" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">多线程允许多个并发任务在单个进程中运行。换句话说，我们将在单个进程中利用资源。假设我们的主python脚本使用了一个进程，并且我们已经指定代码将在GPU上运行。当我们创建线程时，所有的线程都将使用GPU作为默认设置。如果我们使用CPU配置运行python脚本，也会发生同样的情况。因此，要么所有创建的线程都将占用相同的GPU，从而导致内存不足(OOM)错误，要么占用CPU，从而降低推理速度。因此，多线程不是解决上述方法的可行方法。</p><p id="e8b8" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">将通过使用几个python类文件来阐述所使用的方法。</p><p id="885e" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated"><em class="lk">代码的目录结构如下:</em></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ll"><img src="../Images/dabc8314520a3b08876a6de00ace5bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lHlwOhYVvMUmiwOKGq2XXA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">代码的目录结构。</figcaption></figure><p id="c7ed" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated"><strong class="ko hj"> <em class="lk"> file1.py: </em> </strong>这个文件包含了用于调用CPU模型上的推理的类。在<em class="lk"> '__init__' </em>方法中，我们指定了<em class="lk"> 'CUDA_VISIBLE_DEVICES' </em>到<em class="lk"> '-1' </em>，所以它不会挑选GPU。删除此语句将导致OOM错误；也就是说，多个进程将同时尝试使用同一个GPU。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="21ca" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated"><strong class="ko hj"> <em class="lk"> file2.py: </em> </strong>该文件包含了用于调用GPU模型上的推理的类。在<em class="lk"> '__init__' </em>方法中，我们指定了<em class="lk"> 'CUDA_VISIBLE_DEVICES' </em>到<em class="lk"> '0' </em>(或者任何一个特定的GPU设备)，以便它挑选GPU。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="2c81" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated"><strong class="ko hj"> <em class="lk"> main.py: </em> </strong>这是包含驱动代码的主文件。</p><p id="ac32" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated"><em class="lk">多处理模块中的管理器是什么？</em></p><p id="a906" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">管理器代理对象不能传播对机器内部可变对象的更改。举例来说，如果我们有一个<em class="lk"> 'manager.dict()' </em>对象，对托管列表本身的任何修改都将传播到所有其他进程。另一方面，如果我们使用一个标准的python字典，那么更改将不会在该字典中传播，因为管理器无法检测到更改。</p><p id="04dd" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">主进程将运行<em class="lk"> 'main.py' </em>，并在文件的'<em class="lk"> run' </em>方法中创建两个进程。每个过程将使用公共数据源和不同的模型列表独立工作。在两个流程都完成工作后，我们将把两个辅助流程加入到主流程中。最后，我们可以返回从两个过程中收集的结果对象。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="c1a6" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">驱动代码为<strong class="ko hj"> <em class="lk"> main.py </em> </strong></p><p id="6125" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">在下面的代码片段中，我们创建了<em class="lk">‘Main’</em>类对象，并调用了同一个类的<em class="lk">‘run’</em>方法。该方法采用输入数据集路径和可以在CPU和GPU上并行运行的模型。该函数以我们想要的任何格式或对象返回模型的输出。</p><pre class="iy iz ja jb fd lo lp lq lr aw ls bi"><span id="b2c0" class="jo jp hi lp b fi lt lu l lv lw">if __name__ == "__main__":<br/>    obj = Main()<br/>    dataset_path = "/home/prateek/..."<br/>    cpu_model_list = ['...', '...']<br/>    gpu_model_list = ['...', '...']<br/>    preds = obj.run(dataset_path, cpu_model_list, gpu_model_list)</span></pre><p id="41cd" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">完整的代码发布在GitHub上:</p><pre class="iy iz ja jb fd lo lp lq lr aw ls bi"><span id="591a" class="jo jp hi lp b fi lt lu l lv lw">Github Link: <a class="ae jn" href="https://github.com/prateekchhikara/multiprocessing-python" rel="noopener ugc nofollow" target="_blank">https://github.com/prateekchhikara/multiprocessing-python</a></span></pre></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><p id="9d84" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">本文介绍了一种在模型推理过程中利用机器优化计算的方法。</p><h1 id="2f19" class="me jp hi bd jq mf mg mh ju mi mj mk jy io ml ip kc ir mm is kg iu mn iv kk mo bi translated">参考</h1><div class="mp mq ez fb mr ms"><a href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener  ugc nofollow" target="_blank"><div class="mt ab dw"><div class="mu ab mv cl cj mw"><h2 class="bd hj fi z dy mx ea eb my ed ef hh bi translated">多重处理-基于进程的并行性- Python 3.10.1文档</h2><div class="mz l"><h3 class="bd b fi z dy mx ea eb my ed ef dx translated">是一个支持使用类似于模块的API生成进程的包。该套餐提供本地和…</h3></div><div class="na l"><p class="bd b fp z dy mx ea eb my ed ef dx translated">docs.python.org</p></div></div></div></a></div></div></div>    
</body>
</html>