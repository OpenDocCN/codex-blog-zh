<html>
<head>
<title>How to Easily Test Spark DataFrame Transformations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何轻松测试Spark数据帧转换</h1>
<blockquote>原文：<a href="https://medium.com/codex/how-to-easily-test-spark-dataframe-transformations-3b8cc160a705?source=collection_archive---------2-----------------------#2021-05-19">https://medium.com/codex/how-to-easily-test-spark-dataframe-transformations-3b8cc160a705?source=collection_archive---------2-----------------------#2021-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9e3adb364277c9fd65795b342b62c5ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zWEs2TnNw-mJHbKP"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">约翰尼斯·格罗尔在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="fb38" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">作为一名数据工程师，我经常需要编写不同复杂度的数据帧转换。通常，这些操作会变得非常复杂，以至于在一个较大的数据集上，可能需要几个小时甚至更长时间来测试。当你明白这是不可行的时候，你需要利用Spark的一个伟大特性——<em class="jt">无处不在</em>。因此，让我们尝试在我们的IDE中运行我们的测试，看看我们如何能够轻松地测试我们的数据帧转换。</p><h2 id="7dbb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">工作</h2><p id="2ae4" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">首先，我们需要想象一些数据，例如，对于我们来说太大而不能直接测试的数据:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/9b9d953d330b49ab77330f2d3887c8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*GWQkWYe4aB0ym1b-4kvSKw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">公民数据样本</figcaption></figure><p id="9f11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们有一个包含公民姓名和身份证号的数据集。这项任务很简单——我们需要提取公民出生日期的年、月、日。出生日期在<em class="jt">标识号</em>栏内，作为破折号前的第一部分。例如，第一个公民<strong class="ix hj">崇拜柚子</strong>的身份证号<strong class="ix hj">1998 12 17–73959</strong>，因此出生日期<strong class="ix hj"> 1998-12-17 </strong>。</p><h2 id="639a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">解决办法</h2><p id="00ae" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">让我们编写一些代码来实现这一点。首先，我们需要以某种方式捕获破折号符号之前的标识号部分——这里我们可以使用一个简单的<em class="jt">正则表达式来提取它:</em></p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="5348" class="ju jv hi la b fi le lf l lg lh">\d+(?=-)</span></pre><ul class=""><li id="3e9c" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated"><strong class="ix hj"> \d </strong>匹配任何数字字符(0–9)。</li><li id="e802" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated"><strong class="ix hj"> + </strong>是一个量词，用来匹配1个或多个以此为开头的字符类型(数字)。</li><li id="2087" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated"><strong class="ix hj">(？=-) </strong>匹配主表达式后的一个组，而不包括在破折号后的结果中。</li></ul><p id="76fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在是提取出生日期的Spark转换:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="8190" class="ju jv hi la b fi le lf l lg lh">def extractBirthDate(inputDf: DataFrame): DataFrame = {<br/>  inputDf<br/>    .withColumn("birth_date", <em class="jt">regexp_extract</em>(<em class="jt">col</em>("identification_number"), """\d+(?=-)""", 0))<br/>    .withColumn("year", <em class="jt">substring</em>(<em class="jt">col</em>("birth_date"), 0, 4))<br/>    .withColumn("month", <em class="jt">substring</em>(<em class="jt">col</em>("birth_date"), 5, 2))<br/>    .withColumn("day", <em class="jt">substring</em>(<em class="jt">col</em>("birth_date"), 7, 2))<br/>}</span></pre><p id="1b81" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们获取列<em class="jt"> identification_number </em>，并使用我们的<em class="jt"> RegEx </em>表达式将第一部分提取到名为<em class="jt"> birth_date </em>的新列中。然后从这个列中使用<em class="jt"> substring() </em>函数提取<em class="jt">年</em>、<em class="jt">月</em>日<em class="jt">日</em>。</p><h2 id="ffe5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">测试解决方案</h2><p id="cbcd" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">现在，在为你的数据帧转换编写任何测试之前，一定要注意你的函数是纯函数。因此他们不能访问网络资源、数据库或文件系统。</p><p id="a8d4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于测试，我们将使用Scala最流行的测试工具<em class="jt"> ScalaTest </em>,但是你也可以使用任何你喜欢的工具。在编写测试之前，我们还需要让S <em class="jt"> park </em>在我们的IDE中运行。最方便的方法是编写一个<em class="jt">特征</em>，它可以扩展我们的测试类并为我们设置一个<em class="jt"> SparkSession </em>:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="c6d8" class="ju jv hi la b fi le lf l lg lh">import org.apache.log4j.{Level, Logger}<br/>import org.apache.spark.sql.SparkSession<br/><br/>trait SparkSessionTestWrapper {<br/><br/>  Logger.<em class="jt">getLogger</em>("org").setLevel(Level.<em class="jt">ERROR</em>)<br/>  Logger.<em class="jt">getLogger</em>("akka").setLevel(Level.<em class="jt">ERROR</em>)<br/><br/>  val <em class="jt">spark</em>: SparkSession =<br/>    SparkSession<br/>      .<em class="jt">builder</em>()<br/>      .master("local[1]")<br/>      .appName("Local Test")<br/>      .getOrCreate()<br/>}</span></pre><p id="211a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过设置。<em class="jt"> master("local[1]") </em>选项我们指定<em class="jt"> Spark </em>用一个线程在本地运行，这对我们的测试来说非常好。</p><p id="fa5b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了测试一个数据帧转换或这些转换的链，我们需要对需要测试什么有一些概念。我们必须比较两个数据帧，为此我们需要比较以下内容:</p><ul class=""><li id="beba" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated"><strong class="ix hj">数据框架模式</strong> —这包括数据框架的所有结构信息，如列名、数据类型和可空性。</li><li id="1100" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated"><strong class="ix hj">数据帧数据</strong> —这些是存储在我们的数据帧中的值。</li></ul><p id="c407" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们编写一个通用且可重用的函数来比较这两种数据帧属性:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="3a9f" class="ju jv hi la b fi le lf l lg lh">import org.apache.spark.sql.DataFrame<br/>import org.apache.spark.sql.types.StructType<br/><br/>trait DataFrameTestUtils {<br/><br/>  def assertSchema(schema1: StructType, schema2: StructType, checkNullable: Boolean = true): Boolean = {<br/>    val s1 = schema1.fields.map(f =&gt; (f.name, f.dataType, f.nullable))<br/>    val s2 = schema2.fields.map(f =&gt; (f.name, f.dataType, f.nullable))<br/>    if (checkNullable) {<br/>      s1.diff(s2).isEmpty<br/>    }<br/>    else {<br/>      s1.map(s =&gt; (s._1, s._2)).diff(s2.map(s =&gt; (s._1, s._2))).isEmpty<br/>    }<br/>  }<br/><br/>  def assertData(df1: DataFrame, df2: DataFrame): Boolean = {<br/>    val data1 = df1.collect()<br/>    val data2 = df2.collect()<br/>    data1.diff(data2).isEmpty<br/>  }<br/>}</span></pre><p id="13a7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，为了在我们的测试中重用它，我们用两个方法<em class="jt"> assertSchema() </em>和<em class="jt"> assertData() </em>将它编写为一个特征。</p><p id="6a7a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> assertSchema() </strong>接受两个结构类型(数据帧模式)和一个布尔值(是否检查可空性)，并返回一个布尔值来指示这两个数据帧模式是否匹配。如果您为数据指定了自己的模式，并且没有在读取时自动推断它(当您不关心可为空性时)，则需要进行可为空性检查。</p><p id="147d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">assertData() 简单地获取两个数据帧，并返回一个布尔值来表示这两个数据是否相同。它通过在驱动程序中将数据集的所有元素作为数组返回并比较它们来实现这一点。collect() 是一个动作，它可能会在性能方面付出很高的代价，所以注意不要超出测试模型数据的大小。</p><p id="5d4b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们有了创建本地SparkSession和数据帧比较的功能，让我们编写测试本身。首先，我们需要一些测试数据。通常，您可以只从数据集中提取几条记录，但是要确保您被允许这样做，并且代码中没有敏感数据。您可以为测试数据创建一个单独的文件(如. csv或。json)并在运行测试时读取它，或者只是在代码中以编程方式创建一个:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="e30a" class="ju jv hi la b fi le lf l lg lh">import spark.implicits._<br/><br/>val sourceDf = <em class="jt">Seq</em>(<br/>  ("Adore", "Shaddock", "19981217-73959"),<br/>  ("Lorenza", "Kiersten", "19621220-14807"),<br/>  ("Mureil", "Willie", "19781211-72222")<br/>).toDF("name", "surname", "identification_number")</span></pre><p id="0f7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们已经有了源数据，让我们创建一个预期的数据框架——它在我们转换后应该是什么样子:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="20b5" class="ju jv hi la b fi le lf l lg lh">val expectedDf = <em class="jt">Seq</em>(<br/>  ("Adore", "Shaddock", "19981217-73959", "19981217", "1998", "12", "17"),<br/>  ("Lorenza", "Kiersten", "19621220-14807", "19621220", "1962", "12", "20"),<br/>  ("Mureil", "Willie", "19781211-72222", "19781211", "1978", "12", "11")<br/>).toDF("name", "surname", "identification_number", "birth_date", "year", "month", "day")</span></pre><p id="e788" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将所有这些放在一个测试中:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="6282" class="ju jv hi la b fi le lf l lg lh">test("DataFrame Schema Test") {<br/><br/>  val sourceDf = <em class="jt">Seq</em>(<br/>    ("Adore", "Shaddock", "19981217-73959"),<br/>    ("Lorenza", "Kiersten", "19621220-14807"),<br/>    ("Mureil", "Willie", "19781211-72222")<br/>  ).toDF("name", "surname", "identification_number")<br/><br/>  val resDf = <em class="jt">extractBirthDate</em>(sourceDf)<br/><br/>  val expectedDf = <em class="jt">Seq</em>(<br/>    ("Adore", "Shaddock", "19981217-73959", "19981217", "1998", "12", "17"),<br/>    ("Lorenza", "Kiersten", "19621220-14807", "19621220", "1962", "12", "20"),<br/>    ("Mureil", "Willie", "19781211-72222", "19781211", "1978", "12", "11")<br/>  ).toDF("name", "surname", "identification_number", "birth_date", "year", "month", "day")<br/><br/>  assert(assertSchema(resDf.schema, expectedDf.schema))<br/>}</span></pre><p id="6d92" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">类似地，对于DataFrame数据测试:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="cd44" class="ju jv hi la b fi le lf l lg lh">test("DataFrame Data Test") {<br/>  val sourceDf = <em class="jt">Seq</em>(<br/>    ("Jackie", "Ax", "19861126-29967"),<br/>    ("Vanessa", "Campball", "19881021-86591"),<br/>    ("Willetta", "Reneta", "19991125-38555")<br/>  ).toDF("name", "surname", "identification_number")<br/><br/>  val resDf = <em class="jt">extractBirthDate</em>(sourceDf)<br/><br/>  val expectedDf = <em class="jt">Seq</em>(<br/>    ("Jackie", "Ax", "19861126-29967", "19861126", "1986", "11", "26"),<br/>    ("Vanessa", "Campball", "19881021-86591", "19881021", "1988", "10", "21"),<br/>    ("Willetta", "Reneta", "19991125-38555", "19991125", "1999", "11", "25")<br/>  ).toDF("name", "surname", "identification_number", "birth_date", "year", "month", "day")<br/><br/>  assert(assertData(resDf, expectedDf))<br/>}</span></pre><p id="a98d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以在两个测试中重用相同的<em class="jt"> sourceDf </em>和<em class="jt"> expectedDf </em>，减少代码行，但我认为最好是每个测试都有单独的模型数据。现在让我们试着在<em class="jt"> Intellij </em>中运行我们的测试，看看我们的函数<em class="jt"> extractBirthDate() </em>是否做了它应该做的事情:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/1b5f89e74257844d595c38f13579a4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ns-G6J1XPxZmCqsu_noyA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">在Intellij中运行数据帧转换测试</figcaption></figure><p id="5e42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">成功！我们在IDE上运行了一个经过测试的数据帧转换，耗时不到7秒。如果您还没有开始测试您的Spark转换，那么我希望现在您已经有了一些编写您自己的测试的基本设置。</p><p id="48d0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该项目在<a class="ae iu" href="https://github.com/Bigdataengr/dataframe_unittest" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> GitHub </strong> </a>上可用。</p><p id="4a4e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢你，祝你考试顺利！</p></div></div>    
</body>
</html>