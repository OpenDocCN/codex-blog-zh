<html>
<head>
<title>Detecting Breast Cancer Using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习检测乳腺癌</h1>
<blockquote>原文：<a href="https://medium.com/codex/detecting-breast-cancer-using-machine-learning-c1357f2b62f8?source=collection_archive---------1-----------------------#2021-06-20">https://medium.com/codex/detecting-breast-cancer-using-machine-learning-c1357f2b62f8?source=collection_archive---------1-----------------------#2021-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/dc2e066c38917cb16ee2c4a00d2c7e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C58VgQHVn7Qtj4Cw-x8fOA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.nytimes.com/2019/10/24/well/live/machine-intelligence-AI-breast-cancer-mammogram.html" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="9c8d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我记得在我八年级的英语课上，有一天我们都在四处走动，说出一个我们感激的家庭成员的名字。我记得那个男孩害羞地举起手，分享他对母亲的感激，他的母亲一直在与乳腺癌作斗争。</p><p id="4af9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在他分享了他母亲的故事后，许多其他人分享了他们患有乳腺癌的母亲、阿姨、祖母和近亲的名字。</p><p id="fdb2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是一次令人大开眼界的经历。直到那时，我才意识到乳腺癌有多普遍。</p><p id="8ef9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大约八分之一的女性在她们的一生中会患上浸润性乳腺癌。每年，<strong class="ix hj">仅在美国<em class="jt"/>就有超过4万名女性</strong>将死于乳腺癌。</p><p id="c6b2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但更令人震惊的是，乳腺癌最显著的风险因素是性别(身为女性)和年龄(变老)。大多数乳腺癌发生在没有症状的女性身上。</p><p id="3f1f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">女性无法预防或控制患乳腺癌的风险，也无法快速诊断，因为她们面临的症状和异常情况较少。</p><p id="5064" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过利用<strong class="ix hj">机器学习</strong>，我们可以减少被诊断患有乳腺癌和死于乳腺癌的女性人数。机器学习让我们能够更快地检测出肿瘤的存在，从而提高患者的生存机会。</p><p id="cfd3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个项目中，我建立了一个机器学习模型，可以将肿瘤分类为良性<em class="jt"/>，这意味着肿瘤是无害的，或者恶性<em class="jt"/>，这是一种破坏性肿瘤，可以快速生长，对患者构成严重威胁。</p><p id="23d2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个项目中，我使用了三种不同的分类算法，并比较了它们的结果。我测试了逻辑回归模型、决策树分类器和随机森林分类器对肿瘤进行良性或恶性分类的结果。</p><h1 id="2d0e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">1.导入库和数据集</h1><p id="4b4f" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">构建模型的第一步是将我们的库和数据集导入到我们的Google Colab笔记本中。</p><p id="7612" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以从导入这个项目需要的Python库开始:</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="7be0" class="lg jv hi lc b fi lh li l lj lk"><strong class="lc hj">import</strong> numpy <strong class="lc hj">as</strong> np<br/><strong class="lc hj">import</strong> pandas <strong class="lc hj">as</strong> pd<br/><strong class="lc hj">import</strong> matplotlib.pyplot <strong class="lc hj">as</strong> plt<br/><strong class="lc hj">import</strong> seaborn <strong class="lc hj">as</strong> sns</span></pre><blockquote class="ll lm ln"><p id="3f12" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated"><strong class="ix hj"> pandas </strong>:最流行的python库，用于数据操作和分析。在这个项目中，它主要用于数据帧操作。</p><p id="0148" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated"><strong class="ix hj"> NumPy </strong>:一个python库，提供对大型多维数组和矩阵的支持，并具有高级数学函数来帮助操作和操纵这些数组。</p><p id="14f5" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated"><strong class="ix hj"> matplotlib.pyplot </strong>和<strong class="ix hj"> seaborn </strong>:用于数据可视化。</p></blockquote><p id="afbd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我们安装了库，我们就可以使用pandas导入数据集。本项目使用的数据集可以在这里下载<a class="ae iu" href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data" rel="noopener ugc nofollow" target="_blank">！它应该保存为CSV文件。当下载我的数据集时，我将其命名为“data.csv”，并能够导入它，如下所示。</a></p><p id="f17f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该程序块的最后一行将打印前7行数据，允许我们在<strong class="ix hj">数据帧</strong>内看到数据的输入，或<strong class="ix hj">特征</strong>，缩短为<em class="jt"> df </em>。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="4df4" class="lg jv hi lc b fi lh li l lj lk"><strong class="lc hj">from</strong> google.colab <strong class="lc hj">import</strong> files<br/>uploaded = files.upload()<br/>df = pd.read_csv('data.csv')<br/>df.head(7)</span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/d7eeae78bb5721fcb253d999b57614ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3GtaNKniJya6MUU22gebiA.png"/></div></div></figure><p id="d232" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所看到的，第一列的标题是“id”，代表患者的id。第二列显示患者的诊断；“M”代表a <strong class="ix hj">恶性肿瘤</strong>，而前7行未显示的“B”代表<strong class="ix hj">良性肿瘤</strong>。</p><p id="9e1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还可以看到其他特征，包括肿瘤的纹理、周长和面积。如果我们继续向右滚动，我们将能够在数据框中看到所有33个特征。</p><p id="ca42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，数据集中的第一行总是“0”因此，当我们打印前7行时，只打印第0到第6行，而不打印第7行。</p><h1 id="b092" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">2.探索性数据分析</h1><p id="2c82" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">一旦我们导入了必要的库和数据集，我们就可以开始探索性的数据分析，这对于消除数据集中的不一致非常重要。这包括删除重复项、纠正错误和处理缺失值。</p><p id="68cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在项目的这一部分，我们将可视化我们的数据，并删除空值。</p><p id="6fce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">探索性数据分析的第一步是了解我们的数据包括什么和不包括什么。我们需要首先通过运行<em class="jt"> df.shape来找出我们在数据集中有多少行和列。</em>这将返回一个“(569，33)”的输出这意味着我们有569行，或来自569名患者的数据，以及33列，或每个患者的33个输入特征。然而，并不是所有的33个特征都有价值。</p><p id="ee44" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们希望看到数据框中是否存在空值，这可以通过运行<em class="jt"> df.isna()来实现。下一个代码块中的sum( ) </em>。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/61ff0d3a1b67d3ed4d52747d233065d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NyJ4HzqCdveaczZbDYe1rw.png"/></div></div></figure><p id="777c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们运行这个块时，我们应该看到所有特性的列表，在右边的每一列中有空值的数量。如您所见，唯一具有空值的特性是最后一列“未命名:32”，该列完全为空。因此，我们可以通过运行<em class="jt"> df = df.dropna(axis = 1) </em>来删除这个列。</p><p id="0593" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们在下一个代码块中运行<em class="jt"> df.shape </em>，我们应该会看到在我们删除了其中一个特性之后，只有32列，或者32个特性。但是，仍然有569行，因为我们收集数据的患者数量没有变化。</p><p id="b286" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们放弃这个特性后，我们可以通过运行<em class="jt">df[‘诊断’]来诊断是恶性(M)肿瘤还是良性(B)肿瘤。值计数()</em>。这表明数据集包括357个良性肿瘤诊断和212个恶性肿瘤诊断。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/ca5d5f958623f5dceab0b73a8969efe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hfW34miAfpQtYOXwk_dBjA.png"/></div></div></figure><p id="36f2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们也可以通过使用seaborn创建一个<strong class="ix hj">计数图</strong>来可视化这些计数:</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="998c" class="lg jv hi lc b fi lh li l lj lk">sns.countplot(df[‘diagnosis’], label=’count’)</span></pre><p id="9e8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们探索性数据分析的下一步包括将所有数据转换或<strong class="ix hj">编码为数值。在运行<em class="jt"> df.dtypes </em>之后，我们可以看到所有的特性都是数字的(int或float)，除了诊断，它们都是对象数据类型。为了让算法正确使用数据，所有数据都必须是数字，这一点非常重要。</strong></p><p id="70ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用<strong class="ix hj"> sklearn </strong>或sci-kit learn来实现这一点，这是一个Python库，具有各种分类、回归和聚类算法。</p><p id="8bea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过运行以下命令，我们可以在该特性中对数字数据类型进行编码:</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="2b2b" class="lg jv hi lc b fi lh li l lj lk"><strong class="lc hj">from</strong> sklearn.preprocessing <strong class="lc hj">import</strong> LabelEncoder<br/>labelencoder_Y = LabelEncoder()<br/>df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)</span><span id="3f45" class="lg jv hi lc b fi lu li l lj lk">df.iloc[:,1]</span></pre><p id="61ac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种情况下，我们使用<em class="jt"> df.iloc </em>，因为我们的数据帧的索引标签不是数字。使用<em class="jt"> df.iloc </em>我们可以参考数字。例如，我们将诊断特征的值编码成数值，这是我们的数据框架中的第一列。因此，我们可以将其称为第1列。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/7374ccf0b9efba394abf6f315285bd45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*npOWnqp4hOoMnpdxutBG5g.png"/></div></div></figure><p id="9e99" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我们这样做了，我们将能够看到用1和0表示的患者诊断。1代表恶性肿瘤的诊断，0代表良性肿瘤的诊断。</p><p id="954a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们将诊断编码成数值后，我们可以使用seaborn通过<strong class="ix hj"> pairplot </strong>来可视化。</p><p id="05e0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">pairplot包括来自数据帧前6行的信息，并将数据分成不同的颜色以显示两种可能的结果；橙色代表恶性肿瘤，蓝色代表良性肿瘤。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/a7c55ea4e2a99a73a2bd20ba010578bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8blv5YVvIFVnl8HJeZuBSA.png"/></div></div></figure><h1 id="9f51" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">3.数据可视化</h1><p id="586f" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">一旦我们完成了对数据集的探索，并可视化了数据框架，我们就可以查看数据中的<strong class="ix hj">相关性</strong>。</p><p id="08d6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们可以找到列或特征之间的相关性。以下代码将向我们展示前12行数据之间的相关性:</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="0a4a" class="lg jv hi lc b fi lh li l lj lk">df.iloc[:,1:12].corr()</span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/bcde218aa71e5fe64e2c6d83783c5f2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*waAUa1BbT_eRg7O405U4lg.png"/></div></div></figure><p id="6224" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过这张表，我们可以看到其他特性之间的相关性。相关性为1意味着存在几乎完美的相关性，而相关性为0意味着没有相关性。如果该值低于0，这意味着存在反向相关性。例如，我们可以看到，与smoothness _ mean相比，radius_mean对患者的诊断具有更大的影响。</p><p id="e5e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还可以通过创建<strong class="ix hj">热图</strong>来可视化这种关联:</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="b48e" class="lg jv hi lc b fi lh li l lj lk">plt.figure(figsize = (10, 10))<br/>sns.heatmap(df.iloc[:,1:12].corr(), annot = True, fmt = '.0%')</span></pre><p id="b947" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt"> figsize </em>确定了热图的大小，而第二行代码确定了热图将显示数据帧的前12行之间的相关性。使用<em class="jt"> annot = True </em>，向我们显示热图中的数值，而<em class="jt">fmt =“. 0%”</em>将数值相关值转换为相关百分比。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/046fb84fe49065dd8113d43cf09fe4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MvzYDS46pDulEdbM9-dptQ.png"/></div></div></figure><h1 id="977e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.在模型训练之前准备数据</h1><p id="4d94" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">在我们清理了数据并可视化了数据框架中的相关性之后，我们需要在训练模型之前准备数据。</p><p id="45b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们需要将数据分成独立的X和Y数据集。第一列是模型的输出，即患者的诊断，而其余31列是模型的特征或输入。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="4fb6" class="lg jv hi lc b fi lh li l lj lk">X = df.iloc[:,2:31].values<br/>Y = df.iloc[:,1].values</span></pre><p id="dcb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我们建立了X和Y数据集，我们可以将75%的数据分成训练数据，25%的数据分成测试数据。</p><p id="851e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">训练数据</strong>仅用于训练模型。我们只需将数据输入模型，这样它就可以了解输入和输出之间的关系。</p><p id="6fa5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">测试数据</strong>在模型训练后使用。在我们完成训练和迭代之后，我们将测试数据提供给模型。模型在训练期间将永远不会看到测试数据。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="a715" class="lg jv hi lc b fi lh li l lj lk"><strong class="lc hj">from</strong> sklearn.model_selection <strong class="lc hj">import</strong> train_test_split<br/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25 , random_state = 0)</span></pre><p id="68f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们需要在将数据输入算法之前对其进行缩放。缩放数据，或者说<strong class="ix hj">特征缩放</strong>，仅仅意味着我们所有的特征都符合某个范围，无论这个范围是在0和1之间还是在0和100之间。</p><p id="c17b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了扩展我们的数据，我们可以从sklearn导入StandardScaler，并传递我们的训练和测试数据:</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="da8e" class="lg jv hi lc b fi lh li l lj lk"><strong class="lc hj">from</strong> sklearn.preprocessing <strong class="lc hj">import</strong> StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.fit_transform(X_test)</span></pre><p id="4db4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，如果我们简单地运行<em class="jt"> X_train </em>，我们可以看到以下值:</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/0af3ec629b07a23a054c5f5573e685d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7lMrBROHHPyWYKiJvCWAw.png"/></div></div></figure><h1 id="de32" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">5.训练和评估模型</h1><p id="f393" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">在这个项目中，我测试了三种不同分类算法的准确性——逻辑回归模型、决策树分类器和随机森林分类器——并比较了它们在将肿瘤分类为良性或恶性方面的准确率。</p><blockquote class="ll lm ln"><p id="add4" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated"><strong class="ix hj">逻辑回归:</strong>当目标变量的值本质上是分类的时使用的算法。当数据属于一个类别或另一个类别时使用它，在这种情况下，它将肿瘤分类为良性或恶性。</p><p id="0386" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated"><strong class="ix hj">决策树分类:</strong>一种树形结构形式的算法，将数据集分解成越来越小的子集。它由具有分支的决策节点和代表分类或决策的叶节点组成。<strong class="ix hj"> <br/> </strong> <br/> <strong class="ix hj">随机森林分类:</strong>通过在训练时构造大量决策树来运行的算法。每个决策树都是通过随机收集数据样本构建的。</p></blockquote><p id="ee0f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们对正在测试和比较的三种不同模型有了更多的了解，我们可以将我们的训练数据传递给这三种模型中的每一种:</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/45b4e61c0c769647de0fc383a0897664.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1MlgJNg8hRGe3GeSx-WGcw.png"/></div></div></figure><p id="244e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个模型都遵循相似的结构。我们可以从sklearn中分别导入三种算法，将随机状态设置为零。在决策树分类器和随机森林分类器中，我们都需要设置<strong class="ix hj"> <em class="jt">准则=熵</em> </strong>，用于计算决策树节点内的信息增益。</p><p id="ddec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，<em class="jt"> random_state = 0 </em>必须在所有三个算法中建立。将<strong class="ix hj"> random_state </strong>设置为固定值将保证每次运行代码时生成相同的随机数序列。这有助于验证输出。</p><p id="82a7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们可以运行<em class="jt"> model = models(X_train，Y_train) </em>来看看这三个模型在训练数据上的准确率。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/7b729ec9104a9314a00f5fb7c004eb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sYMYA3Du8BWdpYKsGqZ-Bw.png"/></div></div></figure><p id="4ede" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如我们所见，决策树分类器以100%的准确度执行，随机森林分类器以大约99.5%的准确度执行，而逻辑回归模型以大约99%的准确度执行。虽然这些百分比现在可能看起来非常高，但当在测试数据上执行时，它们会下降，这是模型以前没有见过的。</p><p id="860f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了在测试数据上运行模型，我们可以导入一个<strong class="ix hj">混淆矩阵。</strong>混淆矩阵将对测试数据运行模型，并告诉我们模型已分类的真阳性、真阴性、假阳性和假阴性的数量。</p><div class="kx ky kz la fd ab cb"><figure class="mc ij md me mf mg mh paragraph-image"><img src="../Images/a59edc34db913a612481f6a60e6340d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*g5zpskPaxO8uSl0OWT4NTQ.png"/></figure><figure class="mc ij mi me mf mg mh paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/85d7e399027bb970ec1789fc4384a940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*9O51bepoELMRZ4tf5hwVgQ.png"/></div></figure></div><p id="bdc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所看到的，模型0，我们的逻辑回归分类器，在测试数据上已经达到大约<strong class="ix hj"> 95% </strong>的准确度。模型1，我们的决策树分类器在测试数据上已经达到大约<strong class="ix hj"> 94% </strong>的准确度，而模型2，我们的随机森林分类器，在我们的测试数据上已经达到大约<strong class="ix hj"> 96.5% </strong>的准确度。</p><p id="6603" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以得出结论，随机森林分类器是这个项目的最佳算法，因为它在测试数据上表现最好，尽管它在训练数据上的表现仅次于决策树分类器。</p><p id="1f6d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了混淆矩阵之外，我们还可以为我们的每个模型编写一个<strong class="ix hj">分类报告</strong>，它测量模型所做预测的质量。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/dfc893da5a2d21982f1f782d8de48570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zLfLw7wCxudXY1eJ77CCA.png"/></div></div></figure><p id="f658" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管没有一个模型表现完美，但考虑到数据的局限性，它们表现得相当好。通过继续训练模型和调整参数，我们可以继续提高预测的准确性！</p><p id="e670" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你想更深入地了解这个项目是如何进行的，可以看看我用过的<a class="ae iu" href="https://www.youtube.com/watch?v=NSSOyhJBmWY" rel="noopener ugc nofollow" target="_blank">教程</a>，以及我为我的项目制作的<a class="ae iu" href="https://www.youtube.com/watch?v=p1wCg18f8EA&amp;t=626s" rel="noopener ugc nofollow" target="_blank">视频！</a></p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><blockquote class="ll lm ln"><p id="1e2d" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated">非常感谢您阅读这篇文章！如果你从这篇文章中学到了什么，请分享！一定要<a class="ae iu" href="https://linktr.ee/manasigajjalapurna" rel="noopener ugc nofollow" target="_blank">跟我联系</a>，留下这篇文章一个掌声👏如果你喜欢的话！</p></blockquote><h2 id="7256" class="lg jv hi bd jw mr ms mt ka mu mv mw ke jg mx my ki jk mz na km jo nb nc kq nd bi translated">来源:</h2><div class="ne nf ez fb ng nh"><a href="https://randerson112358.medium.com/breast-cancer-detection-using-machine-learning-38820fe98982" rel="noopener follow" target="_blank"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hj fi z dy nm ea eb nn ed ef hh bi translated">使用机器学习的乳腺癌检测</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">在这篇文章中，我将向你展示如何创建你自己的机器学习python程序来检测乳腺癌…</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">randerson112358.medium.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv io nh"/></div></div></a></div><div class="ne nf ez fb ng nh"><a href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" rel="noopener follow" target="_blank"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hj fi z dy nm ea eb nn ed ef hh bi translated">了解随机森林</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">该算法如何工作以及为什么如此有效</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nw l ns nt nu nq nv io nh"/></div></div></a></div><div class="ne nf ez fb ng nh"><a href="https://towardsdatascience.com/logistic-regression-classifier-8583e0c3cf9" rel="noopener follow" target="_blank"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hj fi z dy nm ea eb nn ed ef hh bi translated">逻辑回归分类器</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">它是如何工作的(第1部分)</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nx l ns nt nu nq nv io nh"/></div></div></a></div><div class="ne nf ez fb ng nh"><a rel="noopener follow" target="_blank" href="/swlh/decision-tree-classification-de64fc4d5aac"><div class="ni ab dw"><div class="nj ab nk cl cj nl"><h2 class="bd hj fi z dy nm ea eb nn ed ef hh bi translated">决策树分类</h2><div class="no l"><h3 class="bd b fi z dy nm ea eb nn ed ef dx translated">决策树是对例子进行分类的简单表示。这是一种受监督的机器学习，其中数据…</h3></div><div class="np l"><p class="bd b fp z dy nm ea eb nn ed ef dx translated">medium.com</p></div></div><div class="nq l"><div class="ny l ns nt nu nq nv io nh"/></div></div></a></div></div></div>    
</body>
</html>