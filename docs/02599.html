<html>
<head>
<title>A guide to Two-stage Object Detection: R-CNN, FPN, Mask R-CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">两阶段目标探测指南:R-CNN，FPN，掩模R-CNN</h1>
<blockquote>原文：<a href="https://medium.com/codex/a-guide-to-two-stage-object-detection-r-cnn-fpn-mask-r-cnn-and-more-54c2e168438c?source=collection_archive---------0-----------------------#2021-07-28">https://medium.com/codex/a-guide-to-two-stage-object-detection-r-cnn-fpn-mask-r-cnn-and-more-54c2e168438c?source=collection_archive---------0-----------------------#2021-07-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3bce32dc48d80e58acdbdcb5379237e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZWp4mnDsVbj3_VYT"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@picoftasty?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">梅姆</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="4f4b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">多阶段(两阶段)对象检测</h2><p id="8dac" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">计算机视觉中最基本和最广泛研究的挑战之一是对象检测。该任务旨在绘制给定图像中物体的多个包围盒，这在包括自动驾驶在内的许多领域都非常重要。通常，这些目标检测算法可以分为两类:单阶段模型和多阶段模型。在本帖中，我们将通过回顾该领域中一些最重要的论文，深入探讨对象检测的多级流水线的关键见解。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/f0104939ceed66a3bde15fe5c10fe388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kxAqqhq8NIuDvHes"/></div></div></figure><p id="045f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">目标检测器的一个分支是基于多级模型的。源自R-CNN的工作，一个模型用于提取对象的区域，第二个模型用于分类和进一步改进对象的定位。众所周知，这种方法相对较慢，但非常有效，但最近的进展，如共享功能，改进了2级检测器，使其具有与单级检测器相似的计算成本。这些工程高度依赖于以前的工程，并且大多以以前的管道为基线。因此，了解两级检测器中的所有主要算法非常重要。</p><p id="f756" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">本帖论文的选取多基于调查[8]。</p><h2 id="37ac" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">美国有线电视新闻网</h2><p id="2392" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">2014年的论文提出了基于CNN的两阶段检测算法的简单版本，在后续论文中对其进行了改进和加速。如上图所述，整个管道由三个阶段组成:</p><ol class=""><li id="326c" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn ld le lf lg bi translated">生成区域建议:模型必须独立于类别，在图像中绘制候选对象。</li><li id="a76f" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn ld le lf lg bi translated">第二阶段是一个全卷积神经网络，它计算每个候选区域的特征。</li><li id="874d" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn ld le lf lg bi translated">最后一级是全连接层，在本文中表示为支持向量机。</li></ol><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/e0914eb9f5cc6d6904dd60ecdea20d4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*trBdpUARB5rm3AyCMgnarw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">R-CNN管道概述</figcaption></figure><p id="cb8a" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">可以使用各种方法生成区域建议，本文选择使用选择性搜索来与先前的工作进行比较。尽管如此，管道与大多数区域提议方法兼容。选择性搜索的详细解释在<a class="ae iu" href="https://learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae iu" href="http://vision.stanford.edu/teaching/cs231b_spring1415/slides/ssearch_schuyler.pdf" rel="noopener ugc nofollow" target="_blank">这个</a>演示中提供。</p><p id="f142" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">概括选择性搜索，将分割算法应用于图像，并基于分割图绘制区域提议(边界框)。分割图被迭代地合并，并且从如下图所示的细化图中绘制更大的区域提议。这里详细解释了合并和方框图是如何工作的。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/645c817d0e93249162eee2e5f3cb64a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PgVMkV7logvqfO_b2Q3XYQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="http://vision.stanford.edu/teaching/cs231b_spring1415/slides/ssearch_schuyler.pdf" rel="noopener ugc nofollow" target="_blank">http://vision . Stanford . edu/teaching/cs 231 b _ spring 1415/slides/ssearch _ schuyler . pdf</a></figcaption></figure><p id="3460" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">第二和第三阶段一起可以被认为是常规的CNN，其工作在裁剪区域提议上。本文使用AlexNet的卷积部分作为第二级，而可以使用任何其他CNN架构。由于区域建议的大小不同，本文采用最简单的方法将所有边界框弯曲和调整到所需的大小。</p><p id="b104" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">作者还使用训练的包围盒分类器来进一步改进由分割做出的包围盒估计。另一个完全连接的网络被训练以输入特征图并回归表示相对平移和对数标度宽度/高度标度因子的4元组(r，c，h，w)中的边界框偏移。这项技术在消融研究中显示出性能提升，如<em class="lo"> R-CNN BB </em>。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/832d54916936d401e2b17b95ea9cbf68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JN0WOc5pSlJxSj2Nj-eHbA.png"/></div></div></figure><p id="7b08" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">为了在推理中拒绝重叠区域提议，其中两个或更多边界框指向同一个对象，作者提出了一种贪婪算法，如果一个区域与另一个具有更有把握的预测的区域具有高的交集(IoU ),则拒绝该区域。</p><p id="7ec2" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">由于图像的域被改变为扭曲窗口的图像，分类器模型在扭曲图像和新标签上被进一步训练。在训练分类器时，与地面实况(GT)框具有&gt; 0.5 IoU的区域被认为是该类，并且被训练以输出GT框的类。当盒子与任何GT盒子没有明显重叠时，或者当区域具有&lt;0.5 IoU with every box, the classifier must classify the region in the <em class="lo">背景</em>类时。为了解决潜在的类别不平衡，选择32个阳性区域和96个背景区域来形成大小为128的小批量。</p><p id="e03c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">IoU &gt; 0.5的区域被视为完全重叠，而本文认为IoU&lt;0.5的区域部分重叠。通过提供背景和GT盒类的混合标签，对这些情况进行了特殊处理。</p><p id="c4ae" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">与其他方法相比，R-CNN的性能优势来自于执行自底向上风格的选择性搜索的思想，也使用CNN来定位对象和在对象检测数据上微调网络中使用的技术。这项工作结合了经典CV和深度学习的工作，以改善对象检测。但是CNN非常耗时，因为它将CNN应用于大约2000个扭曲的选择性搜索区域。</p><p id="ab41" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="ddc3" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">提出了用于两阶段目标检测的基线流水线:生成区域提议并对它们进行分类。</li><li id="a385" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">使用选择性搜索生成区域建议</li><li id="4425" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">分类网络调整区域提议的大小，并预测类别概率(包括背景)和边界框细化。</li></ul><h2 id="ca9b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">SPP网[2]</h2><p id="8a26" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">该论文建议使用空间金字塔池(SPP)图层，该图层设计用于任何图像大小，而无需将它们调整为固定大小，这可能导致信息丢失和图像失真。在CNN中被描述为特征提取器的卷积不是约束固定输入大小的卷积，但是输入大小约束是因为完全连接的分类层。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/c442d0457bbff7372f0ddc85b9955841.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-YQGpGWYxqHijcfxKE75w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">上图:传统CNN管道，下图:SPP-net管道</figcaption></figure><p id="ec6e" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">因此，作者提出了一种特殊的池化图层，它可以转换不同大小的要素，并将它们提供给完全连接的图层，以消除网络的固定大小约束，如上图所示。</p><p id="2a9f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">基本上，SPP层在各种比例下应用最大池输出，与图像大小成比例。SPP层使用与图像尺寸成比例的空间箱，允许任何形状的图像被映射成单一尺寸。每个空间箱最大化其区域中的值，并且空间信息可以通过该过程得以保留。下图对此进行了描述。每个过滤器用不同大小的池进行处理，这些池覆盖图像的一部分，并且结果被连接。256是特征图中过滤器的数量。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/f91ddaad6751711ec1c200c45f89edb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*rf7dbrIwqrfJb2IbLJ1huw.png"/></div></figure><p id="e141" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">虽然作者没有提出SPP层，但他们首先考虑在CNN中使用SPP层。spp具有以下特性:</p><ol class=""><li id="68e1" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn ld le lf lg bi translated">无论输入大小如何，都会生成固定长度的输出</li><li id="3e70" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn ld le lf lg bi translated">已知对对象变形具有鲁棒性(正则化)</li><li id="a9bf" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn ld le lf lg bi translated">可以从各种尺度(分辨率)提取信息</li></ol><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/fc45c9ab52b4f0ceb0866c69ad487411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJoLL8LH8bdyclIoG_FHsQ.png"/></div></div></figure><p id="3048" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">该论文集中于图像分类，并示出了作为泛化性能证明的对象检测的结果，但是当应用于对象检测时，具有不同于R-CNN算法的一些有趣的特性。</p><p id="8da5" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">SPP-Net的对象检测管道如上图所示。在整个图像上执行一次CNN，并且基于通过选择性搜索检测到的区域来裁剪CNN的输出特征。SPP应用于每种作物，并基于SPP层的输出预测类别。这样，卷积层仅应用于图像一次，并且对应于检测到的区域的数量，仅应用较亮的FC层。</p><p id="adca" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">卷积特征检测器是在图像分类任务上预先训练的，而不是在对象检测上进一步训练的。分类器FC层基于地面真实窗口被单独训练。尺度不变性是通过使用两种方法来预处理图像，解释了这一点。在微调FC网络时，还应用了R-CNN的许多技术。</p><p id="128f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">这篇论文的贡献确实令人惊讶，因为它将训练和推理的时间减少了几个数量级，同时由于不必调整图像大小和扭曲图像，甚至提高了性能。然而，我怀疑经过图像分类训练的特征图是否真正包含了裁剪图像的空间信息。当使用深度神经网络时，这可能是一个大问题，因为接收大小将会很大，因此可能会限制SPP-Net管道使用更深的特征提取器。一些其他损失可以用于在对象检测数据集上一起微调特征提取器。</p><p id="fcac" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="8e28" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">建议应用空间金字塔池来输出任意输入大小的固定长度要素。</li><li id="b9c4" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">改进了要处理的训练/推理过程，将每个区域的前向传递次数(每个图像约2，000个区域)从一次减少到整个图像的一次前向传递。</li></ul><h2 id="6e8e" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">快速R-CNN[3]</h2><p id="b622" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">先前的对象检测算法，即R-CNN，通常分别学习定位和分类阶段，这使得训练更加昂贵。此外，这些算法在测试时非常慢，不利于实时应用。快速R-CNN联合学习检测物体的空间位置并对其进行分类。</p><p id="236f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">r-CNN很慢，因为每个对象提议都要向前传递。虽然SPP-Nets确实解决了这个问题，并在测试时将R-CNN加速了100倍，但训练是一个多阶段的过程，需要许多步骤的密集计算，与R-CNN相比，仅加速了3倍。此外，固定的卷积层限制了网络的精度。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/9f216ce0d830a79af0eb2ab9128784f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjmbo0sZZmuKM3UGu-U2pA.png"/></div></div></figure><p id="f23e" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">上图展示了快速R-CNN管道。CNN对图像进行处理，并根据对象提议裁剪特征地图。然后，感兴趣区域(RoI)池层提取一个固定长度的向量，然后通过完全连接的网络对其进行处理，以预测类别概率并优化边界框。</p><p id="c880" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">RoI pooling层是SPP层的一个特例，具有一个金字塔等级。高×宽RoI窗口被分成一个高×宽的网格，每个网格的大小为高/高×宽，每个网格单元上应用最大池。输出始终是一个H × W形状的向量。快速R-CNN流程与SPP-Net管道非常相似，只是稍有修改。</p><p id="ecb2" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">以前在SPP-Nets中，通过卷积层的反向传播是低效的，因为感受野可能跨越整个图像，这是非常大的。快速R-CNN通过小批量同时训练一幅图像的多个RoI样本来解决这个问题。这些特征可以在训练期间共享，这样可以加快训练速度，并且无需缓存特征。这一招被命名为<em class="lo">分层采样</em>。此外，快速R-CNN通过多任务损失联合优化分类器和包围盒回归器，而不是单独训练。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/3c3d4e27e92d4d2f295d208ce6d25a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*zGnjk1l3GHDAQHfFMPX--g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">分类损失和定位损失的联合训练</figcaption></figure><p id="1a7c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">还对R-CNN算法进行了一些额外的改进。例如，快速R-CNN使用稳健的L1损失而不是L2损失进行回归。超参数也有修改。本文还结合了R-CNN和SPP-Net的技术。文件中提供了详细的解释。Fast R-CNN能够实现S.O.T.A .的准确性，同时在训练和测试方面的速度也快了几个数量级。</p><p id="65d6" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="9ae6" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">将SPP修改为RoI池</li><li id="d1ce" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">通过从一幅图像中采样多个面片进行高效训练-&gt;卷积层上仅一次向前/向后传递。</li><li id="8457" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">-&gt;通过反向传播训练卷积特征提取器</li></ul><h2 id="f5df" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">更快的R-CNN[4]</h2><p id="7b92" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">指出对象提议阶段是实时对象检测的计算瓶颈。作为一种解决方案，更快的R-CNN实现了与特征提取器网络共享卷积层的区域提议网络(RPN ),为计算对象提议引入了边际成本。管道与Fast R-CNN一致，只是对象提议是通过内部培训的RPN提出的，如下图所示。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/4e3436b1235910ae0e33155df45670ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*tT46AclWWjiyerXbwCSmag.png"/></div></figure><p id="2d4e" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">RPN模型接收由特征提取器计算的特征图，并通过在特征图上滑动小CNN来输出对象提议的列表。在每个滑动窗口位置，网络预测k个参考框(锚)的对象提议，每个对象提议由4个坐标和估计对象概率的分数组成。下图描述了RPN模型。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/3802a0a243ba9497e285bd82b7d0e07c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yePORRYbDdiFC1KKNlBvIA.png"/></div></div></figure><p id="4a2b" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">RPN模型与快速R-CNN分类管道分开训练。快速R-CNN模型的训练类似于原始程序，包括以图像为中心的采样策略。一个区别是RoI的大小可以确定，而不是任意确定。因此，受益于锚设计，训练k个边界框回归器，每个负责提炼相应的锚类型。</p><p id="0f37" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">在训练RPN模型时，基于具有地面真实边界框的IoU，为每个锚点分配二进制标签。标签可以是正的、负的或中性的，取决于带有真相框的欠条。RPN模型在分数和坐标估计上被训练。本文讨论了通过梯度下降法联合训练这两个模型的三种方法。该论文使用交替训练来训练网络，其中首先训练RPN，并且在该过程中计算的建议用于训练快速R-CNN。</p><p id="ff5c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="4201" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">代替缓慢的选择性搜索，提出RPN来训练包围盒提议过程。</li><li id="4235" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">RPN模型预测目标在<em class="lo">锚</em>上的概率、位置。</li><li id="4017" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">比较了各种训练方法，以便与原始的基于区域的检测网络一起有效地训练RPN模型。</li></ul><h2 id="fcdc" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">特征金字塔网络(FPN) [5]</h2><p id="598b" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">特征影像金字塔(图a)提供了多尺度特征表示，通过支持尺度不变性，可方便地用于对象检测。该模型必须能够检测图像中对象的所有比例，并且改变金字塔的层可以容易地抵消对象的比例差异。但是，计算多级特征显然需要相当长的时间，并且不用于快速/更快速的R-CNN等管道中(图b)。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/430a229b865b74d5f4397f71d889cacc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*gDzjNw_VaPUeasGuCRtjIg.png"/></div></figure><p id="4e8c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">卷积神经网络固有地计算多尺度特征表示，因为每一层分级地计算不同分辨率的特征图。然而，以前的工作利用细胞神经网络的层次属性，以较小的计算量制作一个特征图像金字塔(图c)是不完整的。CNN的中间特征映射问题是特征根据网络的深度自然地传达不同的语义。要充分利用CNN进行多比例要素表示，图层在所有比例下都具有强大的语义非常重要。</p><p id="683f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">提议的FPN(图d)被描述为</p><blockquote class="lz ma mb"><p id="fbb9" class="jt ju lo jv b jw kt jy jz ka ku kc kd mc kv kf kg md kw ki kj me kx kl km kn hb bi translated">一种通过自顶向下的路径和横向连接将低分辨率、语义强的特征与高分辨率、语义弱的特征相结合的架构。</p></blockquote><p id="7804" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">FPN旨在为高分辨率要素提供丰富的语义，是一种类似U-Net的架构。一个<em class="lo">自下而上的</em>路径(红色)是前馈CNN。每个分辨率被表示为一个<em class="lo">阶段</em>，并且为每个阶段定义一个金字塔等级。<em class="lo">自上而下</em>路径(蓝色)通过从更高的金字塔等级向上采样语义更强的特征地图来产生更高分辨率的特征。直观上，更多的操作可以增强任意比例尺的要素地图的语义，提供丰富的多比例尺要素。通过<em class="lo">横向连接</em>投射的自下而上路径的特征进一步增强了这些特征。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/4c482cd3db88eee06ec00f0c8d70dd57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*pJbHEQe1ScPzoZ1IiWoSeA.png"/></div></figure><p id="1271" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">FPN管道为生成具有丰富语义内容的多尺度特征地图提供了通用解决方案。当应用于更快的R-CNN对象检测流水线时，FPN架构被应用于用于生成边界框提议的RPN网络和快速的R-CNN基于区域的分类器中枢。通过替换主干网络和馈送FPN输出而不是单个特征地图，FPN被采用到RPN。当应用锚时，我们在金字塔输入的不同级别上应用锚的每个尺度。例如{32、64、128、256、512 }个大小的锚，每个锚用于特征地图{P2、P3、P4、P5、P6}。将更快的R-CNN检测网络应用于根据边界框的大小确定的特征图列表之一。</p><p id="9014" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="94fc" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">提出新的FPN网络体系结构来计算语义丰富的多尺度特征表示。</li><li id="34bd" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">使用CNN的中间层作为多尺度特征和图像金字塔，并使用这些特征训练RPN和主干网络。</li></ul><h2 id="06aa" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">屏蔽R-CNN[6]</h2><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/b2b6a2b79f51581a3c755c930664eaa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3wl3ydxHPUlClfKg_M24Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">实例分割</figcaption></figure><p id="2d4f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">掩模R-CNN被提出来解决一个稍微不同的实例分割问题。简而言之，这个问题是对象检测和语义分割的结合。如上所述，该任务旨在生成划分对象的像素边界。</p><p id="7fd9" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">Mask R-CNN基于更快的R-CNN管道，但每个对象提议有三个输出，而不是两个。附加分支预测K(# classes)个二进制对象掩码，该掩码分割图像中每个类别的对象。使用分类分支的结果选择要绘制的最终实例分割图。这被称为<em class="lo">解耦</em>掩码和类别预测。</p><p id="2f5a" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">使用全卷积网络(FCN)从每个RoI中提取m × m掩模。与绘制边界框不同，生成像素级遮罩需要像素级的空间信息。因此，在生成掩膜分段时，该函数会在折叠要素之前进行分支，如下图所示。</p><p id="6b5c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">RoI是小的特征图，通过RoI汇集操作来计算，RoI汇集操作将特征图严格地分割成箱。这是因为这在RoI和提取的特征之间引入了未对准，这在分类中被忽略，但是会损害像素级掩模，像素级掩模很大程度上受到小平移的影响。提出了RoIAlign层，平滑了RoIPool的硬切片。RoIAlgin图层基本上是大地图到小地图的双线性插值。结果显示了很大的性能提升，并且作者提出了更多的证据表明问题出在不一致的对齐上。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/2c502ec5dfc7b92be912435067c68b41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zsKMIx6e8SDPSpAhweruVQ.png"/></div></div></figure><p id="4594" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">为了训练掩码分支，损失项L_mask被添加到原始分类和边界框回归损失函数中。掩模损失项被计算为具有类别k的基本事实分割图和第k个掩模之间的交叉熵损失。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/aa5e591b7e17390ad7f04211fa7921bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*sv3VocDOxUoG0yYA6CQDvg.png"/></div></figure><p id="727c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">本文不仅实现了高性能的实例分割，而且在常规包围盒对象检测和其他任务(如姿态估计)中也产生了令人惊讶的结果。上表显示了边界框对象检测的结果，其中掩模R-CNN优于更快的R-CNN。更快的R-CNN，RoIAlgin显示了在训练中不使用面罩丢失时的结果。结果表明，当用掩模预测目标训练时，对象检测管道学习到更可概括的丰富特征。</p><p id="5605" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="7f92" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">通过引入<em class="lo">掩码分支</em>，提出了一个基于快速R-CNN的实例分割通用框架。</li><li id="818d" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">通过解决切片中的不对齐问题来修复RoIPooling层。</li><li id="2fb6" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">简单却令人惊叹的论文:)</li></ul><h2 id="6c2a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">级联R-CNN[7]</h2><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/79ee32b0cde74cd194b27c5f8e1e0ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*c451-7binOVY8AqJOJWqlw.png"/></div></figure><p id="9b56" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">如果IoU高于阈值u，则该补丁被认为是类的示例，或者被认为是<em class="lo">背景</em>类。当在使用宽松IoU阈值(如u=0.5)的数据集上训练时，边界框预测变得有噪声。但是提高IoU阈值并不能解决问题，因为用于训练/推断的最佳IoU不匹配。它还会显著减少阳性样本的数量，引入不平衡数据的问题，这在右侧图中红色图表的低性能中有所说明。辨别“接近但不正确”的包围盒很重要，但在以前的工作中没有研究过。</p><p id="ec3e" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">这些图显示了三个检测器在u = 0.5、0.6、0.7的IoU阈值上进行训练。如左图所示，各型号在不同的IoU范围内表现最佳。该论文提供了更多的理由，说明为什么单个分类器难以在整体IoU水平上表现一致。基于单个检测器对于单个质量水平是最佳的假设，级联R-CNN训练用增加的IoU阈值训练的检测器序列。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/9363b866514c7473b402a884d4e8037d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oPfqOPAS1xV9XjWty5C_rw.png"/></div></div></figure><p id="a321" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">在更快的R-CNN(图a)中，RPN网络为细化框和分类提供RoI。在级联R-CNN中，向头部序列提供前一头部的边界框估计，而不是RPN的RoI，这被解释为迭代地改进边界框估计(图b，d)。理论上，下一个头的输出应该逐步改善边界框位置，但是用小的IoU阈值训练边界框细化器将不会改善超过某个值的IoU(上面的图c)。因此，级联R-CNN被设计为不同的<em class="lo">专用</em>回归器的级联(图d)。因此，更深的阶段能够逐步提高IoU阈值，如下图IoU直方图所示。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/9d195a6f69b08b5af467c4bd4340b62e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8r2xYZtpTObkX7W-nXIzFw.png"/></div></div></figure><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/55404ee14975f767698be01e55c26610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3mvbglH5bjvmlIKTjIMdQ.png"/></div></div></figure><p id="978f" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">摘要</p><ul class=""><li id="96cf" class="ky kz hi jv b jw kt ka ku jg la jk lb jo lc kn lq le lf lg bi translated">指出IoU阈值在对象检测中的影响，以及简单修改阈值的问题。</li><li id="fd8d" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">观察到不同型号在不同IoU范围内表现最佳。</li><li id="0a3b" class="ky kz hi jv b jw lh ka li jg lj jk lk jo ll kn lq le lf lg bi translated">级联包围盒回归器，以确保高置信度的包围盒输出，而不会引入额外的问题。</li></ul><h2 id="1308" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结论</h2><p id="0284" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">我们回顾了多阶段目标检测的主要方法。这些算法的进展速度真是惊人。琐碎的R-CNN算法既慢又低效。高级算法的许多关键见解都基于<em class="lo">共享特征</em>(例如SPP-Net、Fast R-CNN、Mask R-CNN)，并支持对先前固定的管道组件(例如Fast R-CNN、Fast R-CNN、Cascade R-CNN)进行梯度训练，以高效地学习更丰富的特征。目标检测是计算机视觉的一个重要领域，多阶段目标检测是目标检测的主流方法。</p><p id="b02a" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">多阶段对象检测的最新工作是检测器，它通过提出一个<em class="lo">递归特征金字塔</em>来改善网络的主干。虽然最近对对象检测的关注已经转移到基于变压器的方法，但这些关于多阶段对象检测的论文总体上提供了对深度学习的深刻见解。本帖介绍的论文选择多以<a class="ae iu" href="https://arxiv.org/pdf/1907.09408.pdf" rel="noopener ugc nofollow" target="_blank">【8】</a>为依据。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/130d021fa49bf7302bdf13074612540a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a9t2N-cb6KCt5jJNqujqUw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://paperswithcode.com/sota/object-detection-on-coco" rel="noopener ugc nofollow" target="_blank">https://paperswithcode.com/sota/object-detection-on-coco</a></figcaption></figure><h1 id="04bb" class="mn iw hi bd ix mo mp mq jb mr ms mt jf mu mv mw jj mx my mz jn na nb nc jr nd bi translated">参考</h1><p id="327d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">[1]r . gir shick、j . Donahue、t . Darrell和j . Malik(2014年)。丰富的特征层次，用于精确的对象检测和语义分割。IEEE计算机视觉和模式识别会议论文集<em class="lo">(第580–587页)。</em></p><p id="bd0e" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[2]何，王，张，徐，任，孙等(2015).用于视觉识别的深度卷积网络中的空间金字塔池。<em class="lo"> IEEE模式分析与机器智能汇刊</em>，<em class="lo"> 37 </em> (9)，1904–1916。</p><p id="105b" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[3]吉尔希克，R. (2015年)。快速r-cnn。IEEE计算机视觉国际会议论文集(第1440-1448页)。</p><p id="bf0c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[4]任，s，何，k，吉希克，r .，，孙，J. (2015)。更快的R-CNN:用区域建议网络实现实时目标检测。<em class="lo">神经信息处理系统的进展</em>，<em class="lo"> 28 </em>，91–99。</p><p id="9da2" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[5]林，T. Y .，多拉尔，p .，吉尔希克，r .，何，k .，哈里哈兰，b .，&amp;贝隆吉，S. (2017)。用于目标检测的特征金字塔网络。IEEE计算机视觉和模式识别会议论文集(第2117-2125页)。</p><p id="0792" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[6] He，k .，Gkioxari，g .，Dollár，p .，&amp; Girshick，R. (2017年)。屏蔽R-CNN。IEEE计算机视觉国际会议论文集(第2961-2969页)。</p><p id="133b" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[7]蔡志勇，等(2018)。级联R-CNN:钻研高质量的对象检测。IEEE计算机视觉和模式识别会议的会议记录(第6154-6162页)。</p><p id="482a" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">[8]焦，李，张，刘，杨，李，冯，曲，等(2019)。基于深度学习的目标检测综述。<em class="lo"> IEEE接入</em>，<em class="lo"> 7 </em>，128837–128868。</p></div></div>    
</body>
</html>