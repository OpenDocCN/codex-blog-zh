<html>
<head>
<title>Small Datasets-Based Object Detection: How Much Data is Enough?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于小数据集的目标检测:多少数据是足够的？</h1>
<blockquote>原文：<a href="https://medium.com/codex/small-datasets-based-object-detection-how-much-data-is-enough-7cade289d340?source=collection_archive---------1-----------------------#2021-09-20">https://medium.com/codex/small-datasets-based-object-detection-how-much-data-is-enough-7cade289d340?source=collection_archive---------1-----------------------#2021-09-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1c4f42c367ad6f92b25729029708b0c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkfcUEsBLAMS9uX08HV1-A@2x.png"/></div></div></figure><p id="a63b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">开始任何机器学习项目通常都是从这个问题开始的:“多少数据才够？”。这种反应取决于许多因素，如生产数据的多样性、开源数据集的可用性、系统的预期性能等等。在这篇文章中，我想揭穿一个关于机器只能从大量数据中学习的流行神话，并分享一个用小数据集应用ML的用例。</p><p id="8bfd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着深度学习在计算机视觉中的快速采用，需要在机器的帮助下解决的多样化任务越来越多。为了理解机器学习在现实世界中的应用，让我们关注一下<em class="jo">的目标检测任务。</em></p><h1 id="ad19" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是物体检测？</h1><p id="ab89" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">对象检测是计算机视觉的一个分支，处理在照片或视频中识别和定位对象。目标检测的目标是在机器学习的帮助下，在数字图像或视频中找到具有某些特征的目标。通常，对象检测是项目识别的初步步骤:首先，我们必须识别对象，然后应用识别模型来识别某些元素。</p><h1 id="078b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">对象检测业务用例</h1><p id="d767" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">物体检测是视觉检测、仓库自动化、库存管理、安全等人工智能解决方案的核心任务。以下是一些跨行业成功实施的对象检测用例。</p><p id="df9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">制造业</strong>。质量保证、库存管理、分拣和装配线—物体检测在许多制造过程的自动化中发挥着重要作用。机器学习算法允许快速检测任何缺陷，自动计数和定位对象。这使他们能够通过最大限度地减少人为错误和花费的时间来提高库存准确性。</p><p id="7470" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">汽车</strong>。机器学习用于自动驾驶汽车、行人检测和优化城市交通流量。物体检测用于感知驾驶员周围的车辆和障碍物。在交通运输中，目标识别用于检测和计数车辆。它还用于交通分析，并有助于检测停在高速公路或十字路口的汽车。</p><p id="276c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">零售</strong>。对象检测通过分析和比较货架图像与理想状态，帮助检测SKU(库存单位)。集成到硬件中的计算机视觉技术有助于减少零售店中的等待时间，跟踪客户与产品的交互方式，并自动交付。</p><p id="8f28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">医疗保健</strong>。对象检测用于研究医学图像，如ct扫描、MRI和X射线。它被用于癌症筛查，帮助识别高危患者，检测异常，甚至提供手术帮助。应用对象检测和识别来辅助远程医疗的医疗检查是改变向患者提供医疗保健的方式的新趋势。</p><p id="b6cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">安全与监控</strong>。目标检测的应用包括能够进行人物检测和人脸识别的视频监控系统。使用机器学习算法，这种系统被设计用于生物识别和远程监控。这项技术甚至被用于自杀预防。</p><p id="d332" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">物流和仓库自动化</strong>。对象检测模型能够对缺陷检测、库存管理、质量控制和供应链管理的自动化进行可视化检查。人工智能驱动的物流解决方案使用对象检测模型，而不是条形码检测，从而取代人工扫描。</p><h1 id="46d8" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">如何开发对象检测系统:PoC方法</h1><p id="93cd" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">开发一个对象检测系统用于类似于我们上面提到的任务与任何其他ML项目没有什么不同。它通常从建立一个假设开始，在几轮实验中用数据进行检验。</p><p id="5808" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种假设是软件开发中PoC方法的一部分。它与机器学习一致，因为在这种情况下，交付不是最终产品。进行研究可以让我们得出结果，从而可以说可以使用任何一种选择的方法，或者需要进行额外的实验来选择不同的方向。</p><p id="4606" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果问题是“多少数据对于机器学习来说是足够的”，假设可能听起来像“150个数据样本足以让模型达到最佳的性能水平”。</p><p id="f497" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">经验丰富的ML从业者，如<a class="ae ks" href="https://en.wikipedia.org/wiki/Andrew_Ng" rel="noopener ugc nofollow" target="_blank">吴恩达</a>(谷歌大脑的联合创始人，前百度首席科学家)<a class="ae ks" href="https://blog.roboflow.com/andrew-ng-scale-transform-conference/" rel="noopener ugc nofollow" target="_blank">建议</a>快速构建具有机器学习功能的系统的第一个迭代，然后部署它，并从那里迭代。</p><p id="4300" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种方法允许我们创建一个功能性的、可伸缩的原型系统，它可以用来自生产团队的数据和反馈来升级。与您试图从一开始就构建最终系统的情况相比，这种解决方案要高效得多。像这样的原型不一定需要大量的数据。</p><p id="8ff3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要回答“多少数据才够”这个问题，绝对没错，没有机器学习专家能预测需要多少数据。找出答案的唯一方法是设定一个假设，并在真实案例中进行测试。这正是我们在下面的对象检测示例中所做的。</p><h1 id="fece" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">案例研究:使用小数据集的对象检测，用于物流中的自动物品计数</h1><p id="e97d" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们的目标是创建一个能够检测物流对象的系统。从生产地到仓库或从仓库到工厂的货物运输通常需要中间控制和实际数量与发票和数据库的协调。当手动完成时，该任务将需要数小时的人工工作，并且涉及高风险。</p><p id="b031" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">说到假设，我们的目的是检查一个小的带注释的数据集是否足以解决为物流目的自动计数各种物品的问题。</p><p id="bc0c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">许多人选择的解决问题的典型方法是使用经典的计算机视觉技术。例如，可以结合Sobel滤波器边缘检测和Hough圆变换方法来检测和计数圆形物体。该方法简单且相对可靠，然而它更适合于受控环境，例如具有轮廓分明的圆形或椭圆形物体的生产线。</p><p id="a245" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们选择的用例中，经典方法的可靠性要低得多，因为对象的形状、图像质量以及照明条件可能会有很大差异。此外，经典方法不能从数据中学习。这使得通过收集更多的数据来迭代系统变得困难。在这种情况下，最好的选择是微调基于神经网络的对象检测器。</p><p id="d064" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数据收集和标记</strong></p><p id="a38f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了用小数据集执行对象检测的实验，我们收集并手动注释了公共来源中可用的几幅图像。我们决定把重点放在原木的检测上，并将带注释的图像分成<em class="jo">验证</em>分割。</p><p id="500c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，我们还收集了一组没有标签的图像，这些图像中的原木在某些方面与训练和验证图像(原木的方向、尺寸和形状、颜色)不同，以查看模型的检测能力在训练集中的限制。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/a236eff4e31e3c56d9c7e0bde0b3dff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iNwlAQZzT6jx8gZa.jpg"/></div></div></figure><p id="2098" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于我们正在处理对象检测，图像注释被表示为边界框。为了创建它们，我们使用了基于开源浏览器的工具<a class="ae ks" href="https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.6.html" rel="noopener ugc nofollow" target="_blank"> VGG图像注释器</a>，它有足够的功能来创建小规模数据集。不幸的是，该工具以自己的格式生成注释，然后我们将其转换为<a class="ae ks" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>对象检测标准。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/de820986db35acc6aaaa393ef8fd35e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hoJXuJJoYnVnYQyr.jpg"/></div></div></figure><p id="d27f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在对象检测中，数据量不仅取决于数据集中的图像数量，还取决于每个图像中的单个对象实例的数量。在我们的例子中，图像中的对象非常密集——每个图像中的实例数量达到50–90个。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/4ac43d5998cc3a0f6345424de059ee32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AyOoAsyEofu7Jpl_.jpg"/></div></div></figure><p id="bb77" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">探测器2物体探测</strong></p><p id="82eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们决定使用的模型是脸书在计算机视觉库<a class="ae ks" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"> Detectron2 </a>中实现的<a class="ae ks" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">快速R-CNN </a>。</p><p id="6519" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们仔细看看R-CNN如何更快地进行对象检测。首先，输入图像通过backbone(一种针对图像分类问题预先训练的深度CNN模型)并被转换为称为特征图的压缩表示。然后，区域提议网络(RPN)处理特征地图，识别特征地图中可能包含感兴趣对象的区域。</p><p id="c4b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，使用RoI合并操作从特征图中提取区域，并通过边界框偏移头(预测每个区域的精确边界框坐标)和对象分类头(预测区域中对象的类别)进行处理。</p><p id="be00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更快的R-CNN(基于区域的卷积神经网络)是R-CNN架构的第三代。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/8651bf2ac11c3137b0f27715db2deda5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QpcbVtZDiKd9De1R.jpg"/></div></div></figure><p id="accc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更快的R-CNN是一个两阶段的对象检测模型。它包括RPN子网络，用于对目标提案进行采样。然而，这不是用于对象检测的小数据集的唯一解决方案。</p><p id="e3b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有一个单阶段探测器模型试图找到相关的对象，而没有这个repion proposal筛选阶段。与两级模型相比，一级检测器的架构更简单，速度更快，但精度较低。这些例子包括<a class="ae ks" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> Yolov4 </a>和<a class="ae ks" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> Yolov5 </a>架构，这些系列中一些配置较轻的型号可以达到50–140 FPS(尽管会影响检测质量)，而更快的R-CNN最大运行速度为15–25 FPS。</p><p id="60c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关于更快的R-CNN解释的原始论文于2016年发表，并从那里获得了一些对架构的小改进，这些改进反映在我们使用的Detectron2库中。</p><p id="f407" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，为我们的实验选择的模型配置<a class="ae ks" href="https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> R50-FPN </strong> </a>使用具有特征金字塔网络的主干ResNet-50——这一概念是在CVPR 2017 <a class="ae ks" href="https://arxiv.org/abs/1612.03144" rel="noopener ugc nofollow" target="_blank">论文</a>中引入的，此后成为CNN主干用于特征提取的主要内容。简单来说，在特征金字塔网络中，我们使用的不仅仅是从CNN中提取的最深层特征图，还有中低层特征图。这允许小物体检测，否则在向下压缩到最深等级期间会丢失该小物体检测。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/c14d0c1584b393e09a04dc8b93bd9476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JV8IHUH7iaTHetV4.jpg"/></div></div></figure><p id="22b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">结果</strong></p><p id="3821" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的实验中，我们使用了以下逻辑:</p><ol class=""><li id="9090" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn ld le lf lg bi translated">拿一个在<a class="ae ks" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO 2017 </a>数据集上预训练的更快的R-CNN，有80个对象类。</li><li id="a630" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">分别用4和1个单位替换边界框回归中的320个单位和分类头中的80个单位，以便为1个新类别训练模型(边界框回归头对于每个类别具有4个单位，以便回归边界框的X、Y、W、H尺寸，其中X、Y是bbox中心的中心坐标，W、H是其宽度和高度)。</li></ol><p id="df8e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">经过一些初步运行后，我们选择了以下训练参数:</p><ul class=""><li id="aa3a" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn lm le lf lg bi translated">型号配置:R50-FPN</li><li id="60b5" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn lm le lf lg bi translated">学习率:0.000125</li><li id="b22b" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn lm le lf lg bi translated">批量:2</li><li id="878c" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn lm le lf lg bi translated">RoI头的批量:128</li><li id="4193" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn lm le lf lg bi translated">最大迭代次数:200</li></ul><p id="023b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有了参数集，我们开始研究训练中最有趣的方面:需要多少训练实例才能在验证集上获得令人满意的结果。因为即使一个图像包含多达90个实例，我们也不得不随机删除部分注释来测试更少的实例。我们发现，对于包含98个实例的验证集，在10个训练实例时，我们只能获得1-2个实例，在25个实例时，我们已经获得了大约40个实例，在75个或更多实例时，我们能够预测所有实例。</p><p id="ea8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将训练实例的数量从75个增加到100个和200个导致了相同的最终训练结果。然而，由于训练样本的更高多样性，该模型收敛得更快。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/4e4dde558bf453ab0dc9adfedc94fd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9kqp-Gx8uMmdQY4B.jpg"/></div></div></figure><p id="d1b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下图中可以看到用来自验证集的图像上的237个实例训练的模型的预测；有几个假阳性(用红色箭头标记)，但它们的可信度低，因此可以通过将可信度阈值设置为大约80%来过滤掉。</p><p id="fbac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下一步中，我们探索了训练模型在没有标签的测试图像上的性能。正如预期的那样，类似于训练集分布的图像具有自信和高质量的预测。而那些原木形状、颜色不寻常或者方向不同的图像，模型就很难处理了。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/bcefad30d2c20fdcb657ca400e6dcba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XmEWYwAigFI6LKn0.jpg"/></div></div></figure><p id="33cc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，即使在来自测试集的具有挑战性的图像上，我们也观察到了增加训练实例数量的积极效果。在下图中，我们展示了随着训练图像数量的增加(1个训练图像-91个实例，2–4个图像-127–237个实例)，模型如何学习挑选额外的实例(用绿色星号标记)。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/d4823e03ee798dc32b8174855f78df2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lHQdNDzlaGz71ybR.jpg"/></div></div></figure><p id="7725" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总之，结果表明，该模型能够挑选验证数据集中约95%的实例。在对75–200个对象实例进行微调后，提供的验证数据类似于训练数据。这证明了选择适当的训练样本使得在有限的数据场景中进行高质量的对象检测成为可能。</p><h1 id="bcbb" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">物体探测的未来</h1><p id="c6c1" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">物体检测是近年来出现的最常用的计算机视觉技术之一。其原因是多功能性。一些现有的模型已经在消费电子产品中成功实现，或者集成在驾驶辅助软件中。其他则是用于自动化物流、转变医疗保健和制造业的机器人解决方案的基础。</p><p id="590a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对象检测的任务对于数字化转型至关重要，因为它是人工智能驱动的软件和机器人的基础，从长远来看，这意味着我们可以逐渐将人们从单调乏味的工作中解放出来，并减轻多种风险。</p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><p id="5f51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由<a class="ae ks" href="https://mobidev.biz/our-team/maksym-tatariants" rel="noopener ugc nofollow" target="_blank"> Maksym Tatariants </a>，AI解决方案架构师<a class="ae ks" href="https://mobidev.biz/services/machine-learning-consulting" rel="noopener ugc nofollow" target="_blank"> MobiDev </a>撰写。</p><p id="873d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">全文原载于</em><a class="ae ks" href="https://mobidev.biz/blog/object-detection-small-datasets-use-cases-machine-learning" rel="noopener ugc nofollow" target="_blank"><em class="jo">https://mobidev . biz</em></a><em class="jo">，基于mobi dev技术研究。</em></p></div></div>    
</body>
</html>