<html>
<head>
<title>Titanic — Predicting Survival rates using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泰坦尼克号——使用机器学习预测存活率</h1>
<blockquote>原文：<a href="https://medium.com/codex/titanic-predicting-survival-rates-using-machine-learning-3e83c56af29f?source=collection_archive---------4-----------------------#2021-06-27">https://medium.com/codex/titanic-predicting-survival-rates-using-machine-learning-3e83c56af29f?source=collection_archive---------4-----------------------#2021-06-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/5fddbe18aecedbb0c682b89718484013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aVaYQTF-nruJyzrB"/></div></div></figure><p id="73c6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据我上一篇文章的类似主题，我探索并试图理解1912年泰坦尼克号灾难的场景。使用许多特征，例如票的类型、年龄、家庭等等；我试图预测这一事件的存活率。</p><h1 id="5262" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">介绍</h1><p id="68fd" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi ks translated">1912年4月15日凌晨，豪华轮船泰坦尼克号在处女航中撞上冰山后，在北大西洋纽芬兰海岸沉没。在船上的2240名乘客和机组人员中，超过1500人在这场灾难中丧生。泰坦尼克号激发了无数的书籍、文章和电影(<em class="lb">包括1997年由凯特·温丝莱特和莱昂纳多·迪卡普里奥主演的电影《泰坦尼克号》</em>)，这艘船的故事作为一个关于人类傲慢的危险的警示故事进入了公众的意识。现在，我将试着预测这场灾难的存活率。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="0682" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">问题定义</h1><p id="7c67" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">泰坦尼克号是一艘由白星公司运营的英国客轮，1912年4月15日在从南安普敦到纽约的处女航中撞上冰山后沉没在北大西洋。据估计，船上有2，224名乘客和船员，其中超过1500人死亡，这是当时最致命的沉船事件之一，也是迄今为止和平时期最致命的超级邮轮或游轮沉没事件。随着公众的关注，这场灾难成了许多艺术作品的素材，也是灾难电影类型的基础素材。</p><p id="a494" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的主要目标是预测泰坦尼克号上的任何一名乘客是否能在沉船中幸存。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="9faf" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">数据分析</h1><p id="3703" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在这个项目中，我们有一个数据集，其中包含泰坦尼克号上每位乘客的详细信息。它还有一个名为“幸存”的列，用来显示这个人是否幸存。</p><p id="0669" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">给定的数据集包含891行和12列。下面给出了每列的描述和类型。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/dcd4bbae4294ea1ba48394fd53636420.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/0*XJgxzdMfXY_8TzHb"/></div></figure><p id="6660" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集有891个示例和11个特征+目标变量(幸存)，其中2个特征是浮点数，5个是整数，5个是对象。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/da7a792083d3640206fac985c9d68d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/0*nbZdQVEVQbytrE2B"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">数据描述</figcaption></figure><p id="d46b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们所见，数据集包含891个条目，这意味着891名乘客在船上，但如果您比较实际乘客总数，会发现大约有2，224名乘客，这意味着我们的数据集不完整，它只是实际数据中的样本。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/3db84b8cdc75634ae2db867caac17d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/0*yR_qVQUa9URUYaHQ"/></div></figure><p id="149d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面我们可以看到38%的数据在泰坦尼克号中幸存。</p><p id="b692" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还可以看到乘客年龄从0.4岁到80岁不等。除此之外，我们已经可以检测到一些包含缺失值的特征，比如“年龄”特征可以处理它们。此外，我们可以看到，这些要素的范围差异很大，我们需要将其转换为大致相同的比例。我们还可以发现更多的特征，这些特征包含我们需要处理的缺失值(NaN =非数字)。</p><p id="e114" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上表中，我们可以注意到一些事情。首先，我们需要将许多特征转换成数字，这样机器学习算法</p><p id="c4d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它还包含一些缺失的值。让我们看看那些缺失的值。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/b31a845731678339e7240d7f88a1251d.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/0*63JzlU5hCpCxLqp-"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">缺少值</figcaption></figure><p id="8600" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">已装载特征只有两个缺失值，可以很容易地填充。处理“年龄”特性要复杂得多，它缺少177个值。“小屋”功能需要进一步调查，但看起来我们可能要从数据集中删除它，因为它的77%丢失了。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="6f75" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">探索性数据分析</h1><ul class=""><li id="90e9" class="ma mb hi is b it kn ix ko jb mc jf md jj me jn mf mg mh mi bi translated"><strong class="is hj">变量之间的相关性:</strong>我们可以看到变量之间并没有太大的相关性。只有列性别与目标变量的负相关性最小。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/cc6656322648a4832cb1ee4be3648363.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/0*KiAWruVAebW9YP-A"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">空值计数</figcaption></figure><ul class=""><li id="ee1b" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">可视化变量:</strong></li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/8f065b767e8950498b192f4fa62c0189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/0*8_2seJdanb9PhFs8"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated"><strong class="bd jr">存活数</strong>相对于<strong class="bd jr">年龄</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/c14d0ef6505025bf2596e13d52a4fca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/0*lqrJJs31NucPXAb3"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">乘客— <strong class="bd jr">幸存</strong>对<strong class="bd jr">未幸存</strong>比率</figcaption></figure><p id="3a92" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的直方图中，我们可以得出结论，男性的存活概率在20至35岁之间，而女性的存活概率在15至40岁之间。幸存的男女比例在女性中更大。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/aaafb3b7d7655e7f629a228bf47150a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/0*Lj_p5XYAM1dV5voy"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">在<strong class="bd jr">出发港开始旅程的乘客的生存机会S </strong> vs <strong class="bd jr">船票等级</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/dbf99b30834a0d32622b18afe002045e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/0*6BuV6KuTtVd943dF"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">在<strong class="bd jr">启运港开始旅程的乘客的生存机会C </strong> vs <strong class="bd jr">船票等级</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/9a92ff94e39964c4ed2b44387598e8d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/0*6RnVJJbbPfY-5XPb"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">在<strong class="bd jr">启运港Q </strong> vs <strong class="bd jr">船票等级</strong>开始旅程的乘客生还几率</figcaption></figure><p id="1207" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的点图中，我们可以说，从S和Q出发的女性比从C出发的女性有更高的生存机会。对于男性来说，从C出发的女性比从Q和S出发的男性有更高的生存机会。</p><p id="2700" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样清楚的是，Pclass 1和p class 2中的男性或女性具有最高的生存概率。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/5634163b48f2d9c9225a42d64db36d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/0*prZM_G2S0bFyAXaZ"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated"><strong class="bd jr">票级</strong> vs <strong class="bd jr">年龄</strong></figcaption></figure><p id="7809" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的方框图中，我们可以观察到，头等舱和二等舱的富裕乘客实际上比三等舱的乘客年龄稍大。也许这是由于积累财富需要时间。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/415522bbf4feec4b52780e62c6105fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SMU_b0tX6PY3hLWu"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated"><strong class="bd jr">存活率</strong>相对于<strong class="bd jr">家庭成员登船数量</strong></figcaption></figure><p id="b08a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们可以看到，随着泰坦尼克号上兄弟姐妹/配偶数量的增加，生还的机会越来越小。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/1be6da054079ee6b6576bc936653cffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BYRYqkkbx3QzoYLt"/></div></div></figure><p id="47be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们可以看到，有3个父母/孩子的人有最高的生存机会。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="0507" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">预处理流水线</h1><p id="3510" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">数据预处理是机器学习中产生高度准确和深刻结果的主要步骤。数据质量越高，产生的结果越可靠。<strong class="is hj">不完整、嘈杂和不一致的数据</strong>是真实世界数据集的固有特性。数据预处理有助于通过填充缺失的不完整数据、平滑噪声和解决不一致来提高数据质量。</p><ul class=""><li id="7b6a" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">数据不完整</strong>可能是由多种原因造成的。由于误解或仪器缺陷和故障，可能无法保存适当的数据。</li><li id="0030" class="ma mb hi is b it mv ix mw jb mx jf my jj mz jn mf mg mh mi bi translated"><strong class="is hj">噪声数据</strong>可能因多种原因出现(具有不正确的特征值)。用于数据收集的仪器可能有故障。数据输入可能包含人为或仪器错误。也可能发生数据传输错误。</li></ul><p id="7ebd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据预处理涉及许多阶段。</p><ul class=""><li id="86f2" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">数据清理</strong>试图估算缺失值，移除异常值。</li><li id="1ee7" class="ma mb hi is b it mv ix mw jb mx jf my jj mz jn mf mg mh mi bi translated"><strong class="is hj">数据集成</strong>将来自多个来源的数据集成到一个数据仓库中。</li><li id="452c" class="ma mb hi is b it mv ix mw jb mx jf my jj mz jn mf mg mh mi bi translated"><strong class="is hj">可应用数据转换</strong>，如标准化。例如，归一化可以提高涉及距离测量的挖掘算法的准确性和效率。</li><li id="de6c" class="ma mb hi is b it mv ix mw jb mx jf my jj mz jn mf mg mh mi bi translated"><strong class="is hj">数据缩减</strong>可以通过删除冗余特征来缩减数据大小。可以使用特征选择和特征提取技术。</li></ul><p id="ad16" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">处理空值</strong></p><p id="f1e3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有时，某些列包含空值，用于指示缺少或未知的值，或者该值可能不存在。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/d6abb5289f4a8b92eaea2864a82052be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9hqsZ40aq9PvCL3v"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">在列<strong class="bd jr">中出现空值年龄</strong>和<strong class="bd jr">舱室</strong></figcaption></figure><p id="0135" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的数据集中，有两列包含空值，即年龄和客舱。我们可以处理年龄列，但是对于客舱列，空值的数量大于70%，所以最好删除此列。</p><p id="9725" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以用帮助Pclass列替换Age列中的空值，即我们计算每个Pclass列的平均年龄，并替换相应Pclass的人的年龄。</p><p id="a7cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">将标签转换成数字</strong></p><p id="62f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在机器学习中，我们通常处理在一列或多列中包含多个标签的数据集。这些标签可以是单词或数字的形式。为了使数据可理解或以人类可读的形式，训练数据通常用文字标注。</p><p id="37a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的数据集中，有姓名、性别、机票、登机等列。这些列必须用一个热编码或标签编码器来处理。</p><p id="ec00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">列名和标签与目标变量无关。因此我们将删除这些列。对于列性和列性，我们使用标签编码器转换成数字列。</p><p id="c813" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">标签编码器</strong>是将标签转换成数字形式，从而转换成机器可读的形式。然后，机器学习算法可以以更好的方式决定这些标签必须如何操作。这是监督学习中结构化数据集的一个重要预处理步骤。</p><p id="b6e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">python中的标签编码可以从Sklearn库中导入。Sklearn提供了一个非常高效的编码工具。标签编码器使用0和n_classes-1之间的值对标签进行编码。从我们的数据集中取一个例子。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="fc83" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">构建机器学习模型</h1><p id="8a55" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了构建机器学习模型，Sklearn模块中有几个模型。</p><p id="779a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Sklearn提供回归和分类两种模型。我们数据集的目标变量是预测欺诈是否被举报。因此，对于这类问题，我们使用分类模型。</p><p id="b401" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但在将数据集拟合到其模型之前，我们首先必须分离预测变量和目标变量，然后将该变量传递给train_test_split方法，以创建随机测试和训练子集。</p><blockquote class="nb nc nd"><p id="0d66" class="iq ir lb is b it iu iv iw ix iy iz ja ne jc jd je nf jg jh ji ng jk jl jm jn hb bi translated"><strong class="is hj">什么是train_test_split </strong>是sklearn模型选择中的一个函数，用于将数据组拆分为训练数据和测试数据两个子集。有了这个函数，就不需要手动划分数据集了。默认情况下，sklearn train_test_split会对这两个子集进行随机分区。但是，您也可以为操作指定随机状态。它给出四个输出x_train、x_test、y_train和y_test。x_train和x_test包含训练和测试预测变量，而y_train和y_test包含训练和测试目标变量。</p></blockquote><p id="3952" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在执行train_test_split之后，我们必须选择模型来传递训练变量。</p><p id="53bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以建立尽可能多的模型来比较这些模型给出的精度，并从中选择最佳模型。</p><p id="6728" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我选择了5种型号:</p><ul class=""><li id="b0eb" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">来自sklearn.linear_model的Logistic回归:</strong> Logistic回归是一种监督学习分类算法，用于预测目标变量的概率。目标或因变量的性质是二元的，这意味着只有两种可能的类别1(代表成功/是)或0(代表失败/否)。在数学上，逻辑回归模型预测P(Y=1)为x的函数。这是最简单的ML算法之一，可用于各种分类问题，如垃圾邮件检测、糖尿病预测、癌症检测等。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nh"><img src="../Images/efa3fe98be40148da2ac57efd3123265.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/0*t7RcMODgvkTfbNwZ"/></div></figure><ul class=""><li id="05e7" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">来自sklearn.ensemble的RandomForestClassifier】正如我们所知，森林是由树木组成的，更多的树木意味着更健壮的森林。类似地，随机森林算法在数据样本上创建决策树，然后从每个样本中获得预测，最后通过投票选择最佳解决方案。这是一种比单一决策树更好的集成方法，因为它通过平均结果来减少过拟合。</strong></li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es ni"><img src="../Images/417979ca8519152e3f04e056921032e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/0*vMy8BVFepJZ5xtOk"/></div></figure><ul class=""><li id="b66b" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated">【sklearn.neighbors的KNeighborsClassifiers:K-nearest neighbors(KNN)算法使用“特征相似度”来预测新数据点的值，这进一步意味着新数据点将根据其与训练集中的点的匹配程度来分配值。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/333f4f302afde1d7cfde50baf0622948.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/0*CO3aR2ccLuoY-OYv"/></div></figure><ul class=""><li id="73bd" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">支持向量分类器:</strong>支持向量机是一种受监督的机器学习算法，可用于分类或回归挑战。但多用于分类问题。在SVM算法中，我们将每个数据项绘制为n维空间中的一个点(其中n是您拥有的要素数量)，每个要素的值是特定坐标的值。然后，我们通过找到能够很好地区分这两类的超平面来执行分类。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nk"><img src="../Images/cfa44db504c005338338003c6c5d7a4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/0*Mf25ZqmacjHToaM0"/></div></figure><ul class=""><li id="88d1" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">来自sklearn.naive_bayes的GaussianNB:</strong>Naive bayes算法是一种基于应用Bayes定理的分类技术，它强烈假设所有预测器都是相互独立的。简而言之，假设一个类中某个特性的存在独立于同一个类中任何其他特性的存在。它是最简单的朴素贝叶斯分类器，假设来自每个标签的数据来自简单的高斯分布。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nl"><img src="../Images/c5cd112f6148478c890643a014875acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/0*aUUFvr_OHL3VmNGU"/></div></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="dc74" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated"><strong class="ak">从模型中得出的结论</strong></h1><p id="b03b" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们得到了我们的最佳模型，即逻辑回归，其准确率为86.7%。这里，我们的模型预测176个阳性病例中的162个真阳性病例和119个真阴性病例中的94个真阴性病例。</p><p id="d295" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它预测176个阳性病例中的14个假阳性病例和119个病例中的25个假阴性病例。它给出了82.8%的f1分数。</p><p id="f4cc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">理解什么是精确回忆和f1分数和准确度</strong></p><ul class=""><li id="3a38" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj"> F1得分</strong>:这是精确度和召回率的调和平均值，比精确度矩阵更能衡量错误分类的情况。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/b2371ac033ce6799df4fe72335865bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/0*1bVNByhUzeiw-qNw"/></div></figure><ul class=""><li id="d109" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">精度:</strong>隐含为从所有预测阳性病例中正确识别阳性病例的度量。因此，当假阳性的成本很高时，它是有用的。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nn"><img src="../Images/94870731f9d0b48e9e45f9362267a6ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*YYaEqut14wn3VW_9"/></div></figure><ul class=""><li id="e7ff" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">召回:</strong>是从所有实际阳性病例中正确识别出阳性病例的度量。当假阴性的成本很高时，这一点很重要。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es no"><img src="../Images/2edfaf9c10bec772784e9704e93166f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/0*rJ7a1fo3ayjOhBzc"/></div></figure><ul class=""><li id="5894" class="ma mb hi is b it iu ix iy jb mk jf ml jj mm jn mf mg mh mi bi translated"><strong class="is hj">准确性:</strong>更明显的度量之一，它是所有正确识别的案例的度量。当所有的类都同等重要时，它最常用。</li></ul><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/e7d2c8cce8a6e8f977c8d30d6ac12a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/0*79m3LsmvxoaXTWIv"/></div></figure><p id="4d4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">混乱矩阵</strong></p><p id="997b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">混淆矩阵是一个表格，通常用于描述一个分类模型(或“分类器”)对一组真实值已知的测试数据的性能。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es np"><img src="../Images/4bd26e2c329c177b133ad59f82ae7aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/0*sJkhZAiYkWhApohG"/></div></figure><blockquote class="nb nc nd"><p id="eb84" class="iq ir lb is b it iu iv iw ix iy iz ja ne jc jd je nf jg jh ji ng jk jl jm jn hb bi translated"><strong class="is hj">注:</strong></p><p id="96ca" class="iq ir lb is b it iu iv iw ix iy iz ja ne jc jd je nf jg jh ji ng jk jl jm jn hb bi translated"><strong class="is hj">TN/真阴性:</strong>病例阴性，预测阴性。</p><p id="2f84" class="iq ir lb is b it iu iv iw ix iy iz ja ne jc jd je nf jg jh ji ng jk jl jm jn hb bi translated"><strong class="is hj">TP/真阳性:</strong>病例阳性，预测阳性。</p><p id="0d47" class="iq ir lb is b it iu iv iw ix iy iz ja ne jc jd je nf jg jh ji ng jk jl jm jn hb bi translated"><strong class="is hj">FN/假阴性:</strong>病例为阳性但预测为阴性。</p><p id="dc1c" class="iq ir lb is b it iu iv iw ix iy iz ja ne jc jd je nf jg jh ji ng jk jl jm jn hb bi translated"><strong class="is hj">TN/真阴性:</strong>病例为阴性但预测为阳性。</p></blockquote></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="74e7" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated"><strong class="ak">超参数调谐</strong></h1><p id="5c3f" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">机器学习中的超参数优化旨在找到给定机器学习算法的超参数，这些参数在验证集上测量时提供最佳性能。与模型参数相反，超参数由机器学习工程师在训练之前设置。随机森林中的树的数量是超参数，而神经网络中的权重是在训练期间学习的模型参数。我喜欢将超参数视为要调整的模型设置，以便模型可以最优地解决机器学习问题。</p><p id="6111" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用GridSearchCV进行超参数调优。</p><p id="9199" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> GridSearchCV </strong></p><p id="e241" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在GridSearchCV方法中，机器学习模型针对一系列超参数值进行评估。这种方法被称为GridSearchCV，因为它从超参数值的网格中搜索最佳超参数集。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nq"><img src="../Images/e3940faf1660297078e6faf2a9fc6c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y6HcX0fvV-SbTEGG"/></div></div></figure><p id="fed9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> ROC曲线:</strong> AUC — ROC曲线是在各种阈值设置下对分类问题的性能测量。ROC是概率曲线，AUC代表可分性的程度或度量。它告诉我们这个模型在多大程度上能够区分不同的类。AUC越高，模型预测0为0和1为1的能力越强。以此类推，AUC越高，模型在区分患病和未患病患者方面就越好。</p><p id="9ebd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用TPR对FPR绘制ROC曲线，其中TPR在y轴上，FPR在x轴上。</p><figure class="lp lq lr ls fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/948eadd57383659d15ce7ea77c9fb120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/0*hZDinXOZfjV0mTq9"/></div></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="3a5a" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">评论</h1><p id="f74a" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们从数据探索开始，对数据集有所了解，检查缺失的数据，了解哪些特征是重要的。在这个过程中，我们使用了<em class="lb"> seaborn </em>和<em class="lb"> matplotlib </em>来做<em class="lb">可视化</em>。在数据预处理部分，我们计算缺失值，将特征转换为数值，将值分组并创建一些新特征。后来，我们开始训练5种不同的机器学习模型，选择了其中一种(逻辑回归)。然后，我们讨论了逻辑回归的工作原理，了解了它对不同特性的重要性，并通过优化其超参数值来调整其性能。最后，我们查看了它的混淆矩阵，并计算了模型的精度、召回率和f值。最后我们绘制了模型的受试者工作特征曲线，并计算了AUC值。</p><p id="6381" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当然，仍有改进的空间，如通过相互比较和绘制特征并识别和去除有噪声的特征，进行更广泛的特征工程。另一个可以改善整体结果的事情是对几个机器学习模型进行更广泛的超参数调整。你也可以做一些整体学习。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="30e7" class="jp jq hi bd jr js lj ju jv jw lk jy jz ka ll kc kd ke lm kg kh ki ln kk kl km bi translated">其他人</h1><ul class=""><li id="752c" class="ma mb hi is b it kn ix ko jb mc jf md jj me jn mf mg mh mi bi translated">趣味阅读:<a class="ae jo" href="https://www.biography.com/news/titanics-100th-anniversary-6-survivor-stories-20799733" rel="noopener ugc nofollow" target="_blank">泰坦尼克号生存故事</a></li><li id="b3cb" class="ma mb hi is b it mv ix mw jb mx jf my jj mz jn mf mg mh mi bi translated"><a class="ae jo" href="https://www.usnews.com/news/national/articles/2008/09/25/the-secret-of-how-the-titanic-sunk#:~:text=In%201985%2C%20when%20oceanographer%20Robert,again%20in%20the%20public%20imagination." rel="noopener ugc nofollow" target="_blank">水槽背后的秘密</a></li><li id="e784" class="ma mb hi is b it mv ix mw jb mx jf my jj mz jn mf mg mh mi bi translated">理解:<a class="ae jo" href="https://rstudio-pubs-static.s3.amazonaws.com/93031_67e7a901cbdf488b8622cfc1979329ea.html" rel="noopener ugc nofollow" target="_blank">泰坦尼克号生存分析</a>作者李晟</li></ul></div></div>    
</body>
</html>