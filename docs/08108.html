<html>
<head>
<title>Regression: Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归:线性回归</h1>
<blockquote>原文：<a href="https://medium.com/codex/regression-linear-regression-ee499c699c8?source=collection_archive---------6-----------------------#2022-07-17">https://medium.com/codex/regression-linear-regression-ee499c699c8?source=collection_archive---------6-----------------------#2022-07-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="140b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在这篇博客中，我们将讨论我们的第一个机器学习模型，即回归。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/997fa8fb9ef3b4e706643368dc94ac24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tBIjWjelFPnukss5"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">穆罕默德·拉赫马尼在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="e2a3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">回归是一种监督学习技术，用于对特征(数据中的自变量)和目标(数据中的因变量)之间的关系进行建模。它有助于我们理解因变量的值是如何随着自变量而变化的。它预测连续值。</p><p id="0e57" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">例如，我们需要预测温度，我们将采用过去的数据，这些数据具有独立变量，如海拔、位置、一年中的月份等。，和因变量温度，然后对它们之间的关系建模，并在给定新的一组独立变量时预测温度。</p><p id="fcf3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">回归通过绘制因变量和自变量给我们一条直线或曲线，然后给我们一条拟合数据点的直线或曲线，我们利用这些数据点对数据进行预测。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kk"><img src="../Images/3a20d50bca44989b28e90689050b4611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ldkrHHtHv23GErb3ieQkvQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">回归</figcaption></figure><h2 id="e1d0" class="kl km hi bd kn ko kp kq kr ks kt ku kv jx kw kx ky kb kz la lb kf lc ld le lf bi translated">欠拟合</h2><ul class=""><li id="c3a0" class="lg lh hi jq b jr li ju lj jx lk kb ll kf lm kj ln lo lp lq bi translated">在这种情况下，模型无法找到给定的从属值和独立值之间的关系。出现这种情况是因为数据量很小</li></ul><h2 id="d28f" class="kl km hi bd kn ko kp kq kr ks kt ku kv jx kw kx ky kb kz la lb kf lc ld le lf bi translated">过度拟合</h2><ul class=""><li id="13c3" class="lg lh hi jq b jr li ju lj jx lk kb ll kf lm kj ln lo lp lq bi translated">当模型试图拟合已知数据的每个数据点时，这是一种情况，因此它无法对看不见的数据或测试数据执行。</li></ul></div><div class="ab cl lr ls gp lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="hb hc hd he hf"><h1 id="3af1" class="ly km hi bd kn lz ma mb kr mc md me kv io mf ip ky ir mg is lb iu mh iv le mi bi translated">线性回归</h1><p id="27fb" class="pw-post-body-paragraph jo jp hi jq b jr li ij jt ju lj im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">线性回归是最简单和最常见的监督学习模型，顾名思义，它是一个回归模型，但在因变量(目标)和自变量(特征)之间找到线性关系。</p><p id="0e1e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">当因变量和自变量绘制在笛卡尔平面上时，它绘制一条试图拟合数据点的线性线。</p><blockquote class="mm mn mo"><p id="085d" class="jo jp mp jq b jr js ij jt ju jv im jw mq jy jz ka mr kc kd ke ms kg kh ki kj hb bi translated"><strong class="jq hj">简单线性回归</strong></p></blockquote><p id="51dd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">考虑这样一种情况，当只有一个独立变量(特征)并且我们需要预测一个值(目标)时，从数学上讲，如果我们想要线性地关联特征和目标，我们将按照<strong class="jq hj"> f(x)=mx + c </strong>来做</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mt"><img src="../Images/e8d349abbe7020956d41d71372be2275.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VGI3iIPTXBYZq0x4ZWSsDg.png"/></div></figure><p id="26d8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这里我们将做一点操作，我可以写<strong class="jq hj"> f(x1) = (w1)(x1) + (w0) </strong>其中x1是独立变量(特征)，w1被称为特征的权重，w0是当特征的值为零时获得的截距。</p><blockquote class="mm mn mo"><p id="317f" class="jo jp mp jq b jr js ij jt ju jv im jw mq jy jz ka mr kc kd ke ms kg kh ki kj hb bi translated"><strong class="jq hj">多元线性回归</strong></p></blockquote><p id="dc9f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这种情况下，有不止一个特征，并且模型将目标线性关联为</p><p id="7408" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> f(x1，x2，x3，x4，…)= w0+(w1)(x1)+(w2)(x2)+(w3)(x3)+…</strong></p><p id="4814" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这里w1，w2，w3，… wn是每个特征x1，x2，x3，… xn的权重。</p><h2 id="a363" class="kl km hi bd kn ko kp kq kr ks kt ku kv jx kw kx ky kb kz la lb kf lc ld le lf bi translated">价值函数</h2><p id="bff1" class="pw-post-body-paragraph jo jp hi jq b jr li ij jt ju lj im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">正如我们所知，<strong class="jq hj"> w </strong>的不同值将给出不同的线性关系，因此我们的任务是找出误差最小的最佳拟合线。</p><p id="9997" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">成本函数用于优化系数或权重(w ),并给出我们的模型如何对数据执行的度量。对于线性回归，我们将使用均方误差成本函数。</p><p id="c19b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">残差:实际值<strong class="jq hj"> y </strong>与预测值<strong class="jq hj"> f(x)之间的垂直距离。</strong></p><p id="c876" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果数据点远离回归线，那么残差会很高，误差也会很大，如果数据点离回归线更近，那么残差会更小，误差也会更小，这就是我们选择回归线的方式。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/7b60059b405fcb1594391644734670f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OixYBBq3jwZH7Nshm_sJdQ.png"/></div></div></figure><p id="4fbc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们使用均方误差函数来了解模型绘制的线性关系的准确性。顾名思义，它是残差平方的平均值。</p><p id="53a5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">MSE=(残差平方和)/ N，其中N是数据点的总数。</p><p id="1121" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">均方误差较小的那条线将被视为最佳拟合线，我们的模型将最准确。</p><h1 id="f02a" class="ly km hi bd kn lz mv mb kr mc mw me kv io mx ip ky ir my is lb iu mz iv le mi bi translated">使用PYTHON进行线性回归</h1><p id="aced" class="pw-post-body-paragraph jo jp hi jq b jr li ij jt ju lj im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">我们将使用Scikit Learn库，这是一个免费的机器学习库，具有各种分类、回归和聚类算法。</p><ul class=""><li id="b092" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">导入库和线性回归模型</li></ul><pre class="iy iz ja jb fd nd ne nf ng aw nh bi"><span id="be40" class="kl km hi ne b fi ni nj l nk nl">from sklearn.linear_model import LinearRegression</span></pre><ul class=""><li id="c73d" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">导入用于操作数据集的工具</li></ul><pre class="iy iz ja jb fd nd ne nf ng aw nh bi"><span id="717c" class="kl km hi ne b fi ni nj l nk nl">#import pandas and numpy to use and manipulate the dataset in your<br/>#program<br/>import pandas as pd<br/>import numpy as np</span><span id="98e3" class="kl km hi ne b fi nm nj l nk nl">#this is a function that splits the data into two subsets i.e. #training data and test data<br/>from sklearn.model_selection import train_test_split as tts</span><span id="bcd0" class="kl km hi ne b fi nm nj l nk nl">#importing the mean squared error function<br/>from sklearn.metrics import mean_squared_error as mse</span></pre><ul class=""><li id="107f" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">例如，我们有csv文件</li></ul><pre class="iy iz ja jb fd nd ne nf ng aw nh bi"><span id="ad52" class="kl km hi ne b fi ni nj l nk nl">data=pd.read_csv(“&lt;file_path&gt;”)</span><span id="24d9" class="kl km hi ne b fi nm nj l nk nl">#assuming the data is already cleaned<br/>y = data["&lt;target_column&gt;"]<br/>x = data["&lt;features_required&gt;"]</span><span id="fb36" class="kl km hi ne b fi nm nj l nk nl">#splitting the data into test and train data<br/>x_train,x_test,y_train,y_test=tts(x,y,test_size=0.2,random_state=42)</span><span id="087f" class="kl km hi ne b fi nm nj l nk nl">#the parameter 'test_size' is used to define the size of test dataset, here it says 20 percent of original<br/>#the parameter 'random_state' is used to shuffle the dataset in every execution, otherwise this function return the same split</span></pre><ul class=""><li id="a55e" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">训练模型</li></ul><pre class="iy iz ja jb fd nd ne nf ng aw nh bi"><span id="78e9" class="kl km hi ne b fi ni nj l nk nl">#creating a Linear Regression model named 'model'<br/>model=LinearRegression()</span><span id="639e" class="kl km hi ne b fi nm nj l nk nl">#training the model<br/>model.fit(x_train,y_train)</span></pre><ul class=""><li id="9b4d" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">预测目标值</li></ul><pre class="iy iz ja jb fd nd ne nf ng aw nh bi"><span id="dd39" class="kl km hi ne b fi ni nj l nk nl">prediction = model.predict(x_test)</span></pre><ul class=""><li id="7942" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">寻找准确性</li></ul><pre class="iy iz ja jb fd nd ne nf ng aw nh bi"><span id="4d6b" class="kl km hi ne b fi ni nj l nk nl">#finding the mean squared error between the correct and predicted<br/>#values<br/>error = mse(y_test,prediction)</span><span id="ef54" class="kl km hi ne b fi nm nj l nk nl">#find the square root of the mean squared error to get a more<br/>#concrete idea about the accuracy<br/>r_error = np.sqrt(error)</span></pre><ul class=""><li id="daf4" class="lg lh hi jq b jr js ju jv jx na kb nb kf nc kj ln lo lp lq bi translated">从均方根误差的值，我们可以确定我们的模型的准确性</li></ul><blockquote class="mm mn mo"><p id="770b" class="jo jp mp jq b jr js ij jt ju jv im jw mq jy jz ka mr kc kd ke ms kg kh ki kj hb bi translated">我希望你们都明白什么是线性回归，以及我们如何衡量模型的准确性。</p><p id="386e" class="jo jp mp jq b jr js ij jt ju jv im jw mq jy jz ka mr kc kd ke ms kg kh ki kj hb bi translated">并保持联系以了解更多关于机器学习模型的信息。</p></blockquote></div></div>    
</body>
</html>