<html>
<head>
<title>Understanding the architecture of a GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解GPU的架构</h1>
<blockquote>原文：<a href="https://medium.com/codex/understanding-the-architecture-of-a-gpu-d5d2d2e8978b?source=collection_archive---------4-----------------------#2021-03-25">https://medium.com/codex/understanding-the-architecture-of-a-gpu-d5d2d2e8978b?source=collection_archive---------4-----------------------#2021-03-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="9134" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph"><a class="ae ge" href="http://medium.com/codex" rel="noopener">法典</a></h2><div class=""/><p id="b6d5" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">最近，在故事<a class="ae jm" href="https://vitalitylearning.medium.com/the-evolution-of-a-gpu-from-gaming-to-computing-ff183a1eea4f" rel="noopener">GPU的演变:从游戏到计算</a>中，讨论了CPU和GPU的滞后演变，并强调了GPU如何能够比商用CPU强大得多。我们现在问自己，为什么个人电脑仍然是基于中央处理器，而不是完全由图形处理器。</p><p id="e39f" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">答案是CPU的工作方式与GPU完全不同，下图有助于我们理解主要区别。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jn"><img src="../Images/4fd85db027a4b26eeb9f586710befc0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BBmJUKNouK9pBvd3.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">左:CPU架构；右图:GPU架构。来源:https://www.omnisci.com/technical-glossary/cpu-vs-gpu<a class="ae jm" href="https://commons.wikimedia.org/wiki/File:Cpu-gpu.svg" rel="noopener ugc nofollow" target="_blank">。</a></figcaption></figure><p id="22a7" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">颜色惯例是<em class="kd">绿色</em>代表<em class="kd">计算单元</em>，或<em class="kd">核心</em>，<em class="kd">橙色</em>内存<em class="kd">内存</em>，<em class="kd">黄色</em>控制单元。</p><p id="a74d" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs">计算单位(核心)</strong></p><p id="6c4a" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">乍一看，在CPU中，计算单元“更大”，但数量很少，而在GPU中，计算单元“更小”，但数量很多。大小和数量让人联想到CPU或GPU核心的能力以及它们在设备中的数量。</p><p id="16e9" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">CPU内核比GPU内核更快、更“智能”。</p><p id="ebfe" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">随着时间的推移，CPU内核受益于时钟速度的逐步提高，从而提高了性能(<a class="ae jm" href="https://vitalitylearning.medium.com/the-evolution-of-a-gpu-from-gaming-to-computing-ff183a1eea4f" rel="noopener">GPU的演变:从游戏到计算</a>)。与此相反，GPU经历了时钟减速，以限制功耗并适应移动或嵌入式设备中的安装。安装在机器人上用于室内绘图和导航的Jetson NANO就是一个需要保持最低功耗以延长电池寿命的相关例子。(参见，<a class="ae jm" href="https://www.youtube.com/watch?v=u9l-8LZC2Dc" rel="noopener ugc nofollow" target="_blank">使用ROS和Nvidia Jetson Nano构建室内地图和导航机器人</a>):</p><p id="95e8" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">CPU内核“聪明”的一个证明是能够执行<em class="kd">无序执行</em>。为了优化，CPU可以以不同于指令进来的顺序执行指令，或者当进入分支时，它可以预测在不久的将来最可能需要的指令(<em class="kd">多分支预测</em>)。这样就可以提前准备好操作数并执行这些操作数(<em class="kd">推测执行</em>)，从而节省时间。</p><p id="18f0" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">相反，GPU核心不会做任何复杂的事情，无论如何，它不会在无序执行方面做太多事情。粗略地说，GPU核心的专长是执行浮点运算，如<em class="kd">乘加</em> (MAD)或<em class="kd">融合乘加</em> (FMA)。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es ke"><img src="../Images/15a26cfc83036bc582bc6c55d26f7f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*HSAoDDRGYzf8Tecj79RP0A.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">乘加(MAD)和融合乘加(FMA)运算。来源:<a class="ae jm" href="http://www.netlib.org/utk/people/JackDongarra/WEB-PAGES/SPRING-2011/Lect03.pdf" rel="noopener ugc nofollow" target="_blank">http://www . net lib . org/utk/people/JackDongarra/WEB-PAGES/SPRING-2011/lect 03 . pdf</a>。</figcaption></figure><p id="223c" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">事实上，最近的GPU架构的核心并不局限于FMA，而是执行更复杂的操作，如张量(<em class="kd">张量核心</em>)或光线跟踪(<em class="kd">光线跟踪核心</em>)操作。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es kf"><img src="../Images/0987de47c6383ef0d211bedd584af9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/0*am1WNF8XjEAA-WVe.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">张量核。来源:<a class="ae jm" href="https://www.anandtech.com/show/12673/titan-v-deep-learning-deep-dive/3" rel="noopener ugc nofollow" target="_blank">https://www . Anand tech . com/show/12673/titan-v-deep-learning-deep-dive/3</a>。</figcaption></figure><figure class="jo jp jq jr fd js er es paragraph-image"><div class="ab fe cl kg"><img src="../Images/b2a492704c8c428daba1d37fce93f791.png" data-original-src="https://miro.medium.com/v2/format:webp/0*Ro2_tAmERveLd5Ec.jpg"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">光线跟踪核心。来源:<a class="ae jm" href="https://www.techspot.com/article/2109-nvidia-rtx-3080-ray-tracing-dlss/" rel="noopener ugc nofollow" target="_blank">https://www . techspot . com/article/2109-NVIDIA-RTX-3080-ray-tracing-dlss/</a>。</figcaption></figure><p id="c1fb" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">张量核旨在服务于人工智能中的张量运算，而光线跟踪核旨在服务于超逼真的实时渲染。</p><p id="e551" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">无论简单与否，GPU核心都达不到CPU核心那样的灵活性。值得一提的是，GPU编程模型是SIMD ( <em class="kd">单指令多数据</em>)，这意味着所有内核执行<em class="kd">完全相同的</em>操作，但处理不同的数据。显然，GPU的优势不在于内核的处理能力，而在于它们巨大的并行性。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es kh"><img src="../Images/0d8efc82ff1e445e2cf91b68817d1d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/0*0ooS8q-Eu3olf30O.jpg"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">以战斗的速度划桨的人。来源:<a class="ae jm" href="https://247sports.com/college/kansas/Board/103726/Contents/Ben-Hur-is-getting-a-remake-71260436/" rel="noopener ugc nofollow" target="_blank">https://247 sports . com/college/Kansas/Board/103726/Contents/bing-Hur-is-getting-a-remake-71260436/</a>。</figcaption></figure><p id="00df" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">核心的作用有点像罗马Galea中的划手:鼓手设定和平(<em class="kd">时钟</em>)，划手以战斗的速度平行划桨(<em class="kd">计算</em>)。</p><p id="08d8" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">SIMD编程模型允许加速一大类应用程序。缩放图像的所有像素就是一个例子。在这种情况下，在将每个像素映射到不同的核(假设有足够的核)时，每个核必须简单地缩放一个像素，这可以以大规模并行的方式发生。虽然顺序机器可以解决<em class="kd"> N </em>个时钟脉冲中的问题，其中<em class="kd"> N </em>是像素的数量，但假设有足够的内核来覆盖整个计算负载，手头的GPU只需一个时钟脉冲就可以解决问题。像图像缩放这样的问题是一个令人尴尬的<em class="kd">并行</em>问题，<em class="kd"> </em>也就是说，在这个问题中，人们不需要努力将它分成许多并行任务。实际上，单个像素的缩放完全独立于其他像素的缩放。然而，要在GPU上运行，问题不需要令人尴尬的并行，但它与SIMD计算方案匹配就足够了，即，它可以通过在每个时刻对不同数据重复相同的操作来分解。</p><p id="0095" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">显然，不是每个问题都符合SIMD模型。这尤其发生在<em class="kd">异步</em>问题中，即，对于没有同步结构的问题，其中处理器需要在任何时候相互通信，并且对于这些问题，计算结构可能非常不规则并且负载不均衡。</p><p id="daac" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs">回忆</strong></p><p id="e359" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">从这个故事的第一张图片，我们还可以讨论CPU和GPU在内存方面的差异。</p><p id="6bec" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">CPU存储器系统基于动态随机存取存储器(DRAM ),在台式PC中，它可以是几(例如，8)千兆字节，但是在服务器中可以达到几百(例如，256)千兆字节。</p><p id="1ba9" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">CPU内存系统的另一个支柱是高速缓存，用于减少从DRAM访问数据的时间。高速缓存是更小(例如，每核千字节)、更快的存储器，位于更靠近处理器核的位置，其存储在DRAM中分配的数据的副本。高速缓存可以有层次结构，通常分为三级:L1高速缓存、L2高速缓存和L3高速缓存。高速缓存离内核越近，越小，但速度越快。例如，L1缓存可以是每核64kb，L2缓存可以是每核256 kb，L3缓存可以是每核4m。</p><p id="90d1" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">假设获取存储在DRAM中i100地址的数据。它将与其相邻元素(例如，存储在i98、i99、i101和i102地址的数据)一起从DRAM移至高速缓存。这是因为假设，如果在某个时间需要地址i100，对于接下来的计算，也将需要i101和i102的内容(想象一个<em class="kd">用于连续扫描数组元素的</em>循环)。多亏了缓存，当需要一个数据时，它首先在L1缓存中被搜索。如果找到了，就以最大速度移动到CPU。如果没有，则在L2缓存中进行搜索。如果找到了，它会被高速提取，尽管比L1慢。如果没有，则在L3缓存中寻找数据。最终，如果L3缓存未命中数据，将从DRAM中进行提取。图中橙色区域的数量是衡量DRAM和高速缓存对CPU重要性的一个指标。</p><p id="53c5" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">从图上看，GPU配备了一个DRAM，命名为<em class="kd">全局内存</em>或GMEM。GMEM比中央处理器的DRAM还小。在最便宜的卡中，有几千兆字节可用，而在性能最好的卡中，GMEM可以高达24千兆字节。GMEM的有限规模是对科学计算中使用GPU的第一个主要批评。十年前，显卡只有512兆字节，这个问题现在已经完全解决了。</p><p id="b709" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">关于缓存，从图ontop我们可以推断出缓存机制是由于内核左侧的所有橙色小矩形。但是，缓存在CPU方面存在差异，这一点很快就会得到证明。</p><p id="b66e" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs">了解GPU架构</strong></p><p id="bfda" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">为了充分理解GPU架构，让我们借此机会再次看看第一张图片，其中显卡显示为计算核心的“海洋”。</p><p id="14c1" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在图像缩放示例中，内核不需要协作，因为它们的任务是完全独立的。然而，可以用GPU解决的问题不一定那么简单。让我们用一个例子来说服自己。</p><p id="af3d" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">假设对一个数组的元素求和。这样的操作属于<em class="kd">归约</em>系列，因为它相当于将一个序列“归约”成一个数。对数组元素求和初看起来本质上是连续的。我们需要获取第一个元素，对第二个元素求和，得到结果，对第三个元素求和，再次得到新的结果，对第四个元素求和，等等。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es ki"><img src="../Images/fd1f5d6260138b1b91d565327252efda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/0*UyXhviROUZeZSOtu.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">顺序还原。来源:<a class="ae jm" href="https://www.eximiaco.tech/en/2019/06/10/implementing-parallel-reduction-in-cuda/" rel="noopener ugc nofollow" target="_blank">https://www . eximiaco . tech/en/2019/06/10/implementing-parallel-reduction-in-cuda/</a>。</figcaption></figure><p id="053f" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">令人惊讶的是，看似内在有序的东西可以在并行算法中进行转换。假设数组长度为8，在第一步中，并行执行两两求和就足够了，因此获得4个部分结果。在第二步中，将对部分结果进行求和，再次以两两的方式进行。最后，将最后2个部分结果相加得到最终结果。所描述的分层方案如下所示:</p><figure class="jo jp jq jr fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kj"><img src="../Images/cb4af109cec4a3e49e80ee41b501e1f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VVfRBgqsbEY36Ypa.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">平行缩减。来源:<a class="ae jm" href="https://www.eximiaco.tech/en/2019/06/10/implementing-parallel-reduction-in-cuda/" rel="noopener ugc nofollow" target="_blank">https://www . eximiaco . tech/en/2019/06/10/implementing-parallel-reduction-in-cuda/</a></figcaption></figure><p id="33f9" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">因此，8个数的和只需要三个步骤，不同于需要8个数的顺序情况。一般来说，用2的<em class="kd"> N </em>次方(<em class="kd"> N </em> =2 <em class="kd"> ⁿ </em>)对<em class="kd"> N </em>个数求和，<em class="kd"> n </em>步就足够了，或者等价地，log₂( <em class="kd"> N </em>。</p><p id="6373" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">从GPU的角度来看，假设在第一个时钟拍摄中从0到3编号内核，即c0、c1、c2和c3，将使用所有四个内核，见下图。在第二个时钟快照中，内核c0和c2将利用之前由四个内核绘制的部分结果。c0和c2操作的部分结果应存储在可由相关内核访问的存储器中。在第三个时钟快照中，只有核心c0处于活动状态:它将对核心c0和c2在前面步骤中计算出的结果进行求和。这样的部分结果也应该存储在c0可访问的某个存储器中。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es kk"><img src="../Images/6efc291a9c3ea9cd8ad84af7af2ad0a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*dECpAXZSZi-wD0Si.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">用GPU并行化简。来源:<a class="ae jm" href="https://www.eximiaco.tech/en/2019/06/10/implementing-parallel-reduction-in-cuda/" rel="noopener ugc nofollow" target="_blank">https://www . eximiaco . tech/en/2019/06/10/implementing-parallel-reduction-in-cuda/</a></figcaption></figure><p id="44e5" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">这种推理的结果是内核必须能够使用共享的<em class="kd">存储空间来协作，在该存储空间上存储/获取部分结果。不幸的是，一个GPU可以托管数千个内核，让每个内核与所有其他内核协作将非常困难和昂贵。出于这个原因，GPU核心被组织成组，形成<em class="kd">流多处理器</em>或SMs。</em></p><p id="9aa0" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs">终极GPU架构</strong></p><p id="aa54" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">图灵家族的GPU架构如下图所示:</p><figure class="jo jp jq jr fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kl"><img src="../Images/f67c175c785e80ffa3ce8cae7ddee124.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m69kvZ98wNk9qi6D.jpg"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">图灵架构。来源:<a class="ae jm" href="https://developer.nvidia.com/blog/nvidia-turing-architecture-in-depth/" rel="noopener ugc nofollow" target="_blank">https://bit-tech . net/features/tech/graphics/nvidias-turing-architecture-explained/2/</a>。</figcaption></figure><p id="6dce" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">绿色部分也是计算单位。绿色模块是SMs，黄色<em class="kd"> RT内核</em>靠近它们。图灵体系结构的SM结构如下所示:</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es km"><img src="../Images/7d25e4129dcc564cf333bbd25d403e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/0*nUSveCb5Gi9vC6Oi.jpg"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">图灵SM。来源:<a class="ae jm" href="https://developer.nvidia.com/blog/nvidia-turing-architecture-in-depth/" rel="noopener ugc nofollow" target="_blank">https://developer . NVIDIA . com/blog/NVIDIA-turing-architecture-in-depth/</a>。</figcaption></figure><p id="81fe" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在图灵SM中，在绿色部分中，我们区分不同种类的内核。</p><p id="b377" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><em class="kd"> FP32核心</em>。它们执行单精度浮点运算。考虑到TU102卡，它每个SM有64个FP32内核。既然我们有72条短信，那么卡里FP32s的总数就是4608条。</p><p id="d17a" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><em class="kd"> FP64核心</em>。实际上，在浮点内核中，应该提到每个SM有2个FP64内核执行双精度浮点运算，尽管FP64内核没有包括在上面的图像中。</p><p id="208a" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><em class="kd">整数核心</em>。这些内核对整数执行操作(例如，地址计算)，并且可以与浮点数学数据路径同时执行指令。在前几代GPU中，只要需要非浮点运算，执行这些指令就会使浮点流水线停滞不前。在TU102中，有4608个整数核心，每个SM 64个。</p><p id="977a" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><em class="kd">张量核</em>。张量核心是FP16单元的分组，即半精度单元，专用于加速常见深度学习操作的张量计算。图灵张量内核还可以执行INT8和INT4精度运算，用于可以容忍量化且不需要FP16精度的工作负载。在TU102中，每个SM有8个张量内核，卡上总共有576个。</p><p id="99eb" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在大致描述了GPU的执行部分之后，让我们来看看上面提出的关于协作的问题。</p><p id="77a0" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在SM的底部，有一个L1缓存/共享内存。这是内核可以工作的内存。每个SM都有一个专用的L1缓存/共享内存。作为片上L1缓存/共享内存，它的大小有限(图灵架构为96k字节)，但它非常快，肯定比GMEM快得多。</p><p id="6912" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">实际上，L1缓存/共享内存具有GMEM访问的缓存和共享内存的双重功能。当内核需要协同工作并交换部分结果时，编码器会对线程进行编程，将部分结果存储在共享内存中，以便随后可以读取它们。这个内存的另一个作用域是缓存。当内核需要访问GMEM时，首先在L1缓存中搜索数据。如果没有找到，则在L2缓存中搜索它们，该缓存是所有SMs的横向缓存。L2缓存比L1缓存大，但速度慢。如果数据在L2找不到，那就从GMEM取来。缓存中的数据会持续存在，除非它们被“更新”的数据驱逐。从这个角度来看，如果需要从GMEM多次访问数据，程序员有权将它们绑定在共享内存中，以加快读取速度。共享内存可以被认为是由<em class="kd">控制的缓存</em>。事实上，L1缓存和共享内存是从同一个电路获得的，程序员有权决定卡是否必须将更多的内存用于缓存或共享内存。</p><p id="77ea" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">最后但并非最不重要的是，可用于存储部分结果的存储器不限于共享存储器。事实上，寄存器代表了离内核最近、最快但最小的内存(见上图中的<em class="kd">寄存器文件</em>)。基本思想是每个线程都可以有一个寄存器来存储临时结果。每个寄存器只能被单条线或同一<em class="kd">经纱</em>或32条连续线的组中的线看到。</p></div></div>    
</body>
</html>