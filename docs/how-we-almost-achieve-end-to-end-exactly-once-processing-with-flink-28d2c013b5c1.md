# 我们如何(几乎:)使用 Flink 实现端到端的一次性处理

> 原文：<https://medium.com/codex/how-we-almost-achieve-end-to-end-exactly-once-processing-with-flink-28d2c013b5c1?source=collection_archive---------2----------------------->

分布式有状态流处理具有挑战性，尤其是在处理故障和恢复方面。在流处理中，最常被问到的一个问题是“*我的流处理系统是否保证每条记录都被处理一次且只有一次，即使在处理过程中遇到一些故障*？”

通过说“*-恰好一次*”语义，我的意思是每个到来的事件恰好影响最终结果一次。即使在机器或软件出现故障的情况下，也不会有重复的数据和未经处理的数据。我们正在使用 Apache Flink，这是一个分布式流处理引擎，长期以来一直在 Flink 应用程序本身中提供一次语义*。Flink 以固定的、可配置的时间间隔生成检查点，然后将它们写入持久存储系统，并在输入流中附加位置。在从故障中恢复的过程中，Flink 从最近成功完成的检查点继续处理。Flink 的检查点算法是基于 1985 年由 Chandy 和 Lamport 介绍的一种技术，这种技术可以绘制分布式系统当前状态的一致快照，不会丢失信息，也不会重复记录*

但是我说的“端到端”是指将“恰好一次”语义扩展到相关的外部系统 Flink 在处理后发送数据。想象一个非常标准和简单的流程，它使用 Kafka topic 中的事件，执行 1 分钟的滚动窗口，一旦窗口到期，就将所有事件写入数据库。以便将事件分组到 1m 个桶中，并通过单个批量插入操作写入。

![](img/7c66a73aafc2a652fc3960b9cd4c90d3.png)

具有外部状态的流处理

显然，理想的情况是所有传入的事件最终都会出现在 DB 中，但只会出现一次。

**等幂书写**

如果应用程序写入具有相关一致的唯一标识符的记录，那么可以通过写入数据库的幂等实现来实现“恰好一次”。这意味着，指示 DB 忽略或覆盖重复，这样即使在重新处理相同事件的情况下，也不会对外部表产生真正的影响。

回到示例应用程序，该应用程序每分钟向 DB 写入一次原始事件，每个事件都有一个关联的 ID，可以用作表 PK。假设每 5 秒触发一次 Flink 检查点，两个检查点之间可能会发生故障。在这种情况下，Flink 将从最后一个检查点恢复，并从那里重放。实际上，来自最后一个检查点的所有消息都将被重新处理并发送到 DB(下图中的*红色虚线*内的所有事件),但它们将被忽略，因为这是两次写入相同事件 ID 的尝试。

![](img/21ac3d3964ec5fb3530650cfe7a96609.png)

重新处理虚线时间线事件，但是 DB 忽略它们

有人可能会说这种模式实际上是无状态事件处理，Flink 可能是一种矫枉过正的解决方案。当有一个状态分布在多个节点上时，复杂的 Flink 检查点机制非常有用，应该正确地持久化，但是这个应用可以简单地由本地 Kafka 消费者/生产者 API 实现，将事件分组，将它们写下来，然后提交 Kafka 偏移量。在任何消费者超时或重试的情况下，相同的消息将被重新处理，但没有实际影响。我同意。如果每一个应用都是确定性的和幂等的，我们的生活会容易得多(或者无聊:)。

**卡夫卡交易**

如果应用程序是从入站主题到出站主题的消费-处理-生产形式，那么通过 Kafka 事务 API 生产消息可能是通过原子操作消费、处理和生产消息的一个好选择。

![](img/0183959d835ec89bc8bdd07de277d8ea.png)

这里的关键是，任何轮询出站主题的下游 Kafka 消费者将只接收一次这些结果消息——它保证不会有重复，即使数据接收器需要重试生成消息。失败场景可能意味着原始消息被多次使用和处理(或部分处理)，但这绝不会导致发布重复的出站事件。

为了利用这种技术，所有这三个操作符(源、窗口和接收器)都应该在同一个组件上运行，这样任何出站消息的生成都将被提交消费者偏移量的同一个事务所包围。以下是交易流程:

1.  启动新事务的服务调用 `beginTransaction`
2.  服务通过生产者发布消息
3.  消费者补偿也被发送给生产者，以便包含在同一事务中
4.  服务调用`commitTransaction`来完成事务

为了支持事务性生产，Kafka 引入了新的组件和概念，如消费者协调器、事务协调器和事务日志，这些在他们的 60 页设计文档中有详细描述，但重要的是要认识到，在原始消息被重新传递的情况下，作为处理的一部分发生的所有其他动作仍然可以发生多次。例如，如果应用程序对其他应用程序执行 REST 调用，或者对数据库执行写入，这些仍然会发生多次。保证处理产生的事件只被写一次。

**两阶段提交方法**

还有另一种类型的应用程序，它使用 Kafka，执行一些聚合，然后将结果写入外部数据库。通常很难实现幂等性，因为聚合值可能会改变，但另一方面，它们不能真正受益于 Kafka 事务，因为它无论如何都没有绑定到 DB 事务。

让我们稍微改变一下我们的原始示例，这样它就可以计算 1 分钟窗口内发生的事件数，并将这个聚合值(只是这个数字)写入一个 DB，而不是写入原始事件。显然，我们的主题有几个分区和几个并行运行的 source、windowing 和 data sink 操作符实例。业务不需要任何 keyBy 或逻辑分区，我们只是希望以分钟的粒度来计数事件。试图实现等幂书写:我们在聚合表中的记录标识符应该是什么？将它定义为 *<接收器实例 ID，分钟>* 是有问题的，因为无法保证在恢复后相同的事件将被发送到相同的操作符实例。下图显示了一种潜在的情况，其中特定的接收器操作符实例最初处理 e45、e47 和 e52 事件，但在从最后一个检查点恢复后，它获得了 e48、e49 和 e50(只是因为它现在获得了 windows 不同的上游 windows 操作符)。

![](img/2449185b739030d53db7bb7592988a1c.png)

[TwoPhasedCommitSink](https://nightlies.apache.org/flink/flink-docs-master/api/java/org/apache/flink/streaming/api/functions/sink/TwoPhaseCommitSinkFunction.html) 功能的 Flink 功能真的很有用。为了在这种情况下实现恰好一次，Flink 支持使用其内部检查点机制协调对外部系统的写入。外部系统必须提供提交或回滚写操作的方法，以便这些事件可以被触发，并与 Flink 的检查点管理相协调。在分布式系统中协调提交和回滚的一种常见方法是[两阶段提交协议](https://en.wikipedia.org/wiki/Two-phase_commit_protocol)。两阶段提交接收器应该实现四种不同的方法，Flink 将在检查点设置过程的各个阶段调用这些方法:

1.  一个事务将两个检查点之间的所有写操作捆绑在一起，因此写操作总是在一个事务的范围内。这个函数在新检查点开始时被调用。因此，如果您的数据库支持，您可以在这里打开一个数据库事务，或者在文件系统中创建一个临时文件。所有后续事件处理将使用它，直到下一个检查点。
2.  `preCommit`在成功保持其内部状态后，一旦接收器获得检查点屏障，就由接收器调用预提交。这将由每个接收器调用，以便只有在所有接收器成功执行预提交后，Flink JobManager(协调器)才能提交检查点。在这里，您可以刷新文件，关闭它，永远不会再写入它。或者，为属于下一个检查点的任何后续写入启动新的数据库事务。
3.  `commit`只有当作业管理器通知每个接收器检查点已完成时，每个接收器才会调用提交。在这个阶段，您可以自动地将预先提交的文件移动到实际的目标目录，或者提交 DB 事务。
4.  `abort` 中止函数将在分布式检查点被中止或中止一个失败后被协调器拒绝的事务时被调用。例如，在这里，您可以删除临时文件或中止数据库事务。

请注意，这个 sink 实现是与支持事务的 DB 一起工作的。但是，即使在我们的例子中，接收器将聚合写到 AWS AppStream (TimeSeries DB)中，TwiPhasedCommit 函数的自定义实现也是可能的，实际的 DB 写入应该推迟到`commit` 阶段。

需要注意的重要一点是，在成功的预提交之后，必须保证提交*最终成功——我们的操作者和外部系统都需要做出这种保证。如果提交失败(例如，由于间歇性的网络问题)，整个 Flink 应用程序将失败，根据用户的重启策略重启，并再次尝试提交。这个过程非常关键，因为如果提交最终没有成功，就会发生数据丢失。*

因此，我们可以确定所有操作符都同意检查点的最终结果:所有操作符都同意要么提交数据，要么中止提交并回滚。

![](img/42052ef1bba8906599cf7f3980aa7ce3.png)

数据库写入附加到检查点机制

因此，我们最终实现的是，实际的数据库写入是在持久化检查点和使用者偏移量的同一个“事务”中执行的。

# **总结**

在分布式系统中处理有状态处理，尤其是当涉及不同的外部数据源或接收器(Kafka 和 DB)时，是一个挑战。重复消息是每个组件都可能暂时或永远失败这一事实的一个不可避免的方面。Flink 的检查点系统是 Flink 支持两阶段提交协议的基础，旨在提供端到端的恰好一次语义。如上所述，可能会有交易无法完成的罕见情况，Flink 将重新开始并永远重试(或者直到 AWS 解决了他们的 AppStream 中断…)，但这应该是一个非常罕见的情况，可能这个著名的笑话正在考虑:

![](img/3238195306afc1171497eede57a2e11e.png)