<html>
<head>
<title>Generalized Method of Moments (GMM) in R (Part 1 of 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R中的广义矩量法(GMM )(第1部分，共3部分)</h1>
<blockquote>原文：<a href="https://medium.com/codex/generalized-method-of-moments-gmm-in-r-part-1-of-3-c65f41b6199?source=collection_archive---------0-----------------------#2021-06-27">https://medium.com/codex/generalized-method-of-moments-gmm-in-r-part-1-of-3-c65f41b6199?source=collection_archive---------0-----------------------#2021-06-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3da0edfe471ef6ffad8ee3b3146704ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3V3ya-ZdhJb80V_L.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://i.ytimg.com/vi/bNWhsHug1rc/maxresdefault.jpg" rel="noopener ugc nofollow" target="_blank">https://i.ytimg.com/vi/bNWhsHug1rc/maxresdefault.jpg</a>和<a class="ae iu" href="https://youtu.be/bNWhsHug1rc" rel="noopener ugc nofollow" target="_blank">https://youtu.be/bNWhsHug1rc</a></figcaption></figure><p id="c081" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文介绍了广义矩量法(GMM)的基本概念，并讨论了它在R中的应用。感兴趣的观众还可以参考<a class="ae iu" href="http://scholar.google.dk/citations?user=BFWWSE8AAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank"> Morten Nyboe Tabor </a>上传的<a class="ae iu" href="https://youtu.be/bNWhsHug1rc" rel="noopener ugc nofollow" target="_blank">视频</a>。嗯，首先要澄清的是，<strong class="ix hj"> GMM </strong>这里是计量经济学中<strong class="ix hj">广义矩方法</strong>的缩写，而不是机器学习中<strong class="ix hj">高斯混合建模</strong>。即使机器学习以及深度学习也是经济和商学院的热门话题，传统的理论驱动的经验主义思想仍然是课程的核心部分。在我大学的教学之旅中，澄清因果推理和预测之间的区别总是第一个话题。一般来说，即使训练有素的机器学习模型也无法直接说出因果推断。如今，<a class="ae iu" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a>的非凡工具可以尝试将个体观测的预测值分解为每个特征值的贡献。然而，在大多数情况下，只能解释相关性或关联性。关于这个问题的详细讨论可以在由<a class="ae iu" href="https://scottlundberg.com/" rel="noopener ugc nofollow" target="_blank">斯科特·伦德伯格</a> (2021)撰写的<a class="ae iu" href="https://towardsdatascience.com/be-careful-when-interpreting-predictive-models-in-search-of-causal-insights-e68626e664b6" rel="noopener" target="_blank">解释预测模型时要小心</a>中找到，他也是关于<a class="ae iu" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a>的文献的主要作者(<a class="ae iu" href="https://scottlundberg.com/" rel="noopener ugc nofollow" target="_blank">斯科特·伦德伯格</a>，2017)。然而，在实践中，政府的经济决策者或公司的管理者总是考虑政策干预。因此，在反事实分析中，评估某项政策的改变对特定目标的影响通常是文章、报告和学术论文的首选。然而，如果不检查背景和理论，关于训练机器学习模型的SHAP值的结果可能会被误解为因果推断，并产生误导性的政策建议。仅以<a class="ae iu" href="https://scottlundberg.com/" rel="noopener ugc nofollow" target="_blank"> Scott Lundberg </a>发布的<a class="ae iu" href="https://towardsdatascience.com/be-careful-when-interpreting-predictive-models-in-search-of-causal-insights-e68626e664b6" rel="noopener" target="_blank">中所示的案例为例，训练好的模型只是表明了<strong class="ix hj">报告的bug数量与个人更新产品的意图</strong>之间的正相关关系。你认为现在的建议是要求技术人员在将来引入更多的bug来促进销售吗？因此，一系列关于因果推论、经济学或商业理论以及经验策略的概念总是在计量经济学课上讨论。为了便于在反事实分析中评估政策，我们认真讨论了生成参数方程的理论。从数据样本中，实施适当的估计方法来估计意义的固定但未知的参数。统计推断因此被讨论关于因果推断。这是经济学和商业研究中关于实证研究的通常路径。</a></p><p id="236f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">广义矩量法(GMM) </strong>是对指定模型内未知参数的一种估计方法。有趣的是，GMM通常不被讨论，尤其是在计量经济学的第一堂课中，可能是因为时间的限制，大多数不追求学术生涯或博士学位的学生通常只愿意选修一门(或更好的零)计量经济学课程。这是大多数商学院学生对GMM感到陌生的基本原因。然而，他们都只是在他们的项目或报告中应用GMM，因为<strong class="ix hj">普通最小二乘法(OLS) </strong>和<strong class="ix hj">最大似然估计(MLE) </strong>可以看作是GMM。GMM实际上很有吸引力，不仅因为它在概念上将其他极值估计量(如OLS和最大似然估计)纳入综合系统，还因为它在模型构建方面的灵活性。在这第1部分(共3部分)中，我主要关注GMM的基本思想，以及GMM如何以简单线性回归(OLS)为例，更稳健地进行统计推断。在第2部分(共3部分)中，<strong class="ix hj"/>讨论了最大似然估计与GMM之间的关系。在第3部分中，结构模型引入了GMM，因此讨论了<strong class="ix hj">两阶段最小二乘(2SLS)回归</strong>与GMM的比较。请查看<a class="ae iu" href="https://github.com/AlfredSAM/medium_blogs/blob/main/GMM_in_R/GMM_in_R.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/AlfredSAM/medium _ blogs/blob/main/GMM _ in _ R/GMM _ in _ R . ipynb</a>了解这些帖子中使用的代码和示例。</p><h1 id="4af3" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">有哪些瞬间？</h1><p id="b359" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">就以这个简单的例子开始来说明什么是<strong class="ix hj">(人口)</strong> <strong class="ix hj">时刻</strong>。其实在概率论与统计中，<strong class="ix hj">(总体)</strong> <strong class="ix hj">矩</strong>指的是<strong class="ix hj">总体均值或期望</strong>，通常是感兴趣的关键总体参数。比如假设x是正态分布的随机变量，那么它的均值就是E(x)=μ。<em class="kw">另一方面，理论上</em> <strong class="ix hj"> <em class="kw">总体均值或期望</em> </strong> <em class="kw">可以在随机变量</em>的任意函数上实现。例如，通过简单的转换，我们也可以得到σ =E[(x-μ) ]。到目前为止，我们已经得到了两个方程，或者说，两个参数σ和μ的矩条件。通过简单的计算，我们可以得到它们的解:μ=E(x)和σ =E[(x-E(x)) ]。这种简单的计算似乎无助于获得μ和σ的值，因为我们不知道x的分布，因此无法计算相应的<strong class="ix hj">总体均值或期望值</strong>。</p><p id="6f19" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，概率论和统计学提供了从<strong class="ix hj">随机样本</strong>中推断人口的想法或思路。为简单起见，对于这种正态分布的x，采集T <strong class="ix hj">(独立同分布)iid </strong>个随机样本。问题是，我们如何利用这些样本来获得μ和σ的合理估计值？这里我们有强大的基本原理:<strong class="ix hj">大数定律(LLN) </strong> : <em class="kw">样本均值收敛于总体均值</em>。诚然，一些技术问题在教科书中被充分讨论，因此我们至少有几个版本的LLN。在这里，我们只是试图让我们的生活更容易获得LLN的本质意义。因此，我们可以用样本均值(矩)代替上述简单解决方案中的总体均值(矩):</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es kx"><img src="../Images/e22567e0d1ce4a691a4d16d6197a69e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:158/0*PLTP00hWxI98ULPM"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/dc78b023d1ebbd6b4a2c9c83aa6eefb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/0*kiyO-jo-Fiw8CJQ7"/></div></figure><p id="a2e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们只得到基于两个矩条件和随机样本的μ和σ的估计量。通常我们称这样的估计量为<strong class="ix hj">矩量法(MM)估计量</strong>。我只记得在我大学的第一堂统计学课上，老师只是说MM比MLE简单得多，因为在获得估计量时忽略了成束的概率密度函数。关于MM(还有GMM)的直接推论是<strong class="ix hj">只假设了矩条件</strong>，但是<strong class="ix hj">不需要分布假设</strong>。这种性质决定了MM(还有GMM)对于数据生成过程中关于分布的不正确假设是相对稳健的。在大多数以因果推论为中心目标的实证研究中，<strong class="ix hj">稳健性检查</strong>总是需要展示的。</p><h1 id="0487" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GMM目标函数背后的思想是什么</h1><p id="c493" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">在本节中，引入了GMM以表明它比MM更一般化<strong class="ix hj"><em class="kw"/></strong>。简单回顾一下上面的MM估计量的例子。一开始我们只是有<strong class="ix hj">两个</strong>未知参数要估计，然后尝试寻找<strong class="ix hj">两个</strong>时刻的条件。在文献中，这种情况被称为<strong class="ix hj">刚识别的</strong>，这意味着我们有足够的信息(两个矩条件)来求解两个估计量。另一方面，如果只给一个力矩条件呢？这种情况称为<strong class="ix hj">未识别</strong>，表示无法获得唯一解的估计量。最有趣的情况是<strong class="ix hj">过识别</strong>，其中矩条件的个数<strong class="ix hj">大于待估计未知参数的个数</strong>。按照上面的例子，实际上还可以给出一个力矩条件</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/2269d7a043fedc89d71a4160f008798a.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/0*XBI57jUR7iCDasA2"/></div></figure><p id="d45f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第三行是关于正态随机变量的三阶矩。一般来说，有更多的信息来获得未知参数的估计量应该是有利的。然而，在实践中，用样本矩条件代替总体矩条件会产生可能无解的方程组，这仅仅是因为三个方程只给出了两个未知数。下图直观地说明了这一困难:一般来说，我们无法在x轴上找到完全相同的一点来使两条线同时等于零。那么，我们该怎么办呢？</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/45dc2fcc2c6df30eab90a3b3b0d2d4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bDVLU7zljmR95RmBG7piOA.jpeg"/></div></div></figure><p id="d64f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果总体矩条件有效，那么<strong class="ix hj">基于总体矩条件的明智估计器应该使所有相应的样本矩条件尽可能接近零</strong>。因此，我们可以将方程组的求解问题转化为优化问题，目标函数为</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/c01a3284f55dbb6e8f5c07c726ea2918.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/0*i1KRyWBTL3M1UZHS"/></div></figure><p id="1794" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在哪里</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/a1280799eb630af14f17bd03c8eeb84d.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/0*HlnAZzu9ScZLLkmt"/></div></figure><p id="76d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">是这三个样本矩的向量函数。也就是说，未知量的估计量应该是所有样本矩条件的加权平均值的最小值，这种估计量称为<strong class="ix hj">广义矩方法(GMM) </strong>估计量。需要注意的一点是，<strong class="ix hj"> MM估计量只是GMM估计量</strong>的特例。在刚刚确定的的<strong class="ix hj">情况下，上述目标函数应该具有最小值零，使得最优值是MM估计量，以使采样时刻条件下的方程组等于零。这也是有助于检查最小化过程是否对刚刚确定的</strong>情况产生误差的特征。</p><h1 id="f39d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">高效GMM</h1><p id="7700" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">本节讨论最佳权重的选择。从目标函数中，人们可以容易地发现，最优值实际上取决于样本时刻条件和每一时刻权重的选择。问题是，应该选择什么样的权重？为了回答这个问题，我们需要有评价选择的目标或标准，而<strong class="ix hj">效率</strong>就是考虑的总点。一般来说，点估计是不够的，在验证性分析方面通常需要后续的统计推断(例如假设检验和置信区间)。由此可见，通常会考虑估计量的采样分布<strong class="ix hj">。粗略地说，估计量的方差越小越精确。只需跳过繁琐的矩阵微积分推导，当矩条件协方差矩阵的逆作为权值</strong>时，就可以得到<strong class="ix hj">高效GMM估计器</strong>。(马萨诸塞州维尔比克，2004年)也就是说，</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/bf402189104ccbb1d800b8b7d6f3e98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/0*4yGnyWI9aL4QcbrO"/></div></div></figure><p id="b7bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基本原理也很简单。仅以上面的例子为例，可以想象增加越来越多的矩条件是可能的，例如四阶矩、五阶矩等。xᵢ.的然而，你认为它们同等重要吗？从理论上讲，如果某个力矩条件具有很大的方差，那么将其视为不稳定或不可靠是明智的。也就是说，人们应该对这种力矩条件给予较小的重视。实际上，在较大方差的意义上，高阶矩更不稳定，因此应该对它们赋予较小的权重以保持估计量的稳定性(尽可能小的方差)。</p><p id="089e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">就可操作性而言，我们需要对这种权重矩阵进行可行的估计，因为它取决于未知数。因此，估计策略是两步走的。在第一步中，我们仅仅使用相等的权重(单位矩阵)来获得所有未知数的估计。利用这样的估计，其仍然是未知量的<strong class="ix hj">一致</strong>估计，我们可以得到权重矩阵的以下一致估计:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es li"><img src="../Images/734eda801e18e385353bc866a6e02636.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/0*9BfHO3s4BcqvwzBq"/></div></figure><p id="fc63" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当然，<strong class="ix hj">这个结果也取决于样本之间没有自相关的假设，但是允许样本之间有不同的方差</strong>。因此，我们有了关于<strong class="ix hj">有效GMM </strong>的采样分布的完整表达式:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/75d055827c2101ad81cc9f4868669a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*_k6jSjRuOwncL7CoWq-xEA.png"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/44996552ad1784294130976fd5d62dc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*1BMCutSPsP-qUGxKjwJCXA.png"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/aca3098e203a0566dbef8acdd519b4dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*xbSeu7n75E2tYyWFqLC2JQ.png"/></div></figure><p id="6c73" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中D是导数矩阵，用于测量矩条件对未知量变化的敏感性，在实践中，使用样本矩代替总体矩进行一致估计。幸运的是，在R中，我们有包<code class="du lm ln lo lp b">gmm</code>来处理上述优化过程和统计推断的标准误差的计算(Chaussé，p . 2021)。</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="3551" class="lu ju hi lp b fi lv lw l lx ly"># Simulate One column data</span><span id="7bb8" class="lu ju hi lp b fi lz lw l lx ly"># Reproducible<br/>set.seed(123)<br/># Generate the data from normal distribution<br/>n &lt;- 200<br/>x &lt;- rnorm(n, mean = 4, sd = 2)</span><span id="8a2d" class="lu ju hi lp b fi lz lw l lx ly"># set up the moment conditions for comparison</span><span id="c80f" class="lu ju hi lp b fi lz lw l lx ly"># MM (just identified)<br/>g0 &lt;- function(tet, x) {<br/>  m1 &lt;- (tet[1] - x)<br/>  m2 &lt;- (tet[2]^2 - (x - tet[1])^2)<br/>  f &lt;- cbind(m1, m2)<br/>  return(f)<br/>}</span><span id="a77d" class="lu ju hi lp b fi lz lw l lx ly"># GMM (over identified)<br/>g1 &lt;- function(tet, x) {<br/>  m1 &lt;- (tet[1] - x)<br/>  m2 &lt;- (tet[2]^2 - (x - tet[1])^2)<br/>  m3 &lt;- x^3 - tet[1] * (tet[1]^2 + 3 * tet[2]^2)<br/>  f &lt;- cbind(m1, m2, m3)<br/>  return(f)<br/>}</span><span id="2457" class="lu ju hi lp b fi lz lw l lx ly">print(res0 &lt;- gmm(g0, x, c(mu = 0, sig = 0)))</span><span id="5d87" class="lu ju hi lp b fi lz lw l lx ly">print(res1 &lt;- gmm(g1, x, c(mu = 0, sig = 0)))</span></pre><p id="e35d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">人们可以检查详细的结果</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="bf5d" class="lu ju hi lp b fi lv lw l lx ly">summary(res0)</span></pre><p id="a563" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果是</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="41d0" class="lu ju hi lp b fi lv lw l lx ly">Call:<br/>gmm(g = g0, x = x, t0 = c(mu = 0, sig = 0))<br/><br/><br/>Method:  twoStep <br/><br/>Kernel:  Quadratic Spectral<br/><br/>Coefficients:<br/>     Estimate     Std. Error   t value      Pr(&gt;|t|)   <br/>mu    3.9812e+00   1.2373e-01   3.2177e+01  3.7093e-227<br/>sig   1.8814e+00   9.9904e-02   1.8832e+01   4.1605e-79<br/><br/>J-Test: degrees of freedom is 0 <br/>                J-test                P-value             <br/>Test E(g)=0:    0.000702626643691055  *******             <br/><br/>#############<br/>Information related to the numerical optimization<br/>Convergence code =  0 <br/>Function eval. =  67 <br/>Gradian eval. =  NA</span></pre><p id="d833" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">和</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="e2a3" class="lu ju hi lp b fi lv lw l lx ly">summary(res1)</span></pre><p id="8809" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果是</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="9cb9" class="lu ju hi lp b fi lv lw l lx ly">Call:<br/>gmm(g = g1, x = x, t0 = c(mu = 0, sig = 0))<br/><br/><br/>Method:  twoStep <br/><br/>Kernel:  Quadratic Spectral(with bw =  0.71322 )<br/><br/>Coefficients:<br/>     Estimate     Std. Error   t value      Pr(&gt;|t|)   <br/>mu    3.8939e+00   1.2032e-01   3.2364e+01  8.9213e-230<br/>sig   1.7867e+00   8.3472e-02   2.1405e+01  1.1937e-101<br/><br/>J-Test: degrees of freedom is 1 <br/>                J-test   P-value<br/>Test E(g)=0:    2.61527  0.10584<br/><br/>Initial values of the coefficients<br/>      mu      sig <br/>4.022499 1.881766 <br/><br/>#############<br/>Information related to the numerical optimization<br/>Convergence code =  0 <br/>Function eval. =  63 <br/>Gradian eval. =  NA</span></pre><p id="afcd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个简单的例子说明了如何使用<code class="du lm ln lo lp b">gmm</code>包进行GMM。重点是设置关于时刻条件的功能，如<code class="du lm ln lo lp b">g0</code>和<code class="du lm ln lo lp b">g1</code>。自变量是参数<code class="du lm ln lo lp b">tet</code>和数据<code class="du lm ln lo lp b">x</code>，输出是T × q矩阵，其中q是矩条件的数量。实际上，这个函数需要导出每个样本(行)的q矩条件的结果。将这个函数放入<code class="du lm ln lo lp b">gmm</code>中，包将完成剩下的工作来获得估计值和标准误差。下面关于回归的例子可以说明更多的细节。</p><h1 id="ae48" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">OLS扮演GMM</h1><p id="84e4" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">这一部分通过一个更现实的例子来说明OLS和GMM的关系。简短的回答是，OLS估计量实际上是GMM估计量。为了解释这个问题，说明启发OLS的<strong class="ix hj">线性投影模型</strong>中嵌入的人口矩条件是有益的。</p><p id="1d98" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设𝑦的线性预测值是𝒙′𝜷形式的函数。我们怎样才能让这样的<strong class="ix hj">线性预测器</strong>明智地成为<strong class="ix hj">最佳</strong>？实际上我们可以有合理的目标函数，称为<strong class="ix hj">均方预测误差(MSE)</strong>:𝑆(𝜷)=𝔼[(𝑦−𝒙′𝜷】。给定𝒙，𝑦的<strong class="ix hj">最佳线性预测器</strong>是𝒫[𝑦∣𝒙]=𝒙′𝜷，其中𝜷最小化均方预测误差𝑆(𝜷)=𝔼[(𝑦−𝒙′𝜷】。请注意，最小化𝜷=argmin𝑆(𝒃)被称为<strong class="ix hj">线性投影系数</strong>。人们可以很容易地证明，极小𝜷只是使𝔼[𝒙𝑒]=𝔼[𝒙(𝑦−𝒙′𝜷)]=𝔼[𝒙𝑦]−𝔼[𝒙𝒙′](𝔼[𝒙𝒙′])^(-1)𝔼[𝒙𝑦]=0从这样的优化问题的一阶条件。看，我们刚刚导出了关于人口矩条件的向量函数:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/27e53a8de46975e8f6f2110a53dbbdbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*UkEb7XLLPaNwFeAu8a-spw.png"/></div></figure><p id="a79e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中<strong class="ix hj">投影误差</strong>通过构造定义为𝑦和𝒫[𝑦∣𝒙]: 𝑒=𝑦−𝒙′𝜷.之间的差异只要遵循GMM的逻辑，就可以得到相应的样本矩条件。还有一点需要注意，这是MM的情况，因为矩条件的数量与未知数的数量相同:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/ec30fa2e331e8e52c5907afb20e5fee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/0*Iodb2Ar745LriYVb"/></div></figure><p id="6da9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一方面，上面的<strong class="ix hj">线性投影模型</strong>只是授权OLS给出样本。另一方面，OLS估计量的含义也指向与上述完全相同的方程组:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/ec30fa2e331e8e52c5907afb20e5fee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/0*Iodb2Ar745LriYVb"/></div></figure><p id="2d86" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，OLS估计量就是GMM估计量，在给定同一组样本的情况下，它们应该给出完全相同的估计。然而，一个棘手的问题是，在没有特殊设置的情况下，它们具有不同的协方差。基本原因是来自线性回归情况下有效GMM的抽样分布:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/a4a8bdaef140b8d20ec53f2c56fe5e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X32fVcgWMZYPtFIGc4Whug.png"/></div></div></figure><p id="5893" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是在线性回归情况下有效GMM估计量的协方差矩阵的结果。默认情况下，有效的GMM估计器只考虑样本间的<strong class="ix hj">异方差</strong>。也就是中间部分是</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es md"><img src="../Images/3da757c8e403f4ffb500b1ac80dedd8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*dwjGeUTyNWx7Ox4UcDa5yg.png"/></div></figure><p id="527b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">实际上我们也有</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es me"><img src="../Images/7caa95c6a85d12f2d53e10a4a2706554.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*WFvb5qp-gRyFRELkJI2tvA.png"/></div></figure><p id="b94f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">和</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/3792234ea6802bda20b06c7cdb7cfce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0MMs6AOix83vFyRQVTp1QA.png"/></div></div></figure><p id="7f15" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">实际上，这个协方差矩阵就是OLS估计量的<strong class="ix hj">怀特(1980)异方差稳健协方差</strong>。但是，包中的默认OLS协方差通常采用以下形式</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/b23432efe9b53d91a4a93141c211dee7.png" data-original-src="https://miro.medium.com/v2/resize:fit:110/0*AD6zi_aSG5Ficxl5"/></div></figure><p id="3db1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，<strong class="ix hj">在线性回归中，即使是OLS估计量也只是GMM估计量，但GMM的软件包通常会生成比OLS </strong>更稳健的协方差矩阵。在jupyter笔记本中，关于R &amp; D支出和专利的数据被用来说明这一点。关于数据的细节，也请查看<a class="ae iu" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南(第二版)</a>第<strong class="ix hj"> 7.3.2 </strong>节。</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="54b8" class="lu ju hi lp b fi lv lw l lx ly"># Simple regression can be implemented<br/>lm_res &lt;- patents_df %&gt;%<br/>  lm(p91 ~ lr91 + aerosp + chemist + computer + machines +<br/>    vehicles + japan + us, data = .)</span><span id="44df" class="lu ju hi lp b fi lz lw l lx ly">summary(lm_res)</span></pre><p id="b478" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果是</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="dfc5" class="lu ju hi lp b fi lv lw l lx ly">Call:<br/>lm(formula = p91 ~ lr91 + aerosp + chemist + computer + machines + <br/>    vehicles + japan + us, data = .)<br/><br/>Residuals:<br/>    Min      1Q  Median      3Q     Max <br/>-355.26  -54.78   -1.84   34.98  624.22 <br/><br/>Coefficients:<br/>            Estimate Std. Error t value Pr(&gt;|t|)    <br/>(Intercept) -234.631     55.543  -4.224 3.88e-05 ***<br/>lr91          65.639      7.907   8.302 2.91e-14 ***<br/>aerosp       -40.771     35.700  -1.142   0.2550    <br/>chemist       22.915     26.640   0.860   0.3909    <br/>computer      47.370     27.834   1.702   0.0906 .  <br/>machines      32.089     27.941   1.148   0.2524    <br/>vehicles    -179.949     36.731  -4.899 2.21e-06 ***<br/>japan         80.883     41.060   1.970   0.0505 .  <br/>us           -56.964     28.794  -1.978   0.0495 *  <br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1<br/><br/>Residual standard error: 114.8 on 172 degrees of freedom<br/>Multiple R-squared:  0.4471,	Adjusted R-squared:  0.4213 <br/>F-statistic: 17.38 on 8 and 172 DF,  p-value: &lt; 2.2e-16</span></pre><p id="ef6c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一方面，GMM的估计类似于上一部分中的例子:</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="ed1b" class="lu ju hi lp b fi lv lw l lx ly"># Generate the data with all needed variables only<br/>df_n &lt;- patents_df %&gt;%<br/>  select(<br/>    p91, lr91, aerosp, chemist, computer, machines,<br/>    vehicles, japan, us<br/>  ) %&gt;%<br/>  mutate(const = 1) %&gt;%<br/>  # Please hold the order as previous glm() to facilitate comparison<br/>  select(<br/>    p91, const, lr91, aerosp, chemist, computer, machines,<br/>    vehicles, japan, us<br/>  )</span><span id="a988" class="lu ju hi lp b fi lz lw l lx ly">## Need to converse the tibble class to dataframe<br/>df_n &lt;- as.data.frame(df_n)</span><span id="aa31" class="lu ju hi lp b fi lz lw l lx ly">mom_lm &lt;- function(beta, df) {<br/>  # df is the data frame with first column as dv<br/>  # This function returns n * q matrix<br/>  # Each column is one moment condition before taking sample average<br/>  # There are totally q moment conditions</span><span id="a2c2" class="lu ju hi lp b fi lz lw l lx ly">y &lt;- as.numeric(df[, 1])<br/>  x &lt;- data.matrix(df[, 2:ncol(df)])</span><span id="ef7f" class="lu ju hi lp b fi lz lw l lx ly"># Refer to moment conditions of QMLE<br/>  m &lt;- x * as.vector(y - x %*% beta)</span><span id="2c38" class="lu ju hi lp b fi lz lw l lx ly">return(cbind(m))<br/>}</span><span id="3b23" class="lu ju hi lp b fi lz lw l lx ly">set.seed(1024)<br/>gmm_lm_mds &lt;- gmm(mom_lm, df_n, rnorm(length(coef(lm_res))),<br/>  wmatrix = "optimal",<br/>  vcov = "MDS",<br/>  optfct = "nlminb",<br/>  control = list(eval.max = 10000)<br/>)<br/>summary(gmm_lm_mds)</span></pre><p id="b22b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果是</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="c191" class="lu ju hi lp b fi lv lw l lx ly">Call:<br/>gmm(g = mom_lm, x = df_n, t0 = rnorm(length(coef(lm_res))), wmatrix = "optimal", <br/>    vcov = "MDS", optfct = "nlminb", control = list(eval.max = 10000))<br/><br/><br/>Method:  twoStep <br/><br/>Kernel:  Quadratic Spectral<br/><br/>Coefficients:<br/>          Estimate     Std. Error   t value      Pr(&gt;|t|)   <br/>Theta[1]  -2.3463e+02   7.3190e+01  -3.2058e+00   1.3468e-03<br/>Theta[2]   6.5639e+01   1.2913e+01   5.0833e+00   3.7097e-07<br/>Theta[3]  -4.0771e+01   1.9869e+01  -2.0521e+00   4.0164e-02<br/>Theta[4]   2.2915e+01   2.4433e+01   9.3787e-01   3.4831e-01<br/>Theta[5]   4.7370e+01   4.0565e+01   1.1678e+00   2.4291e-01<br/>Theta[6]   3.2089e+01   2.4385e+01   1.3159e+00   1.8820e-01<br/>Theta[7]  -1.7995e+02   4.3154e+01  -4.1699e+00   3.0474e-05<br/>Theta[8]   8.0883e+01   7.5709e+01   1.0683e+00   2.8537e-01<br/>Theta[9]  -5.6964e+01   3.6552e+01  -1.5585e+00   1.1913e-01<br/><br/>J-Test: degrees of freedom is 0 <br/>                J-test                P-value             <br/>Test E(g)=0:    4.08752755490864e-14  *******             <br/><br/>#############<br/>Information related to the numerical optimization<br/>Convergence code =  0 <br/>Function eval. =  66 <br/>Gradian eval. =  590 <br/>Message:  X-convergence (3)</span></pre><p id="b477" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">人们可以发现，OLS和GMM都能给出与我们的讨论相一致的相同的点估计。另一方面，它们的标准误差不同。实际上，我们可以通过下式获得白色鲁棒标准误差</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="58db" class="lu ju hi lp b fi lv lw l lx ly"># The estimates of the above GMM are the same as those in lm<br/># The sd of the above GMM are the white heterosketicity robust cov for linear regression<br/>diag(vcovHC(lm_res, type = "HC0"))^0.5</span></pre><p id="0d22" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果是</p><pre class="ky kz la lb fd lq lp lr ls aw lt bi"><span id="021e" class="lu ju hi lp b fi lv lw l lx ly">(Intercept)73.1895474823068<br/>lr91 12.9127608451989<br/>aerosp 19.8685659210385<br/>chemist 24.4331404653491<br/>computer 40.5652626257489<br/>machines 24.3850596348934<br/>vehicles 43.1544093699569<br/>japan 75.7092057725459<br/>us 36.5516092451842</span></pre><p id="dace" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也就是说，白色的协方差与GMM的相同，再次与我们的讨论相一致。</p><h1 id="e969" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">摘要</h1><p id="08df" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">这篇文章或一系列文章的主要目的是用最少的数学知识和最多的概念来介绍GMM。总的来说，回顾这一系列关于GMM的文章可能有助于建立计量经济学中未知参数极值估计的统一体系。特别是从讨论中，人们可以得到以不同方式理解问题的提示。例如，观众可能记得OLS估计量在没有投影误差正态假设的情况下仍然是渐近正态的，一种解释是GMM估计量只有在矩条件有效时才是渐近正态的。另一方面，人们也可以设想R中的<code class="du lm ln lo lp b">gmm</code>包是强大的，可以用最少的编码工作来执行GMM过程。这里还可以提出关于<code class="du lm ln lo lp b">gmm</code>应用的几点:</p><ul class=""><li id="6cf1" class="mh mi hi ix b iy iz jc jd jg mj jk mk jo ml js mm mn mo mp bi translated">应尽可能设置<code class="du lm ln lo lp b">wmatrix</code><code class="du lm ln lo lp b">"optimal"</code>(默认)，以便使用最佳权重提高效率。同时，将相应地应用两步估计，以采用一致的权重估计。</li><li id="2da0" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated"><code class="du lm ln lo lp b">vcov</code>的设置很棘手。在<a class="ae iu" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南</a>第151页中，人们可以很容易地检查到<strong class="ix hj">效率GMM </strong>估计量的协方差的表达式。棘手之处在于Wᵒᵖᵗ.的假设请查阅<a class="ae iu" href="https://cran.r-project.org/web/packages/momentfit/vignettes/gmmS4.pdf" rel="noopener ugc nofollow" target="_blank">广义矩量法的第1.1节，可以找到可能的选项。一般来说，对于允许<em class="kw">异方差</em>的<em class="kw">鞅差序列</em>，至少应该使用<code class="du lm ln lo lp b">"MDS"</code>。就线性回归的情况而言，来自GMM的这种协方差矩阵应该与异方差一致性协方差矩阵(HCCM)估计器的怀特<code class="du lm ln lo lp b">HC0</code>版本相同。此外，在马尔诺·维尔比克的书</a><a class="ae iu" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南</a>中，他也建议至少将这样的假设应用于稳健的标准误差。为了复制马诺·维尔比克的书<a class="ae iu" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南</a>中的结果，将使用这个选项。然而，<code class="du lm ln lo lp b">gmm()</code>函数<strong class="ix hj">默认情况下</strong>使用<code class="du lm ln lo lp b">"HAC"</code>，它假设弱依赖进程。实际上，这应该比<code class="du lm ln lo lp b">"MDS"</code>更稳定，因为<code class="du lm ln lo lp b">"HAC"</code>对于异方差和自相关都是鲁棒的。</li><li id="d8e0" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">在https://github . com/Alfred Sam/medium _ blogs/blob/main/GMM _ in _ R/GMM _ in _ R . ipynb中，详细讨论了在GMM设置下复制OLS估计量的协方差，但在实践中几乎没有用处。</li><li id="4595" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">请确保<code class="du lm ln lo lp b">optfct</code>应该设置为<code class="du lm ln lo lp b">"nlminb"</code>而不是默认的<code class="du lm ln lo lp b">"optim"</code>，这样会产生<strong class="ix hj">不正确的结果</strong>。在后面的帖子里，这一点会被高度讨论。</li></ul></div><div class="ab cl mv mw gp mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hb hc hd he hf"><h1 id="a4ed" class="jt ju hi bd jv jw nc jy jz ka nd kc kd ke ne kg kh ki nf kk kl km ng ko kp kq bi translated">参考</h1><ul class=""><li id="575a" class="mh mi hi ix b iy kr jc ks jg nh jk ni jo nj js mm mn mo mp bi translated">Chaussé，P. (2021年)。<a class="ae iu" href="https://cran.r-project.org/web/packages/gmm/vignettes/gmm_with_R.pdf" rel="noopener ugc nofollow" target="_blank">用R </a>计算广义矩方法和广义经验似然。<em class="kw">统计软件杂志</em>，<em class="kw"> 34 </em> (11)，1–35。</li><li id="2aa4" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">肖斯议员和肖斯议员(2021年)。<a class="ae iu" href="https://cran.r-project.org/web/packages/gmm/gmm.pdf" rel="noopener ugc nofollow" target="_blank">包‘GMM’</a>。</li><li id="3a42" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">米·维尔比克(2004年)。<a class="ae iu" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南(第二版)</a>。ERIM(电子)书籍和章节。约翰·威利的儿子们，奇切斯特。</li><li id="dcc7" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">布鲁斯·汉森(2021)。<a class="ae iu" href="https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf" rel="noopener ugc nofollow" target="_blank">计量经济学</a>。威斯康星大学打字稿。普林斯顿大学出版社，即将出版。</li><li id="34c5" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">布鲁斯·汉森(2021)。<a class="ae iu" href="https://www.ssc.wisc.edu/~bhansen/probability/Probability.pdf" rel="noopener ugc nofollow" target="_blank">经济学家概率统计</a>。威斯康星大学打字稿。普林斯顿大学出版社，即将出版。</li><li id="f772" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">Lundberg，s .，，Lee，S. I. (2017)。解释模型预测的统一方法。<em class="kw"> arXiv预印本arXiv:1705.07874 </em>。</li><li id="7036" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">Lundberg，s .，，Lee，S. I. (2021)。<a class="ae iu" href="https://towardsdatascience.com/be-careful-when-interpreting-predictive-models-in-search-of-causal-insights-e68626e664b6" rel="noopener" target="_blank">在解释预测模型以寻找因果洞察力时要小心</a>。<a class="ae iu" href="https://towardsdatascience.com/" rel="noopener" target="_blank">走向数据科学</a>。</li><li id="9ab5" class="mh mi hi ix b iy mq jc mr jg ms jk mt jo mu js mm mn mo mp bi translated">怀特·哈尔伯特(1980)。“异方差一致的协方差矩阵估计量和异方差的直接检验”。<a class="ae iu" href="https://en.wikipedia.org/wiki/Econometrica" rel="noopener ugc nofollow" target="_blank"> <em class="kw">计量经济学</em> </a>。<strong class="ix hj">48</strong>(4):817–838。<a class="ae iu" href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" rel="noopener ugc nofollow" target="_blank">CiteSeerX</a><a class="ae iu" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.7646" rel="noopener ugc nofollow" target="_blank">10 . 1 . 1 . 11 . 7646</a>。<a class="ae iu" href="https://en.wikipedia.org/wiki/Doi_(identifier)" rel="noopener ugc nofollow" target="_blank">doi</a>:<a class="ae iu" href="https://doi.org/10.2307%2F1912934" rel="noopener ugc nofollow" target="_blank">10.2307/1912 934</a>。<a class="ae iu" href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" rel="noopener ugc nofollow" target="_blank"> JSTOR </a> <a class="ae iu" href="https://www.jstor.org/stable/1912934" rel="noopener ugc nofollow" target="_blank"> 1912934 </a>。<a class="ae iu" href="https://en.wikipedia.org/wiki/MR_(identifier)" rel="noopener ugc nofollow" target="_blank">先生</a>T20】0575027。</li></ul></div></div>    
</body>
</html>