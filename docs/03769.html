<html>
<head>
<title>NLP: Sentiment Analysis or Emotion Mining on Amazon Product Reviews - Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理:亚马逊产品评论的情感分析或情感挖掘-第一部分</h1>
<blockquote>原文：<a href="https://medium.com/codex/nlp-sentiment-analysis-or-emotion-mining-on-amazon-product-reviews-part-1-428d43112027?source=collection_archive---------0-----------------------#2021-09-23">https://medium.com/codex/nlp-sentiment-analysis-or-emotion-mining-on-amazon-product-reviews-part-1-428d43112027?source=collection_archive---------0-----------------------#2021-09-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/878d9831d065e96f3067298d2c2e7d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*YNyJ9dA7WrPj90PF6hhB3w.jpeg"/></div></figure><p id="217f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">太棒了。既然您已经成功地从Amazon网站中挖掘了文本语料库，那么让我们学习NLP技术来对从Amazon中提取的产品评论执行情感分析或情感挖掘。</p><p id="810c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你还在纠结如何进行文本挖掘，请参考我之前的文章<a class="ae jk" rel="noopener" href="/codex/text-mining-how-to-extract-amazon-reviews-using-scrapy-5bd709cb826c">文本挖掘:如何使用Scrapy </a>提取亚马逊评论，以一种非常简单的方式解释。</p><p id="6be6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">那么，我们开始吧。这是自然语言处理的系统方法，用于执行情感分析或情感挖掘。本文分为两部分。第一部分包括文本预处理和特征提取，第二部分包括文本语料库上的情感分析或情感挖掘。</p><h1 id="d89e" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated"><strong class="ak">导入库和数据集</strong></h1><p id="dfc3" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">首先，我们从使用python导入NLP所需的所有库开始。</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><p id="d8b3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">关于NLP非常重要的库是<a class="ae jk" href="https://docs.python.org/3/library/string.html" rel="noopener ugc nofollow" target="_blank">字符串</a>和<a class="ae jk" href="https://spacy.io/usage/spacy-101" rel="noopener ugc nofollow" target="_blank">空间</a>。两者在文本处理中都发挥着巨大的作用。</p><p id="ceac" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">python中的字符串是一个序列或有序的字符集。它是一种派生的数据类型，一旦定义就不能更改。然而，使用replace()、join()、strip()或split()命令可以进行各种字符串修改，但是它们不会更改原始字符串，而是修改该字符串的副本并返回值。</p><p id="bf9d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Spacy用于python中的高级NLP。它旨在精确处理和理解大量文本，包括信息提取、自然语言理解(NLU)或深度学习的预处理文本。它具有许多语言机器学习功能，如标记化、词性(POS)标注、词汇化、命名实体识别(NER)、文本分类等。</p><p id="909f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，您已经对这些库有了一些背景知识，让我们继续前进，导入我们已经从亚马逊网站为<a class="ae jk" href="https://www.amazon.in/Bosch-Inverter-Control-Automatic-Loading/product-reviews/B08SR372S7/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&amp;reviewerType=all_reviews&amp;pageNumber=" rel="noopener ugc nofollow" target="_blank">博世洗衣机前置</a>提取的亚马逊评论数据集，如下所示:</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><p id="92e6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">输出如下所示:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/7287dc3ce61b90efd8732d1ac4594c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*oA7foVLENLvqftlcmqW7BA.png"/></div></figure><h1 id="1811" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated"><strong class="ak">文本预处理</strong></h1><p id="26ff" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">起点是在将文本数据输入模型或用于分析目的之前，清理和准备文本数据。文本预处理有助于去除数据中以评论、评论或推文形式出现的噪音。它有助于执行文本分析，通过转换所有字符为小写，删除标点符号，删除停用词，错别字等。</p><ol class=""><li id="ee14" class="kv kw hi io b ip iq it iu ix kx jb ky jf kz jj la lb lc ld bi translated">我们首先删除前导字符和尾随字符，并删除空字符串</li></ol><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/7fd0f5157bd7b70eb306804ddea264bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wyAN1Lxw39G0KisjLYIG4g.png"/></div></div></figure><p id="48dc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.接下来，将前面的输出列表合并成一个字符串/文本</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lj"><img src="../Images/87a75f336846be6d225b642671f78b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQFPdZ-DjOldvDxJQlT7pg.png"/></div></div></figure><p id="9b95" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">3.从字符串或文本中删除标点符号</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lk"><img src="../Images/0bfef203d705a7566e775c5a4d6e298d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DMyy7wqbO7gZzY-NftCkQ.png"/></div></div></figure><p id="cb7a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">4.使用NLTK库执行文本标记化</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ll"><img src="../Images/387790858c722b7719defb415ac85107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Un6f9I1ElNAAx0prcS7Q2A.png"/></div></div></figure><p id="fc43" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">5.从文本标记中删除停用词(频繁出现的意义较小的通用词)</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lm"><img src="../Images/905919d01f55b3d2d8de5deb86d45920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2yaoVQjLgmGRiJtla0Z5yg.png"/></div></div></figure><h1 id="e979" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated"><strong class="ak">文本规范化</strong></h1><p id="cee6" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">对文本进行预处理后，下一步是文本规范化，即将文本转换为所有小写字母。这样做是为了减少随机性和消除偏见，将其转换成标准格式，以提高计算机处理不同类型信息的效率。</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ln"><img src="../Images/01949fe8bde1c2068cb528576425587b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8qWRzINJfS9GrjwS-Ltlhg.png"/></div></div></figure><p id="71d4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">文本规范化的目标也是导出单词的词根或基本形式。这可以通过两种方法来实现:词干化或词汇化。</p><h2 id="fb93" class="lo jm hi bd jn lp lq lr jr ls lt lu jv ix lv lw jz jb lx ly kd jf lz ma kh mb bi translated"><strong class="ak">词干</strong></h2><p id="c2b5" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在这里，每个单词的最后几个字符都被删除了，并且经常有不正确的拼写和意思。例如:浪费-&gt;浪费</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mc"><img src="../Images/d8a2300a5e83e47945df59b228497905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*on9H1gQQ6LTlnDFBJ5P5sw.png"/></div></div></figure><h2 id="8253" class="lo jm hi bd jn lp lq lr jr ls lt lu jv ix lv lw jz jb lx ly kd jf lz ma kh mb bi translated">词汇化</h2><p id="621a" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">它比词干法要好，因为它考虑了单词的上下文，并将其转换为正确的拼写和含义。例如:浪费-&gt;浪费</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es md"><img src="../Images/2bb9d678c25e7ab7ed793d365dc140ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_v4Txxp_ondZl0BQCqnmA.png"/></div></div></figure><h1 id="a8ab" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">特征抽出</h1><p id="18bf" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在文本标准化并导出其基本形式后，下一步是特征提取。它侧重于分析不同信息或文本之间的相似性。NLP算法或模型不能处理原始文本，因此需要特征提取来提取特征并将文本转换成矩阵或向量格式。最流行的两种方法是BOW和TFIDF。</p><h2 id="2871" class="lo jm hi bd jn lp lq lr jr ls lt lu jv ix lv lw jz jb lx ly kd jf lz ma kh mb bi translated">1.BOW:字数统计矢量器</h2><p id="a85c" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">单词包创建文本语料库中存在的唯一单词的词汇表，并执行文本矢量化。BOW count矢量器通过为每个单词分配单独的列来创建特征矩阵，每行对应一个评论文本。矩阵中的值表示该评论中唯一单词的存在(1)或不存在(0)。</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es me"><img src="../Images/8ee130d0d0849e205d056a19ffb88125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oew0LdksA0aQs1RJyQQ5CA.png"/></div></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mf"><img src="../Images/4a23aef453f1c62b6f4d9875bd378094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tZdU-Ktpz9Jsm_Am3IWqiw.png"/></div></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mg"><img src="../Images/33b6a1c76ecf44e56eb0409f9eabc858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2QrKMnwV1SdG_SMve3vFNA.png"/></div></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mh"><img src="../Images/7bc2baa4938af67aa86e6180d0a98af8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PjD9QEclyCrAZqFvT604JQ.png"/></div></div></figure><h2 id="7e1c" class="lo jm hi bd jn lp lq lr jr ls lt lu jv ix lv lw jz jb lx ly kd jf lz ma kh mb bi translated">使用N-gram的BOW CV</h2><p id="afa6" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">BOW count矢量器的主要缺点是单词出现的顺序丢失了，因为标记的矢量是以随机顺序创建的。因此，文本失去了它的语境。这个问题可以通过使用保持单词局部顺序的N元语法来解决。N-grams可以是单个grams(单个单词，如“happy”)、双元grams(两个单词放在一起，如“完全失望”)和三元Grams(三个单词放在一起，如“没有服务，不完整”)。</p><p id="7a87" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然而，当词汇量很大时，使用N-gram和BOW会产生巨大的稀疏矩阵(大量的0)。因此，我们需要删除高频n元语法(即停用词)和低频n元语法(即错别字)。理想情况下，中频n-grams效果最佳。我们还可以限制矩阵中使用的特征数量。</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mi"><img src="../Images/0f62a57f4134938b1dfd2277253f2ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8D7hHM43-6thyGMuRLS89w.png"/></div></div></figure><h2 id="930e" class="lo jm hi bd jn lp lq lr jr ls lt lu jv ix lv lw jz jb lx ly kd jf lz ma kh mb bi translated">2.使用N-gram的TFIDF计数矢量器</h2><p id="9245" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">使用n-gram的BOW count矢量器的另一个缺点是，它忽略了在语料库中很少出现但可能具有重要价值的n-gram，如“无演示调用”。虽然这个n-gram很少出现在语料库中，但它突出了需要注意的主要问题。TFIDF矢量器拯救了它。</p><p id="20e7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TFIDF是术语频率逆文档频率的缩写，是术语频率和逆文档频率的乘积。TFIDF值与单词在文档或评论中出现的次数成比例地增加，而与包含该单词的语料库中的文档数成反比地减少。<strong class="io hj"> TFIDF =TF x IDF </strong></p><p id="3097" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TFIDF强调了很少出现但非常重要的特定n-grams。当n-gram在文档中具有高频率而在语料库中具有低文档频率时，TFIDF得分高。对于在语料库中具有高文档频率的n元语法，IDF值和最终的TFIDF值接近于0。当TF和IDF值都很高时，TFIDF值也很高，即n-gram很少但存在于文档中，并且在语料库中具有低文档频率。</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mh"><img src="../Images/a130caaa9b195ed28e05cc7585100a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RF3MwAtkmzjPENJ2hD8nZQ.png"/></div></div></figure><p id="3db0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们难以被计算机理解的文本数据被转换成易于计算机处理的数字数据。此后，您可以继续构建合适的预测模型，并找到业务问题的答案。</p><p id="610d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">由于本文的目的不是建立模型，而是分析文本背后的情感，所以让我们继续深入。</p><h1 id="171c" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">词云</h1><p id="28cd" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">文本语料库中使用的高频词的非常好的可视化可以通过生成词云来实现。在词云中，每个词的大小表明其频率或重要性。只要看一看，你就可以判断你的客户对你的产品有什么评价。</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="ks kt l"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/8f4874d3649849dcffb2b2da0684e739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*YmMlcGWdryAHX0goPfe_1A.png"/></div></figure><p id="12ec" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里，我们完成了如何执行文本预处理和特征提取。要进一步了解如何进行情感分析和情感挖掘，请参考即将发布的文章NLP:亚马逊产品评论的情感分析或情感挖掘-第二部分。</p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><p id="4108" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我将在下一篇文章中写更多关于如何执行自然语言处理文本挖掘的内容，包括文本预处理、特征提取、命名实体识别和情感挖掘或对亚马逊上产品评论的情感分析。所以请关注我在<a class="ae jk" rel="noopener" href="/subscribe/@vaitybharati">媒体</a>上的帖子😃快乐学习！</p><p id="e0f1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">请关注我的<a class="ae jk" href="https://github.com/vaitybharati" rel="noopener ugc nofollow" target="_blank"> GitHub </a>有170多个这样的库。</p><p id="e655" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">另外，请告诉我，你对这篇文章有什么看法。如果你真的觉得这篇文章有用，请鼓掌。</p></div></div>    
</body>
</html>