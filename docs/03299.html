<html>
<head>
<title>Quantization Tutorial in TensorFlow to optimize an ML model like a pro</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow中的量化教程，像专业人士一样优化ML模型</h1>
<blockquote>原文：<a href="https://medium.com/codex/quantization-tutorial-in-tensorflow-to-optimize-a-ml-model-like-a-pro-cadf811482d9?source=collection_archive---------4-----------------------#2021-08-27">https://medium.com/codex/quantization-tutorial-in-tensorflow-to-optimize-a-ml-model-like-a-pro-cadf811482d9?source=collection_archive---------4-----------------------#2021-08-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d7eb" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在TensorFlow中解释和实现量化感知训练和训练后量化</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/15c68dfdb47461478afe33cee8bbfe14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YHaqDKuFQmLC_FC4"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">萨汉德·巴巴里在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="cb01" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果我告诉你，你可以使用量化等技术在这个只有256 kb RAM(内存)和1MB Flash(存储)的微型嵌入式设备上运行机器学习应用程序，会怎么样？</p><p id="cb39" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">印象深刻，对吧？</p><p id="c245" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在某些情况下，与非量化的ML模型相比，通过量化，我们甚至会有一个<strong class="jq hj">稍微好一点的精确度</strong>。但稍后会详细介绍。</p><p id="ef41" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这一点上，我希望我可以用这个小小的介绍让你对量子化感到兴奋。在这篇博文中，你将了解到:</p><ul class=""><li id="6747" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated">什么是量子化？</li><li id="749f" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">量化有什么好处？</li><li id="b6ae" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">量子化是如何工作的？在这里，我们将在TensorFlow中做训练后整数量化和量化感知训练的教程</li><li id="a68d" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">什么时候应该使用哪种量化技术？</li></ul><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">TensorFlow中的量化教程，像专业人士一样优化ML模型</figcaption></figure></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><h1 id="1e78" class="lh li hi bd lj lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated">定义</h1><p id="33f7" class="pw-post-body-paragraph jo jp hi jq b jr lz ij jt ju ma im jw jx mb jz ka kb mc kd ke kf md kh ki kj hb bi translated">量化是一种优化，可以降低模型参数所用数字的精度。例如，在TensorFlow中，模型的参数默认为32位浮点数。</p><p id="8f85" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于这是一个相当技术性的定义，让我们更形象地说明量化:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/9b9598f9fd59836bf1b6680e94eac32b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTMHZUXS4Kc5Exqd6ntw8Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">机器学习中的量化</figcaption></figure><p id="d83a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们有一个想要压缩的模型:</p><ul class=""><li id="5458" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated">我们的模型层的权重分布在-5.4和+4.5的范围内，这是你在这里看到的(第一)条线。这意味着当前所有的权重都是float(32)类型。</li><li id="c6b7" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">在量化中，我们将每个层的最小和最大值存储在int(8)中。所以，我们说-5.4是0，+4.5是255。</li><li id="ff90" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">接下来，通过表示范围内最接近的固定值，将-5.4到+4.5之间的所有float(32)权重压缩为一个八位整数。</li></ul><p id="3da4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从图中可以看出，红色单元格表示量化过程中损失了一些精度。例如，两个不同的值(如-4.87和-4.86)可能由相同的int(8)值表示，这意味着如果我们反转量化，它们将被重构为一个float(32)浮点值。显然，这导致了准确性的降低。</p><p id="b213" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">那么，为什么量子化是如此流行和重要的技术呢？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mf"><img src="../Images/cf4794e1990c1b0266dcbf6e3b442a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-lZdbpG8t2F4lEAA"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://unsplash.com/@alesnesetril?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Ales Nesetril </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="c2cc" class="lh li hi bd lj lk mg lm ln lo mh lq lr io mi ip lt ir mj is lv iu mk iv lx ly bi translated"><strong class="ak">量化的好处</strong></h1><ul class=""><li id="3276" class="kk kl hi jq b jr lz ju ma jx ml kb mm kf mn kj kp kq kr ks bi translated"><strong class="jq hj">闪存(存储)大小:</strong>从32位移动到8位导致内存减少4倍。</li><li id="f225" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj"> RAM(内存)大小:</strong>较小的模型在运行时使用较少的RAM，这释放了内存供应用程序的其他部分使用。此外，这可以转化为更好的性能和稳定性。</li><li id="7d39" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">延迟:</strong> Int8 (v. fp32)格式大大减少了使用模型进行推理的计算量，从而降低了延迟。此外，延迟优化对功耗有显著影响。</li><li id="18b6" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">便携性权衡:</strong>在嵌入式系统中，为了获得更高的效率，通常会牺牲便携性。一些嵌入式设备不支持浮点值，这是使用量化的另一个重要原因。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/5459de20b509d246741f41ac0c3e25a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n2bXZZpW5KgDTKro"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">阿诺德·弗朗西斯卡在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="ef92" class="lh li hi bd lj lk mg lm ln lo mh lq lr io mi ip lt ir mj is lv iu mk iv lx ly bi translated">量子化是如何工作的？</h1><p id="9093" class="pw-post-body-paragraph jo jp hi jq b jr lz ij jt ju ma im jw jx mb jz ka kb mc kd ke kf md kh ki kj hb bi translated">有两种主要的量化形式:</p><ul class=""><li id="682a" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated">训练后量化</li><li id="9cc2" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">量化感知训练</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/8cbf31a7eb97794c2f8816e314712f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Oui-0IsO9gc4QqCH"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">由<a class="ae jn" href="https://unsplash.com/@cgower?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯托弗·高尔</a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="4a82" class="lh li hi bd lj lk mg lm ln lo mh lq lr io mi ip lt ir mj is lv iu mk iv lx ly bi translated">训练后量化</h1><h2 id="88d9" class="mq li hi bd lj mr ms mt ln mu mv mw lr jx mx my lt kb mz na lv kf nb nc lx nd bi translated">理论</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ne"><img src="../Images/e81ec4700da591ebe81be8e4fa806f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jT6JO1tBnsS_P6kQp_iFtQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">训练后量化:TensorFlow提供的技术比较(<a class="ae jn" href="https://www.tensorflow.org/lite/performance/model_optimization" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="bbf5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如图所示，这是TensorFlow自己提供的比较，有三种方法可以使用训练后量化来量化模型(第1–3行)。由于训练后整数量化(第三行)是最准确的，并且大小减少了75%，这就是我将向您展示的技术。</p><p id="787c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">训练后整数量化是一种优化策略，将<strong class="jq hj">所有权重和激活输出</strong>从32位浮点数转换为最接近的8位定点数。训练后整数量化(第1–2行)中使用的其他技术将一些数据留在浮点中。</p><h2 id="6af1" class="mq li hi bd lj mr ms mt ln mu mv mw lr jx mx my lt kb mz na lv kf nb nc lx nd bi translated">张量流</h2><p id="e875" class="pw-post-body-paragraph jo jp hi jq b jr lz ij jt ju ma im jw jx mb jz ka kb mc kd ke kf md kh ki kj hb bi translated">使用TensorFlow Lite转换器将经过训练的浮点TensorFlow模型转换为TensorFlow Lite格式时，可以使用此技术对其进行量化。</p><p id="79f2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在<a class="ae jn" href="https://github.com/superintelligence-lab/tensorflow_model_optimization" rel="noopener ugc nofollow" target="_blank">这个Colab教程</a>中，我们将训练一个MNIST模型，将其转换为Tensorflow Lite文件，并使用训练后整数量化对其进行量化。然后，我们将检查转换后的模型的准确性，并将其与原始模型进行比较。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nf kz l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/735aa6c1e85fb2cfbedbd9994bfc4b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yFrn0h20EkJHU_1y"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">奥斯卡·伊尔迪兹在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="4ff0" class="lh li hi bd lj lk mg lm ln lo mh lq lr io mi ip lt ir mj is lv iu mk iv lx ly bi translated">量化感知训练</h1><h2 id="9a00" class="mq li hi bd lj mr ms mt ln mu mv mw lr jx mx my lt kb mz na lv kf nb nc lx nd bi translated">理论</h2><p id="c998" class="pw-post-body-paragraph jo jp hi jq b jr lz ij jt ju ma im jw jx mb jz ka kb mc kd ke kf md kh ki kj hb bi translated"><strong class="jq hj">量化感知训练不是在训练后应用量化技术，而是在训练期间引入量化误差作为噪声</strong> <strong class="jq hj">。</strong>它是总损失的<strong class="jq hj"> </strong>部分，优化算法试图将其最小化。因此，该模型学习对量化更鲁棒的参数。</p><h2 id="d43c" class="mq li hi bd lj mr ms mt ln mu mv mw lr jx mx my lt kb mz na lv kf nb nc lx nd bi translated">张量流</h2><p id="ce74" class="pw-post-body-paragraph jo jp hi jq b jr lz ij jt ju ma im jw jx mb jz ka kb mc kd ke kf md kh ki kj hb bi translated">TensorFlow Keras提供了一个用于量化感知训练的API，有助于训练具有量化感知的模型。</p><p id="e9cf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">以下是量化整个Keras模型的必要操作:</p><pre class="iy iz ja jb fd nh ni nj nk aw nl bi"><span id="0233" class="mq li hi ni b fi nm nn l no np">import tensorflow_model_optimization as tfmot<br/><br/>model = tf.keras.Sequential([<br/>   ...<br/>])<br/># Quantize the entire model.<br/>quantized_model = tfmot.quantization.keras.quantize_model(model)<br/><br/># Continue with training as usual.<br/>quantized_model.compile(...)<br/>quantized_model.fit(...)</span></pre><p id="2048" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><a class="ae jn" href="https://github.com/superintelligence-lab/tensorflow_model_optimization" rel="noopener ugc nofollow" target="_blank">这个Colab </a>将训练一个有和没有量化感知训练的模型，并比较它们的准确性。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nf kz l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nq"><img src="../Images/1de5b77b3100e10475c39cee6d1cadcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vIFUXTmbj_5n5H_i"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://unsplash.com/@nateggrant?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">内特·格兰特</a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="e212" class="lh li hi bd lj lk mg lm ln lo mh lq lr io mi ip lt ir mj is lv iu mk iv lx ly bi translated">你应该使用哪种量化技术？</h1><p id="7d55" class="pw-post-body-paragraph jo jp hi jq b jr lz ij jt ju ma im jw jx mb jz ka kb mc kd ke kf md kh ki kj hb bi translated">在这篇2020年<a class="ae jn" href="https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html" rel="noopener ugc nofollow" target="_blank"> TensorFlow博客文章</a>中，比较了三种流行模型的准确性，分别使用浮点值、量化感知训练或训练后整数量化。QAT准确度数字是用默认TensorFlow Lite配置训练的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/adb30b84e97f54a640bb4777a1571c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TyVkvFLrHwLBXHz9.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">TensorFlow提供的不同量化技术的准确性比较(<a class="ae jn" href="https://1.bp.blogspot.com/-y2x7mevzJcA/XozZJ2pnjkI/AAAAAAAAC6Y/jg00dVQJLx4wFx7eNz0gOY4gdLRSs3H_wCLcBGAsYHQ/s1600/Screen%2BShot%2B2020-04-07%2Bat%2B12.48.34%2BPM.png" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="bf2a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这种比较真正说明了量化和准确性的所有要点，这真的很重要。</p><ul class=""><li id="509d" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated">首先，你可以看到，在大多数情况下，量化感知训练在准确性方面优于训练后整数量化。这也是为什么这种量化技术最常用的原因。</li><li id="19f1" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">第二个重要观察是<strong class="jq hj">量化感知训练有时甚至比浮点基线模型</strong>更准确，正如您在MobileNet v1中看到的。这也是我在这篇博文开头提到的。</li><li id="a643" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">最后，第三个观察结果是，虽然训练后整数量化在准确性方面通常较差，但仍有一些例外，正如您在MobileNetv2中看到的那样。尽管如此，这种情况非常罕见。</li></ul><p id="bf91" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="ns">我希望你能从TensorFlow的这些量子化教程中获得一些新的见解。让我知道，你还对哪些ML主题感兴趣！</em></p></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><p id="53f6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">来源:</p><p id="c4dc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[1]tensor flow模型优化，<a class="ae jn" href="https://www.tensorflow.org/lite/performance/model_optimization" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/lite/Performance/Model _ Optimization</a>[2]tensor flow模型优化工具包量化感知训练—性能与准确性，2020年4月8日，<a class="ae jn" href="https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html" rel="noopener ugc nofollow" target="_blank">https://blog . tensor flow . org/2020/04/Quantization-Aware-Training-with-tensor flow-Model-Optimization-Toolkit . html</a></p></div></div>    
</body>
</html>