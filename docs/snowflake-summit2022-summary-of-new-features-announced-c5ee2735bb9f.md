# 雪花峰会 2022:发布的新特性摘要

> 原文：<https://medium.com/codex/snowflake-summit2022-summary-of-new-features-announced-c5ee2735bb9f?source=collection_archive---------2----------------------->

雪花数据云在过去的 12 个月里进行了许多突破性的创新，改变了客户使用数据的方式，并扩展了雪花平台的价值。雪花数据云构建于七大支柱之上:

1.  **行业一致性:**与垂直行业及其用例保持一致。你会看到金融数据云、零售、电信、媒体、医疗保健等。由此您可以获得与相应行业相关的数据、工作负载和用例。
2.  **可扩展性和并发性**:雪花支持所有来源、所有数据(结构化、半结构化和非结构化格式)、所有工作负载(机器学习、分析、数据应用、协作)，多集群共享架构对并发性没有限制。数据和计算具有近乎无限的可扩展性，可以运行“任何”工作负载。
3.  **全球**:雪花是全球性的，多云，多地域。这意味着它允许数据和其他雪花对象跨云/跨区域复制。您可以拥有联邦数据，SnowGrid 允许您将其视为一个云。
4.  自我管理的:雪花是聪明的，它在幕后为你工作。这是一个运行良好的平台，它管理着幕后的一切，如安全性、基础架构、优化等。因此，您关注的是您的工作负载，而不是使其工作的基础架构。
5.  **可编程性**:雪花支持 Python、Java、Scala 等各种编程语言，以及 ANSI SQL 来运行你的工作负载。您可以用自己选择的语言编写 UDF，并且可以在 SQL 中使用该 UDF。例如，您可以使用 Python UDF 和 Java UDF 在 SQL 语句中处理雪花表中的列值。您还可以使用 UDTF 将逻辑应用于一组行。
6.  **Marketplace** :雪花有一个社区驱动的 Marketplace，不仅可以共享数据，还可以共享应用。它还允许你的数据和你开发的应用程序货币化。然而，就像苹果商店和谷歌市场一样，雪花市场是为企业服务的。这是合作伙伴开发应用程序并向客户销售的绝佳机会。
7.  **治理**:雪花有许多与数据治理相关的特性，比如动态数据屏蔽、行级策略、加密、数据分类、标记、沿袭和访问历史。合规性等。无论您在哪里访问数据，此功能都会自动启用。因此，您的数据不仅安全，而且符合您的组织定义的合规性。

![](img/64d8cb9e35b4627c753636ffd7b6ffba.png)

*以下是对这些支柱的所有创新和特性的总结:*

1.  [**混合表**](https://www.snowflake.com/blog/introducing-unistore/) :雪花是为分析工作负载而构建的，雪花以柱状格式存储数据。**不再是了！**借助 Unistore 工作负载(又称混合表),您可以在一个地方存储交易数据和分析数据。这将允许您更快地进行单行接收和查找，并使用主键和外键来消除重复行，从而为您提供数据完整性。它允许您进行分析查询，并能够将混合表与“常规”表连接起来。这允许您减少多个数据存储(即一个用于 OLTP，另一个用于分析工作负载)。此外，防止创建将数据从 OLTP 源迁移到雪花的管道。都在一个地方，即雪花。这是消除孤岛的又一步骤。请注意，您可以使用与分析工作负载相同的仓库。
2.  **账号复制**:雪花已经可以让你跨云/跨地域复制数据。但是，现在它允许您复制其他对象，如仓库、用途、角色等。因此，它无缝地允许您在发生灾难时将生产站点重定向到灾难恢复站点。不仅如此，现在您还可以复制管道，因此，如果您有一个从 blob 存储(如 S3)加载数据的管道，该管道可以无缝地复制到另一个区域，而无需复制来自源的数据。
3.  **Snowpipe 流**:目前为止，当新数据到达云存储时，客户使用 Snowpipe 自动接收数据。Snowpipe 流允许接收数据的速度比 snowpipe 快 10 倍。Snowpipe 流使用行集而不是分阶段加载数据，从而减少延迟。它具有对 **Kafka 连接器**的开箱即用支持，这意味着只需对配置文件进行一次更改，您就可以通过利用 snowpipe 流来减少流数据的延迟。Snowpipe 流是一个无服务器的功能。除此之外，雪花还将有**物化表**，它允许你创建一个声明性管道来定义何时以及如何进行增量数据维护。
4.  [**Snowpark for Python**](https://www.snowflake.com/blog/snowpark-python-innovation-available-all-snowflake-customers/):您可以使用自己选择的编程来构建数据工程和机器学习模型，而不用担心为每种编程语言设置单独的集群。您不再需要担心库的版本和依赖性。有了 Snowpark，它现在可以在同一个仓库中运行 SQL、Java、Python 和 Scala 代码，并且您可以在工作负载允许的情况下随时扩展，因此，您可以控制成本。它支持可以在数据帧上操作的标量 UDF 和 UDTF。当然，您可以使用 Jupyter notebook 作为客户端来处理数据框架，但是您也可以选择 IDE 在您喜欢的任何地方运行您的过程。您还可以使用通过 Anaconda 获得的开源库进行 ML 培训。此外，Snowsight 现在有一个基于 Python 的工作表，消除了对额外 ide 的需求，因此您可以更快地开始构建代码。
5.  [**原生应用框架**](https://www.snowflake.com/blog/introducing-snowflake-native-application-framework/) **:** 你可以通过新建一个名为“Streamlit”的一级对象，在雪花上用 Python 构建一个应用。它在 Snowflake 中本地运行，允许你在 Snowflake Marketplace 中列出这个应用程序并从中获利。这将使您能够消除构建&销售应用所需的摩擦和专业知识，例如建立基础设施、构建身份验证、安全性和治理。
6.  **Iceberg Table:** 对于那些由于合规性原因在雪花中加载数据有问题的人，现在您可以选择通过使用真正开源的 Apace Iceberg table 来保管数据(即，将数据保存在您的存储中)。它提供了 CRUD 操作和其他开源的冰山特性，以及雪花的基本特性，如时间旅行、治理等。您所要做的就是创建一个指向 blob 存储的存储卷对象(就像雪花 T12 存储集成对象 T13)，并在创建表时使用该存储卷对象。您数据将与 Iceberg 元数据一起存储在 blob 存储中。冰山数据以拼花格式存储。
7.  **Streamlit 应用:** Streamlit 增加了数据科学和业务团队之间的协作，同时利用 Snowpark 的能力进行模型开发和生产。使用此功能，您现在可以创建一级细流对象“创建细流…”用你的 python 代码，可以在雪花中运行。这将允许您在雪花中构建、部署和安全共享您的 Streamlit 应用程序。
8.  **成本治理**:雪花现在允许您创建一个资源组，您可以通过该资源组向您的客户或业务线添加所有您想要用于成本治理或退款的雪花对象。此外，您可以创建预算并将其与资源组相关联，并在资源组超出预算时创建规则和操作。
9.  **治理**:一个叫做基于标签的屏蔽的新特性，允许你创建基于标签而不是列的策略，这将应用到与标签相关的所有列。因此，如果您有一个新的表/列，您需要做的就是分配一个标记，该列和 dat 将根据您定义的策略受到保护。还宣布了许多其他特性，比如列级沿袭和治理 UI。
10.  **内部数据的外部表**:如果您的数据驻留在内部，并且使用与 S3 API 兼容的存储，如戴尔 ECS、PureStorage 或 [Minio](https://blog.min.io/minio_and_snowflake/) ，那么您的存储可以用作雪花中的外部表，这样可以更容易地将数据加载到雪花中。

除此之外，该平台还有许多增强功能和性能改进，可以帮助您节省成本，例如，**AWS 的性能提高了 10%**，**写入繁重工作负载的性能提高了 10%，**以及存储压缩方面的进一步改进。雪花还宣布了**几何数据类型**的更好性能，它允许更快的本地地理计算，并简化了从传统 DW 到雪花的迁移。所有这些都自动应用到你身上，不需要做任何改变。

总之，雪花数据云是一个单一的产品/服务(软件即服务)，您可以在其中为所有用户安全地放置所有数据并运行所有用例。

*免责声明:本帖表达的观点为本人观点，不一定代表本人雇主(雪花)。*