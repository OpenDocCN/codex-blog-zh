<html>
<head>
<title>Getting the attention of your spatial transformer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">引起你的空间转换器的注意</h1>
<blockquote>原文：<a href="https://medium.com/codex/getting-the-attention-of-your-spatial-transformer-5f43114df937?source=collection_archive---------10-----------------------#2021-08-18">https://medium.com/codex/getting-the-attention-of-your-spatial-transformer-5f43114df937?source=collection_archive---------10-----------------------#2021-08-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="db95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们承认，<strong class="ih hj">空间变形金刚</strong>真的很酷，自从它们在2015年被Google Deep Mind引入以来，它们的潜力还没有被充分挖掘。这些小小的<strong class="ih hj">可区分注意力</strong>砖块非常容易拖放到任何现有的ConvNet中，为其提供了抵抗大规模空间转换的能力，这种转换无法通过max-pooling层的固有空间不变性来捕捉。</p><p id="159c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在最初的工作中，空间转换器增强的ConvNets又名空间转换器网络(<strong class="ih hj">stn</strong>)在一个大型任务面板上进行测试。从原始的MNIST数据集，到街景门牌号码数据集，最后由加州理工学院-加州大学圣迭戈分校Birds 200完成细粒度分类任务。</p><p id="ff5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，是的，如果没有达到<strong class="ih hj">最先进的性能</strong>，我们就不会在这里和一堆其他媒体文章中讨论它们。</p><h1 id="7cae" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">那么，我今天在这里做什么？</h1><p id="e489" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">让它变得非常简单，我们在这里不是为了解释和回顾stn的内部工作原理，我认为最初的文章和我的medium作者同事用每一个可能的工具和动画解释了它们。我们今天要讨论的是如何<strong class="ih hj">构建</strong>(用Pytorch)这些空间转换器的一个变种，即<strong class="ih hj">注意力受限空间转换器</strong>。</p><h1 id="908a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">等等，你想限制空间转换器？</h1><p id="e058" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">你完全正确，当空间转换器建立时，它们被设计成捕捉所有类型的仿射变换。这可以很容易地用一个2×3仿射变换矩阵，或者著名的<strong class="ih hj"> 6维<em class="kg"> θ </em> </strong>来完成，我们在这里和那里不停地谈论。</p><p id="4214" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，当我们想要在空间上扭曲我们的照片时，我们将在我们的空间转换器中做类似的事情(或者在采样网格中，对于你们这些好奇的人来说)</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/4dd62234c4df2053c86c63e0aeecba62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QUzspMqoYAU-IsN0qWJHAA.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">为全仿射空间变换参数化的STN</figcaption></figure><p id="5be6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的<strong class="ih hj"> <em class="kg"> θ </em> </strong>矩阵是一个真正的坏蛋，它可以捕捉所有类型的<strong class="ih hj">缩放</strong>，<strong class="ih hj">旋转，平移，裁剪和倾斜</strong>在物体内部的图像，但如果我们不想要所有这些呢？如果我们只是想让网络关注图像中不在中心的小物体呢？</p><p id="0de1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯那就简单了，我们可以召唤那个不太酷的兄弟，那个<strong class="ih hj">注意力受限的</strong> <strong class="ih hj"> <em class="kg"> θ </em> </strong> <em class="kg">。</em></p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kx"><img src="../Images/21543a84b412fcfcc858219152375f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UotN5VWLwDAJb0cYZ1WGjw.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">注意力受限的空间变换类</figcaption></figure><p id="e330" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所见，这个矩阵只有<strong class="ih hj">个三维</strong>，我们有<strong class="ih hj">个</strong>标度变量和<strong class="ih hj">个</strong>平移变量。在注意力的情况下，我们只想捕捉缩放和平移的对象，所以我们不需要其他θ因子。</p><h1 id="fe4c" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">算够了，给我果汁</h1><p id="032e" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">所以，如果你像我一样，是一个空间转换迷，你可能偶然发现了这个<a class="ae ky" href="https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html" rel="noopener ugc nofollow" target="_blank"> Pytorch教程</a>来让你的STN运行起来。</p><p id="749d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但没有这么快，不幸的是，它只显示了如何建立成熟的仿射空间转换器，而不是我们正在寻找的类型，我们将不得不在这里和那里做一些调整。不会很复杂的，我保证。</p><p id="5d21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们更深入地看一下架构，我们可以看到<em class="kg">定位网络</em>(空间变形金刚的主要黑魔法/深度学习方案)有一个回归器，在最后一层有6个输出神经元。</p><pre class="ki kj kk kl fd kz la lb lc aw ld bi"><span id="b4f1" class="le je hi la b fi lf lg l lh li"><em class="kg"># Regressor for the 3 * 2 affine matrix</em><br/>        self<strong class="la hj">.fc_loc</strong> <strong class="la hj">=</strong> <strong class="la hj">nn.Sequential(</strong><br/>            <strong class="la hj">nn.Linear(</strong>10 <strong class="la hj">*</strong> 3 <strong class="la hj">*</strong> 3<strong class="la hj">,</strong> 32<strong class="la hj">),</strong><br/>            <strong class="la hj">nn.ReLU(True),</strong><br/>            <strong class="la hj">nn.Linear(</strong>32<strong class="la hj">,</strong> 3 <strong class="la hj">*</strong> 2<strong class="la hj">)</strong><br/>        <strong class="la hj">)</strong></span></pre><p id="b32e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这6个输出神经元对应于等式(1)中的<strong class="ih hj"> <em class="kg"> θ仿射矩阵</em> </strong>内的6个变量，当我们要在不使用transformer的情况下进行正向传递时，将使用Pytorch的视图()简单地将输出构建为2×3矩阵。</p><pre class="ki kj kk kl fd kz la lb lc aw ld bi"><span id="6fb2" class="le je hi la b fi lf lg l lh li"><strong class="la hj">theta</strong> <strong class="la hj">=</strong> self<strong class="la hj">.fc_loc(xs)</strong><br/><strong class="la hj">theta</strong> <strong class="la hj">=</strong> <strong class="la hj">theta.view(-</strong>1<strong class="la hj">,</strong> 2<strong class="la hj">,</strong> 3<strong class="la hj">)</strong></span></pre><p id="17a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以如果我们想把它限制在注意力上，我们就必须改变这两个地方的网络行为。</p><p id="b012" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以通过两个小步骤来实现这一点，<strong class="ih hj">首先是</strong>，简单地迫使定位网络具有3个输出神经元而不是6个，一个神经元用于缩放，两个用于转换。</p><pre class="ki kj kk kl fd kz la lb lc aw ld bi"><span id="12e2" class="le je hi la b fi lf lg l lh li">        self<strong class="la hj">.fc_loc</strong> <strong class="la hj">=</strong> <strong class="la hj">nn.Sequential(</strong><br/>            <strong class="la hj">nn.Linear(</strong>10 <strong class="la hj">*</strong> 3 <strong class="la hj">*</strong> 3<strong class="la hj">,</strong> 32<strong class="la hj">),</strong><br/>            <strong class="la hj">nn.ReLU(True),</strong><br/>            <strong class="la hj">nn.Linear(</strong>32<strong class="la hj">,</strong> 3<strong class="la hj">) # ONLY 3 Neurons</strong><br/>        <strong class="la hj">)</strong></span></pre><p id="80fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">其次</strong>，也是最后，我们要建立等式(2)*中定义的2×3矩阵，从著名的定位网络吐出的3个神经元开始。</p><p id="c95f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，从3×1张量开始，我们取第一个特征并将其视为缩放因子，复制它并在2×2矩阵内对角化它。</p><p id="1d2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这之后，我们取剩下的两个特征，把它们当作两个翻译因子，并把所有的东西串联起来，得到最终美丽的<strong class="ih hj"> <em class="kg">注意力受限的</em> </strong> <strong class="ih hj"> <em class="kg"> θ矩阵。</em>T25】</strong></p><pre class="ki kj kk kl fd kz la lb lc aw ld bi"><span id="66d0" class="le je hi la b fi lf lg l lh li"># All this action happens inside the forward pass function<br/>theta = self.fc_loc(xs)<br/><strong class="la hj">scale</strong> = theta[:, 0].unsqueeze(1)<br/>scale_mat = torch.cat((scale, scale), 1)<br/><strong class="la hj">translation</strong> = theta[:, 1:].unsqueeze(2)<br/>theta = <strong class="la hj">torch.cat((torch.diag_embed(scale_mat), translation), 2)</strong></span></pre><p id="721b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Tada！简单地这样做，我们用Pytorch魔法限制了我们的空间转换器！</p><p id="1899" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">*P.S:这背后的原因是，我们可以利用Pytorch中强大的F.affine_grid()函数，只需对空间转换器进行最小的修改。</p><h1 id="811f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">嗯，谢谢，但我只是来看一些有效的东西</h1><p id="744d" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我听得很清楚，你想看到一些结果，但你不确定这是否可行，让我们试试吧。</p><p id="da0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我采用了本文中定义的数据集，我们将28x28的MNIST图像嵌入到一个大的128x128像素的灰度图像中，并添加一些噪声，然后我们从中心随机移动数字。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lj"><img src="../Images/a1d317e7024a11760581e186d019beb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZzDFuBgJ9AWwQD8C"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">128x128噪声偏移MNIST数据集</figcaption></figure><p id="8ba4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于这项任务非常简单，我们只需要一个简单的分类器，LeNet ConvNet就足够了，而且由于空间转换器的魔力，一切都将以端到端的方式学习。所以让我们写下<strong class="ih hj">注意力受限的空间转换器</strong>！</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">注意力受限空间转换器模块的PyTorch体系结构</figcaption></figure><p id="0bbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，我做了完全相同的修改，并更改了F.affine_grid()以返回28x28像素的大小，这是图像的原始大小，因此添加了一些不错的下采样，并且为了使网络更容易学习，我将本地化网络的权重设置为0.2(大约为28 px /128 px)而不是1，以使收敛更快。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lm"><img src="../Images/90e27a561cba712b1f0fe405d2746cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zWGeqdZ9HD4RfxUm6zhazg.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">通过注意力受限空间转换器前后的数据集图像</figcaption></figure><p id="8504" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是事情变得有趣的地方，我们可以看到空间转换器能够学习如何处理大图像中的小数字，并作为一种有效的注意机制，没有任何硬编码的规则或任何额外的监督添加到这个过程中。</p><p id="7b9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这项任务实际上是一个名为Foveated Spatial Transformers的项目的一部分，该项目是一种生物启发的注意力机制，如果您想更深入地了解代码，请随时访问并启动<a class="ae ky" href="https://github.com/dabane-ghassan/int-lab-book" rel="noopener ugc nofollow" target="_blank">官方github repo </a>。</p><p id="8dab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢你走到这一步！</p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="08ae" class="jd je hi bd jf jg lu ji jj jk lv jm jn jo lw jq jr js lx ju jv jw ly jy jz ka bi translated">参考</h1><p id="23be" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae ky" href="https://arxiv.org/abs/1506.02025" rel="noopener ugc nofollow" target="_blank"><em class="kg">【1】马克斯·贾德伯格、卡伦·西蒙扬、安德鲁·齐塞尔曼、科雷·卡武克库奥格鲁；空间变压器网络。arXiv:1506.02025 </em> </a></p><p id="70b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ky" href="https://jov.arvojournals.org/article.aspx?articleid=2770680" rel="noopener ugc nofollow" target="_blank"><em class="kg">【2】埃马纽埃尔·多塞、皮埃尔·阿尔比格斯、洛朗·乌·佩里内；双视网膜中央凹-周边视觉处理模型实现了有效的扫视选择。2020年远景杂志；20(8):22.</em>T11】</a></p></div></div>    
</body>
</html>