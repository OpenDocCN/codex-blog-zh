<html>
<head>
<title>Starting out as a Data Engineer (and how to apply() a regex replace on an entire DataFrame in Spark)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从数据工程师起步(以及如何在Spark中的整个数据帧上应用()正则表达式替换)</h1>
<blockquote>原文：<a href="https://medium.com/codex/starting-out-as-a-data-engineer-and-how-to-apply-a-regex-replace-on-an-entire-dataframe-in-b60f5f37624c?source=collection_archive---------5-----------------------#2022-06-09">https://medium.com/codex/starting-out-as-a-data-engineer-and-how-to-apply-a-regex-replace-on-an-entire-dataframe-in-b60f5f37624c?source=collection_archive---------5-----------------------#2022-06-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/0bb0937a025276788b97436ecc906053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*u1Nvri0qyejLmy4ckEogYg.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">在外面我在工作，但在里面我快死了</figcaption></figure><blockquote class="iq ir is"><p id="5fd1" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果<!-- -->你想直接找到真正简单的解决方案，那就去看看文章底部附近的<strong class="iw hj">对数据帧部分</strong>执行正则表达式(Regex)替换操作。</p></blockquote><h2 id="6299" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">你可能想知道我是怎么来到这里的…</h2><p id="8516" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je kd ks jh ji kh kt jl jm kl ku jp jq jr hb bi translated">最近，我的老板让我做一件非常简单的事情。</p><p id="67c9" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je kd jg jh ji kh jk jl jm kl jo jp jq jr hb bi translated">“嘿，JL！我想让你看一下我们的顾问试图修复的代码。你真的应该删除我们数据中的双引号，但他们说这需要几周时间。”</p><p id="30e5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je kd jg jh ji kh jk jl jm kl jo jp jq jr hb bi translated">因此，我开始尝试寻找一种在整个数据帧上应用<em class="iv">正则表达式替换函数的方法。</em></p><h2 id="db1c" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">关于我和我的工作的一些背景</h2><p id="4ac2" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je kd ks jh ji kh kt jl jm kl ku jp jq jr hb bi translated">我对我的工作不熟悉，刚来不到一个月。我开始尽我所能地学习关于数据工程、数据砖、Azure等等的一切。我曾在发电厂处理物联网数据，这对我来说非常陌生。我确实有一个舒适的开发背景。在疫情开始时，我提高了我的Javascript和Python，所以我至少对数据操作感到满意，尽管在大数据环境中这样做有点不同。</p><h2 id="42f0" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">那么，如何才能从数据工程入手呢？</h2><p id="e9d7" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je kd ks jh ji kh kt jl jm kl ku jp jq jr hb bi translated">无论如何，如果你是从数据工程和大数据的东西开始，只要阅读并练习你可以用<strong class="iw hj"> Spark </strong> (PySpark，熊猫对Spark的东西)做的不同事情，据我所知，你已经有了一个很好的开始。Databricks 平台也有社区版，所以你可以使用它。这只是一个起点。也许，如果以后我有更多的时间，我可以更深入的用什么资源去看看。</p><h2 id="3d26" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">“兔子洞”</h2><p id="06a8" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je kd ks jh ji kh kt jl jm kl ku jp jq jr hb bi translated">所以，如果你开始在谷歌上搜索How<em class="iv">“How to execute regex operation on data frames”</em>，你会看到很多答案，它们看起来是非常简单的解决方案。但是，我可能“过度阅读”了搜索结果，并开始看到为什么你<strong class="iw hj">不应该</strong>使用像<strong class="iw hj"> <em class="iv"> apply()、applymap()、transform() </em> </strong>这样的东西，因为性能问题。我想对此感到焦虑是合理的，这将是我在生产流水线上实现的第一个代码片段，我的老板非常强调要比顾问做的更快。因此，我开始尝试基于我在<strong class="iw hj"> StackOverflow </strong>上看到的东西实现许多非常复杂的代码，并在两天的时间里做了许多疯狂的事情。最后我又回到了只使用<strong class="iw hj"><em class="iv">apply()</em></strong><em class="iv"/>(<strong class="iw hj"><em class="iv">apply()</em></strong>好像比<strong class="iw hj"> <em class="iv"> applymap() </em> </strong>快了不少，所以只是注意一下)。为什么我又回去用<strong class="iw hj"> <em class="iv"> apply() </em> </strong>？嗯，我的解决方案是<em class="iv">过度工程化，</em>而且它甚至都不快。另外，我在使用<strong class="iw hj"> <em class="iv"> apply() </em> </strong>(以及<strong class="iw hj"> <em class="iv"> applymap() </em> </strong>和<strong class="iw hj"><em class="iv">transform()</em></strong><em class="iv"/>)时遇到了麻烦。我可以看到<strong class="iw hj"> <em class="iv"> apply() </em> </strong>不会给我合适的输出，这是因为我在一个系列上使用了<strong class="iw hj"><em class="iv">【replace()</em></strong>方法(这个问题的解决方案在下一节中)。</p><h2 id="f946" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">对数据帧执行正则表达式(Regex)替换操作</h2><p id="b86a" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je kd ks jh ji kh kt jl jm kl ku jp jq jr hb bi translated">感谢<strong class="iw hj"> Tambayan404 discord社区</strong>和我最好的朋友的kuya(菲律宾语中“兄弟”的意思)帮助我弄清楚我需要传递<strong class="iw hj"> <em class="iv"> str </em> </strong>属性，并帮助我更好地理解<strong class="iw hj"> <em class="iv">替换</em> </strong>的方法。(感谢kuya梳理)</p><blockquote class="iq ir is"><p id="fc5d" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">请注意，我摄取了我的数据，它最初是一个<strong class="iw hj"> Spark数据帧(df) </strong>，所以我也转换成一个<strong class="iw hj"> pandas-on-spark数据帧(psdf) </strong>，以便用于<strong class="iw hj"> <em class="hi">。运用()</em> </strong>的方法去工作。</p></blockquote><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="c3e7" class="js jt hi la b fi le lf l lg lh">#imports</span><span id="96ac" class="js jt hi la b fi li lf l lg lh">import pandas as pd<br/>import numpy as np<br/>import pyspark.pandas as ps<br/>from pyspark.sql import SparkSession</span><span id="12c0" class="js jt hi la b fi li lf l lg lh"># Creating a spark dataframe from the CSV file</span><span id="c8ba" class="js jt hi la b fi li lf l lg lh"># File location and type</span><span id="7da0" class="js jt hi la b fi li lf l lg lh"># Note, replace the [] with actual stuff<br/>file_location = "[fill this with your file location]"<br/>file_type = "CSV"</span><span id="69c3" class="js jt hi la b fi li lf l lg lh"># CSV options<br/>infer_schema = "[true or false]"<br/>first_row_is_header = "[true or false]"<br/>delimiter = ","</span><span id="7575" class="js jt hi la b fi li lf l lg lh"># The applied options are for CSV files. For other file types, these will be ignored.<br/>df = spark.read.format(file_type) \<br/>  .option("inferSchema", infer_schema) \<br/>  .option("header", first_row_is_header) \<br/>  .option("sep", delimiter) \<br/>  .load(file_location)</span><span id="c39d" class="js jt hi la b fi li lf l lg lh"># Creating a pandas-on-spark dataframe from spark dataframe<br/>psdf = ps.DataFrame(df)<br/>display(psdf)</span><span id="86c6" class="js jt hi la b fi li lf l lg lh"># Perform an apply on the pandas-on-spark dataframe</span><span id="f99a" class="js jt hi la b fi li lf l lg lh"># Instead of simply passing x to the lambda, you must access the .str property of the Pandas Series that is taken as a parameter by the lambda function<br/># For beginning and end of string only<br/>psdf2 = psdf.apply(lambda x: x.str.strip(‘\”’))<br/># For whole string<br/>psdf3 = psdf.apply(lambda x: x.str.replace(r’\”’, ‘’, regex=True))</span><span id="3c21" class="js jt hi la b fi li lf l lg lh">display(psdf2)<br/>display(psdf3)</span></pre><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es if"><img src="../Images/0bb0937a025276788b97436ecc906053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*u1Nvri0qyejLmy4ckEogYg.jpeg"/></div></figure><p id="8921" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je kd jg jh ji kh jk jl jm kl jo jp jq jr hb bi translated">运行这段代码并显示<em class="iv"> psdf2 </em>和<em class="iv"> psdf3 </em>，您应该会看到<em class="iv"> psdf2 </em>在整个数据帧中的字符串的开头和结尾不再有双引号。而在<em class="iv"> psdf3 </em>中，你应该看到所有的双引号都被完全删除了。当然，您可以将lambda函数替换为您想要在数据帧上应用的任何转换(并将其保存到一个新的数据帧中！).</p></div></div>    
</body>
</html>