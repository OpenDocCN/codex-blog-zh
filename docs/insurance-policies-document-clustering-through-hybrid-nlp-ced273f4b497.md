# 保险单:通过混合 NLP 的文档聚类

> 原文：<https://medium.com/codex/insurance-policies-document-clustering-through-hybrid-nlp-ced273f4b497?source=collection_archive---------4----------------------->

# 保险文档和保单:一个复杂的用例

众所周知，[高达 87%的数据科学项目](https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/)未能从概念验证进入生产；保险领域的 NLP 项目也不例外。相反，他们必须克服几个困难，这些困难不可避免地与这个空间及其复杂性相关联。

最常见的困难来自:

保险相关文档的复杂布局

缺乏带有相关注释的大型语料库。

布局的复杂性如此之大，以至于完全相同的语言概念可以根据它在文档中的位置而极大地改变其含义和价值。

让我们看一个简单的例子:如果我们试图构建一个引擎来识别一个策略中是否存在“恐怖主义”保险，我们将不得不为它指定一个不同的值:

1.申报页面的子限额部分。

2.政策的“除外”一章。

3.增加一项或多项保险的背书。

4.为该覆盖范围添加特定内容的背书。

**缺乏高质量、适当大小的带注释的保险文档**语料库与注释如此复杂的文档的固有困难以及注释数万份保单所需的工作量直接相关。

而这只是冰山一角。除此之外，我们还必须考虑保险概念规范化的必要性。

![](img/0e9e48c810cca88da74de4155acdfeac.png)

[斯科特·格雷厄姆](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

# 语言规范化:保险语言中一股无形而强大的力量

在处理数据库时，**概念的规范化**是一个很好理解的过程，但它对于保险领域的 NLP 也很关键，因为它是应用推理和提高注释过程速度的关键。

规范化概念意味着将看起来可能非常不同的语言元素归入同一标签下。例子很多，但最主要的一个来自针对自然灾害的保险单。

在这种情况下，不同的子限制将适用于不同的洪水区。洪水风险最高的地区通常被称为“高风险洪水区”；然而，这个概念可以表达为:

1.一级洪水区

2. [SFHA](https://www.fema.gov/glossary/flood-zones)

3.洪水区 A

4.诸如此类…

实际上，任何保险都可以有许多可以组合在一起的条款，最重要的自然灾害保险甚至根据具体的地理区域及其内在风险有 2 或 3 层的区别(一级、二级和三级)。

把这个乘以我们能找到的所有可能的元素，变体的数量很快就会变得非常大。这导致 ML 标注器和 NLP 引擎在试图检索、推断甚至标记正确的信息时都很费力。

# 一种新型的语言聚类:混合方法

解决复杂 NLP 任务的更好方法是基于混合(ML/Symbolic)技术，该技术通过基于机器学习的微语言聚类来改进保险工作流的结果和生命周期，然后由符号引擎继承。

而**传统的文本聚类**被用于[无监督学习](https://en.wikipedia.org/wiki/Unsupervised_learning)方法中，以推断语义模式并将具有相似主题的文档、具有相似含义的句子等分组在一起。混合方法有很大的不同。使用预定义的标准化值，通过对标记数据进行训练的 ML 算法，在粒度级别上创建微语言聚类。一旦微语言聚类被推断出，它就可以被用于进一步的 ML 活动或在基于符号层驱动推理逻辑的混合流水线中使用。

这符合传统的编程黄金法则:“分解问题”。解决复杂用例的第一步(就像保险领域的大多数用例一样)是将它分解成更小、更容易接受的块。

![](img/ca601dab5bd0522087625fc09a0aa377.png)

由[凯利·西克玛](https://unsplash.com/@kellysikkema?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

# 混合语言聚类可以完成什么任务，可扩展性如何？

符号引擎经常被贴上极其精确但不可扩展的标签，因为在处理训练阶段看不到的情况时，它们没有 ML 的灵活性。

然而，这种语言聚类的方向是通过利用 ML 识别概念来解决这个问题，这些概念随后被传递给管道中下一个符号引擎的复杂(和精确)逻辑。

可能性是无限的:例如，**符号步骤可以根据概念所属的文档段改变 ML 标识的内在值**。

下面是一个例子，它使用“分段”的符号过程(将一个文本分割成相关的区域)来理解如何使用 ML 模块传递的标签。

假设我们的模型需要理解一份 100 页的保单中是否包含某些保险项目。

ML 引擎首先将“美术”覆盖范围的所有可能变化聚集在一起:

-“美术”

-“艺术作品”

-“艺术品”

-“珠宝”

-等等。

紧接着，管道的符号部分将检查“美术”标签是否在“除外责任”部分中提及，从而了解该保险是被排除在保单之外还是被涵盖(作为子限额列表的一部分)。

由于这一点，ML 注释器将不必担心必须根据它们在策略中的位置为所有“美术”变体分配不同的标签:它们只需要将“美术”的规范化值注释到它的变体，这将作为一个微语言集群。

复杂任务的另一个有用的例子是数据的聚合。如果混合引擎的目标是提取特定覆盖的子限制，以及覆盖规范化问题，那么还有一个额外的复杂层需要处理:语言项聚合的顺序。

让我们考虑一下，手头的任务不仅是提取特定覆盖范围的子限制，而且还要提取它的限定符(每次出现、总计等等。).这三个项目可以按几种不同的顺序排列:

每件艺术品 10 万美元

每件艺术品 100，000 美元

每件 10 万美元的艺术品

十万美元的艺术品

美术 10 万美元

在聚合数据时利用所有这些排列可以大大增加机器学习模型的复杂性。另一方面，混合方法会让 ML 模型识别标准化标签，然后让符号推理基于来自 ML 部分的输入数据识别正确的顺序。

显然，这只是两个例子；无限数量的复杂符号逻辑和推理可以应用于可扩展的 ML 算法之上，用于规范化概念的识别。

# 更易于构建和维护的更具可扩展性的工作流

除了可伸缩性之外，符号推理还为整个项目工作流程带来了其他好处:

不需要为复杂的任务实施不同的 ML 工作流，需要实施和维护不同的标签。此外，对单个 ML 模型进行再培训比对多个模型进行再培训**更快，资源消耗更少**。

由于业务逻辑的复杂部分被象征性地处理*，对于数据注释者来说，向 ML 管道添加手动注释要容易得多。*

*出于上述原因，测试人员也更容易直接为 ML 规范化过程提供反馈。此外，由于工作流的 ML 部分对语言元素进行了规范化，因此用户可以用更少的标签来标记文档。*

***符号规则不需要经常更新**:会比较经常更新的是 ML 部分，也可以受益于用户的反馈。*

*![](img/87e34f4e6df6684b883eba169ea69387.png)*

*由[杰佩·霍夫·詹森](https://unsplash.com/@jayhaywire?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片*

# *总结和结论*

*保险领域复杂项目中的 ML 可能会受到影响，因为**推理逻辑很难被浓缩成简单的标签**；这也使得注释者的生活更加艰难。*

*文本位置和推理可以极大地改变具有相同语言形式的概念的实际含义*

*在一个*纯 ML 工作流*中，一个逻辑越复杂，通常需要越多的训练文档来达到 [**生产级精度**](https://community.expert.ai/articles-showcase-56/precision-and-recall-f-score-and-accuracy-measuring-nlp-performance-191)*

*由于这个原因，ML 需要成千上万(甚至上万)预先标记的文档来构建有效的模型*

*复杂性可以通过采用混合方法来降低:ML 和用户的注释创建语言簇/标签，然后这些将被用作符号引擎达到其目标的起点或构建块，这将管理特定用例的所有复杂性*

*来自用户的反馈一旦被验证，就可以被用来重新训练模型，而不用改变最微妙的部分(可以由工作流的符号部分来处理)*

*[**加入对话**](https://community.expert.ai/articles-showcase-56/insurance-policies-document-clustering-through-hybrid-nlp-238)*