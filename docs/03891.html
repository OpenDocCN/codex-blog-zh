<html>
<head>
<title>Get started with Azure SQL in Databricks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Databricks中的Azure SQL入门</h1>
<blockquote>原文：<a href="https://medium.com/codex/get-started-with-azure-sql-in-databricks-9bfa8d590c64?source=collection_archive---------2-----------------------#2021-10-05">https://medium.com/codex/get-started-with-azure-sql-in-databricks-9bfa8d590c64?source=collection_archive---------2-----------------------#2021-10-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ea8a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">-以熊猫为特色</h2></div><p id="5620" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本教程将介绍如何在Databricks中使用pandas从Azure SQL数据库中读取和写入数据。如果你想学习数据砖块的基础知识，你可以看看<a class="ae jt" href="https://chpatola.medium.com/get-started-with-pandas-in-databricks-70b184be0ad3" rel="noopener">这篇文章</a>。</p><p id="6dad" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">这是关于数据砖块系列的第2部分:</strong></p><ol class=""><li id="9ae5" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js jz ka kb kc bi translated"><a class="ae jt" href="https://selectfrom.dev/get-started-with-pandas-in-databricks-70b184be0ad3" rel="noopener ugc nofollow" target="_blank">从数据砖块中的熊猫开始</a></li><li id="f882" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated">Databricks中的Azure SQL入门</li><li id="5226" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated"><a class="ae jt" rel="noopener" href="/codex/get-started-with-azure-blobs-in-databricks-a6c965b7af4d">从数据块中的Azure Blobs开始</a></li></ol><h1 id="cf1a" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">先决条件</h1><ol class=""><li id="a843" class="ju jv hi iz b ja la jd lb jg lc jk ld jo le js jz ka kb kc bi translated">对蟒蛇熊猫有些熟悉</li><li id="6903" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated">Databricks的一个实例——最好通过<a class="ae jt" href="https://docs.microsoft.com/en-us/azure/databricks/scenarios/quickstart-create-databricks-workspace-portal?tabs=azure-portal" rel="noopener ugc nofollow" target="_blank"> Azure </a></li><li id="6fe1" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated">一个<a class="ae jt" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/single-database-create-quickstart?tabs=azure-portal" rel="noopener ugc nofollow" target="_blank"> Azure SQL数据库实例。</a>确保连接设置允许从数据块访问。如果你在Azure上有Databricks实例，你可以将“<em class="lf">允许Azure服务和资源访问此服务器</em>”(见下图)设置为yes。确保使用强密码/访问方式，因为数据库现在对外界是可访问的。如果你想要更强的安全等级，你可以看一下<a class="ae jt" href="https://databricks.com/blog/2020/02/28/securely-accessing-azure-data-sources-from-azure-databricks.html" rel="noopener ugc nofollow" target="_blank">本指南</a>。</li></ol><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es lg"><img src="../Images/a16cb2319d005c0d20ce8f56d767b619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*rm8-T-lcD6R8_wljTX1WKQ.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">Azure SQL访问设置</figcaption></figure><h1 id="c769" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">我们的演示案例</h1><p id="0348" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">作为演示数据，我们有一个保存课程评估的sql文件。你可以在Github 上找到文件<a class="ae jt" href="https://raw.githubusercontent.com/chpatola/databricks_tutorials/main/data/course_feedback_setup.sql" rel="noopener ugc nofollow" target="_blank">。我们将把这些数据插入我们的Azure SQL服务器，在Databricks中连接到它，用pandas转换它，并把它作为一个新表写回到Azure SQL中。该过程完成后，我们将安排它每月运行一次。</a></p><h1 id="3b6a" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">设置和准备</h1><p id="092b" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">为了进入正题，我们需要一个启动并运行的集群和一个空的python笔记本。如果你不知道如何设置，看看这篇文章中的<a class="ae jt" href="https://chpatola.medium.com/get-started-with-pandas-in-databricks-70b184be0ad3" rel="noopener">步骤1和步骤3。</a></p><p id="e87b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您还需要在Azure SQL中创建一个表，并用我们的示例数据填充它。通过(例如)进入Azure门户中的查询编辑器并在查询编辑器窗格中输入<a class="ae jt" href="https://raw.githubusercontent.com/chpatola/databricks_tutorials/main/data/course_feedback_setup.sql" rel="noopener ugc nofollow" target="_blank"> this query </a>来实现这一点。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es lv"><img src="../Images/07fff2239568a9d86dedf999f5d07852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*YWCO9PQOrBGTePEWMNXTnQ.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">Azure SQL中的查询编辑器</figcaption></figure><p id="a709" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用jdbc/PySpark连接到数据库，然后将数据保存到pandas dataframe中。在这之后，我们对熊猫进行改造。这是可能的，因为我们目前正在处理一个小数据集。如果需要处理大数据，可以用<a class="ae jt" href="http://spark.apache.org/docs/latest/api/python/getting_started/quickstart.html" rel="noopener ugc nofollow" target="_blank"> PySpark </a>或者<a class="ae jt" href="https://databricks.com/blog/2021/10/04/pandas-api-on-upcoming-apache-spark-3-2.html" rel="noopener ugc nofollow" target="_blank"> PySpark熊猫</a>代替。</p><p id="37e6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了使连接工作，您需要数据库名称、服务器名称以及您的用户名和密码(在下面的代码中标记在&lt;&gt;符号内)。当您在Azure中访问数据库时，您会在概览页面上看到数据库名称和服务器名称。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es lw"><img src="../Images/bdde74580f002cdd5367b788cb42553b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nXvK469w6-z3jGXFv_TT-g.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">Azure SQL连接信息</figcaption></figure><p id="05b6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不在笔记本上写用户名和密码是一个好习惯。在本教程中，我们破例这样做，但对于生产数据库，您应该使用一个密钥库或类似的。密钥库允许您为敏感信息提供别名，然后您可以在笔记本中引用该别名，例如:<em class="lf">dbutils . secrets . get(scope = " azurekeyvault _ secret _ scope "，key = "sqldbpwd ")。</em> <a class="ae jt" href="https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-portal" rel="noopener ugc nofollow" target="_blank">这里的</a>是关于如何在Azure上建立密钥库的信息，这里的<a class="ae jt" href="https://docs.microsoft.com/en-us/azure/databricks/security/secrets/secret-scopes" rel="noopener ugc nofollow" target="_blank">是关于如何将其连接到Databricks的信息。完成此操作后，您可以从笔记本中访问密钥库的秘密。</a></p><p id="4f38" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以在下面的GitHub(course _ feedback _ database)上找到我们演示的全部代码。</p><h1 id="b0eb" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">提取</h1><p id="31bf" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">我们从导入所需的库和创建sparksession开始。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="a4d4" class="mg kj hi mc b fi mh mi l mj mk">import pandas as pd<br/>from pyspark.sql import SparkSession</span><span id="e405" class="mg kj hi mc b fi ml mi l mj mk">spark = SparkSession.builder.appName( "pandas to spark").getOrCreate()</span></pre><p id="68c8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们用数据库信息配置jdbc连接。输入变量用<strong class="iz hj">粗体</strong>标记。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="83dc" class="mg kj hi mc b fi mh mi l mj mk">jdbcHostname = "<strong class="mc hj">&lt;database_server_name&gt;</strong>.database.windows.net"</span><span id="5f12" class="mg kj hi mc b fi ml mi l mj mk">jdbcDatabase = "<strong class="mc hj">&lt;database_name&gt;</strong>"</span><span id="8514" class="mg kj hi mc b fi ml mi l mj mk">jdbcPort = 1433</span><span id="77a5" class="mg kj hi mc b fi ml mi l mj mk">jdbcUrl = "jdbc:sqlserver://{0}:{1};database={2}".format(jdbcHostname, jdbcPort, jdbcDatabase)</span><span id="9805" class="mg kj hi mc b fi ml mi l mj mk">connectionProperties = {</span><span id="f844" class="mg kj hi mc b fi ml mi l mj mk">"user" : "<strong class="mc hj">&lt;database_username_or_keyvault_alias&gt;</strong>",</span><span id="ae6a" class="mg kj hi mc b fi ml mi l mj mk">"password" : "<strong class="mc hj">&lt;database_password_or_keyvault_alias&gt;</strong>",</span><span id="f139" class="mg kj hi mc b fi ml mi l mj mk">"driver" : "com.microsoft.sqlserver.jdbc.SQLServerDriver"</span><span id="d6c1" class="mg kj hi mc b fi ml mi l mj mk">}</span></pre><p id="3f14" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在可以提取数据并检查它。注意，我们需要定义我们想要从中提取的表，这里是<em class="lf"> COURSE_FEEDBACK </em>。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="e4b4" class="mg kj hi mc b fi mh mi l mj mk">Spdf = spark.read.jdbc(url=jdbcUrl, table="COURSE_FEEDBACK", properties=connectionProperties)</span><span id="3242" class="mg kj hi mc b fi ml mi l mj mk">display(Spdf)</span></pre><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mm"><img src="../Images/0f2247eff628fc70a4074e4fedcdd0e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O5iP85BH7f3x3VzbiJju-A.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">提取的火花数据帧</figcaption></figure><h1 id="f3f1" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">转换</h1><p id="9d31" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">为了在pandas中进行转换，我们需要将Spark数据帧转换成pandas数据帧。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="f7fc" class="mg kj hi mc b fi mh mi l mj mk">course_feedback = Spdf.toPandas()<br/>course_feedback.info()</span></pre><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es mn"><img src="../Images/5689718204c273ad66f9f10b95e879c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*CKig5UDt8jUp42NHoR91bw.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">提取的熊猫数据帧</figcaption></figure><p id="64fd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们通过添加具有反馈列<em class="lf">设置</em>、<em class="lf">材料</em>和<em class="lf">教师</em>的行方式平均值的新列来转换数据帧。这等于每个学生给这门课的总分数。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="7298" class="mg kj hi mc b fi mh mi l mj mk">#Create Overall column</span><span id="b287" class="mg kj hi mc b fi ml mi l mj mk">course_feedback['COURSE_EVALUATION'] = course_feedback.iloc[:, 4:7].mean(axis=1).round(2)</span><span id="4dbd" class="mg kj hi mc b fi ml mi l mj mk">#Drop not needed columns</span><span id="2eb3" class="mg kj hi mc b fi ml mi l mj mk">course_feedback.drop(['SETUP','MATERIAL','TEACHER'], inplace= True, axis=1)</span><span id="d371" class="mg kj hi mc b fi ml mi l mj mk">#Inspect</span><span id="7f44" class="mg kj hi mc b fi ml mi l mj mk">course_feedback.head(5)</span></pre><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es mo"><img src="../Images/d9effaa2aae9fdd7fa8408bb2fe5f563.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*IRgx_cfn0N_iWNVekMyiig.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">转变的熊猫数据框架</figcaption></figure><h1 id="c356" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">负荷</h1><p id="deb5" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">为了将新的数据帧加载回Azure SQL，我们需要再次将其转换为Spark数据帧。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="a06b" class="mg kj hi mc b fi mh mi l mj mk">Spdf_overall=spark.createDataFrame(course_feedback)</span></pre><p id="940b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们可以将它作为一个新表写入数据库。请注意，我们将模式定义为覆盖。这意味着每次代码运行时，表不会用新行更新，但整个表将被替换。你可以在这里找到更多模式选择<a class="ae jt" href="https://spark.apache.org/docs/2.0.2/api/R/write.jdbc.html" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="lh li lj lk fd mb mc md me aw mf bi"><span id="9fc4" class="mg kj hi mc b fi mh mi l mj mk">Spdf_overall.write.jdbc(url=jdbcUrl, table="COURSE_FEEDBACK_OVERALL", mode = "overwrite",properties=connectionProperties)</span></pre><h1 id="436e" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">确认</h1><p id="6c59" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">我们可以确认新表是由(例如)使用Azure门户中的查询编辑器创建的。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mp"><img src="../Images/e04129ebf02f79c8878dc7d759b567eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cek9QOoELnE1LKC9kyaUSg.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">检查Azure SQL中的新表</figcaption></figure><h1 id="30c8" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">日程安排</h1><p id="ead4" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">当我们确认代码如预期的那样工作时，就该安排它了。在我们的演示案例中，每个月都会有新的课程评估，每个月的评估在下个月的第一天结束。我们将安排代码在每个月的这几天之后运行。</p><p id="17a1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在Databricks的左侧菜单中选择<strong class="iz hj">作业</strong>，然后选择<strong class="iz hj">创建作业。</strong>会弹出下面的窗口。填写<strong class="iz hj">任务名称</strong>，选择<strong class="iz hj">笔记本</strong>。我们将为计划运行使用一个新的作业集群，因此我们继续在<strong class="iz hj">集群</strong>/编辑下指定它。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mq"><img src="../Images/775d4743d35de72ebc0bcdb7ffa9cd6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BsLvnDZuQbb_O6QOL9QWWA.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">计划作业，1</figcaption></figure><p id="df06" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您可以按照自己的方式配置集群，但是对于这个小演示任务，我们只需要一个工作人员。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div class="er es lv"><img src="../Images/c836098697b6828d2e18d03e16ba0245.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*xUZodbpJPw25nqWju48QhA.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">计划作业，2</figcaption></figure><p id="5ca2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">设置好集群后，点击右边菜单中的<strong class="iz hj">编辑时间表</strong>，在弹出的窗口中填写首选时间表。如果您愿意，还可以在代码运行失败时创建电子邮件提醒。这是在右侧菜单中的<strong class="iz hj">编辑警报</strong>下完成的。</p><figure class="lh li lj lk fd ll er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mr"><img src="../Images/d02cc8a1640193e375d0bd8a5fc1587c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zKyL3XChlK0Wde_mve86g.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">计划作业，3</figcaption></figure><h1 id="db59" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">状态</h1><p id="86bb" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg ls ji jj jk lt jm jn jo lu jq jr js hb bi translated">我们现在已经连接到一个Azure SQL数据库，用PySpark提取数据，用pandas转换数据，然后用PySpark加载回数据库。我们还计划每月调整一次代码。</p></div></div>    
</body>
</html>