<html>
<head>
<title>Python Web Scraping Using BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用BeautifulSoup的Python网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/codex/python-web-scraping-using-beautifulsoup-ad2f111b48a2?source=collection_archive---------9-----------------------#2021-12-12">https://medium.com/codex/python-web-scraping-using-beautifulsoup-ad2f111b48a2?source=collection_archive---------9-----------------------#2021-12-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/eff9b978a8a3b95d234c5f8b6012c105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jEp5OmoWXEWAix0jnJGJCg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由作者通过<a class="ae iu" href="https://www.canva.com/" rel="noopener ugc nofollow" target="_blank"> Canva </a>提供</figcaption></figure><p id="72f9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di"> H </span> ello世界！在本文中，我们将探究python中web抓取的本质。但是首先，重要的是要知道网络抓取实际上意味着什么，为什么我们应该关心它。</p><p id="6fae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">想象你正在一个电子商务网站上尝试分析数据。您需要来自该特定网站的数据能够被访问，以便对您的代码进行操作。一种典型的方法是向网站的API端点发出请求，获取您想要的数据。但是这并不总是可能的，因为有些网站并没有给我们提供一个好的API。还有一些情况下，你必须付费才能访问API。那么我们该如何着手呢？这就是网络抓取派上用场的地方。</p><p id="9f17" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">网络抓取让我们可以快速、轻松地从网站上获取我们想要的数据。就像我提到的，当你要找的网站没有提供任何API来提取需要的数据时，这是非常有用的。</p><p id="6f8e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这并不是说没有关于网络抓取的问题。事实上，立法机构也参与了网络抓取的话题，因为当恶意抓取时，会导致知识产权被盗或不公平的竞争优势。这意味着从一个网站获取数据并用这些数据构建另一个网站是不合法的。下面给出了一些经验法则，当你不得不刮的时候，你可以遵守。</p><ul class=""><li id="161f" class="kc kd hi ix b iy iz jc jd jg ke jk kf jo kg js kh ki kj kk bi translated">如果你能找到一个可以获取你想要的数据的公共API，总是使用那个API而不是抓取。</li><li id="6190" class="kc kd hi ix b iy kl jc km jg kn jk ko jo kp js kh ki kj kk bi translated">如果你想弄清楚网站对不允许抓取哪些内容的要求，你可以在开始抓取之前查阅<strong class="ix hj"> robot.txt </strong>文件。您可以通过在网站URL中添加<em class="kq"> '/robot.txt' </em>来查看该文件。例如，<a class="ae iu" href="https://github.com/robots.txt" rel="noopener ugc nofollow" target="_blank">下面是</a>GitHub版本的文件。看起来是这样的:</li></ul><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/a21965025b9729fdfcdce363a0c71d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3m69rMHNUZHf-kimfnIow.jpeg"/></div></div></figure><ul class=""><li id="9702" class="kc kd hi ix b iy iz jc jd jg ke jk kf jo kg js kh ki kj kk bi translated">始终确保以合理的速度请求数据。您可以在请求之间添加一点时间间隔来实现这个目标。</li><li id="d807" class="kc kd hi ix b iy kl jc km jg kn jk ko jo kp js kh ki kj kk bi translated">始终保持礼貌，获取你绝对需要的数据，而不是像年终大甩卖一样什么都拿。</li></ul></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><p id="b4c2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们深入了解网络抓取实际上是如何完成的。在python中，我们使用一个名为<a class="ae iu" href="https://pypi.org/project/bs4/" rel="noopener ugc nofollow" target="_blank"> bs4 </a>的模块来获取BeautifulSoup，它是这个模块的一部分。此外，我们确实需要<a class="ae iu" href="https://pypi.org/project/requests/" rel="noopener ugc nofollow" target="_blank">请求</a>模块来实际发送HTTP请求。一旦安装了bs4和requests模块，就可以如下所示导入它们，</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/36354e6657ead8d41322a9d93709a965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UCM73IDSllnJ6T86xiNkjA.jpeg"/></div></div></figure><p id="9d1a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，您必须向预期的URL发出请求，并获得响应体。有很多网站只是用来刮的，<a class="ae iu" href="https://quotes.toscrape.com/" rel="noopener ugc nofollow" target="_blank">报价刮</a>和<a class="ae iu" href="https://books.toscrape.com/" rel="noopener ugc nofollow" target="_blank">书籍刮</a>不一而足。在这个演示中，我将使用报价刮网站。您需要像这样发出请求并保存响应，</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/a815d968b418b51ff411b2655b172de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Wsr2oQOLMvD47E5cSmuxA.jpeg"/></div></div></figure><p id="fc02" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们得到的响应是一个<em class="kq">字符串</em>，所以我们不能以我们想要的方式访问或操作它。下一步是通过传递得到的响应来创建BeautifulSoup的实例。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/0459934b256ee4d949503ab90f7f74b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kzsPC_IVRFsfXGjuti5R-w.jpeg"/></div></div></figure><p id="d541" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果您使用devtools检查<a class="ae iu" href="https://quotes.toscrape.com/" rel="noopener ugc nofollow" target="_blank">报价来抓取</a>，您可以看到每个报价的详细信息都放在一个div下，该div的类为“quote”</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/070d11f1f8183b23dcb41a15cce20b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpuoLjpRakukUwqgaCv-Kw.jpeg"/></div></div></figure><p id="b92d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在为每个报价识别容器的CSS选择器之后，您所要做的就是选择它们。可以这样做，</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/dfc28be9a1941f01242247379ac2f58f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RZY9XQQKM02XVxUx6YCeOQ.jpeg"/></div></div></figure><p id="0e75" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kq">。select() </em>返回一个数组，即使只有一个结果。在这种情况下，我们有一个div(引号)数组。我们可以遍历刚刚创建的引号数组，提取每个引号和作者或者我们想要的任何内容。最后<em class="kq">将每条记录作为字典添加到另一个数组中，以便于使用。</em></p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/39688d77cd04cbe6ae76b520562f32ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RyIBHIjWtMV8ca8fMpQ1QA.jpeg"/></div></div></figure><p id="44a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">报价文本位于类别为<em class="kq">“文本”</em>的范围内。带有类别<em class="kq">‘author’</em>的小标签中的作者姓名。我们用<em class="kq">。get_text() </em>方法获取元素的innerText。使用tailing print命令，你可以在一个数组中看到网站首页的所有引文和作者。</p><p id="2024" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但更多时候，我们需要从网站的所有可用页面中提取数据，对吗？我们希望一次又一次地点击“下一步”按钮，并获得所有页面中的所有可用数据，而不仅仅是一个页面。</p><p id="32c5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是如何做到的:</p><p id="5708" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先我们需要定位下一个按钮<em class="kq">或</em>类似导航到当前页面的下一页。然后，我们选择下一个URL，并继续抓取数据，直到下一个URL不再存在(这意味着我们在最后一页)。</p><p id="2712" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">获取所有可用报价的最终代码如下所示，</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/07bf8ca6bb3fea50dd06a3de0f22c6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XtWJjtjtMWRT4bGzYT_wbw.jpeg"/></div></div></figure><p id="0372" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的例子中，为了重用，我把所有东西都包装在一个函数中。此外，通过引入函数，我们可以仅在需要时通过调用函数来重复抓取，而不是每次运行文件时都运行抓取过程。</p><p id="009a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，我通过添加<em class="kq"> sleep(1) </em>在try块中的每个请求之间添加了1秒的间隔，以避免对服务器造成不良影响。当我们进行网络抓取时，这是一个很好的实践。</p><p id="1868" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果您愿意，也可以将结果保存到一个<em class="kq"> csv文件</em>中，</p><p id="ca34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先你需要从'<em class="kq"> csv </em>模块中导入'<em class="kq"> DictWriter </em>:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/696e8a3421f82ea8e08a285bab85d04b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTFPo2otODvdecuREEYjSw.jpeg"/></div></div></figure><p id="69b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后你可以写一个小函数，接受我们生成的引号数组，并把它写到一个<em class="kq"> csv文件中。</em></p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/e8175f3837ac26de73c755e36cc18c52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFf-XZCI7HfHY0QomdsSoQ.jpeg"/></div></div></figure><p id="3652" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，您可以像这样执行这两个函数来生成包含所有引用和作者的<em class="kq"> csv文件</em>。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/9530383397e2525b438f4e358ec00ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oD8tn1t4VDI_knmCWKH7Bw.jpeg"/></div></div></figure></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><p id="ffd4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望你清楚地了解什么是网络抓取，以及它是如何完成的。下次见！</p></div></div>    
</body>
</html>