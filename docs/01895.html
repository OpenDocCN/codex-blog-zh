<html>
<head>
<title>Computer Vision-Basic Building blocks and step by step beginner guide for model building.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉-基本积木和一步一步的建模初学者指南。</h1>
<blockquote>原文：<a href="https://medium.com/codex/computer-vision-basic-building-blocks-and-step-by-step-beginner-guide-for-model-building-c98ce994eca9?source=collection_archive---------5-----------------------#2021-06-12">https://medium.com/codex/computer-vision-basic-building-blocks-and-step-by-step-beginner-guide-for-model-building-c98ce994eca9?source=collection_archive---------5-----------------------#2021-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f251cf5fc22af60c2548f84b55e80ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uvb_If5TveG3UW3YIUoZhg.jpeg"/></div></div></figure><p id="ca1a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">计算机视觉越来越受欢迎！它使计算机能够像人类一样观察、分析和处理图像/视频中的对象。目标检测广泛应用于机器人、文本提取、自动驾驶汽车、盗窃检测、卫星分析等领域。在本文中，我们将重点介绍图像基础知识、卷积神经网络的构建模块以及一步一步的建模方法。</p><h1 id="51fb" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">图像基础和操作</strong></h1><p id="58ac" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">像素是数字图像的最小元素。它的取值范围从0到255，其中0代表黑色，1代表白色。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/c9144c5882882c11f44fdc68ed12b54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*6K8lQjdk2JuJgfzpIHqZGw.jpeg"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图1:像素格式的图像</strong></figcaption></figure><p id="0dcf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像有不同的通道，如RGB(红绿蓝)、BGR(蓝绿红)和灰度。图像过滤用于通过锐化、平滑和边缘增强等操作传输图像。一些图像变换技术是旋转，镜像，识别，反射，缩放。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="1bb7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面这段代码中，scikit-image读取并显示在每个RGB通道图像中。</p><h1 id="5fed" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">从图像中提取特征</strong></h1><p id="ab7f" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这可以通过SIFT &amp; HOG方法等开放CV技术或卷积来解决。这里我们将重点讨论卷积。</p><p id="0a9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">卷积是使用<strong class="is hj">内核</strong>从图像中提取图层的过程。这个过程类似于<strong class="is hj">人类</strong> <strong class="is hj">眼睛的视网膜，</strong>它的意思是视网膜逐层看到2D的图像。卷积提供了很好精度，但是计算量很大。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/8e616a855042af4230593562852673e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*aTGwuCQLN9pRLOFJrklsyw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图2:卷积运算</strong></figcaption></figure><h1 id="3aa2" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">内核</strong></h1><p id="2e3c" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">内核是一个矩阵，通过<strong class="is hj">步长</strong>值<strong class="is hj"> </strong>和<strong class="is hj"> </strong>对输入数据的子区域执行点积。它有不同的类型，如身份，边缘检测和锐化，如图3所示。</p><p id="d11c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">具有不同核的卷积用于图像变换，但是边缘检测核主要用于从图像中提取像边缘这样的高级特征。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/058c7746cae2a9c2943211562e08c0fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*r8zg6jTdDntrNswAQj8_tA.jpeg"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图3:应用不同类型内核后的卷积图像。</strong></figcaption></figure><h1 id="4312" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">联营</strong></h1><p id="8619" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">不是应用多个内核，而是将池应用于模型。它会将输入数据的大小减少一半。</p><p id="c02c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">池化不会改变输入的深度，但会影响长度和宽度。</p><p id="bafd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">联营层的好处</strong>:</p><ul class=""><li id="273c" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">减少过度拟合</li><li id="43eb" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">通过减少模型计算来提高效率。</li></ul><p id="6f3d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">汇集层的类型</strong>:</p><ul class=""><li id="4576" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated"><strong class="is hj">最大汇集:</strong>从特征图的每个区域中选择最大值。</li><li id="d464" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated"><strong class="is hj">平均池:</strong>计算特征图每个区域中所有元素的<strong class="is hj"> </strong>平均值。</li></ul><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/125256be62eb52c02de7a180857ccc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*k5wxI8SOJzAfGonAopncqA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图4:联营</strong></figcaption></figure><h1 id="7b40" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">填充</strong></h1><p id="5203" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">填充是向输入数据对称添加零的过程，如图5所示。例如，如果您正在训练一个自动编码器，自动编码器结果图像的输出大小应该与输入大小相同。在这里，填料开始发挥作用。填充会在输入数据中添加“额外空间”,以避免空间维度的损失。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/535d7305adeb76878f8e3788af32e519.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*KarKoO6G-al6-XUaQwnlkw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图5:填充</strong></figcaption></figure><h1 id="7331" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">全连接层</strong></h1><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/89a53fc1584ce7a2aa4cff394c5fe838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIHJB6fIj45YOurs66HzGg.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">图6:完全连接的层</figcaption></figure><blockquote class="lv lw lx"><p id="76d0" class="iq ir ly is b it iu iv iw ix iy iz ja lz jc jd je ma jg jh ji mb jk jl jm jn hb bi translated">什么是全连接层？</p><p id="5151" class="iq ir ly is b it iu iv iw ix iy iz ja lz jc jd je ma jg jh ji mb jk jl jm jn hb bi translated">也被称为“前馈神经网络”。全连接层是来自一层的所有输入都连接到下一层的每个激活单元的层。它有三层，<strong class="is hj">输入层</strong>表示输入向量的维数，<strong class="is hj">隐含层</strong>取一组加权输入，用激活函数处理输出，<strong class="is hj">输出层</strong>表示神经网络的输出。</p></blockquote><p id="5d98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">来自最终汇集或卷积层的输出将是全连接层的输入。这些输出被展平，<em class="ly"> </em>即将其所有值展开成一个向量，然后馈入全连接层。</p><p id="7e98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">激活功能</strong></p><p id="57bf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">激活函数通过计算加权和来决定一个神经元是否应该被激活。它还应用非线性来避免输出图层成为一次多项式的线性函数。</p><p id="5ab9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">激活功能的类型</strong></p><p id="fe67" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1。乙状结肠功能</strong>:</p><p id="8866" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">sigmoid函数用于深度学习模型的输出层，用于预测基于概率的输出。sigmoid函数表示为:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/e932b2d96da2797f33aeb4bf85109255.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*1soDn1JRSyNhnFPy.png"/></div></figure><p id="82e2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。双曲正切函数:</strong></p><p id="2c39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Tanh的范围在-1到1之间，它是一个更平滑的零中心函数。双曲正切函数表示为:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es md"><img src="../Images/233f4b7c2c5b020d92caf23fc6b73485.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/0*B_8rhWx-hrr0FPmu.png"/></div></figure><p id="3385" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。整流线性单元(ReLU)功能:</strong></p><p id="4ff6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个流行的激活功能。与sigmoid和tanh等其他函数相比，此函数的性能更好。当z &lt;0, which allows to have an average output closer to 0. The ReLU function performs a threshold operation on each input element where all values less than zero are set to zero. The ReLU function represented as:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es me"><img src="../Images/5b72379973a5f6adbc8631db49fb2659.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/0*vfx5XUz8UEvx6gAl.png"/></div></figure><p id="df3f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4时，ReLU通过取负值来帮助解决消失梯度问题。SoftMax功能:</strong></p><p id="5934" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">SoftMax输出范围在0和1之间，概率之和等于1。该函数将在多类分类问题中用作最终层。SoftMax函数表示如下:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es md"><img src="../Images/45403b6f5885620b3faf1cf6b3d1ceaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/0*tidDYXav26zQ-_59.png"/></div></figure><h1 id="be99" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">卷积神经网络架构</strong></h1><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/41c885ac6ff440fbdde6ee8af2f2fbdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OUonEDfZwCfR4Y-G-h1fw.jpeg"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图6:卷积神经网络架构</strong></figcaption></figure><blockquote class="lv lw lx"><p id="096b" class="iq ir ly is b it iu iv iw ix iy iz ja lz jc jd je ma jg jh ji mb jk jl jm jn hb bi translated">如何计算CNN的输出形状？</p><p id="b4e1" class="iq ir ly is b it iu iv iw ix iy iz ja lz jc jd je ma jg jh ji mb jk jl jm jn hb bi translated">CNN的输出波形由公式<strong class="is hj">[(W K+2P)/S]+1</strong>计算。其中<strong class="is hj"> W=输入大小，K =内核大小，P =填充，S =步距</strong>。</p></blockquote><p id="c70a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图6总结，</p><ul class=""><li id="9a8a" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated"><strong class="is hj">卷积层</strong>:给定图像的输入大小为28*28*1，其中1代表图像的通道&amp;应用的内核大小为5*5。输出大小确定为(28–5)+1 = 24 * 24 * n1(应用n1通道)。</li><li id="87dc" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated"><strong class="is hj">池层:</strong>此处使用最大池层。输入大小=24*24*n1(n通道)，输出大小确定为24/2=12*12*n1</li><li id="e681" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated"><strong class="is hj">卷积层</strong>:给定图像的输入尺寸为12*12*n1(n通道)&amp;应用的内核尺寸为5*5。输出大小确定为(12–5)+1 = 8 * 8 * n2(应用N2通道)。</li><li id="09d8" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated"><strong class="is hj">池层:</strong>此处使用最大池层。输入大小=8*8*n2(应用n2通道)，输出大小确定为8/2=4*4*n2</li><li id="b87d" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">展平输出(即4*4*n2)并将其传递给激活函数为ReLU的全连接层，并对图像进行分类。</li></ul><h1 id="df10" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">用计算机视觉解决问题</strong></h1><p id="43dc" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我们从MNIST数据集开始。MNIST数据集是用于图像分类的最常用数据集之一，它包含从美国人口普查局员工和美国高中生收集的60，000幅训练图像和10，000幅测试图像。TensorFlow和Keras允许我们直接导入和下载MNIST数据集。</p><p id="ca87" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下代码显示了如何从MNIST数据集导入数据，以及如何将数据混洗、拆分为训练集和测试集。</p><blockquote class="lv lw lx"><p id="fff7" class="iq ir ly is b it iu iv iw ix iy iz ja lz jc jd je ma jg jh ji mb jk jl jm jn hb bi translated">如何安装TensorFlow？</p><p id="61a7" class="iq ir ly is b it iu iv iw ix iy iz ja lz jc jd je ma jg jh ji mb jk jl jm jn hb bi translated">！pip安装张量流</p></blockquote><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图7 </strong></figcaption></figure><p id="9d06" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，可视化来自训练集和测试集的数据。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图8 </strong></figcaption></figure><p id="61df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在将数据输入模型之前，需要对数据进行预处理，如图9所示。</p><ul class=""><li id="aa4b" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">输入数据需要重新整形，因为模型需要特定格式的输入(数据的数量、高度、宽度、数据通道)。</li><li id="fed6" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">归一化是神经网络中预处理/特征工程的必需步骤，因为我们更喜欢[0，1]范围内的数据。它是通过将数据除以255得到的，因为数据的整个范围在[0，1]中。在规范化之前，所有值都需要是浮点数据类型，这样我们就可以在除法运算后得到小数点。</li></ul><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图9 </strong></figcaption></figure><p id="651e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一键编码将类别向量转换为二进制类别矩阵。因为我们处理的是多类分类数据集，所以需要像步骤8中那样将标签转换为分类。现在数据已经准备好输入到模型中了。</p><p id="7cc6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从模型构建开始，从keras.model导入顺序模型，从keras.layers导入层，如步骤9所示。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图10 </strong></figcaption></figure><ul class=""><li id="2ee6" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">定义顺序模型</li><li id="81d9" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">添加一个卷积层，其具有32个滤波器、3*3内核大小、作为ReLU的激活层以及28*28*1的输入大小，其中1表示灰度通道。输出形状将是(28–3)+1 = 26 * 26 * 32</li><li id="3bac" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">添加一个最大池层。输出形状将是(26/2) = 13*13*32</li><li id="cdf2" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">在构建完全连接的图层之前，向1D阵列添加展平2D阵列的展平图层。</li><li id="941e" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">增加密集层，神经元数为128，激活函数为ReLU。</li><li id="d628" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">添加神经元数量为10(即输出类的数量)且激活函数为SoftMax的密集层。最终的密集层应该包含输出类的数量作为神经元的数量。</li></ul><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图11 </strong></figcaption></figure><p id="5df9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用分类交叉熵作为损失函数，度量定义为准确性，Adam用作优化器来编译模型。</p><p id="1d8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用x，y，批量大小为32，时期为5(即5个周期的模型序列)和验证分割为0.2(即80:100)来拟合模型</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图12 </strong></figcaption></figure><p id="792c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练和测试准确率都在95%以上。步骤13中显示的预测输出。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="ak">图十三</strong></figcaption></figure><h1 id="d5c3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">资源</h1><ol class=""><li id="5b86" class="le lf hi is b it km ix kn jb mg jf mh jj mi jn mj lk ll lm bi translated">张量流:<a class="ae mk" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/pyod/</a></li><li id="738f" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn mj lk ll lm bi translated">TensorFlow keras模型:<a class="ae mk" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/keras/Model</a></li><li id="a9d7" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn mj lk ll lm bi translated">tensor flow keras Layer:<a class="ae mk" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/layers/Layer</a></li><li id="3d7a" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn mj lk ll lm bi translated">TensorFlow keras损失:<a class="ae mk" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/keras/losses</a></li><li id="5402" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn mj lk ll lm bi translated">TensorFlow keras优化器:<a class="ae mk" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/optimizer</a></li></ol><p id="b266" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望听到一些关于我第一部作品的反馈。感谢您的宝贵时间！T19】</p></div></div>    
</body>
</html>