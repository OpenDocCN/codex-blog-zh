<html>
<head>
<title>Challenging big data: Apache DolphinScheduler applied in practice with billions of data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">挑战大数据:Apache DolphinScheduler在数十亿数据中的实际应用</h1>
<blockquote>原文：<a href="https://medium.com/codex/challenging-big-data-apache-dolphinscheduler-applied-in-practice-with-billions-of-data-c54e76ec2cb5?source=collection_archive---------6-----------------------#2022-11-14">https://medium.com/codex/challenging-big-data-apache-dolphinscheduler-applied-in-practice-with-billions-of-data-c54e76ec2cb5?source=collection_archive---------6-----------------------#2022-11-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/08d9eca1860efc16cc164fa4fc1139a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2sUnAfzJd8nRlTKYDfIsvw.jpeg"/></div></div></figure><blockquote class="iq ir is"><p id="de00" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">近日，Churinga大数据开发工程师钟在网络社区Meetup上举办了主题为“Apache DolphinScheduler在实践中应用数十亿数据”的主题演讲</p><p id="8b50" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在分析和选择了数千亿数据的数据同步需求后，中国Churinga(CNCR)最终决定使用DolphinScheduler进行任务调度，并且还需要定期调度DataX、SparkSQL等方法进行海量数据迁移。他们在日常大数据工作中使用DolphinScheduler，减少日常运维工作量。</p></blockquote><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es js"><img src="../Images/d5781aba0b04d78cd7ab1d5a6b394479.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/0*vAgcWujauAHSey_0.png"/></div></figure><p id="b0e9" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">演讲人|中国Churinga大数据开发工程师钟</p><p id="f20a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">议程:</p><ol class=""><li id="da36" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr kf kg kh ki bi translated">背景资料</li><li id="6858" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">大数据处理</li><li id="8d38" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">应用场景</li><li id="073f" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">未来计划</li></ol><h1 id="3c69" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">背景资料</h1><h2 id="1dbd" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">自行开发的任务调度</h2><p id="f9fb" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">我们公司一开始一直使用自主开发的任务调度框架。随着开源软件在这一领域的发展，出现了许多像DolphinScheduler这样优秀的任务调度应用。此外，我们的需求已经到了必须引入新的解决方案的地步——调度系统级别以确保技术的更新和迭代。</p><h2 id="7e55" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">需求分析</h2><p id="afc0" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">1.多租户权限控制在我们的日常工作中，R&amp;D等业务部门或厂商可能会在DS上运行一些任务。有了多租户访问权限控制，整个集群将更易于使用。</p><p id="1080" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">2.易用性和对可视化任务管理的支持很容易上手，因为在我们的团队中，很多时候仓库/业务团队会使用开发。如果任务调度很难开始，如果需要大量的配置或编码，相对成本会高得多。我相信很多大数据团队都会有这个需求，有些项目需要快速迭代，所以工具的选择一定要好用。</p><p id="dbb3" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">3.任务和节点的状态监控对于任务调度的本地监控，我们有两个主要需求。第一个是服务器监控，必须直接在任务调度web应用程序上查看。第二个是任务调度监控，要一目了然的显示一个任务是否成功，执行时间，以及其他相关信息和状态。</p><p id="d35a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">4.支持更方便的重新运行和补充我们的数据有三个部分:实时，定期和离线。数据特征产生了这种需求。比如每15分钟或者每小时的数据任务，如果不能很好的支持重运行和补充，对我们的影响还是比较大的。</p><p id="3020" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">5.支持高可用性HA、灵活扩展和容错，还需要支持集群操作、维护和错误管理。</p><p id="cba7" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">6.支持时间参数有时可能需要根据时间参数对数据执行ETL定期操作。</p><h2 id="e3e3" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">任务计划程序比较</h2><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/691068aa8d9fecc742231b36e14eb1a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SrQ-awqdfgFh-ST0CwtfNA.png"/></div></div></figure><p id="e76d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Crontab在Unix或类Unix系统中定期执行指令或脚本，用于在Linux上直接执行脚本，但只能运行脚本。它不支持多租户访问权限管理、平台管理、分发执行和其他功能。我们公司的应用是在一些特色服务器上运行一些临时脚本。而且原生Crontab只支持分钟级调度，不支持重新运行。</p><p id="848d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Rundeck Rundeck是一款基于Java和Grails的开源运维自动化工具。它为管理操作、命令行工具和WebAPI访问控制方法提供了一个Web界面。Ansible和Rundeck等工具可以帮助开发人员和操作人员更好地管理各个节点。Rundeck有企业版和免费版。免费版为了我们的目的，在一些功能上还是需要改进的。</p><p id="5be1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Quartz Quartz是一个开源的、功能丰富的任务调度库。它是一个基于Java的框架，可以与任何Java应用程序集成。任务调度必须用Java编写，非R&amp;D团队无法使用。</p><p id="6a18" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">这是一个由中国开发的轻量级分布式日程安排工具。然而，它的功能比DolphinScheduler少。它不依赖于重要的数据基础，而是依赖于MySQL，这与DolphinScheduler是相同的依赖关系。</p><p id="358e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Elastic-Job It是一个灵活的分布式任务调度应用，基于Quartz的进一步发展。它的初衷是处理高度并发和复杂的任务。设计概念是分散的。主服务器是通过ZooKeeper选举机制选出的。如果主服务器出现故障，将选择新的主服务器。因此，弹性作业具有良好的可扩展性和可用性。但是使用和操作起来比较复杂。</p><p id="c236" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Azkaban也是一个轻量级的任务调度框架，但是它的缺点是可视化功能。除此之外，该任务必须通过键入zip包来实现，这可能更方便。</p><p id="e706" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">AirFlow是一个用Python编写的任务调度系统。界面很优质，但需要符合国人的使用习惯。用Python画DAG图很有必要。此外，低代码任务调度是不可实现的。</p><p id="d1a0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Oozie它是一个广泛的数据任务调度框架，集成了Hadoop。任务创建必须在XML中执行。</p><h2 id="6b8a" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">选择DolphinScheduler的原因</h2><ol class=""><li id="3a3a" class="ka kb hi iw b ix ma jb mb jx mg jy mh jz mi jr kf kg kh ki bi translated">部署非常简单。主人和工人都各司其职。可以线性扩展，不依赖大数据集群。</li><li id="d353" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">任务和节点的直观监控；每个结局都一目了然。</li><li id="8122" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">有许多类型的支持任务，DAG图决定了可视化配置和可视化任务的沿袭。</li><li id="be29" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">甘特图和版本管理对于大量的任务都很方便。</li><li id="7f32" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">它很好地满足了所有工作的要求。大数据平台架构</li></ol><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/2e6de0ec152197135003231d05aa479d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GiTvW5n6jA94QNiVTJ7ECg.png"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated"><strong class="bd kq">大数据平台架构</strong></figcaption></figure><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/ee27deb12f44c21afbd7e9d39876c068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r0fiIM0xCDzVpxt6JPJISQ.png"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated"><strong class="bd kq">数据流图</strong></figcaption></figure><h1 id="0625" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">海量数据处理</h1><h2 id="e157" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">数据要求</h2><p id="cd00" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">数据量:每天数千亿条数据记录字段数:数百个字段，主要是字符串类型数据流:在数据存储中处理，处理后的数据放入CK，之后应用程序直接从CK查询数据存储周期:21到60天查询响应:特定字段需要二次响应</p><h2 id="f179" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">数据同步工具选择</h2><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/9f4c32ce938f8a1cb17cb3339cf4766a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L4WwIR8BlKPm1i7GYEE06w.png"/></div></div></figure><p id="e140" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj"> Sqoop </strong></p><p id="038d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Sqoop是一个开源工具，主要用来在Hadoop (Hive)和传统数据库(MySQL，PostgreSQL……)之间传输数据。DolphinScheduler还可以集成Sqoop的任务调度。但是对于从Hive到ClickHouse的数据传输需求，Sqoop是无法支持的。</p><p id="0617" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj">弗林克</strong></p><p id="3fd0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">通过DS调度Flink任务或者直接搭建一套基于Flink的实时流计算框架。应该为这个需求建立一套计算框架，Kafka作为消息队列。此外，额外的资源开销。</p><p id="1494" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">其次，程序必须重写，给运维团队带来不便。</p><p id="d46f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">最后，我们的中心场景是离线。比较吞吐量，使用Spark效率更高。</p><p id="6baa" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj">火花&amp;火花SQL </strong></p><p id="c123" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">不考虑环境和资源，Spark是最好的选择，因为我们也使用SparkSQL作为我们的数据处理器。我们目前有两种方法来进行数据同步。</p><p id="7e4b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj">第一种方法不是持久存储处理过的数据。</strong>但是，通过网络IO直接写入ClickHouse。这种方法在服务器资源上的开销最小，但是它的风险也最大。这是因为考虑了处理过的数据。假设在数据同步或ClickHouse存储中发现异常。所以必须重新处理，但是后面dws和dwd的数据每14天清理一次。这意味着如果磁盘没有被丢弃，就必须重新考虑它。</p><p id="c2b6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj">第二种方法是将处理后的数据放入Hive，使用SparkSQL进行同步。</strong>然而，这需要更多的纱线资源。所以在项目的第一阶段，由于资源的限制，我们没有使用SparkSQL。在项目的第二阶段，扩展后的集群完全可以取代SparkSQL的所有数据处理和数据同步。</p><p id="62db" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj">海底隧道</strong></p><p id="404e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">SeaTunnel是Spark和Flink上的一层包装。它将其配置文件转换为Spark和Flink在Yarn上运行的任务。它的实现也是通过各种实现文件来完成的。</p><p id="9ac8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">对于这种选择，海底隧道必须消耗纱线资源。</p><p id="608c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated"><strong class="iw hj"> DataX </strong></p><p id="2d7f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">经过各种研究，我们选择DataX作为数据传输工具，这是项目的第一阶段。此外，我们决定使用DolphinScheduler进行周期性调度。</p><h2 id="78da" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">点击屋优化</h2><p id="4038" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">ClickHouse需要在数据传输和同步架构之后进行优化。</p><ul class=""><li id="e191" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">写入本地表</li></ul><p id="441b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">Nginx在整个集群初期用于负载均衡。在这个过程中，我们意识到结果本可以更好。我们还尝试用分布式表进行编写，但是结果并没有显著改善。在第二种情况下，我们的解决方案是调整对本地表的写入。整个集群有多个设备，这些设备都直接写入每个CK节点的本地表，然后在查询操作期间检查分布式表。</p><ul class=""><li id="84d8" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">使用合并树表引擎系列</li></ul><p id="63c1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">ClickHouse的一个核心功能是MergeTree表引擎。社区也将基于MergeTree表引擎的优化视为一项关键工作。在CK，我们使用ReplicatedMergeTree作为数据表的本地表引擎。而且我们使用ReplicatedReplacingMergeTree作为从MySQL迁移过来的数据字典的表引擎。</p><ul class=""><li id="5eaf" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">二级索引优化</li></ul><p id="8f62" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">优化的第一点是二级索引。我们用bloom_filter替换了min-max中的二级索引，并将索引粒度切换为32768。关于二级索引，我们尝试过min-max、intHash64、halfMD5、farmHash64等。但是，对于我们的数据量来说，查询很慢，或者传入的数据不够好。换成bloom_filter后书写也很平衡。</p><ul class=""><li id="2289" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">小文件优化</li></ul><p id="2e31" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">经过数据处理，有很多小文件。处理的小文件大小都在5M左右。这些参数加载到SparkSQL中，重新处理后的文件大约60M~100M。</p><pre class="jt ju jv jw fd mq mr ms bn mt mu bi"><span id="81ac" class="mv kp hi mr b be mw mx l my mz">set spark.sql.adaptive.enabled=true;<br/>set spark.sql.adaptive.shuffle.targetPostShuffleInputSize=256000000;</span></pre><ul class=""><li id="cde1" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">参数最优化</li></ul><p id="a2c7" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">CK有许多优化参数。除了基本参数之外，在二级索引被调整到布隆过滤器之后，写入CK的部分的数量比最初更多。这时，我们需要调整CK的零件参数，使其正常运行。但是，该参数会稍微影响CK查询的性能。如果数据加载不进去，那么再给我们查询就没用了。还激活了background_pool_size参数(我们没有使用它)。</p><pre class="jt ju jv jw fd mq mr ms bn mt mu bi"><span id="d3dd" class="mv kp hi mr b be mw mx l my mz">parts_to_delay_insert：200000parts_to_throw_insert：200000</span></pre><ul class=""><li id="04d3" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">动物园管理员优化</li></ul><p id="f2c1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">对于ClickHouse的多分片多副本集群模式，Zookeeper是性能的最大瓶颈。</p><p id="ab2b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">在不改变源代码的情况下，我们进行了以下优化:</p><p id="eefc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">1.调整MaxSessionTimeout参数以增加每个Zookeeper会话的最大超时。</p><p id="1c06" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">2.在Zookeeper中分离数据记录器和数据目录。</p><p id="e3f5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">3.已经为ClickHouse部署了一个单独的CK集群。如果磁盘选择超过1T，SSD磁盘将被激活。</p><h2 id="dd83" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">海量数据处理体系结构</h2><ul class=""><li id="2982" class="ka kb hi iw b ix ma jb mb jx mg jy mh jz mi jr mp kg kh ki bi translated">第一阶段技术架构</li></ul><p id="79aa" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">HiveData仓库结构--Hive--spark SQL--DataX--DataX Web--dolphin scheduler--click house</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/086394d8bb8ff31cfe1bd7158f8572bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JoNLgBsfNBpMZ4Pweu-8qQ.png"/></div></div></figure><ul class=""><li id="9c39" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">第二阶段架构1</li></ul><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/81a3913251c63f721e30048f14614e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Es1WGetmdr1cvgs0lyhyA.png"/></div></div></figure><ul class=""><li id="c0ae" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">第二阶段架构2</li></ul><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/d99a38eb911663130b1284398cac9d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LeiuPO5eXfIyp86DCLtvow.png"/></div></div></figure><h2 id="1965" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">数据同步操作</h2><ul class=""><li id="16ed" class="ka kb hi iw b ix ma jb mb jx mg jy mh jz mi jr mp kg kh ki bi translated">DataX技术原理</li></ul><p id="6233" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">DataX是阿里巴巴开源的异构数据源离线同步工具。旨在实现各种异构数据源之间稳定高效的同步，包括关系数据库(MySQL、Oracle等。)，HDFS，Hive，ODPS，HBase，FTP等。</p><p id="ca86" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">数据同步功能。</p><p id="b761" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">DataX使用起来相对简单。有两个模块，一个阅读器和一个编写器。配置设置主要针对这两个模块。DataX支持许多插件。除了官方插件，可以直接使用，还可以从GitHub下载源代码进行Maven编译。这是ClickHouse和Starrocks的writer插件所必需的。</p><h2 id="3b05" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">DataX在DS中的应用</h2><p id="cf3a" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">要使用datax，必须在dolphinscheduler_env.sh文件中指定DataX的路径。</p><pre class="jt ju jv jw fd mq mr ms bn mt mu bi"><span id="f320" class="mv kp hi mr b be mw mx l my mz">export DATAX_HOME=${DATAX_HOME:-/opt/module/datax}</span></pre><p id="3c77" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">之后，DataX可能有三种用途。第一种方法是创建一个“自定义模板”,然后将DataX JSON语句写入该自定义模板:</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/542be856b7519b752cb68c21778d0d95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtmmZVc7AP7a9lc8V-EwsA.png"/></div></div></figure><p id="c8d2" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">第二种方式是使用DS的模型，写SQL使用DataX。可以通过DS中的GUI配置的插件包括MySQL、PostgreSQL、ClickHouse、Oracle和SQLServer:</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/35ceecf196b478a61c008d5f46e888c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IHa70wjbPq8ZRBwkopyC0g.png"/></div></div></figure><p id="31f6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">第三种方式是在DS中创建一个shell任务，然后通过shell调用部署在服务器上的DataX脚本，将脚本放在DS的资源中心:</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/2bd5ffd5afab7d2c06c4b5bd1d090da2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aTUV1wkg2PSZef1wfyK2eg.png"/></div></div></figure><p id="2042" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">第一种方法对我们来说是最方便、最适应的方法，第二种和第三种方法要视情况而定。</p><h2 id="2c89" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">DataX的使用</h2><p id="fa59" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">DataX中每个通道有两种速度控制。第一个是控制每秒同步的记录数，另一个是控制每秒同步的字节数。默认的速度限制是1MB/s，这个字节速度或者记录速度限制可以根据具体的硬件情况来设置，字节速度设置为固定的标准。</p><p id="9064" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">我们的通道是根据每个任务的数据数量和大小经过多次调整后获得的。这需要根据我们的数据情况进行调整。我的任务的最大数据量是由数据总量配置的。记录限速300M/s，单通道记录限速10M/s，第一种方法对我们来说是最方便最适应的方法，第二种和第三种方法要视情况而定。</p><pre class="jt ju jv jw fd mq mr ms bn mt mu bi"><span id="15c6" class="mv kp hi mr b be mw mx l my mz">{<br/>"core": {<br/>"transport": {<br/>"channel": {<br/>"speed": {<br/>"record": 10485760<br/>}<br/>}<br/>}<br/>},<br/>"job": {<br/>"setting": {<br/>"speed": {<br/>"record": 314572800<br/>},<br/>"errorLimit": {<br/>"record": 10000,<br/>"percentage": 0.1<br/>}<br/>},</span></pre><p id="fba2" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">但并不是越大越好。如果通道太大，会影响服务器的性能。它将不断向GC报告。一旦报告了GC，性能就会下降。</p><p id="0b19" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">一般在我们的服务器上配置好以上参数后，一个任务就顺利运行了。如果多个DataX任务同时在一台服务器上运行，并且JVM设置得太小，那么每5分钟就会报告一次GC。</p><p id="4fc0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">根据控件，很明显，DataX任务中的通道数量增加了，这意味着占用的内存也将增加。使用DataX，数据交换通道将在内存中缓存更多的数据。</p><p id="0e3b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">DataX中有一个缓冲区用于临时内存交换。读取器和写入器中还有一个缓冲区来缓存数据。如果JVM报告GC，主要是在那里报告，所以我们需要根据配置进行调整。JVM参数。</p><p id="794c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">一般我的任务参数都是由DS的参数控制的。如下图所示，主要设置为4G~16G，具体取决于硬件的性能。</p><pre class="jt ju jv jw fd mq mr ms bn mt mu bi"><span id="3c50" class="mv kp hi mr b be mw mx l my mz">$DATAX_HOME：/opt/beh/core/datax/pybin/datax.py --jvm="-Xms8G -Xms8G" -p"-Da=1"</span></pre><p id="ec3a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">在调优了内存和CPU之后，下一步就是读取器和写入器的基本配置，比如HDFS路径、Kerberos相关的设置、字段映射、CK库表等。</p><p id="6e91" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">最后一部分是我们在使用的时候发现，即使优化了CK，各个部分还是会有太多的误差。经过进一步调查，DataX的ClickHouse编写器通过JDBC远程连接到ClickHouse数据库。然后将ClickHouse公开的用于写数据的插入接口插入到ClickHouse中。根据ClickHouse特性，每个插入都是一个部分，所以不可能一次插入一段数据。必须海量插入ClickHouse，这也是官方推荐的。</p><p id="c6d7" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">因此，我们优化了DataX batchSize，优化参数如下:</p><pre class="jt ju jv jw fd mq mr ms bn mt mu bi"><span id="a6cf" class="mv kp hi mr b be mw mx l my mz">"batchSize": 100000,                          <br/>"batchByteSize": 268435456,</span></pre><h1 id="df77" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">应用场景</h1><h2 id="4932" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">元数据备份</h2><p id="8a73" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">使用DS定期备份Hive元数据、CDH元数据、HDP元数据和DS自己的元数据，并上传到HDFS进行存储。</p><h2 id="d2b1" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">任务调度</h2><p id="e81f" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">计划任务，如Shell、SparkSQL、Spark、DataX和Flink。当前任务主要分为新任务和旧任务迁移。任何新添加的任务都是新项目之一。我们正在推动业务部和其他R&amp;D中心将任务上传到DS调度平台。旧任务迁移的话，阻力比较大。以前的离线、流和shell任务将迁移到DS。一些旧的MR代码在迁移过程中被改成Spark或Flink，放到DS上运行。</p><h2 id="5ba6" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">甘特图表</h2><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/1e02eb53cdb0ae2e82333415e7995776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nZ5XqmUZcMB2dO_6XQWwAA.png"/></div></div></figure><h2 id="8de0" class="lm kp hi bd kq ln lo lp ku lq lr ls ky jx lt lu lc jy lv lw lg jz lx ly lk lz bi translated">数据清理</h2><p id="93ff" class="pw-post-body-paragraph it iu hi iw b ix ma iz ja jb mb jd je jx mc jh ji jy md jl jm jz me jp jq jr hb bi translated">这主要是针对有存储期的数据，Hive、HDFS和一些服务器上的日志也需要定期清理。</p><h1 id="99fc" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">未来规划</h1><ol class=""><li id="66d0" class="ka kb hi iw b ix ma jb mb jx mg jy mh jz mi jr kf kg kh ki bi translated">开发一个系统，将特定任务调度系统中的任务迁移到DS中。它将是半自动化的，有助于促进DS在任务调度领域的应用。</li><li id="a34d" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">DS集群部署和升级工具减少了运维工作量。</li><li id="2baa" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">从定制监控到插件监控，从高代码到低代码，时间监控和告警更加灵活，节点、工作流、数据库、任务等问题。被及早发现。</li><li id="7276" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">二次开发，增加只读场景，回收站功能，增加判断条件和功能，资源批量上传等。，来帮助大数据。</li><li id="2fee" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr kf kg kh ki bi translated">集成API网关功能，对协议适配、服务管理、限流和融合、认证和授权以及接口请求执行一站式操作。</li></ol><p id="84cf" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">这就是我的分享。谢谢！有兴趣的话欢迎加入社区和我一起讨论添加社区助手添加进中文用户群~</p><p id="a226" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">最后，欢迎大家加入DolphinScheduler大家庭:</p><p id="8097" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je jx jg jh ji jy jk jl jm jz jo jp jq jr hb bi translated">我们鼓励任何形式的社区参与，最终成为PMC的委托人，例如:</p><ul class=""><li id="ceba" class="ka kb hi iw b ix iy jb jc jx kc jy kd jz ke jr mp kg kh ki bi translated">在GitHub上以问题的形式报告遇到的问题。</li><li id="db60" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr mp kg kh ki bi translated">回答其他人遇到的任何问题。</li><li id="a114" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr mp kg kh ki bi translated">帮助改进文档。</li><li id="f4f4" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr mp kg kh ki bi translated">项目帮助和添加测试用例。</li><li id="5120" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr mp kg kh ki bi translated">向代码添加注释。</li><li id="dd71" class="ka kb hi iw b ix kj jb kk jx kl jy km jz kn jr mp kg kh ki bi translated">提交PR以修复bug或特性。</li></ul></div></div>    
</body>
</html>