<html>
<head>
<title>Machine Learning — K-Nearest Neighbors algorithm with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习——基于Python的K近邻算法</h1>
<blockquote>原文：<a href="https://medium.com/codex/machine-learning-k-nearest-neighbors-algorithm-with-python-df94b374ad41?source=collection_archive---------0-----------------------#2020-10-23">https://medium.com/codex/machine-learning-k-nearest-neighbors-algorithm-with-python-df94b374ad41?source=collection_archive---------0-----------------------#2020-10-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="4170" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">K-最近邻(KNN)及其Python实现的分步指南</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/b2e1872b610e1489863213926063a78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jUMexU3zpd10SkvMzt64oA.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">由<a class="ae jn" href="https://www.pexels.com/" rel="noopener ugc nofollow" target="_blank">像素</a>上的<a class="ae jn" href="https://www.pexels.com/@pixabay" rel="noopener ugc nofollow" target="_blank">像素</a>生成的图像</figcaption></figure><h1 id="6d61" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">k-最近邻算法</h1><blockquote class="kg"><p id="0850" class="kh ki hi bd kj kk kl km kn ko kp kq dx translated">k-最近邻(KNN)是一种基于最相似的点对数据点进行分类的模型。它使用测试数据对一个未分类的点应该分类为什么进行“有根据的猜测”</p></blockquote><h1 id="9cb3" class="jo jp hi bd jq jr js jt ju jv jw jx jy io kr ip ka ir ks is kc iu kt iv ke kf bi translated">KNN Python实现</h1><p id="c449" class="pw-post-body-paragraph ku kv hi kw b kx ky ij kz la lb im lc ld le lf lg lh li lj lk ll lm ln lo kq hb bi translated">我们将使用python最流行的机器学习包“scikit-learn”来构建我们的KNN模型。Scikit-learn为数据科学家提供了执行机器学习任务的各种工具。对于我们的KNN模型，我们将使用<em class="lp">‘KNeighborsClassifier’</em>算法，该算法在scikit-learn包中很容易获得。最后，我们将使用scikit-learn中的<em class="lp">“准确度分数”</em>函数评估我们的KNN模型预测。我们开始吧！</p><h2 id="9eee" class="lq jp hi bd jq lr ls lt ju lu lv lw jy ld lx ly ka lh lz ma kc ll mb mc ke md bi translated">步骤1:导入所需的包</h2><p id="dfec" class="pw-post-body-paragraph ku kv hi kw b kx ky ij kz la lb im lc ld le lf lg lh li lj lk ll lm ln lo kq hb bi translated">每个简单或复杂的编程任务都是从导入所需的包开始的。为了构建我们的KNN模型，我们的主要软件包包括用于构建模型的scikit-learn、用于探索性数据分析(EDA)的pandas和用于可视化的seaborn。</p><p id="73ac" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="491f" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">现在我们已经导入了所有必要的包来训练和构建我们的KNN模型。下一步是导入数据并做一些探索性的数据分析。</p><h2 id="b146" class="lq jp hi bd jq lr ls lt ju lu lv lw jy ld lx ly ka lh lz ma kc ll mb mc ke md bi translated">步骤2:导入数据集和EDA</h2><p id="cfc7" class="pw-post-body-paragraph ku kv hi kw b kx ky ij kz la lb im lc ld le lf lg lh li lj lk ll lm ln lo kq hb bi translated">在本文中，我们将利用seaborn包提供的iris数据集。让我们导入数据，用python看一下。</p><p id="2713" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="67f8" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="7546" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">     sepal_length  sepal_width  petal_length  petal_width    species<br/>0             5.1          3.5           1.4          0.2     setosa<br/>1             4.9          3.0           1.4          0.2     setosa<br/>2             4.7          3.2           1.3          0.2     setosa<br/>3             4.6          3.1           1.5          0.2     setosa<br/>4             5.0          3.6           1.4          0.2     setosa<br/>..            ...          ...           ...          ...        ...<br/>145           6.7          3.0           5.2          2.3  virginica<br/>146           6.3          2.5           5.0          1.9  virginica<br/>147           6.5          3.0           5.2          2.0  virginica<br/>148           6.2          3.4           5.4          2.3  virginica<br/>149           5.9          3.0           5.1          1.8  virginica<br/>[150 rows x 5 columns]</strong></span></pre><p id="1d1a" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">现在让我们看看使用python中的<em class="lp">‘describe’</em>函数的数据的统计视图，以及使用<em class="lp">‘info’</em>函数的数据的一些信息。</p><p id="f8d8" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="4d25" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">数据描述:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="8fef" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">       sepal_length  sepal_width  petal_length  petal_width<br/>count    150.000000   150.000000    150.000000   150.000000<br/>mean       5.843333     3.057333      3.758000     1.199333<br/>std        0.828066     0.435866      1.765298     0.762238<br/>min        4.300000     2.000000      1.000000     0.100000<br/>25%        5.100000     2.800000      1.600000     0.300000<br/>50%        5.800000     3.000000      4.350000     1.300000<br/>75%        6.400000     3.300000      5.100000     1.800000<br/>max        7.900000     4.400000      6.900000     2.500000</strong></span></pre><p id="a5fe" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">数据信息:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="9362" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 150 entries, 0 to 149<br/>Data columns (total 5 columns):<br/> #   Column        Non-Null Count  Dtype  <br/>---  ------        --------------  -----  <br/> 0   sepal_length  150 non-null    float64<br/> 1   sepal_width   150 non-null    float64<br/> 2   petal_length  150 non-null    float64<br/> 3   petal_width   150 non-null    float64<br/> 4   species       150 non-null    object <br/>dtypes: float64(4), object(1)<br/>memory usage: 6.0+ KB</strong></span></pre><p id="a07a" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">在对我们的数据有了清晰的理解之后，我们可以对它进行可视化。我们将使用我们的数据和python中的seaborn和matplotlib创建四种不同的可视化。</p><p id="0e7b" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">(一)散点图</strong></p><p id="98e9" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">我们将创建两个不同的散点图，一个是萼片长度对萼片宽度，另一个是花瓣长度对花瓣宽度。用python来做吧！</p><p id="ac69" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">萼片散点Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="8f76" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/b56ab15c781f91fd08f17f296298355a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXelwDLtOCtPFksobrclMQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片作者<a class="ae jn" rel="noopener" href="/@nikhiladithyan">作者</a></figcaption></figure><p id="8b6f" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">花瓣散点Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="6ae0" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mv"><img src="../Images/31fb49616bd58ad035646dc28de4ea2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lIgKFF0tf1A1VceROpvB-g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片由<a class="ae jn" rel="noopener" href="/@nikhiladithyan">作者</a></figcaption></figure><p id="66c9" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">(二)热图</strong></p><p id="3b54" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">热图对于发现数据中变量之间的相关性和关系非常有用。使用python中的seaborn可以有效地生成热图。</p><p id="561f" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="ace0" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mw"><img src="../Images/fd5519f8e508446fe0c8a067a6056775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UpH0D2X6Y3HE8d7Sh2fqjg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片由<a class="ae jn" rel="noopener" href="/@nikhiladithyan">作者</a></figcaption></figure><p id="9ab0" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">(三)散布矩阵</strong></p><p id="d5b4" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">散布矩阵是有效地发现数据集中变量之间的关系或相关性的另一种方法。这个绘图也可以使用python中的seaborn库来完成。</p><p id="00f9" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="f23a" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mx"><img src="../Images/977177a27064bb17ea3a0efed45e1a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BCQY7IGDNr_OyQrbCfh_HA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片作者<a class="ae jn" rel="noopener" href="/@nikhiladithyan">作者</a></figcaption></figure><p id="7bbf" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">(四)分布图</strong></p><p id="aa51" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">分布图用于显示数据集中指定值的出现频率。使用seaborn包在python中实现是可行的。鉴于我们的虹膜数据集，我们将绘制萼片和花瓣的长度和宽度，以观察其分布。用Python来做吧！</p><p id="c6fc" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="020b" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/e9e21b7ce7913e0f483e29d6c6c4df8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*whY4A6mOjxUpn_iscD7VvQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片作者<a class="ae jn" rel="noopener" href="/@nikhiladithyan">作者</a></figcaption></figure><p id="0ec8" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">有了这个可视化，我们就可以进入编码的下一部分，即使用python中的scikit-learn构建和训练我们的K近邻模型。</p><h2 id="6744" class="lq jp hi bd jq lr ls lt ju lu lv lw jy ld lx ly ka lh lz ma kc ll mb mc ke md bi translated">步骤3:构建和训练模型</h2><p id="d21b" class="pw-post-body-paragraph ku kv hi kw b kx ky ij kz la lb im lc ld le lf lg lh li lj lk ll lm ln lo kq hb bi translated">首先，我们需要定义一个“X”变量和一个“Y”变量来构建我们的KNN模型。给定我们的数据集，“物种”变量是我们需要分类的变量，因此它可以作为“Y”变量或因变量。我们数据集中的所有其他变量都可以被视为独立变量或“X”变量。现在，让我们在Python中定义我们的X和Y变量！</p><p id="ee5c" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="f8d0" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="ed53" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">X variable :</strong> [[5.1 3.5 1.4 0.2]<br/> [4.9 3.  1.4 0.2]<br/> [4.7 3.2 1.3 0.2]<br/> [4.6 3.1 1.5 0.2]<br/> [5.  3.6 1.4 0.2]]<br/><strong class="mm hj">Y variable :</strong> ['setosa' 'setosa' 'setosa' 'setosa' 'setosa']</span></pre><p id="069b" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">现在，我们必须标准化我们的“X”变量值，这在训练我们的KNN模型时是有用的。在此之前，规范化是针对给定的一组值构建和移除异常的过程。它还减少了数据冗余，提高了数据完整性。为了标准化这些值，我们可以使用scikit-learn中的<em class="lp">‘standard scaler’</em>函数。用Python来做吧！</p><p id="f7ea" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="90b2" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="9e69" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]<br/> [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]<br/> [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]<br/> [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]<br/> [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]</strong></span></pre><p id="71c5" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">现在我们有了完美的因变量和自变量。现在，我们可以继续训练我们的KNN模型。为了训练我们的模型，我们必须首先将我们的数据分成训练集和测试集，其中训练集具有最多的数据点。为了拆分我们的数据，我们可以使用python中scikit-learn提供的<em class="lp"> 'train_test_split' </em>函数。</p><p id="78c6" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="0d18" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="f6bf" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">Train set shape :</strong> (105, 4) (105,)<br/><strong class="mm hj">Test set shape :</strong> (45, 4) (45,)</span></pre><p id="5af2" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">在上面的代码中，我们使用‘the train _ test _ split’将数据分成训练集和测试集。在函数内部，我们指定我们的测试集应该是30%的数据，其余的是训练集。最后，我们提到在拆分时不应该对我们的数据进行随机洗牌。</p><p id="295a" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">我们现在准备创建我们的KNN算法。用Python来做吧！</p><p id="02d2" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="34cf" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="f448" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">KNeighborsClassifier(algorithm='auto',leaf_size=30,metric=minkowski,<br/>                   metric_params=None,n_jobs=None,n_neighbors=3,p=2,<br/>                   weights='uniform')</strong></span></pre><p id="f66b" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">首先，我们指定K值为3。接下来，我们定义了我们的算法，最后，将我们的训练集值拟合到算法中。在打印出该算法后，我们可以看到“metric=minkowski ”,它只是说明了用于计算邻居距离的方法是minkowski方法。还有其他方法，如欧几里德距离法和雅克卡指数法，但需要手动定义。</p><p id="7e18" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">完成训练我们的KNN算法后，让我们通过我们训练的算法预测测试值，并使用scikit-learn的评估指标评估我们的预测结果。</p><p id="b33a" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj"> Python实现:</strong></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="43bc" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">输出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="a1fd" class="lq jp hi mm b fi mq mr l ms mt"><strong class="mm hj">Prediction Accuracy Score (%) :</strong> 97.78</span></pre><p id="1459" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">使用我们训练的KNN算法，我们已经预测了测试集值。最后，我们使用<em class="lp">‘准确性分数’</em>评估标准来检查我们预测结果的准确性。在输出中，我们可以看到结果的准确率为97.78%，这意味着我们的KNN模型对于给定的虹膜数据集表现得非常好，并且它具有解决现实世界分类问题的能力。至此，我们已经成功地用python构建、训练和评估了我们的KNN模型。说完，我们就来到了这篇文章的结尾。</p><p id="af6f" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">我希望，您会发现这篇文章是有用的，如果您没有遵循任何编码部分也不要担心，因为我已经为这篇文章提供了完整的源代码。</p><p id="f245" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated"><strong class="kw hj">机器学习快乐！</strong></p><p id="0362" class="pw-post-body-paragraph ku kv hi kw b kx me ij kz la mf im lc ld mg lf lg lh mh lj lk ll mi ln lo kq hb bi translated">完整代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure></div></div>    
</body>
</html>