# 为了智胜人工智能陷阱，我们必须意识到它们

> 原文：<https://medium.com/codex/the-age-of-algorithms-ushers-in-a-new-morality-f0a14925abbc?source=collection_archive---------13----------------------->

了解算法如何改变我们的参与度可以帮助你保持选择的自由。

![](img/9ee4be374880a30ba2b22b183d136a1c.png)

哈桑·阿尔马西在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

## 你需要明白的第一件事是，危险是真实存在的，科学家和人工智能专家已经承认了这种危险。

2015 年 1 月*，[斯蒂芬·霍金](https://en.wikipedia.org/wiki/Stephen_Hawking)，[埃隆·马斯克](https://en.wikipedia.org/wiki/Elon_Musk)和数十位[人工智能](https://en.wikipedia.org/wiki/Artificial_intelligence)专家签署了一封关于人工智能的**公开信，呼吁研究人工智能的社会影响。**

这封信肯定了社会可以从人工智能中获得巨大的潜在利益，但呼吁就如何防止某些潜在的“陷阱”进行具体研究。

对研究人员的呼吁是，他们不能创造出无法控制的东西。这封四段的信题为“**健壮有益的人工智能的研究优先事项:一封公开信，**”，在附带的 12 页文件中列出了详细的研究优先事项。

顶级科学家和研究人员对此类问题的关注请参见[https://deepai . org/publication/research-priorities-for-robust-and-benefit-artificial-intelligence](https://deepai.org/publication/research-priorities-for-robust-and-beneficial-artificial-intelligence)上的文档。

这里引用一点这种担心:

**…斯坦福大学的人工智能百年研究将“人工智能系统失控”作为一个研究领域，特别强调了对以下可能性的担忧**

有一天，随着不按照人类意愿行事的超级智能的崛起，我们可能会失去对人工智能系统的控制——这些强大的系统会威胁到人类。这种反面的结果可能吗？如果是，这些情况是如何出现的？……为了更好地理解和解决危险的超级智能的崛起或“智能爆炸”的发生的可能性，应该对研究进行何种投资？

虽然人工智能有可能减轻人类的贫困和疾病等疾病，但这项技术虽然创新性很强，但却是在道德的基础上形成的，因为它们是现存的和不断发展的，所以必须加以审视。

我们越来越多地被我们不理解的算法所驱使和引导，这些算法的真实意图没有充分向我们揭示，甚至它们的设计者也没有完全理解。这提出了许多具有深远影响的伦理问题。

## 令人担忧的是，算法正在推动人类参与度的波动。这些设计的意图根植于最初并不明显的基本前提。风险在于，有时我们只是在被卷入其中后才发现后果。对一些人来说，后果可能是可怕的。

以我们数字化互动的方式为例。人们最常使用的是搜索引擎，比如谷歌，来获取信息。过去，存档信息的抄本是静态的。

静态信息日志和交互式信息日志之间的区别意味着我们无法控制获取信息的方式。

信息不是导航我们如何发现和找到我们想要和需要的东西，而是变化和变形。我们获得的不像我们被喂给的那么多。

虽然这可能看起来无关紧要，但它可能会产生相当阴险的后果。

如果你想象矩阵中的虚假信息，这将变得更成问题。就政治、治理、新闻、历史记录而言，对信息的控制很容易变成操纵。

## 我们获取的信息不再像我们被灌输的那样多。

我们越来越多地参与或依赖那些让我们陷入算法探戈的平台；我们输入偏好和口味，人工智能算法根据过去的行为来预测我们未来的决定和愿望。

问题是算法有它们自己的参与目标，这些设计不可能在每种情况下都符合用户的需求。

这就产生了矛盾，必然会与个人用户的利益发生冲突。

它会扰乱人类学习他们想要什么和需要什么的方式。它会阻碍自然的、有机的(通常是笨拙的)发现过程，从而导致思维的精炼。

个人成长是通过自然的尝试和错误实现的，但算法设计似乎可能会破坏这一过程。

这种内在的矛盾存在于设计中；包含我们欲望的参数阻碍了通过自由探索而发生的人类发展。

**在固定的、预设的前提下的发现是被引导的发现。**

**本质上，(为了让算法发挥作用)有参数意味着它必须有偏差。它必须有一个既定的目标。这意味着，通过设计，由算法驱动的社交媒体平台有可能受到奇怪的限制。**

问题是,“不可预测性”能在算法的设定参数中共存吗？

**如果它们被设计用来预测和预期我们的欲望，它们有可能是不可预测的吗？**

**如果他们预测一个结果，他们必须有参数。**

这变成了一种自引用循环。为了预测某事，他们必须抑制人类经验中固有的某种自然徘徊或徘徊。

如果你曾经在一个平台中选择了一些选项，(想想网飞的反馈)，你会意识到你是如何被人工智能算法控制的，它会给你它认为你想要的东西。而且，因为选项是预先设想的，所以缺乏自由和创造性。

如果道德是我们辨别能力的产物，那么我们必须有接近的自由，以便能够辨别。这是我们人类道德的一个基本前提。算法似乎有能力腐蚀我们的道德发展，因为它们扰乱了这个过程。

新道德的诞生——一种存在于反馈循环中的道德，与成长和理解的新前景的可能性是对立的。作为人类，我们以不规则和不寻常的方式进化，不仅仅是个体，而是整体，作为一个种族。

人类的意识总是在一种相互联系、共享的体验中进化和变形。算法的“如果-那么”思维使这个过程变得愚蠢。

以社交媒体平台为例，或者重新定位广告活动的想法，你肯定经历过这种令人疲惫的发现循环，感觉像一个陷阱。事实上，正是这个平台，(无意冒犯)Medium 自己的口号是“好主意*找到你*”

控制一个平台如何继续向你提供你已经消化掉、不再想要的东西，是一件棘手且难以解读的事情。在选择场景时，人们会被迫做出缺乏细微差别和判断力的决定。探索是受控的，迷宫般的。

**除了影响人类努力的算法循环、陷阱和遏制设置之外，还有那些掌舵这些平台的人的问题。**

我们不能排除这样一个事实，即创始人的个性、偏好和动机本质上是运营企业并保持盈利的算法设计前提的一部分。

想想谷歌的商业模式和众多的利益冲突。与谷歌的关系是交换我们的数据和行为模式，以及我们的私人互动，以换取管理我们生活和我们如何搜索信息的技术。

此外，如果报酬与发现挂钩(即谁从谷歌在其搜索栏中显示信息的方式中受益)，那么发现过程就是扭曲的，尽管并不总是清楚谁受益谁损失。

然而，有一点是明确的，在与动态指数之类的商业关系的探戈中，未经同意的信息交换使得算法设计对平台非常有利。他们掌握着所有的牌。

“取消文化”揭示了用户和平台所有者之间思想和言论控制的危险。即使你消除了因观点与平台所有者和运营者不一致而被压制的恐惧，内在的冲突是，潜在的商业模式是为其所有者的主要利益服务的。

这些人工智能转向策略的一个最可怕的例子曝光在《华尔街日报》的《脸书档案》(【https://www.wsj.com/articles/the-facebook-files-11631713039 档案】[)中，他们的调查揭示了一项 Instagram 算法阴谋中固有的趣味屋镜像策略的研究。](https://www.wsj.com/articles/the-facebook-files-11631713039)

也就是说，人工智能将与色情和暴力互动的用户引入了上瘾参与的蠕虫洞。

**对于 25 岁以下的人来说，危险更大。**

大约 45 岁及以上的成年人能够理解这种技术出现之前的生活对比。他们拥有丰富的生活经验，能够判断和识别平台何时以可疑的动机重塑了我们的互动。

年轻一代没有成熟的视角，也没有与历史的深刻联系作为参照系。这是他们可能被误导和误导的地方。

有人怀疑一旦孩子们被困在马克·扎克伯格的元宇宙里，他会对他们做什么吗？他不掩饰自己的意图，事实上，他的目标得到了丰厚的回报。

早在这些内容被发现之前，他就已经在为孩子们创建 Instagram 了。还有人怀疑历史可以轻而易举地被改写吗？在没有监督或密切检查的情况下，创新有一个非常麻烦和阴险的黑暗面。

这就是为什么像 Elon Musk 这样的人一直在为保持人工智能的诚实而奋斗，并创造了一些倡议，通过建立支持开放人工智能和所有人之间合作的平台。领导这项研究的科学家群体，那些创造这项技术的科学家，敏锐地意识到了这些危险，并公开承认，他们还无法理解人工智能和深度学习的意外后果。

AI 及其算法设计可以电气化*弗兰肯斯坦*；一个我们自己的合成模拟物，没有明确的或有意校准的目标。幽灵更可怕，因为它现在以超人类的速度移动。

我们想象自己之外，我们的物理环境，更广阔，更广阔，更广阔，进入“宇宙之外”是我们人类道德和感觉的证明。但我们不能满足于为创新而创新。如果我们不至少识别和阐明这些固有的缺陷是什么，我们肯定会被它们带走，永远无法阻止它们，或控制它们。

## 如果人工智能和深度学习的创新是为了满足人类的需求，那么它们的根本前提要求我们定义成为人类和拥有人类需求意味着什么。这不能从等式中解析出来。

## 这并不是一种新卢德主义的恳求，而是一种重新想象，关于我们如何理解作为一个人意味着什么，以及如何保持我们推进道德义务和自我意识的能力。

人工智能计算的超人类速度也是一个令人担忧的原因。

随着算法利用大量收集的数据，电力利用我们的计算速度，我们必须意识到，我们正在建立的技术是为了满足我们人类的需求，但却具有超人的速度和规模。

这种自然速度与超高速关系的影响是什么？

如果一个人要教一个蹒跚学步的孩子在设定为奥林匹克运动员速度的跑步机上行走，人们会理解，一些东西在开始自然发展或以自然方式进步之前就被破坏了。

**我们正在以超高速将海量数据释放到一个僵化固定的人工智能手中，并让它影响我们的人类互动。本质上，我们相信我们可以克隆我们的感觉，然后让它自动运行。**

这就是我们削弱人性的地方。人类不是一成不变的。它是不断发展的。然而，假设我们可以数字化我们的思想和经历，然后将它们克隆到一个数字矩阵中，那么在某种程度上，如果我们陷入其中，我们就会使我们的人性变得愚蠢。

算法设计的最新创新显示了计算机如何计算道德的深层伦理难题。

不管你喜不喜欢，算法正在重塑我们交流和互动的方式。不仅仅是压倒性的速度和数据会击垮我们，我们看待自己的方式也发生了根本性的变化。