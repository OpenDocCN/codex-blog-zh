# 减缓你的网络抓取过程的 3 个问题

> 原文：<https://medium.com/codex/3-issues-that-slow-your-web-scraping-process-ec7f93e872dc?source=collection_archive---------1----------------------->

![](img/8f51bec204503ad75f46a4af59b49b20.png)

对于任何依赖大型数据集发展的企业来说，网络抓取都是一项有价值的技术。然而，网络已经发展了，当你试图从互联网上提取有价值的数据时，有时你会遇到障碍。

虽然有些网站很容易收集数据，但其他网站有办法阻止你收集信息。不仅如此，您还会遇到一些与刮刀设置方式相关的问题。

本文将简要探讨人们在尝试抓取网页时遇到的最常见问题，并讨论解决方案。网页抓取并不难。但是有了一点编码知识、耐心和实践，你就可以确保不再遇到这些问题。

在深入探讨最常见的 web 抓取问题之前，让我们看看这个过程会带来什么。

# 网络抓取的好处

网络抓取工具对于提取大量数据来优化你的业务非常有帮助。这里有一个关于为什么停止手动收集数据的简单介绍。

企业使用网络抓取有许多不同的目的。它可以用于线索生成、市场研究、价格优化和机器学习等等。

除了速度之外，网络抓取还保证了数据比手动复制和粘贴信息更加准确。它节省了你的资源，你可以专注于其他重要的任务。

但是，不管好处如何，你几乎肯定会遇到不想被刮的网站。这些网页通常会设置对策来检测和阻止他们认为可疑的活动。除此之外，你还会遇到其他你应该知道的意想不到的问题。让我们来探讨一下从网站中提取数据时会遇到的主要问题。

# 网络抓取的常见挑战

从技术上来说，如果你有技能和知识，所有的网站都是可废弃的。但是，有些数据很难收集。某些网站管理员可能会过度保护他们的网站，并实施一些技术来阻止您从他们的页面收集信息。因此，让我们来看看在试图从互联网上提取数据时常见的障碍。

## HTTP 4xx 响应代码

这些响应通常是由网站管理员设置的限速技术触发的，以防止像网络抓取这样的活动。最常见的是 429 响应，一般表示网站检测到您，并试图阻止您。

在某些情况下，放慢刮的速度可以解决这个问题。然而，有时你需要对你的抓取策略进行一些改变。

当接收这些类型的响应代码时，您需要考虑的第一件事是轮换代理。从同一个 IP 发送多个请求会触发检测。这就是为什么使用代理轮换服务很重要，它会随着每个请求改变你的 IP 地址。[熟悉代理可能是有价值的](https://www.webscrapingapi.com/datacenter-residential-and-rotating-ips-why-you-need-proxies-for-web-scraping/)，因为它为你提供了一个优化你的抓取过程的好方法。然而，通常有两种类型的代理 IP 您应该知道。

数据中心代理是基于云的 IP，没有实际位置。它们相对便宜，并建立在现代基础设施上。但是，这些代理可以被多个用户同时使用，从而更容易被检测到。

住宅代理更可靠和昂贵，因为它们是由具有实际位置的互联网提供商提供的真实 IP。他们通过模仿常规访问者的活动使你的请求无法被阻止。

避免这些响应代码的另一个很好的技巧是让你的抓取看起来像常规的用户活动。这样做的一个方法是包含一定程度的随机性。重复和可预测的抓取方法是机器人正在浏览网站的明确标志。为了避免这种情况，请尝试在请求之间添加随机延迟，并避免在一个扩展序列中链接所有请求。另一个很好的选择是在同一个会话中抓取不同的 URL，但不是同时抓取。

## 收集的部分数据

如果你在提取数据时只收集了部分需要的信息，你的抓取工具可能会被验证码阻止。下面是如何绕过这种常见的验证技术。

验证码可以有各种形状和大小。它们可以是一个简单的数学问题，也可以是一个单词或图像识别游戏。对我们来说，解决它们很容易。然而，这些测试对机器人来说很难，因为它们是为了验证一个真实的人正在进行浏览。

那么你能做什么呢？你可以使用验证码解决服务。有些网站会雇人帮你解决。或者，您可以使用不同的代理。但是这种解决方案需要访问可靠的代理池。[要理解一个伟大的代理池在网络抓取中的重要性，请查看这篇文章](https://www.webscrapingapi.com/a-quick-glance-at-why-proxy-pools-are-important-when-scraping-the-web/)。

无论你如何解决验证码，请记住，消除障碍使您能够访问数据，但它不会阻止您被网站检测到。关于验证码，最好的药是预防。

## 得到罐装蜂蜜

如果你发现自己得到了错误的信息，你很可能掉进了所谓的蜜罐。这些是由网站管理员以 HTML 链接的形式设置的陷阱。普通用户看不到它们，但是网络爬虫会请求它们并被阻止。

这些陷阱可以将您的工具重定向到无休止的空白页面，并识别刮刀请求的属性，这实质上阻止了您的活动。让我们来看看如何避免这种流行的对策。

首先，请记住，网站管理员往往会不断改变他们的蜜罐网址和网站属性，所以请确保您的刮刀是最新的，可以解决这个障碍。如果你用的是预制的刮刀，检查一下，看看它有没有绕过蜜罐的所有必要元素。

此外，请确保在抓取时只跟随可见的链接。如果你认为你的刮刀已经上钩，在链接中寻找“显示:无”或“可见性:隐藏”CSS 属性。

# 智能解决方案

当你陷入网络抓取时，知道该怎么做对于获取尽可能多的数据是至关重要的。从不太理想的做法到网站对策，你需要为你所有的努力准备一套整洁的技巧。

在这个过程中，你可能会遇到更多的问题。但是知道从哪里着手解决基本的网络抓取问题可以让这个过程变得更简单和更有效。

如果你准备开始刮痧，但不知道如何开始，[我们推荐阅读这个全面的工具列表](https://www.webscrapingapi.com/scraping-essential-tools-10-best-web-scraping-apis/)。