<html>
<head>
<title>Generalized Method of Moments (GMM) in R (Part 2 of 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R中的广义矩量法(GMM )(第2部分，共3部分)</h1>
<blockquote>原文：<a href="https://medium.com/codex/generalized-method-of-moments-gmm-in-r-part-2-of-3-5d03f4097044?source=collection_archive---------6-----------------------#2021-06-27">https://medium.com/codex/generalized-method-of-moments-gmm-in-r-part-2-of-3-5d03f4097044?source=collection_archive---------6-----------------------#2021-06-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8638" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是GMM系列文章的第二篇，是计量经济学和统计学中广义矩量法的简称。欢迎有兴趣的观众来回顾我在R(第2部分，共3部分)中的上一篇帖子<a class="ae jd" href="https://alfredfaisam.medium.com/generalized-method-of-moments-gmm-in-r-part-1-of-3-c65f41b6199" rel="noopener">广义矩量法(GMM)对于GMM的基本思想和使用R包的应用<code class="du je jf jg jh b">gmm</code>。在最后一篇文章中，说明了OLS估计量就是GMM估计量，因此在线性回归的情况下，对于同一组数据<strong class="ih hj">，可以观察到OLS的点估计与GMM的点估计完全相同。然而，为OLS计算的标准误差通常不同于由<code class="du je jf jg jh b">gmm</code>软件包返回的标准误差，因为默认情况下<code class="du je jf jg jh b">gmm</code>至少允许样本间的异方差，但通常OLS函数的标准误差通常取决于同方差。也就是说，<code class="du je jf jg jh b">gmm</code>只是提供了与OLS相同的点估计，但比OLS更稳健的标准误差。诚然，在计量经济学的第一堂课中，对OLS的讨论不需要明确触及GMM。甚至对于应用来说，直接证明OLS估计量的稳健的标准误差也是好的，而不用麻烦GMM。然而，正如我之前所说，GMM只是提供了另一种观点来构建极值估计的综合体系，并从另一个角度来看待我们对OLS和极大似然估计的了解。在结构模型的应用方面，GMM是一种自然的估计方法，它只需要矩条件的有效性。一般来说，这样的时刻条件可以通过领域知识的相关理论(例如，经济学、市场营销等)推导出来。)在下一篇文章中，我将尝试用GMM来解释结构模型的内生性问题。然而，在这篇文章中，我仍然希望从我们熟悉的东西开始理解GMM。</strong></a></p><p id="3006" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文讨论了为什么极大似然估计也是GMM估计。另一方面，也进行了几个实验来说明R 中 <code class="du je jf jg jh b"><strong class="ih hj">optim()</strong></code> <strong class="ih hj">的怪异行为，然后强烈建议<strong class="ih hj">避免使用它</strong>。</strong></p><h1 id="dbe0" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">GMM的MLE</h1><p id="7daf" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">只要模仿上一篇文章中关于OLS是GMM的讨论中的观点，这里就说明了为什么MLE估计量只是GMM估计量。这一陈述的中心点是关于MLE一般应用的矩条件的构造。</p><p id="4176" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人们可能记得，在关于OLS扮演GMM的讨论中，我只是去了启发OLS的<strong class="ih hj">线性投影模型</strong>，而不是直接去了OLS。实际上这是汉森的教科书(<a class="ae jd" href="https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf" rel="noopener ugc nofollow" target="_blank">计量经济学</a>和<a class="ae jd" href="https://www.ssc.wisc.edu/~bhansen/probability/Probability.pdf" rel="noopener ugc nofollow" target="_blank">经济学家概率统计</a>)中关于极值估计量的一种图解风格。也就是说，我们可以建立<strong class="ih hj">一种通用的方法来构造估计量作为总体参数</strong>的样本类似物。因此，对于敏感的<strong class="ih hj">线性投影系数</strong> 𝜷，说明<strong class="ih hj">线性投影模型</strong>，以最小化<strong class="ih hj">均方预测误差</strong>:𝑆(𝜷)=𝔼[(𝑦−𝒙′𝜷】。基于这样的概念总体模型，<strong class="ih hj">的样本模拟</strong>的<strong class="ih hj"> MSE </strong>就是<strong class="ih hj">的平方和误差:</strong></p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es kl"><img src="../Images/a20f532ddb3fcee4622fa70f0543e517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*aSVck7hORhHyQIdtL-l2JQ.png"/></div></figure><p id="a1aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，OLS估计器只是<strong class="ih hj">线性投影系数</strong> 𝜷的样本模拟，因为<strong class="ih hj">线性投影系数</strong> 𝜷最小化<strong class="ih hj">均方预测误差</strong>:𝑆(𝜷)=𝔼[(𝑦−𝒙′𝜷】并且OLS估计器最小化<strong class="ih hj">均方误差</strong>。这样做的好处之一是便于构造GMM的总体矩条件，然后指出OLS估计量和GMM估计量之间的关系。基本原因是它们都可以追溯到<strong class="ih hj">共同的人口时刻条件</strong>:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es kt"><img src="../Images/d59a9ced42339886ccb1a3851e8da95e.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/0*M-TQUsy8wTWBMDKB.png"/></div></figure><p id="0f71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据总体模型的对数似然函数，显示<strong class="ih hj"> MLE是真实参数</strong>的样本模拟也是有用的。从联合可能性开始是有用的:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es ku"><img src="../Images/97594acf7135677b00956cd0995b017c.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/0*lpNJgPzgjYlQSAoU"/></div></figure><p id="12e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一般来说，进行常规假设，使得条件似然是唯一的焦点，并且定义<strong class="ih hj">期望对数密度函数</strong>也是有用的:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es kv"><img src="../Images/9522feb02d6012bcee72bb2873e43725.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/0*_AzZJOUHgxFbEf9S"/></div></figure><p id="aa5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">去除y和𝒙的随机性，使其成为参数𝜽.的函数<strong class="ih hj">一个重要的定理是，当模型被正确指定时，真实参数𝜽₀使期望对数密度𝑙(𝜽最大化。人们可以在<a class="ae jd" href="https://www.ssc.wisc.edu/~bhansen/probability/Probability.pdf" rel="noopener ugc nofollow" target="_blank">的《经济学家的概率与统计》</a> (Hansen，Bruce E .，2021)的第10.20节中查看关于该定理的技术问题。基本想法很简单。如果关于数据生成过程和分布的假设是可靠的，那么真实参数应该与这些假设一致，以最大化<strong class="ih hj">【𝑙(𝜽】</strong>。这个想法启发了MLE，就像<strong class="ih hj">线性投影模型</strong>启发了OLS一样。也就是说，MLE估计器模拟<strong class="ih hj"> 𝜽₀ </strong>，因为MLE估计器最大化了<strong class="ih hj"> 𝑙(𝜽): </strong>的样本模拟</strong></p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kw"><img src="../Images/f4d3b547e157a02d3bd1c2d1d7fc4c0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQkkYRRI_ZXcQtRTQunmog.png"/></div></div></figure><p id="0618" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于<strong class="ih hj">期望对数密度函数</strong>的优化问题，一阶条件为</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lb"><img src="../Images/2383dedabd88ec866f1bfaeec2a1a176.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*NyQjfnaVr6g770CKaXSUIA.png"/></div></figure><p id="7cca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是GMM的人口状况。同样，相应的样本矩条件也是样本对数似然最大化的一阶条件的直接结果</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lc"><img src="../Images/8fb421446430db207a611f31aff79099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*w5rcgZDb32Bqmx93V78lhA.png"/></div></figure><p id="a18d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，MLE估计量就是GMM估计量，实际上它是MM估计量<strong class="ih hj">,因为矩条件的数量与未知数的数量相同。</strong></p><p id="1c20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一个问题是MLE估计量的协方差是否与GMM估计量的协方差相同。简短的回答是，不。基本原因是，在最大似然估计下，分布假设是为数据生成过程作出的，但GMM只需要矩条件。因此，GMM协方差再次<strong class="ih hj">更稳健</strong> MLE协方差。这里是一些数学的插图。根据上一篇文章中关于GMM的一般性讨论，GMM估计量具有以下抽样分布:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ld"><img src="../Images/387c9c4844df71096631c1bfbd93be97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kVV6j869GI8GFCEKmHuzsg.png"/></div></div></figure><p id="8708" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如上一篇文章中所讨论的，J(θ)实际上是<strong class="ih hj">最优权重矩阵</strong>，它是力矩条件的协方差:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es le"><img src="../Images/eca4e450110753a3f3de44d14c477f1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*y-3M7yb_rwOfX6jX17U8aA.png"/></div></figure><p id="a401" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从教科书上关于MLE的讨论，我们知道I(θ)称为<strong class="ih hj">信息矩阵</strong>，是对数似然的海森。此外，如果分布假设有效，那么我们有<strong class="ih hj">信息等式</strong> : I(θ) = J(θ)。也就是说，MLE估计量只是明确地依赖于分布假设，所以协方差是I⁻。因此，GMM协方差通常比MLE协方差更稳健，因为它不期望<strong class="ih hj">信息等式</strong>依赖于分布假设的有效性。</p><h1 id="d5bb" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">R&amp;D数据的案例研究</h1><p id="7d2f" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">只要回到<a class="ae jd" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南(第二版)</a>第<strong class="ih hj"> 7.3.2 </strong>节关于R&amp;D的数据，并尝试对其进行MLE和GMM。一般来说，人们很容易想到，专利的数量是离散的，只有非负的，所以可以作出具体的分布，如泊松。实际上，泊松模型只是将专利数量的条件分布描述为</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lf"><img src="../Images/55a187ae5069c1e20dbd297194b3bc4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GvE0GXrLMr6xwnZIZjlaDw.png"/></div></div></figure><p id="b5d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lg"><img src="../Images/81431063c1212201d2476793125cced8.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*aqI2ZAiEsnPd8sxjSzG4Ig.png"/></div></figure><p id="f8f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也是这种泊松分布的条件均值。由于它不再是简单的线性模型，而且作了特定的分布假设，极大似然估计成为估计参数的自然选择。在R中很容易得到结果:</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="f800" class="ll jj hi jh b fi lm ln l lo lp">poisson_res &lt;- patents_df %&gt;%<br/>  glm(p91 ~ lr91 + aerosp + chemist + computer + machines +<br/>    vehicles + japan + us, family = poisson(), data = .)</span><span id="e52b" class="ll jj hi jh b fi lq ln l lo lp">summary(poisson_res)</span></pre><p id="f160" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="59c0" class="ll jj hi jh b fi lm ln l lo lp">Call:<br/>glm(formula = p91 ~ lr91 + aerosp + chemist + computer + machines + <br/>    vehicles + japan + us, family = poisson(), data = .)<br/><br/>Deviance Residuals: <br/>    Min       1Q   Median       3Q      Max  <br/>-27.979   -5.246   -1.572    2.352   29.246  <br/><br/>Coefficients:<br/>             Estimate Std. Error z value Pr(&gt;|z|)    <br/>(Intercept) -0.873731   0.065868  -13.27  &lt; 2e-16 ***<br/>lr91         0.854525   0.008387  101.89  &lt; 2e-16 ***<br/>aerosp      -1.421850   0.095640  -14.87  &lt; 2e-16 ***<br/>chemist      0.636267   0.025527   24.93  &lt; 2e-16 ***<br/>computer     0.595343   0.023338   25.51  &lt; 2e-16 ***<br/>machines     0.688953   0.038346   17.97  &lt; 2e-16 ***<br/>vehicles    -1.529653   0.041864  -36.54  &lt; 2e-16 ***<br/>japan        0.222222   0.027502    8.08 6.46e-16 ***<br/>us          -0.299507   0.025300  -11.84  &lt; 2e-16 ***<br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1<br/><br/>(Dispersion parameter for poisson family taken to be 1)<br/><br/>    Null deviance: 29669.4  on 180  degrees of freedom<br/>Residual deviance:  9081.9  on 172  degrees of freedom<br/>AIC: 9919.6<br/><br/>Number of Fisher Scoring iterations: 5</span></pre><p id="37c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，泊松分布往往过于强大，其直接属性是<strong class="ih hj">等离差</strong>，它描述了每个样本的均值和方差相等。如果是这样，第一个问题就是MLE估计量是否仍然可靠，或者说，<a class="ae jd" href="https://en.wikipedia.org/wiki/Consistent_estimator" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a>？由以上讨论可知，极大似然估计量就是GMM估计量，而GMM估计量的一致性只取决于矩条件的有效性。那么，让我们检查相应的力矩条件。就这种情况而言，我们可以认为条件期望被假定为具有exp()形式:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lr"><img src="../Images/dd38eca7384c27d5b8eeba475b0f3fd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*tv6tJO2CpnhBs9AvDcKoGA.png"/></div></figure><p id="948b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们可以有以下构造的错误</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es ls"><img src="../Images/dd8237be923099fd3bb89c7395a80766.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*Oh1OtM3rDEoLBqp6msanAQ.png"/></div></figure><p id="1544" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">令人满意的</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lt"><img src="../Images/69bb03e4dc885d60bdfafdab0259fd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*_49G5z_p4Duck0-iy_BRHQ.png"/></div></figure><p id="65c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lu"><img src="../Images/82780c6886dc6584d5012adc09e7438e.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*xZkvbbfDZv2SMC06fo_Y0Q.png"/></div></figure><p id="13a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，样本力矩条件为</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lv"><img src="../Images/aabcd62341de0486c60102c351f97fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eGNTUj1PmCb3CRZmpbRyGw.png"/></div></div></figure><p id="feec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这也是<strong class="ih hj">假设泊松分布的对数似然最大化的一阶条件</strong>。也就是说，它也是这种泊松MLE模型的<strong class="ih hj">对应GMM估计器的样本矩条件。因此，如果我们可以信任条件期望的特定函数形式，那么GMM估计的相合性是可靠的，因此极大似然估计的相合性也是可靠的。这就是结论的神奇之处:即使y的条件分布不遵循泊松分布，泊松MLE估计量基于条件<strong class="ih hj">假设条件期望具有exp()形式</strong>仍然是一致的:</strong></p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lr"><img src="../Images/dd38eca7384c27d5b8eeba475b0f3fd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*tv6tJO2CpnhBs9AvDcKoGA.png"/></div></figure><p id="621e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在文献中，我们将估计量称为<strong class="ih hj">一个准最大似然估计量(QMLE) </strong>。准通常意味着不真实。表面上这种估计量是从泊松分布导出的，但实际上它也可以由依赖于条件期望的矩条件导出。</p><p id="1e8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据协方差矩阵的估计，可以看出MLE过程只返回I⁻，而GMM过程应该返回</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lw"><img src="../Images/eb5ae1da60c144e7f573ef97524b10f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*Oq0k5JL6dm2Of66N6rfaVg.png"/></div></figure><p id="16da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">哪个更健壮。利用<code class="du je jf jg jh b">gmm</code>，人们可以很容易地构建力矩条件:</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="0858" class="ll jj hi jh b fi lm ln l lo lp"># GMM estimator as Quasi- (Psudo-) MLE<br/># Define moment conditions matrix for QMLE (gmm)</span><span id="28cc" class="ll jj hi jh b fi lq ln l lo lp">mom &lt;- function(beta, df) {<br/>  # df is the data frame with first column as dv<br/>  # This function returns n * q matrix<br/>  # Each column is one moment condition before taking sample average<br/>  # There are totally q moment conditions</span><span id="5dea" class="ll jj hi jh b fi lq ln l lo lp">y &lt;- as.numeric(df[, 1])<br/>  x &lt;- data.matrix(df[, 2:ncol(df)])</span><span id="43c2" class="ll jj hi jh b fi lq ln l lo lp"># Refer to moment conditions of QMLE<br/>  m &lt;- x * as.vector(y - exp(x %*% beta))</span><span id="6844" class="ll jj hi jh b fi lq ln l lo lp">return(cbind(m))<br/>}</span><span id="ba64" class="ll jj hi jh b fi lq ln l lo lp"># Generate regression coef as the initial values for QMLE (gmm)<br/>init_values &lt;- patents_df %&gt;%<br/>  select(<br/>    p91, lr91, aerosp, chemist, computer, machines,<br/>    vehicles, japan, us<br/>  ) %&gt;%<br/>  mutate(const = 1) %&gt;%<br/>  # Please hold the order as previous glm() to facilitate comparison<br/>  select(<br/>    p91, const, lr91, aerosp, chemist, computer, machines,<br/>    vehicles, japan, us<br/>  ) %&gt;%<br/>  lm(p91 ~ lr91 + aerosp + chemist + computer + machines +<br/>    vehicles + japan + us, data = .) |&gt;<br/>  {\(x) coef(x)*0.01}()</span><span id="9475" class="ll jj hi jh b fi lq ln l lo lp"># Be careful that we need to use "nlminb" INSTEAD OF "optim", which is<br/># bloody awful.<br/># Refer to <a class="ae jd" href="https://cran.r-project.org/web/packages/gmm/vignettes/gmm_with_R.pdf" rel="noopener ugc nofollow" target="_blank">https://cran.r-project.org/web/packages/gmm/vignettes/gmm_with_R.pdf</a></span><span id="5cd7" class="ll jj hi jh b fi lq ln l lo lp"># Just use random initial values<br/>set.seed(1024)<br/>qmle_res_1 &lt;- gmm(mom, df_n, rnorm(length(init_values)),<br/>  wmatrix = "optimal",<br/>  vcov = "MDS",<br/>  optfct = "nlminb",<br/>  control = list(eval.max = 10000)<br/>)</span><span id="a2e4" class="ll jj hi jh b fi lq ln l lo lp">summary(qmle_res_1)</span></pre><p id="594c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="7d96" class="ll jj hi jh b fi lm ln l lo lp">Call:<br/>gmm(g = mom, x = df_n, t0 = rnorm(length(init_values)), wmatrix = "optimal", <br/>    vcov = "MDS", optfct = "nlminb", control = list(eval.max = 10000))<br/><br/><br/>Method:  twoStep <br/><br/>Kernel:  Quadratic Spectral<br/><br/>Coefficients:<br/>          Estimate     Std. Error   t value      Pr(&gt;|t|)   <br/>Theta[1]  -8.7373e-01   7.4295e-01  -1.1760e+00   2.3958e-01<br/>Theta[2]   8.5453e-01   9.3694e-02   9.1204e+00   7.4878e-20<br/>Theta[3]  -1.4219e+00   3.8016e-01  -3.7401e+00   1.8395e-04<br/>Theta[4]   6.3627e-01   2.2536e-01   2.8234e+00   4.7520e-03<br/>Theta[5]   5.9534e-01   3.0080e-01   1.9792e+00   4.7795e-02<br/>Theta[6]   6.8895e-01   4.1468e-01   1.6614e+00   9.6628e-02<br/>Theta[7]  -1.5297e+00   2.8069e-01  -5.4496e+00   5.0489e-08<br/>Theta[8]   2.2222e-01   3.5284e-01   6.2981e-01   5.2882e-01<br/>Theta[9]  -2.9951e-01   2.7362e-01  -1.0946e+00   2.7368e-01<br/><br/>J-Test: degrees of freedom is 0 <br/>                J-test                P-value             <br/>Test E(g)=0:    4.82602870693394e-15  *******             <br/><br/>#############<br/>Information related to the numerical optimization<br/>Convergence code =  0 <br/>Function eval. =  83 <br/>Gradian eval. =  515 <br/>Message:  X-convergence (3)</span></pre><p id="6ae9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人们可以发现点估计与最大似然估计相同，但协方差不同。你可以检查一下，我们只是复制了<a class="ae jd" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南</a>第216页表格中的结果:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lx"><img src="../Images/059e17c7a98a7cc8cd03c9f501a26e12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MSVMWcbBvedBfA6duRHoww.png"/></div></div></figure><h1 id="3534" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">R中<code class="du je jf jg jh b">optim()</code>的不稳定性</h1><p id="54c4" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">直到现在，一直强调<code class="du je jf jg jh b">optfnc</code>选择<code class="du je jf jg jh b">"nlminb"</code>，而不是默认的<code class="du je jf jg jh b">optim</code>。当使用<code class="du je jf jg jh b">optim</code>解决问题时，可以检查实验，发现不正确的结果:</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="b20b" class="ll jj hi jh b fi lm ln l lo lp"># Just use random initial values<br/>set.seed(1024)<br/>qmle_res_3 &lt;- gmm(mom, df_n, rnorm(length(init_values)),<br/>  wmatrix = "optimal",<br/>  vcov = "MDS",<br/>  optfct = "optim",<br/>  control = list(maxit = 10000)<br/>)</span><span id="0f46" class="ll jj hi jh b fi lq ln l lo lp">summary(qmle_res_3)</span></pre><p id="d8f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="4523" class="ll jj hi jh b fi lm ln l lo lp">Call:<br/>gmm(g = mom, x = df_n, t0 = rnorm(length(init_values)), wmatrix = "optimal", <br/>    vcov = "MDS", optfct = "optim", control = list(maxit = 10000))<br/><br/><br/>Method:  twoStep <br/><br/>Kernel:  Quadratic Spectral<br/><br/>Coefficients:<br/>          Estimate     Std. Error   t value      Pr(&gt;|t|)   <br/>Theta[1]   4.68677922   1.27672054   3.67095152   0.00024165<br/>Theta[2]   0.11570739   0.19122828   0.60507468   0.54512938<br/>Theta[3]  -3.27941695   2.04110024  -1.60669079   0.10812222<br/>Theta[4]  -0.22722767   0.33122546  -0.68602113   0.49269979<br/>Theta[5]   0.34977317   0.32271631   1.08384100   0.27843530<br/>Theta[6]  -1.29893740   1.31655110  -0.98662133   0.32382831<br/>Theta[7]  -4.52432887   4.93624197  -0.91655330   0.35937677<br/>Theta[8]   0.66823830   0.42017527   1.59037989   0.11174920<br/>Theta[9]  -1.19538287   0.43457120  -2.75071811   0.00594648<br/><br/>J-Test: degrees of freedom is 0 <br/>                J-test            P-value         <br/>Test E(g)=0:    24521.7280884245  *******         <br/><br/>#############<br/>Information related to the numerical optimization<br/>Convergence code =  0 <br/>Function eval. =  1558 <br/>Gradian eval. =  NA</span></pre><p id="81f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="6e4c" class="ll jj hi jh b fi lm ln l lo lp"># What about anoter set of random initial values<br/>set.seed(4201)<br/>qmle_res_4 &lt;- gmm(mom, df_n, rnorm(length(init_values)),<br/>  wmatrix = "optimal",<br/>  vcov = "MDS",<br/>  optfct = "optim",<br/>  control = list(maxit = 10000)<br/>)<br/>summary(qmle_res_4)</span></pre><p id="172e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是</p><pre class="km kn ko kp fd lh jh li lj aw lk bi"><span id="fe23" class="ll jj hi jh b fi lm ln l lo lp">Call:<br/>gmm(g = mom, x = df_n, t0 = rnorm(length(init_values)), wmatrix = "optimal", <br/>    vcov = "MDS", optfct = "optim", control = list(maxit = 10000))<br/><br/><br/>Method:  twoStep <br/><br/>Kernel:  Quadratic Spectral<br/><br/>Coefficients:<br/>          Estimate     Std. Error   t value      Pr(&gt;|t|)   <br/>Theta[1]  -2.2705e+00   8.8977e-01  -2.5518e+00   1.0717e-02<br/>Theta[2]   1.0505e+00   1.0605e-01   9.9060e+00   3.9217e-23<br/>Theta[3]   1.2665e+00   4.5386e-01   2.7904e+00   5.2639e-03<br/>Theta[4]   8.2098e-01   2.7199e-01   3.0184e+00   2.5414e-03<br/>Theta[5]   1.0493e+00   3.2657e-01   3.2130e+00   1.3134e-03<br/>Theta[6]   1.0738e+00   5.0875e-01   2.1106e+00   3.4806e-02<br/>Theta[7]  -1.7693e+00   3.8303e-01  -4.6194e+00   3.8490e-06<br/>Theta[8]  -1.1773e-01   3.7078e-01  -3.1752e-01   7.5085e-01<br/>Theta[9]  -6.2103e-01   3.0085e-01  -2.0643e+00   3.8991e-02<br/><br/>J-Test: degrees of freedom is 0 <br/>                J-test            P-value         <br/>Test E(g)=0:    7532.64472252297  *******         <br/><br/>#############<br/>Information related to the numerical optimization<br/>Convergence code =  0 <br/>Function eval. =  846 <br/>Gradian eval. =  NA</span></pre><p id="0518" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以发现优化结果只是表示成功收敛，结果却<strong class="ih hj">不正确</strong>！这只是MM估计量，所以值应该是0！老实说，当我准备讲稿时，这些发现让我大吃一惊。据我所知，很多R包仍然使用<code class="du je jf jg jh b">optim()</code>进行数值优化，但从这些经验来看，建议要小心，尽可能不要使用<strong class="ih hj"/>。</p><h1 id="6715" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">摘要</h1><p id="9e14" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">本文讨论了最大似然估计与GMM的关系。实际上极大似然估计也是GMM估计，如果GMM估计的相合性成立，那么极大似然估计的相合性仍然成立。在R&amp;D的例子中，如果条件期望的exp()规格是可接受的，那么当泊松分布受到挑战时，人们仍然可以争论一致性。另一方面，当数据生成过程不服从泊松分布时，GMM过程可以提供更稳健的协方差。</p><p id="61d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一方面，从实验中我也发现了数值优化常用的R函数<code class="du je jf jg jh b">optim()</code>的不稳定性。糟糕的是，据我所知，许多计量经济学或统计学的软件包通常使用<code class="du je jf jg jh b">optim()</code>，所以人们应该小心这些软件包的未来用途。幸运的是，目前我们有其他选择。在<code class="du je jf jg jh b">gmm</code>的岗位上，我只是切换到<code class="du je jf jg jh b">nlminb</code>。我相信其他R包应该有类似的优化方法选项。对于那些想进行计算课题研究的人来说，<a class="ae jd" href="https://julialang.org/" rel="noopener ugc nofollow" target="_blank">茱莉亚</a>被推荐试用。嗯，几年前我曾为两种语言的问题困扰过Rcpp。Julia被期望处理这样的问题来平衡简单编码和快速。</p></div><div class="ab cl ly lz gp ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="hb hc hd he hf"><h1 id="2615" class="ji jj hi bd jk jl mf jn jo jp mg jr js jt mh jv jw jx mi jz ka kb mj kd ke kf bi translated">参考</h1><ul class=""><li id="6966" class="mk ml hi ih b ii kg im kh iq mm iu mn iy mo jc mp mq mr ms bi translated">Chaussé，P. (2021年)。<a class="ae jd" href="https://cran.r-project.org/web/packages/gmm/vignettes/gmm_with_R.pdf" rel="noopener ugc nofollow" target="_blank">用R计算广义矩方法和广义经验似然</a>。<em class="mt">统计软件杂志</em>，<em class="mt"> 34 </em> (11)，1–35。</li><li id="54f8" class="mk ml hi ih b ii mu im mv iq mw iu mx iy my jc mp mq mr ms bi translated">肖斯议员和肖斯议员(2021年)。<a class="ae jd" href="https://cran.r-project.org/web/packages/gmm/gmm.pdf" rel="noopener ugc nofollow" target="_blank">包装‘GMM’</a>。</li><li id="fee5" class="mk ml hi ih b ii mu im mv iq mw iu mx iy my jc mp mq mr ms bi translated">米·维尔比克(2004年)。<a class="ae jd" href="https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf" rel="noopener ugc nofollow" target="_blank">现代计量经济学指南(第二版)</a>。ERIM(电子)书籍和章节。约翰·威利的儿子们，奇切斯特。</li><li id="efe0" class="mk ml hi ih b ii mu im mv iq mw iu mx iy my jc mp mq mr ms bi translated">布鲁斯·汉森(2021)。<a class="ae jd" href="https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf" rel="noopener ugc nofollow" target="_blank">计量经济学</a>。威斯康星大学打字稿。普林斯顿大学出版社，即将出版。</li><li id="09f0" class="mk ml hi ih b ii mu im mv iq mw iu mx iy my jc mp mq mr ms bi translated">布鲁斯·汉森(2021)。<a class="ae jd" href="https://www.ssc.wisc.edu/~bhansen/probability/Probability.pdf" rel="noopener ugc nofollow" target="_blank">经济学家概率统计</a>。威斯康星大学打字稿。普林斯顿大学出版社，即将出版。</li><li id="d779" class="mk ml hi ih b ii mu im mv iq mw iu mx iy my jc mp mq mr ms bi translated">怀特·哈尔伯特(1980)。“异方差一致的协方差矩阵估计量和异方差的直接检验”。<a class="ae jd" href="https://en.wikipedia.org/wiki/Econometrica" rel="noopener ugc nofollow" target="_blank"> <em class="mt">计量经济学</em> </a>。<strong class="ih hj">48</strong>(4):817–838。<a class="ae jd" href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" rel="noopener ugc nofollow" target="_blank">CiteSeerX</a><a class="ae jd" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.7646" rel="noopener ugc nofollow" target="_blank">10 . 1 . 1 . 11 . 7646</a>。<a class="ae jd" href="https://en.wikipedia.org/wiki/Doi_(identifier)" rel="noopener ugc nofollow" target="_blank">doi</a>:<a class="ae jd" href="https://doi.org/10.2307%2F1912934" rel="noopener ugc nofollow" target="_blank">10.2307/1912 934</a>。<a class="ae jd" href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" rel="noopener ugc nofollow" target="_blank"> JSTOR </a> <a class="ae jd" href="https://www.jstor.org/stable/1912934" rel="noopener ugc nofollow" target="_blank"> 1912934 </a>。<a class="ae jd" href="https://en.wikipedia.org/wiki/MR_(identifier)" rel="noopener ugc nofollow" target="_blank">先生</a>T20】0575027。</li></ul></div></div>    
</body>
</html>