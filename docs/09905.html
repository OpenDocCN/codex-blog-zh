<html>
<head>
<title>VGGNet Complete Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">VGGNet完整架构</h1>
<blockquote>原文：<a href="https://medium.com/codex/vggnet-complete-architecture-5c6fa801502b?source=collection_archive---------11-----------------------#2022-11-18">https://medium.com/codex/vggnet-complete-architecture-5c6fa801502b?source=collection_archive---------11-----------------------#2022-11-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="5ab7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">VGGNet简介</h1><p id="faa1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">VGG的全称是<strong class="jf hj">视觉几何组</strong>，隶属于牛津大学科学与工程系。它发布了一系列从VGG开始的卷积网络模型，可以应用于人脸识别和图像分类，从VGG16到VGG19。VGG研究卷积网络深度的最初目的是了解卷积网络的深度如何影响大规模图像分类和识别的准确度和精度。-Deep-16 CNN)，为了加深网络层数，避免参数过多，所有层都使用了一个小的3×3卷积核。</p><p id="0851" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae kg" href="http://ethereon.github.io/netscope/#/gist/dc5003de6943ea5a6b8b" rel="noopener ugc nofollow" target="_blank">vgg 19</a>的网络结构</p><h1 id="820b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">网络结构</h1><ul class=""><li id="860e" class="kh ki hi jf b jg jh jk jl jo kj js kk jw kl ka km kn ko kp bi translated">VGG的输入设置为224x244大小的RGB图像。为训练集图像上的所有图像计算平均RGB值，然后将该图像作为输入输入到VGG卷积网络。使用3×3或1×1滤波器，卷积步长是固定的。。有3个VGG全连接层，根据卷积层+全连接层的总数，可以从VGG11到VGG19不等。最小的VGG11有8个卷积层和3个全连接层。最大的VGG19有16个卷积层。+3个完全连接的层。此外，VGG网络在每个卷积层之后没有跟随池层，或者在不同的卷积层下总共分布5个池层。下图是VGG的结构图:</li></ul><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/cadb1cf56ca413b2d2363e002bd2c0f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v4YDpwhBGF-B42E4.png"/></div></div></figure><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lc"><img src="../Images/09ce4fb8aead1de779493c3d383a5925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E8ttL5YuOVu58ky_.png"/></div></div></figure><ul class=""><li id="de23" class="kh ki hi jf b jg kb jk kc jo ld js le jw lf ka km kn ko kp bi translated">VGG16包含16层，VGG19包含19层。一系列vgg在最后三个全连接层完全相同。整体结构包括5组卷积层，后面是一个最大池。不同的是，五组卷积层中包含了越来越多的级联卷积层。</li></ul><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lg"><img src="../Images/4d61b3986bfba41339c321c89cce681a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*00k7SE_0S6cq6HuM.jpg"/></div></div></figure><ul class=""><li id="8c94" class="kh ki hi jf b jg kb jk kc jo ld js le jw lf ka km kn ko kp bi translated">AlexNet中的每个卷积层只包含一个卷积，卷积核的大小为7 * 7，。在VGGNet中，每个卷积层包含2到4个卷积运算。卷积核的大小是3 * 3，卷积步长是1，池核是2 * 2，步长是2。VGGNet最明显的改进是减小了卷积核的大小，增加了卷积层数。</li></ul><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lc"><img src="../Images/18c9d9ef9e4d7b62fdcf5411556779f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F2EriOvWmcdLDmPH.jpg"/></div></div></figure><ul class=""><li id="71a4" class="kh ki hi jf b jg kb jk kc jo ld js le jw lf ka km kn ko kp bi translated">使用具有较小卷积核的多个卷积层而不是具有卷积核的较大卷积层一方面可以减少参数，并且作者认为它相当于更多的非线性映射，增加了拟合表达能力。</li></ul><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lh"><img src="../Images/4bd33aca8bfbd6985787b3e7df061590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OxLwJqf6tHymhFcf.png"/></div></div></figure><ul class=""><li id="9a07" class="kh ki hi jf b jg kb jk kc jo ld js le jw lf ka km kn ko kp bi translated">两个连续的3 * 3卷积相当于一个5 * 5感受野，三个相当于7 * 7。使用三个3 * 3卷积而不是一个7 * 7卷积的优点是双重的:一个，包括三个ReLu层而不是一个，使得判定函数更具鉴别性；第二，减少参数。比如输入输出都是C通道。3个使用3 * 3的卷积层需要3 (3 * 3 * C * C) = 27 * C * C，1个使用7 * 7的卷积层需要7 * 7 * C * C = 49C * C，这可以看作是对7 * 7卷积应用了一种正则化，使其分解为三个3 * 3卷积。</li><li id="07b0" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated">1 * 1卷积层主要是在不影响卷积层感受野的情况下，增加判决函数的非线性。虽然1 * 1卷积运算是线性的，但ReLu增加了非线性。</li></ul><h1 id="be65" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">网络结构</h1><ul class=""><li id="eee0" class="kh ki hi jf b jg jh jk jl jo kj js kk jw kl ka km kn ko kp bi translated">表1显示了所有网络配置。这些网络遵循相同的设计原则，但深度不同。</li></ul><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ln"><img src="../Images/31c52b8053b557b46ee12449816f0cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rOW97xY4yKkPXmjH.png"/></div></div></figure><ul class=""><li id="7c79" class="kh ki hi jf b jg kb jk kc jo ld js le jw lf ka km kn ko kp bi translated">介绍VGG16的时候肯定用这张图。这张图片包含了很多信息。我在这里的解读可能是有限的。如有补充，欢迎留言。</li><li id="4002" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated"><strong class="jf hj">数字1 </strong>:这是6个网络的对比图。从A到E，网络越来越深。添加了几个层来验证效果。</li><li id="6818" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated"><strong class="jf hj">数字2 </strong>:每一栏都详细解释了每个网络的结构。</li><li id="882f" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated"><strong class="jf hj">数字3 </strong>:这是一个正确的做实验的方法，就是用最简单的方法解决问题，然后针对出现的问题逐步优化。</li></ul><p id="7fb6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">网络A: </strong>先提一个浅层网络，这个网络很容易汇聚到ImageNet上。然后呢？<br/> <strong class="jf hj">网络A-LRN </strong>:加上别人(AlexNet)实验过说有效(LRN)但好像没用的东西。然后呢？<br/> <strong class="jf hj">网B </strong>:那就试试加2层？似乎有效。然后呢？<br/> <strong class="jf hj">网络C </strong>:再加两层1 * 1卷积，一定会收敛。效果好像更好。有点激动。然后呢？<br/> <strong class="jf hj">网络D </strong>:将1 * 1卷积核改为3 * 3。试试看。效果又提升了。好像是最好的(2014)。</p><h1 id="6c5d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">培养</h1><ul class=""><li id="8fe7" class="kh ki hi jf b jg jh jk jl jo kj js kk jw kl ka km kn ko kp bi translated"><strong class="jf hj">优化方法</strong>是带动量的随机梯度下降SGD + momentum (0.9)。批量大小为256。</li><li id="ef3b" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated"><strong class="jf hj">正则化</strong>:使用L2正则化，权重衰减为5e-4。压差出现在前两个完全连接的层之后，p = 0.5。</li><li id="b367" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated">虽然它比AlexNet网络更深，参数更多，但我们推测VGGNet可以在更少的周期内收敛，原因有两个:一是更大的深度和更小的卷积带来隐式正则化；第二，一些层的前期训练。</li><li id="8ae6" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated"><strong class="jf hj">参数初始化</strong>:对于浅A网络，参数随机初始化，权重w从N (0，0.01)采样，偏差初始化为0。然后，对于更深的网络，首先用A网络的参数初始化前四个卷积层和三个全连接层。但是，后来发现也可以不使用预先训练的参数直接初始化它。</li><li id="349e" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka km kn ko kp bi translated">为了获得224 * 224的输入图像，在每次SGD迭代中随机裁剪每个重新缩放的图像。为了增强数据集，裁剪后的图像也随机水平翻转，并进行RGB颜色转换。</li></ul><h1 id="b66f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">VGGNet改进点总结</h1><ol class=""><li id="983e" class="kh ki hi jf b jg jh jk jl jo kj js kk jw kl ka lo kn ko kp bi translated">使用更小的3 * 3卷积核和更深的网络。两个3 * 3卷积核的堆叠是相对于5 * 5卷积核的视场而言的，三个3 * 3卷积核的堆叠相当于7 * 7卷积核的视场。这样可以有更少的参数(3个堆叠的3 * 3结构只有7 * 7个结构参数(3 * 3 * 3)/(7 * 7)= 55%)；另一方面，它们具有更多的非线性变换增加了CNN的学习能力的特性。</li><li id="24a0" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka lo kn ko kp bi translated">在VGGNet的卷积结构中，引入了1 * 1卷积核。在不影响输入输出维数的情况下，引入非线性变换，增加网络的表达能力，减少计算量。</li><li id="6e2d" class="kh ki hi jf b jg li jk lj jo lk js ll jw lm ka lo kn ko kp bi translated">训练时，先训练一个简单的(低级的)VGGNet A级网络，然后用A级网络的权值初始化后面的复杂模型，以加快训练的收敛速度。</li></ol><h1 id="e8ef" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">一些基本常见问题</h1><p id="b35b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj"> Q1:为什么3个3×3的卷积可以代替7×7的卷积？</strong></p><p id="96ae" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lp">答案1 </em> </strong> <br/> 3个3x3卷积，使用3个非线性激活函数，增加非线性表达能力，使分割平面更可分减少参数数量。对于C通道的卷积核，7×7包含参数，3×3的参数数量大大减少。</p><p id="a329" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">Q2:1x1卷积核的作用</strong></p><p id="a6d2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lp">答案2 </em> </strong> <br/>在不影响感受野的情况下增加模型的非线性1x1绕线机相当于线性变换，非线性激活函数起非线性作用</p><p id="aba8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> Q3:网络深度对结果的影响(同年Google也独立发布了深度为22层的网络Google net)</strong></p><p id="1989" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lp">答案3 </em> </strong> <br/> VGG和GoogleNet模型都是深度小卷积VGG只用3x3，而GoogleNet用1x1，3x3，5x5，模型更复杂(模型开始用大卷积核来减少后续机器层的计算)</p><h1 id="888e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">代码实现:</strong></h1><pre class="kr ks kt ku fd lq lr ls bn lt lu bi"><span id="c06f" class="lv ig hi lr b be lw lx l ly lz">from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D<br/>from tensorflow.keras.layers import Dense, Flatten<br/>from tensorflow.keras.models import Model<br/><br/>import warnings<br/>warnings.filterwarnings("ignore", category=FutureWarning)<br/><br/>_input = Input((224,224,1)) <br/><br/>conv1  = Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu")(_input)<br/>conv2  = Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu")(conv1)<br/>pool1  = MaxPooling2D((2, 2))(conv2)<br/><br/>conv3  = Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu")(pool1)<br/>conv4  = Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu")(conv3)<br/>pool2  = MaxPooling2D((2, 2))(conv4)<br/><br/>conv5  = Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(pool2)<br/>conv6  = Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(conv5)<br/>conv7  = Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(conv6)<br/>pool3  = MaxPooling2D((2, 2))(conv7)<br/><br/>conv8  = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(pool3)<br/>conv9  = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv8)<br/>conv10 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv9)<br/>pool4  = MaxPooling2D((2, 2))(conv10)<br/><br/>conv11 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(pool4)<br/>conv12 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv11)<br/>conv13 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv12)<br/>pool5  = MaxPooling2D((2, 2))(conv13)<br/><br/>flat   = Flatten()(pool5)<br/>dense1 = Dense(4096, activation="relu")(flat)<br/>dense2 = Dense(4096, activation="relu")(dense1)<br/>output = Dense(1000, activation="softmax")(dense2)<br/><br/>vgg16_model  = Model(inputs=_input, outputs=output)<br/><br/># Working with pretrained model<br/><br/><br/>from keras.applications.vgg16 import decode_predictions<br/>from keras.applications.vgg16 import preprocess_input<br/>from keras.preprocessing import image<br/>import matplotlib.pyplot as plt <br/>from PIL import Image <br/>import seaborn as sns<br/>import pandas as pd <br/>import numpy as np <br/>import os <br/><br/>img1 = "../input/flowers-recognition/flowers/tulip/10094729603_eeca3f2cb6.jpg"<br/>img2 = "../input/flowers-recognition/flowers/dandelion/10477378514_9ffbcec4cf_m.jpg"<br/>img3 = "../input/flowers-recognition/flowers/sunflower/10386540696_0a95ee53a8_n.jpg"<br/>img4 = "../input/flowers-recognition/flowers/rose/10090824183_d02c613f10_m.jpg"<br/>imgs = [img1, img2, img3, img4]<br/><br/>def _load_image(img_path):<br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    img = image.img_to_array(img)<br/>    img = np.expand_dims(img, axis=0)<br/>    img = preprocess_input(img)<br/>    return img <br/><br/>def _get_predictions(_model):<br/>    f, ax = plt.subplots(1, 4)<br/>    f.set_size_inches(80, 40)<br/>    for i in range(4):<br/>        ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))<br/>    plt.show()<br/>    <br/>    f, axes = plt.subplots(1, 4)<br/>    f.set_size_inches(80, 20)<br/>    for i,img_path in enumerate(imgs):<br/>        img = _load_image(img_path)<br/>        preds  = decode_predictions(_model.predict(img), top=3)[0]<br/>        b = sns.barplot(y=[c[1] for c in preds], x=[c[2] for c in preds], color="gray", ax=axes[i])<br/>        b.tick_params(labelsize=55)<br/>        f.tight_layout()<br/><br/>#Using pretrained weights<br/><br/>from keras.applications.vgg16 import VGG16<br/>vgg16_weights = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5'<br/>vgg16_model = VGG16(weights=vgg16_weights)<br/>_get_predictions(vgg16_model)</span></pre></div></div>    
</body>
</html>