<html>
<head>
<title>How Web Scraping of Zomato can be done by BeautifulSoup Library in Python?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用Python中的BeautifulSoup库完成Zomato的网页抓取？</h1>
<blockquote>原文：<a href="https://medium.com/codex/how-web-scraping-of-zomato-can-be-done-by-beautifulsoup-library-in-python-6f996a30fd0a?source=collection_archive---------19-----------------------#2022-04-27">https://medium.com/codex/how-web-scraping-of-zomato-can-be-done-by-beautifulsoup-library-in-python-6f996a30fd0a?source=collection_archive---------19-----------------------#2022-04-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e0415f83597f47488e4c400ec023bea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zTwdpdbu3tQi5sWe.jpg"/></div></div></figure><h1 id="e869" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="17bf" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">网页抓取，也称为数据抓取，是一种用于从不同网站收集信息的数据抽取。网络抓取软件使用网络浏览器或HTTP访问这些网站。软件用户手动执行网络抓取，但是网络抓取通常是由机器人或网络爬虫完成的自动过程。这是一种将网站和互联网上的特定数据复制并存储到本地数据集或电子表格中以供日后检索的过程。</p><p id="b9fe" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在这里，我们将使用<a class="ae kr" href="https://www.webscreenscraping.com/scraping-zomato-restaurant-data.php" rel="noopener ugc nofollow" target="_blank"> Zomato data scraper </a>来收集印度本加卢鲁最好的餐馆的信息。HTML网页将用于访问和阅读信息。</p><h1 id="cac2" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">抓取网站内容</h1><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d97682a4112f232489f63397e34faa79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CrpOCQAyqwP6IJ45.jpg"/></div></div></figure><p id="3e65" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在浏览器中键入网址，并发出HTTP请求来访问网页。如果请求成功完成，浏览器将显示网页，否则将显示错误。访问Zomato网页也需要同样的请求。</p><p id="ae05" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们可用的一些工具帮助我们使用Python访问网页。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="93e9" class="lb ir hi kx b fi lc ld l le lf">import requests from bs4 import BeautifulSoup</span></pre><p id="7937" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们在使用库之前了解它们的用途，以及访问网页的功能。</p><h1 id="70b3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">提出请求</h1><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0abb72885369cb1fbd96f9d51c0c4b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xJOEJV98rpGOJXbl.jpg"/></div></div></figure><p id="a483" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">它是为依赖这种语言的人而创造的。它消除了向URL手动添加查询字符串或加密帖子数据的需要。这些请求允许您使用Python发送HTTP/1.1的请求。您可以使用简单的Python库来添加诸如标题、多部分文件、表单数据和参数等内容。同样，可以检索Python的响应数据。</p><h1 id="6fc1" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">美丽组(BS4)</h1><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b607beafb1522719d52b2135277c3c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f0N7Xq1Fe3st3fXU.jpg"/></div></div></figure><p id="ee63" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">BeautifulSoup4是一个<a class="ae kr" href="https://www.webscreenscraping.com/hire-python-developers.php" rel="noopener ugc nofollow" target="_blank"> Python </a>的包，用于从XML和HTML文件中提取数据。它与您喜欢的解析器集成在一起，提供导航、搜索和修改解析树。对于程序员来说，节省几个小时甚至几天的努力是很正常的。</p><p id="b1ca" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">了解了工具之后，我们现在将尝试访问Zomato的网页。</p><p id="c35a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">Zomato上最好的酒店的数据现在已经被放入变量中。然而，除了计算机科学家之外，它并不是人人可读的格式。让我们来看看刮出的数据的用途。</p><p id="9306" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在这里，我们寻找餐馆的名称、地址和菜肴的种类。为了开始寻找所有这些特征，我们需要定位包含这些数据的HTML元素。</p><p id="a44d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">通过查看上面提到的BeautifulSoup资料，或者使用Chrome浏览器上的评论来检查哪个标签包含最佳餐厅的集合，以及包含更多信息的附加标签。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="19b7" class="lb ir hi kx b fi lc ld l le lf">top_rest = soup.find_all("div",attrs={"class": "bb0 collections-grid col-l-16"}) list_tr = top_rest[0].find_all("div",attrs={"class": "col-s-8 col-l-1by3"})</span></pre><p id="a70f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">前面的代码将查找任何带有class="col-s-8 col-l-1by3 "的div HTML标记，并返回用于收集酒店列表的数据。我们需要使用一个循环来访问列表项，即每次访问一个餐馆信息，以便使用循环提取附加信息。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2b1f" class="lb ir hi kx b fi lc ld l le lf">list_rest =[] for tr in list_tr: dataframe ={} dataframe["rest_name"] = (tr.find("div",attrs={"class": "res_title zblack bold nowrap"})).text.replace('\n', ' ') dataframe["rest_address"] = (tr.find("div",attrs={"class": "nowrap grey-text fontsize5 ttupper"})).text.replace('\n', ' ') dataframe["cuisine_type"] = (tr.find("div",attrs={"class":"nowrap grey-text"})).text.replace('\n', ' ') list_rest.append(dataframe) list_rest</span></pre><p id="e2aa" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">前面代码中的tr变量保存了酒店的各种细节，比如酒店的名称、菜系、地址、价格、评论和菜单。每条信息都保存在其特定的标签中，可以通过查看称为每项数据的tr来识别。</p><p id="d6d2" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在HTML中寻找标签之前，我们应该看看餐馆的菜单是如何出现在网站上的。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0d5079ae9936d8522d22cd36ed436503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jQ_x7ita5y4I_2lS.jpg"/></div></div></figure><p id="e3eb" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">您可以在上面的图片中看到，抓取所需的数据以几种格式显示。回到HTML内容，我们发现数据保存在定义所用格式或字体的模块的div标记中。</p><p id="7fb7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">开发数据框架是为了收集必要的信息。我们一个接一个地检查数据的每个细节，并将其保存在不同的DataFrame列中。因为HTML数据利用“n”来分割不能保存在DataFrame中的数据，所以我们必须使用一些字符串函数。因此，我们可以将“n”替换为“以防止任何空间问题。</p><p id="4b40" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">从上述代码中获得的结果如下-</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/5e8ef310cb5a2969ed6ad91a60d8ad05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v4jAyJTOJQ4B2QK0.jpg"/></div></div></figure><p id="3aaf" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">以可读格式保存数据</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d28346a57726a0e73d4f3a3852f7edbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4TtfZbYeXXvDqP1d.jpg"/></div></div></figure><p id="93bd" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">假设您需要将数据交付给一个不熟悉Python的人。他们不会理解任何信息。dataframe数据将以CSV等可读格式保存。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="58f8" class="lb ir hi kx b fi lc ld l le lf">import pandas df = pandas.DataFrame(list_rest) df.to_csv("zomato_res.csv",index=False)</span></pre><p id="f75b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">上面的代码将生成Zomato res CSV文件。</p><h1 id="a08c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="da08" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这篇博客中，我们学习了从Python和BeautifulSoup4发出访问网页的请求，以便从可用内容中提取HTML数据。然后，将数据格式化为数据帧，并保存为CSV格式。</p><p id="f85a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">寻找网页抓取服务来抓取Zomato数据？立即联系Web screen Scraping！请求报价！</p></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="8334" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><em class="ln">最初发表于</em><a class="ae kr" href="https://www.webscreenscraping.com/how-web-scraping-of-zomato-can-be-done-by-beautifulsoup-library-in-python.php" rel="noopener ugc nofollow" target="_blank"><em class="ln">【https://www.webscreenscraping.com】</em></a><em class="ln">。</em></p></div></div>    
</body>
</html>