<html>
<head>
<title>Get On Board with JAX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">和JAX一起上船吧</h1>
<blockquote>原文：<a href="https://medium.com/codex/get-on-board-with-jax-c55733439f99?source=collection_archive---------2-----------------------#2022-12-23">https://medium.com/codex/get-on-board-with-jax-c55733439f99?source=collection_archive---------2-----------------------#2022-12-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="2931" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">新书</h2><div class=""/><div class=""><h2 id="9a88" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated"><em class="jg">摘自格里戈里·萨普诺夫</em>的 <a class="ae jh" href="https://www.manning.com/books/jax-in-action?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=book_sapunov_jax_7_28_22" rel="noopener ugc nofollow" target="_blank"> <em class="jg"> JAX在行动</em> </a> <em class="jg"/></h2></div><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es ji"><img src="../Images/13b9d07af03e62268bb05db3d842976d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VuXTApY6Vb3lc8y3gKoMA.jpeg"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">照片由<a class="ae jh" href="https://unsplash.com/@charlesdeluvio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> charlesdeluvio </a>在<a class="ae jh" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="dae3" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated"><em class="ku">本节选涵盖:</em></p><ul class=""><li id="1ec5" class="kv kw hi ka b kb kc ke kf kh kx kl ky kp kz kt la lb lc ld bi translated"><em class="ku">什么是JAX，它与NumPy相比如何</em></li><li id="e24b" class="kv kw hi ka b kb le ke lf kh lg kl lh kp li kt la lb lc ld bi translated"><em class="ku">为什么使用JAX？</em></li><li id="2f15" class="kv kw hi ka b kb le ke lf kh lg kl lh kp li kt la lb lc ld bi translated"><em class="ku">比较JAX与TensorFlow/PyTorch </em></li></ul><p id="8cdc" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">如果您是对JAX及其功能感兴趣的Python开发人员或机器学习从业者，请阅读本书。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><p id="4a9e" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">将<strong class="ka hs"> fccsapunov </strong>输入<a class="ae jh" href="https://www.manning.com/books/jax-in-action?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=book_sapunov_jax_7_28_22" rel="noopener ugc nofollow" target="_blank">manning.com</a>收银台的折扣代码框，即可享受<a class="ae jh" href="https://www.manning.com/books/jax-in-action?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=book_sapunov_jax_7_28_22" rel="noopener ugc nofollow" target="_blank"> <em class="ku"> JAX活动</em> </a>七五折优惠。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><p id="4dcd" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">随着越来越多的研究人员将其用于研究，JAX越来越受欢迎，DeepMind等大公司也开始为其生态系统做出贡献。</p><p id="a330" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">在这一节选中，我们将介绍JAX及其强大的生态系统。我们将解释什么是JAX，以及它与NumPy、PyTorch和TensorFlow的关系。我们将通过JAX的优势来了解它们如何协同工作，为您提供一个非常强大的深度学习研究和高性能计算工具。</p><h2 id="961c" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated">什么是JAX？</h2><p id="d7c6" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">JAX是一个Python数学库，带有由Google(确切地说是Google Brain团队)开发的NumPy接口。它大量用于机器学习研究，但不限于此——许多其他事情都可以用JAX解决。</p><p id="22ee" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">JAX的创作者将它描述为亲笔签名和XLA。如果你不熟悉这些名字，不要害怕；这很正常，尤其是你刚入行的时候。</p><p id="bff3" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">autograded(<a class="ae jh" href="https://github.com/hips/autograd" rel="noopener ugc nofollow" target="_blank">https://github.com/hips/autograd</a>)是一个高效计算NumPy代码导数的库；它是JAX的前身。《亲笔签名》的主要开发者现在正在开发JAX。简而言之，Autograd可以让你自动计算计算的梯度，这是深度学习和许多其他领域的本质，包括数值优化，物理模拟，以及更普遍的可微分编程。</p><p id="9fea" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">XLA是谷歌特定领域的线性代数编译器，称为加速线性代数。它通过线性代数运算将您的Python函数编译成高性能代码，以便在GPU或TPU上运行。</p><p id="45d3" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">让我们从数字部分开始。</p><h2 id="ede5" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated"><strong class="ak"> JAX饰演NumPy </strong></h2><p id="6b52" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">NumPy是Python数值计算的主力。它在工业和科学领域得到了广泛的应用，以至于NumPy API成为了在Python中使用多维数组的事实上的标准。JAX提供了一个兼容NumPy的API，但是提供了许多其他的NumPy所没有的特性，所以有些人把JAX称为“类固醇上的NumPy”。</p><p id="1d56" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">JAX提供了一个名为<code class="du mp mq mr ms b">DeviceArray</code>的多维数组数据结构，它实现了<code class="du mp mq mr ms b">numpy.ndarray</code>的许多典型属性和方法。还有一个<code class="du mp mq mr ms b">jax.numpy</code>包，它实现了NumPy API，具有许多众所周知的功能，如<code class="du mp mq mr ms b">abs()</code>、<code class="du mp mq mr ms b">conv()</code>、<code class="du mp mq mr ms b">exp()</code>等等。</p><p id="d78b" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">JAX试图尽可能紧密地遵循NumPy API，在许多情况下，你可以从<code class="du mp mq mr ms b">numpy</code>切换到<code class="du mp mq mr ms b">jax.numpy</code>而不改变你的程序。</p><p id="4a14" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">仍然有一些限制，并不是所有的NumPy代码都可以与JAX一起使用。JAX提倡函数式编程范式，要求没有副作用的纯函数。因此，JAX数组是不可变的，而NumPy程序经常使用就地更新，如<code class="du mp mq mr ms b">arr[i] += 10</code>。JAX提供了一个替代的纯函数式API，用纯索引更新函数代替就地更新，从而解决了这个问题。对于这种特殊情况，它将是<code class="du mp mq mr ms b">arr = arr.at[i].add(10)</code>。还有一些其他的区别，在书中有所阐述。</p><p id="94ae" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">因此，您可以使用NumPy的几乎所有功能，并以您在使用NumPy时习惯的方式编写程序。但是，JAX让你做得更多。</p><h2 id="6978" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated"><strong class="ak">可组合转换</strong></h2><p id="1b8a" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">JAX不仅仅是NumPy。它为Python+NumPy代码提供了一组<em class="ku">可组合的函数转换</em>。在其核心，JAX是一个可扩展的系统，通过四个主要的转换来转换数值函数(但这并不意味着没有更多的转换即将到来！):</p><ol class=""><li id="09c7" class="kv kw hi ka b kb kc ke kf kh kx kl ky kp kz kt mt lb lc ld bi translated"><strong class="ka hs">获取代码的梯度</strong>或对其进行微分。这是深度学习和许多其他领域的本质，包括数值优化，物理模拟，以及更普遍的可微分编程。JAX使用一种叫做<em class="ku">自动微分</em>(或简称<em class="ku">自动微分</em>)的方法。自动微分有助于你专注于你的代码，而不是直接处理衍生品；框架会处理它。这通常由<code class="du mp mq mr ms b">grad()</code>函数来完成，但也存在其他高级选项。</li><li id="c697" class="kv kw hi ka b kb le ke lf kh lg kl lh kp li kt mt lb lc ld bi translated"><strong class="ka hs">用<code class="du mp mq mr ms b">jit()</code>编译</strong>你的代码，或者即时编译。JIT使用谷歌的XLA为GPU(通常是通过CUDA的NVIDIA，尽管AMD ROCm平台支持正在进行中)和TPU(谷歌的张量处理单元)编译和生成高效的代码。XLA是在各种设备上支持机器学习框架的后端，最初是TensorFlow，包括CPU、GPU和TPU。</li><li id="e62e" class="kv kw hi ka b kb le ke lf kh lg kl lh kp li kt mt lb lc ld bi translated"><strong class="ka hs">用<code class="du mp mq mr ms b">vmap(),</code>自动矢量化</strong>您的代码，这是矢量化地图。如果你熟悉函数式编程，你可能知道什么是映射。如果没有，不要担心；我们会在书中详细描述它的含义。<code class="du mp mq mr ms b">vmap()</code>处理数组的批量维度，可以轻松地将代码从处理单个数据项转换为一次处理多个数据项(称为批量)。你可以称之为自动批处理。通过这样做，您可以对计算进行矢量化，这通常会显著提升现代硬件的性能，从而有效地并行化矩阵计算。</li><li id="ad9b" class="kv kw hi ka b kb le ke lf kh lg kl lh kp li kt mt lb lc ld bi translated"><strong class="ka hs">并行化</strong>您的代码在多个加速器上运行，比如GPU或TPU。这是用<code class="du mp mq mr ms b">pmap()</code>完成的，它帮助编写单程序多数据(SPMD)程序。<code class="du mp mq mr ms b">pmap()</code>用XLA编译一个函数，然后复制它，并在其XLA设备上并行执行每个副本。</li></ol><h2 id="9dc2" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated">为什么要用JAX？</h2><p id="6ff6" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">JAX现在势头越来越大。众所周知的《2021年人工智能状况报告》将JAX列为新框架的挑战者。</p><p id="6e36" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">深度学习研究人员和实践者热爱JAX。越来越多的新研究正在JAX身上进行。在最近的研究论文中，我可以提到谷歌的<a class="ae jh" href="https://github.com/google-research/vision_transformer" rel="noopener ugc nofollow" target="_blank">视觉转换器(ViT)和MLP混合器</a>。Deepmind <a class="ae jh" href="https://www.deepmind.com/blog/using-jax-to-accelerate-our-research" rel="noopener ugc nofollow" target="_blank">宣布</a>他们正在使用JAX加速他们的研究，JAX很容易被采用，因为Python和NumPy都被广泛使用和熟悉。它的可组合功能转换有助于支持机器学习研究，JAX已经实现了对新算法和架构的快速实验，现在它支撑着DeepMind的许多最新出版物。其中，我要强调一种自我监督学习的新方法，称为<a class="ae jh" href="https://www.deepmind.com/publications/bootstrap-your-own-latent-a-new-approach-to-self-supervised-learning" rel="noopener ugc nofollow" target="_blank"> BYOL </a>(“引导你自己的潜能”)，一种基于通用变压器的结构化输入和输出架构，称为<a class="ae jh" href="https://www.deepmind.com/blog/building-architectures-that-can-handle-the-worlds-data" rel="noopener ugc nofollow" target="_blank">感知者IO </a>，以及对具有2800亿参数<a class="ae jh" href="https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval" rel="noopener ugc nofollow" target="_blank">地鼠</a>和700亿参数<a class="ae jh" href="https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training" rel="noopener ugc nofollow" target="_blank">龙猫</a>的大型语言模型的研究。</p><p id="a3af" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">2021年中期，Huggingface使JAX/亚麻成为他们著名的变形金刚库中第三个官方支持的框架。截至2022年4月，预训练模型的Huggingface集合的JAX模型(5530个)已经是TensorFlow模型(2221个)的两倍。PyTorch仍然以24467个模型领先于这两者，并且将模型从PyTorch移植到JAX/弗莱克斯是一项正在进行的工作。</p><p id="4ea1" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">其中一个开源的大型类似GPT的模型，由EleutherAI称为GPT-J-6B，60亿参数转换器语言模型，在谷歌云上与JAX一起训练。作者表示，这是快速开发大规模模型的正确工具。</p><p id="6012" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">JAX现在可能不太适合生产部署，因为它主要专注于研究方面，但这正是PyTorch所走的路。研究和生产之间的差距很可能很快就会缩小。拥抱脸和GPT-J-6B的案例已经朝着正确的方向发展。鉴于谷歌的影响力和社区的快速扩张，我预计JAX会有一个光明的未来。</p><p id="0c8b" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">JAX并不局限于深度学习。JAX上有许多令人兴奋的应用程序和物理库，包括分子动力学、流体动力学、刚体模拟、量子计算、天体物理学、海洋建模等等。有用于分布式矩阵分解、流数据处理、蛋白质折叠和化学建模的库，其他新的应用程序也在不断出现。</p><h2 id="97ec" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated">JAX与TensorFlow/PyTorch有何不同？</h2><p id="3d32" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">我们已经讨论了JAX和NumPy的比较。让我们将JAX与另外两个领先的现代深度学习框架进行比较:PyTorch和TensorFlow。</p><p id="790f" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们提到，与PyTorch和TensorFlow常见的面向对象方法相比，JAX提倡函数方法。当你开始用JAX编程时，这是你面临的第一件非常实际的事情。它改变了你构建代码的方式，并且需要改变一些习惯。同时，它给你强大的函数转换，迫使你写干净的代码，并带来丰富的可组合性。</p><p id="94e9" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">你很快就会注意到的另一件切实的事情是，JAX非常简约。它并没有实现所有的东西。TensorFlow和PyTorch是两个最受欢迎和发展良好的深度学习框架，它们标配了所有的花哨功能。与他们相比，JAX是一个非常简约的框架，以至于很难称之为框架。这更像是一个图书馆。</p><p id="457d" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">例如，JAX没有提供任何数据加载器，因为其他库(例如PyTorch或Tensorflow)做得很好。JAX的作者不想重新实现一切；他们想专注于核心。这正是你可以并且应该混合JAX和其他深度学习框架的情况。从PyTorch获取数据加载材料并使用它是可以的。PyTorch有优秀的数据加载器，所以让每个库发挥自己的优势。如果别人已经做了一个好轮子，就没有必要重新发明轮子。</p><p id="c326" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">另一个值得注意的事情是，JAX原语非常低级，根据矩阵乘法编写大型神经网络可能非常耗时。因此，您需要一种更高级的语言来指定这样的模型。JAX不提供这种现成的高级API(类似于TensorFlow 2中添加高级Keras API之前的TensorFlow 1)。没有包括这样的特性，但是这不是问题，因为JAX生态系统也有高级的库。</p><p id="3074" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">你不需要用类似NumPy的原语来编写你的神经网络。有优秀的神经网络库，如Google的Flax和DeepMind的Haiku，还有Optax库，它收集了最先进的优化器。还有更多！</p><p id="5ba0" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">图1显示了PyTorch/TensorFlow和JAX之间的差异。</p><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es mu"><img src="../Images/05b02bd3ef3f90183b53dabc7efc16a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cNgmcsJ4SAjT8Wrq.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">图一。JAX与PyTorch/TensorFlow的比较</figcaption></figure><p id="da3e" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">因为JAX是一个用于可组合函数转换的可扩展系统，所以很容易为所有东西构建单独的模块，并根据您的需要进行混合和匹配。</p><h2 id="af03" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated">你将从这本书中学到什么</h2><p id="428c" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">简而言之，这本书将教你如何利用JAX进行机器和深度学习。您将了解如何使用JAX的高级库和模块生态系统，以及如何将TensorFlow和PyTorch与JAX结合起来进行数据加载和部署。</p><h2 id="34c9" class="lq lr hi bd ls lt lu lv lw lx ly lz ma kh mb mc md kl me mf mg kp mh mi mj ho bi translated"><strong class="ak">这本书是给谁的？</strong></h2><p id="0ea3" class="pw-post-body-paragraph jy jz hi ka b kb mk is kd ke ml iv kg kh mm kj kk kl mn kn ko kp mo kr ks kt hb bi translated">本书面向熟悉深度学习和/或机器学习的中级Python程序员。然而，任何对JAX感兴趣的人都会发现这本书引人入胜，内容丰富。</p><p id="bc63" class="pw-post-body-paragraph jy jz hi ka b kb kc is kd ke kf iv kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">如果你想了解这本书的更多内容，请点击这里查看<a class="ae jh" href="https://www.manning.com/books/jax-in-action?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=book_sapunov_jax_7_28_22" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>