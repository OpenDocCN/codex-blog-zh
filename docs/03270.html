<html>
<head>
<title>GAN Technology: Use Cases for Business Applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GAN技术:商业应用的用例</h1>
<blockquote>原文：<a href="https://medium.com/codex/gan-technology-use-cases-for-business-applications-261a1c5a9e9e?source=collection_archive---------8-----------------------#2021-08-25">https://medium.com/codex/gan-technology-use-cases-for-business-applications-261a1c5a9e9e?source=collection_archive---------8-----------------------#2021-08-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8b65810559b6b8e6ab62fa888dc4d3b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oedi3IdGdfPMrBz2R7iCtw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.pexels.com/photo/photo-of-code-projected-over-woman-3861969/" rel="noopener ugc nofollow" target="_blank">图像信用</a></figcaption></figure><p id="6b8b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一台机器能够尝试创造与人类生产的人工制品没有区别的独特内容吗？有没有可能借助生成性对抗网络(GANs)——通过学习复杂现实世界数据示例的结构，并生成由相同结构绑定的类似合成示例——来做到这一点？随着最近生成模型的发展，答案似乎是肯定的，至少在一定程度上是这样。现有的GAN应用证明了这一点。</p><p id="34a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我们将深入探讨什么是生成模型，该领域的最新发展，以及gan在商业中的应用。</p><h1 id="871a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GANs的主要原理</h1><p id="ab0e" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">让我们从非常基础的东西开始。生成-对抗网络由两部分组成:<strong class="ix hj">生成</strong>和<strong class="ix hj">区别。</strong>生成型神经网络创建样本，鉴别型神经网络试图区分正确和错误的样本。</p><p id="1d9a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">想象一下<strong class="ix hj">甘作为一个造假者和一个警察相互竞争</strong>。伪造者学习制作假钞，警察学习检测假钞。两者都是动态的。警察也接受培训，双方在不断升级中学习对方的方法。</p><p id="4023" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">换句话说，甘就像一个作家和一个编辑，或者一个艺术家和一个批评家，他们总是相互影响，在训练中提高他们的技能，以及生成和鉴别模型。</p><p id="3378" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这两种模型的主要目的是能够将新的观察结果分类为属于其中一个类别。模型从更大的总体中接收有限的训练数据样本(数据包括一组具有已知类别成员的观察值)。</p><p id="c2cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">判别模型</strong> <strong class="ix hj">只能区分两个或多个类别</strong>但不能描述类别本身。模型学习条件概率。</p><p id="1a02" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一方面，<strong class="ix hj">生成模型</strong>学习<strong class="ix hj">什么是类别</strong>(值如何在每个类别中分配)。它可以用来判断某个值是属于一个类别还是另一个类别。这个模型学习联合概率分布。</p><p id="dd8c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谷歌提供的模型的一个很好的说明(<strong class="ix hj">图1 </strong>)显示了实践中的这一原理——一个<strong class="ix hj">判别模型</strong>只学习类别之间的一般阈值。尽管如此，一个<strong class="ix hj">生成模型</strong>更加具体，并且知道每个类别的边界在哪里。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/cf0d65768eadd26ef71eafa69d57732d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/0*8EffdL22VSUvoL_Z.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图一。</strong>手写数字的判别和生成模型(<a class="ae iu" href="https://developers.google.com/machine-learning/gan/generative" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="8bd1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将关注生成模型，它们创建新数据样本的能力，以及如何在实践中使用。</p><p id="1adc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lb">注:</em> </strong> <em class="lb">虽然gan包括生成模型和判别模型，但生成模型和判别模型可以分开存在，并用于不同的任务。然而，只有生成模型能够从目标分布创建新的数据样本。由于gan是生成模型的普遍类型，我们将对它们给予最大的关注。</em></p><p id="ea14" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Goodfellow等人在他们现在著名的2014年论文[ <a class="ae iu" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> link </a> ]中首次提出了生成对抗网络的概念。研究人员提出了一个不寻常的训练设置(<strong class="ix hj">图2 </strong>)，其中两个网络，生成器和鉴别器，在一场比赛中相互对抗。给定随机噪声作为输入，生成器必须生成伪图像，而鉴别器必须从我们希望模型学习的目标域(例如，面部图像)中辨别伪图像和真实图像。随着时间的推移，两个网络的任务都在逐步改进，人们可以获得一个训练有素的生成器模型，它可以很好地复制来自目标域的图像。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/03f455e12bd08076abe41447637560de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xlIn5PmA3Jr4ezSL.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图二</strong>。典型生成性对抗网络的示意图(<a class="ae iu" href="https://www.mdpi.com/2072-4292/12/7/1149/htm" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="6238" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们已经发现了GAN的基本结构。所以让我们进一步探讨它们的可能性。</p><h1 id="e710" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">生成模型能做什么？</h1><p id="8c29" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">通过正确的问题定义，GANs能够在处理图像时解决不同的问题，即:</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/a25ccf2523166bc15bfbff71e68592d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nhEuckltrLV812aD.png"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/efa7bd2a5af74bca9af97d822c8ffb41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oQF4b_dIY820BA2_.jpg"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/c77ca23fc95380d92e6263a457e80071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mLjHCUCBKE5mzLXR.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图3 </strong>。GANs ( <a class="ae iu" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank">源1 </a>、<a class="ae iu" href="https://arxiv.org/abs/1912.00953" rel="noopener ugc nofollow" target="_blank">源2 </a>、<a class="ae iu" href="https://news.mit.edu/2020/rewriting-rules-machine-generated-art-0818" rel="noopener ugc nofollow" target="_blank">源3 </a>)生成的不同图像示例</figcaption></figure><ul class=""><li id="ca76" class="lf lg hi ix b iy iz jc jd jg lh jk li jo lj js lk ll lm ln bi translated"><strong class="ix hj">图像修复</strong>——修复图像的缺失部分。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/7365f851ad27d4b8069da6074fe98140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QsXqYQqdby5AHdcl.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图4 </strong>。修补和恢复图像被移除的部分(<a class="ae iu" href="https://heartbeat.fritz.ai/guide-to-image-inpainting-using-machine-learning-to-edit-and-correct-defects-in-photos-3c1b0e13bbd0" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="52c2" class="lf lg hi ix b iy iz jc jd jg lh jk li jo lj js lk ll lm ln bi translated"><strong class="ix hj">图像超分辨率</strong> —将低分辨率图像放大到高分辨率，没有明显的放大伪像。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/2f5de28485015f5df38a2dea59ce115d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zFPR9jhA8-wXCEbQ.jpg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图五</strong>。与非机器学习双三次插值法和非GAN ML法相比，使用GAN (SRGAN)放大图像</figcaption></figure><ul class=""><li id="60da" class="lf lg hi ix b iy iz jc jd jg lh jk li jo lj js lk ll lm ln bi translated"><strong class="ix hj">域调整</strong> —使一个域中的数据与另一个域中的数据相似(例如，使普通照片看起来像油画，同时保留最初描绘的内容)。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/ee5f8d54d39c6f2392bacbd32ea55ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kMSX3hVDspQpG9k6.jpg"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/7eaf213e39f70fc90575fa14bc61d648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6DHh7FBLsL0VgXuO.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图6 </strong>。使用GAN的域适配示例(<a class="ae iu" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><ul class=""><li id="5d86" class="lf lg hi ix b iy iz jc jd jg lh jk li jo lj js lk ll lm ln bi translated"><strong class="ix hj">去噪</strong> —从数据中去除各种噪声。例如，从x射线图像中去除统计噪声符合医疗需求，这将在我们的用例中描述。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/cbbd328f3069f059cf9c98c10a5afda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7m6-i3eKlbMNRx1Y.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图7 </strong>。使用GAN去除断层图像中的噪声(<a class="ae iu" href="https://www.sciencedirect.com/science/article/abs/pii/S1746809419302137" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="0e81" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了上述提到的程序，甘还有很多能力。创造数据——从图像到文本甚至是旋律——只是冰山一角。在未来，我们可能会见证伟大的工艺和专门用于医疗领域、增强现实、创建训练数据等的新GAN应用的出现。</p><p id="1a12" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> GANs应用能够解决不同的任务</strong>:</p><ul class=""><li id="53be" class="lf lg hi ix b iy iz jc jd jg lh jk li jo lj js lk ll lm ln bi translated">生成图像数据集的示例</li><li id="71cc" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">图像到图像的翻译</li><li id="c601" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">文本到图像的翻译</li><li id="f0e4" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">语义图像到照片的翻译</li><li id="dd6b" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">人脸正面视图生成</li><li id="6608" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">生成新的人体姿态</li><li id="7620" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">照片到表情符号</li><li id="07f7" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">照片编辑</li><li id="5c58" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">面部老化</li><li id="7fc2" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">照片混合</li><li id="13be" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">超分辨率</li><li id="da2e" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">照片修复</li><li id="8f44" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">服装翻译</li><li id="6e0b" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">视频预测</li><li id="50de" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js lk ll lm ln bi translated">3D对象生成</li></ul><p id="6fcd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在是实施GANs从他们的能力中获益的最佳时机，因为他们可以模拟真实的数据分布，并学习有助于改善人工智能管道、保护数据、发现异常和适应特定真实世界情况的有用表示。</p><p id="93f2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">既然我们已经知道了生成模型能做什么，那么是时候更进一步了。让我们来看看gan在不同领域的应用示例。</p><h1 id="d821" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GAN使用案例和项目创意</h1><p id="c334" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">离开理论和学术/非学术研究，现在让我们来看看在哪里以及如何在商业中实际使用GANs。虽然自2015-2016年以来，关于该主题的研究一直非常活跃，但这些模型的实际采用现在才开始，这是有充分理由的。</p><p id="0346" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">GANs已经制作出照片级的图像，例如用于<a class="ae iu" href="https://mobidev.biz/blog/ai-machine-learning-in-manufacturing" rel="noopener ugc nofollow" target="_blank">工业设计</a> <strong class="ix hj"> </strong>元素、室内设计、服装、包、公文包、电脑游戏场景等。此外，GANs还被用来培训电影或动画制作人员。他们能够使用碎片图像重建物体的三维模型，并改进从天文观测中获得的照片。</p><h1 id="5005" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GANs在医疗保健中的应用</h1><p id="5bca" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">图像改善的可能性使我们能够在医学领域实现GANs，以获得照片般逼真的单幅图像超分辨率。为什么这很重要？</p><p id="3fb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">医疗保健行业对GANs需求高的原因是图像应该符合特定的要求并且是高质量的。在某些测量协议下可能难以获得高图像质量，例如，当在计算机断层摄影(ct，以减少对具有某些健康先决条件如肺癌的人的有害影响)或MRI中使用低剂量扫描时，强烈需要减少辐射对患者的影响。由于低质量的扫描，它具有使获得高质量图片的努力复杂化的效果。</p><p id="df48" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">超分辨率改善了捕获的图像，可以很好地去除噪声，但是在医疗领域采用GANs相当缓慢，因为出于安全考虑，必须进行许多实验和试验。在处理医疗保健时，必须让许多领域专家参与评估模型，并确保去噪不会以某种方式扭曲图像的实际内容，从而导致错误的诊断。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/b50da439dbb52c2b09cbb5ad6bb5c02e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/0*isyOeiiFK5ejVLtQ.jpg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://link.springer.com/article/10.1007/s11042-020-08980-w" rel="noopener ugc nofollow" target="_blank">斯普林格林克</a></figcaption></figure><p id="7300" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管有巨大的机会，甘也有问题。最大的问题是它们的不稳定性。众所周知，GANs很难训练，有时这些网络可能会生成带有伪像的图像，因为模型在训练数据中没有足够的信息来理解某些事情在现实生活中是如何工作的。例如，给定一个肖像图像数据集，网络可能知道如何模拟人脸，但可能无法理解服装的特定元素应该是什么样子。因此，必须仔细选择与预期结果相关的数据。</p><p id="535a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">总的来看，广告和营销行业的GAN采用率最高。这是合理的，因为推广某种产品或服务通常需要创建独特但重复的内容，例如拍摄照片模型的图像。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/50e4529a04e11f5d6184db1875580682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gQH_lXW0sma-xyT8.png"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/e37ff595aab330212db257fb2795c447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9cctzw9iksSvBQYz.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图13 </strong> —使用创成式照片从真实照片生成的人造人脸(真实照片<a class="ae iu" href="https://unsplash.com/photos/rDEOVtE7vOs" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="e88a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了抓住这个机会，Rosebud AI开发了一个<a class="ae iu" href="https://www.rosebud.ai/generativephotos" rel="noopener ugc nofollow" target="_blank">生成照片</a>应用程序，该应用程序大量使用了GANs的最新进展。应用程序с创建不存在的时装模特的自定义图像。这是通过使用真实模型的库存图像并用生成的图像替换面部来实现的。这里真正有趣的事情是，你可以用一个生成的面来替换这个面，并以多种方式定制生成的面。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/19356fc4835a54fa15725050d2abb2ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A-NpXUmALiBMXGsI.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图十四</strong> —生成人脸定制(<a class="ae iu" href="https://www.rosebud.ai/generativephotos" rel="noopener ugc nofollow" target="_blank">生成照片</a>)。从左到右:原创，添加微笑和年龄，种族编辑，发色编辑。</figcaption></figure><p id="ab23" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">像这样的解决方案通常采用以下步骤来完成任务:</p><ol class=""><li id="b732" class="lf lg hi ix b iy iz jc jd jg lh jk li jo lj js ly ll lm ln bi translated">必须在图像中检测人脸及其边界框，这是一种相当常见的操作，可以使用现有的人脸检测模型来完成。</li><li id="3bfb" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js ly ll lm ln bi translated">检测到的面部被裁剪出图像(有不同的方法来解决这个任务。</li><li id="70a8" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js ly ll lm ln bi translated">裁剪的面部被投影到GAN模型的潜在空间中，并且相似的面部由该模型合成(反转)。</li><li id="fc73" class="lf lg hi ix b iy lq jc lr jg ls jk lt jo lu js ly ll lm ln bi translated">新生成的人脸必须“移植”回原始图像。它可以通过<a class="ae iu" href="https://lingzhili.com/FaceShifterPage/" rel="noopener ugc nofollow" target="_blank"> FaceShifter </a>型号或类似型号实现。</li></ol><p id="972d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Rosebud AI的另一款奇怪的软件是<a class="ae iu" href="https://rosebud.ai/tokkingheads" rel="noopener ugc nofollow" target="_blank"> Tokkingheads </a> app，它可以通过音频或文本输入来制作任何面部照片(合成或真实)的动画(<strong class="ix hj">图15 </strong>)。甘人被允许进行的下一个技术步骤——不仅是生成人造照片，而且要使它们具有动画效果，让它们活起来。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/d71749b2083a03b3313997650d5caaf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/0*MuVhzxPRZfca33lT.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图十五</strong>。合成面部动画示例— <strong class="bd jv"> Tokkingheads </strong> app、<strong class="bd jv"> Rosebud AI </strong> ( <a class="ae iu" href="https://www.rosebud.ai/company" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="c7a6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Generated Media Inc .——这家公司应用<strong class="ix hj"> StyleGan </strong>模型来创建不同种族、年龄和性别的合成面部照片。虽然生成过程没有什么值得注意的(该公司提到他们使用Karras等人的<a class="ae iu" href="https://arxiv.org/abs/1812.04948" rel="noopener ugc nofollow" target="_blank"> StyleGAN和Nvidia </a>)，但有趣的是合作公司如何使用人工智能生成的照片。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/242bf50edf50b6fd6ec378130fab0710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7y4orpPWALjcjkFv.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图十六</strong>。来自<strong class="bd jv">生成媒体公司</strong> ( <a class="ae iu" href="https://generated.photos/" rel="noopener ugc nofollow" target="_blank">来源</a>)的合成面孔</figcaption></figure><p id="15ef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">用例跨越了广泛的领域。事实证明，合成人脸在3D图形行业很有用，2D的面部图像可以转换成3D模型，并用作视频游戏或动画的资产。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="8709" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当谈到移动应用市场时，GANs正在那里取得进展，并主要作为一种娱乐工具。两个特别知名的这类应用程序(面向西方市场)和(面向东方市场)为用户提供了原创功能——编辑一个人的面部外观，甚至将视频中名人的脸换成他们自己的脸。</p><p id="a8e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">FaceApp使用基于StyleGAN或类似神经网络的面部编辑方法。它可以处理照片和视频，建议进行一些修改以确保生成帧的时间一致性。如果视频中的每一帧都由GAN单独处理，当处理后的帧重新组合成视频时，这很可能会导致“脸部退缩”伪像。因此，需要额外的努力来确保帧从一个平滑地过渡到另一个。</p><p id="84be" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">值得注意的是，这一过程所需的计算仍然过于密集，无法在移动设备上直接运行该软件。因此，处理是在公司的服务器上以集中的方式完成的。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/ef147009e5feca0c718c55665ff0dea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vCM5B0849LGxaBS0.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图17 </strong>。人脸编辑选项— <strong class="bd jv"> FaceApp </strong> ( <a class="ae iu" href="https://www.faceapp.com/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><h1 id="49fe" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GANs即服务</h1><p id="ec7c" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">一些公司不是为模型找到特定的利基应用，而是提供对GANs和所有基础设施和接口的访问，以处理数据、训练模型并获得最终结果。</p><p id="7fc7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://runwayml.com/" rel="noopener ugc nofollow" target="_blank"> Runway AI </a>就是这样一家公司，将自己定位为机器学习的平台，实现新颖的内容创作技术。该公司称之为生成媒体功能，是一个网络界面的一部分，支持在你自己的数据集上训练GAN模型，并以图像甚至视频的形式收集结果——这对内容创作者和其他感兴趣的人来说非常有用，因为它有助于将GAN的功能推广到大众(没有图形用户界面的GAN可能对大多数非程序员用户来说太不方便了)。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/91fd79dc41424d354877d7e827430f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_7Tuc3jcq8v2xnnE.gif"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图二十二</strong>。Runway AI进行GAN实验的接口(<a class="ae iu" href="https://runwayml.com/generative-media/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><h1 id="1de6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">计算机视觉中数据集生成的人工智能</h1><p id="5dca" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">任何计算机视觉模型(在某种程度上，任何基于神经网络的模型)都渴望数据，这不是什么秘密——你拥有的数据越多，你可能创建的模型就越好。然而，为训练手动标注数据标签是一个缓慢而昂贵的过程。很多公司负担不起。</p><p id="2113" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在生成模型领域中可以找到一种可能的解决方案(至少是部分的)——事实证明，生成模型可以作为一种工具，用于基于相对少量的手工制作的资产来合成新的标记数据样本。一家以色列初创公司采用了这种方法，据报道，该公司在2021年3月获得了1850万美元的资金。</p><p id="e573" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该公司致力于缩小真实数据和模拟数据之间的差距，以便从模拟数据中获得的知识可以用于真实世界的场景。为了实现这一目标，该公司首先使用3D扫描或传统的3D建模技术创建了一个针对特定应用领域的3D模型数据库(例如用于人脸识别的3D人脸模型)。之后，初始3D模型(它们的3D网格、纹理和语义信息)被转换成潜在空间(反映所有这些特征的压缩表示)。gan被应用于从这个分布中搜索和采样，有效地从与原始资产相同的域中创建新的资产。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/e2241bb18106ee7c69321ac4077aa4e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oSx5xax3JMsMN7Fs.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">图。</strong>由DataGen制作的人工手模型(<a class="ae iu" href="https://venturebeat.com/2021/03/16/datagen-emerges-from-stealth-with-18-5m-to-create-synthetic-datasets-for-computer-vision-models/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="dc94" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种方法似乎很有前途，随着时间的推移，无疑会被更多的公司采用。合成数据为模拟非常复杂的对象和环境开辟了一条全新的可能性范围，同时提供了比手动注释更精确的注释。</p><p id="0b2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">模拟数据使我们能够完全控制数据的变化(例如，对于人体模型，我们可以选择种族、体形、尺寸等。，我们希望拥有以及以何种比例拥有)。我们可能正站在计算机视觉密集型应用(如机器人、自动驾驶汽车和虚拟现实)新时代的黎明。</p></div><div class="ab cl mg mh gp mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="hb hc hd he hf"><p id="a85c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由<a class="ae iu" href="http://Maksym Tatariants" rel="noopener ugc nofollow" target="_blank"> Maksym Tatariants </a>，AI解决方案架构师<strong class="ix hj"> </strong>在<a class="ae iu" href="https://mobidev.biz/services/machine-learning-consulting" rel="noopener ugc nofollow" target="_blank"> MobiDev </a>撰写。</p><p id="a743" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lb">全文原载于</em><a class="ae iu" href="https://mobidev.biz/blog/gans-technology-use-cases-for-business-application" rel="noopener ugc nofollow" target="_blank"><em class="lb">https://mobidev . biz</em></a><em class="lb">，基于mobi dev技术研究。</em></p></div></div>    
</body>
</html>