<html>
<head>
<title>Philosophy of Incremental ML Learning with River</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用River进行增量式ML学习的哲学</h1>
<blockquote>原文：<a href="https://medium.com/codex/philosophy-of-incremental-ml-learning-with-river-f309050ccbc?source=collection_archive---------6-----------------------#2022-01-04">https://medium.com/codex/philosophy-of-incremental-ml-learning-with-river-f309050ccbc?source=collection_archive---------6-----------------------#2022-01-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="af0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对运动中的数据执行机器学习</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/8a3807b099aa4694868b9f55719fcc55.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*QTYj0I1P_AcbP3T9Arf_EA.png"/></div></figure><p id="a136" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你是否厌倦了重新训练模型，而是想建立动态模型，然后在线机器学习(因此河！)可能就是你要找的。当目标是一次学习和预测一个实例时，这里有一些信息。<strong class="ih hj"> River比PyTorch、Tensorflow和scikit-learn快一个数量级。</strong></p><h2 id="0285" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated"><strong class="ak"> ML传统方法</strong></h2><p id="0445" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">机器学习通常是在批量设置中完成的，即一个模型一次性适合一个数据集。这导致静态模型必须被重新训练，以便从新数据中学习。</p><h2 id="921e" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated"><strong class="ak">传统ML的一些弊端</strong></h2><p id="8810" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">在许多情况下，这既不优雅也没有效率，而且通常会招致相当数量的技术债务。事实上，如果您正在使用批处理模型，那么您需要考虑维护一个训练集、监控实时性能、模型再训练等。</p><h2 id="2f2c" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">冷增量河流法</h2><p id="bb01" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">使用River，你可以不断地从数据流中学习。这意味着模型一次处理一个观察值，因此可以动态更新。这允许从不适合主存储器的大规模数据集学习。</p><p id="ec2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在流设置中，使用<em class="km">运行统计数据</em>进行特征缩放，这是一种允许均值和标准差增量更新的数据结构。</p><p id="9b0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">对于增量式训练模型，常见的学习算法是</strong> <a class="ae kl" href="https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31" rel="noopener" target="_blank"> <strong class="ih hj"> <em class="km">随机梯度下降</em> </strong> </a> <strong class="ih hj"> (SGD)。</strong> SGD是一种用于训练神经网络的流行算法，有多种变体。它还可以用于训练其他模型，如线性回归。SGD的核心思想是在每个训练步骤中，模型参数权重在梯度的相反方向上进行调整，该梯度是使用该步骤中的模型预测误差来计算的。</p><h2 id="f089" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">用例</h2><p id="f806" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">River-approach在新数据不断到达的情况下集成得很好。它在许多用例中表现出色，如时间序列预测、垃圾邮件过滤、推荐系统、CTR预测和物联网应用。</p><p id="7230" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是使用River(以及一般的在线机器学习)的一些好处:</p><ul class=""><li id="188d" class="kn ko hi ih b ii ij im in iq kp iu kq iy kr jc ks kt ku kv bi translated"><strong class="ih hj">增量</strong>:模型可以实时更新自己。</li><li id="0816" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">自适应</strong>:车型可以适应<a class="ae kl" href="https://www.wikiwand.com/en/Concept_drift" rel="noopener ugc nofollow" target="_blank">概念漂移</a>。</li><li id="58f3" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">生产就绪</strong>:处理数据流使得在模型开发期间复制生产场景变得简单。</li><li id="ef0c" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">高效</strong>:模特不需要重新培训，需要很少的计算能力，这<a class="ae kl" href="https://arxiv.org/abs/1907.10597" rel="noopener ugc nofollow" target="_blank">降低了她们的碳足迹</a></li><li id="f099" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">快:</strong>当目标是一次学习和预测一个实例时，River比PyTorch、Tensorflow和scikit-learn快一个数量级。</li></ul><h2 id="12f1" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated"><strong class="ak">河流解释</strong></h2><p id="42c0" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">学习和预测是所有预测模型的两个主要功能。learn one方法用于学习(更新模型的内部状态)。<code class="du lb lc ld le b"><em class="km">predict one</em></code>(分类、回归和聚类)<code class="du lb lc ld le b"><em class="km">predict proba one</em> </code>(分类)和<code class="du lb lc ld le b"><em class="km">score one</em></code>(异常检测)算法根据学习目标提供预测。值得注意的是，river包含了transformers，这是使用transform one方法转换输入的有状态对象。</p><p id="43c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要安装river，您可以使用pip，如下所示</p><pre class="je jf jg jh fd lf le lg lh aw li bi"><span id="17a9" class="jl jm hi le b fi lj lk l ll lm">pip install river</span></pre><p id="5003" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">River like creme有一个类似于Scikit-learn的API，也称为用于流或在线机器学习的Scikit-learn。它支持几乎所有不同的最大似然估计器和转换器，但设计用于流数据。</p><p id="4d4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单的事实是，我们以流的形式获取数据，这意味着我们不能像在传统的批处理设置中那样做很多事情。</p><h2 id="2c6d" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">缩放比例</h2><p id="8f78" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">例如，假设我们想要缩放数据，使其均值为0，方差为1，就像我们之前做的那样。为此，我们只需从每个值中减去每个特征的平均值，然后将结果除以特征的标准偏差。问题是，在实际检查所有数据之前，我们不可能知道平均值和标准差的值！一种继续进行的方法是对数据进行第一次传递以计算必要的值，然后在第二次传递期间缩放这些值。问题是，这违背了我们的目的，即通过只看一次数据来学习。虽然这可能看起来相当严格，但它会带来相当大的好处。</p><p id="03e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在<code class="du lb lc ld le b">river</code>中进行<strong class="ih hj">特征缩放</strong>的方式包括计算<em class="km">运行统计</em>(也称为<em class="km">移动统计</em>)。其思想是，我们使用一种数据结构来估计平均值，并在获得一个值时进行自我更新。这同样适用于<strong class="ih hj">方差(以及标准偏差)。现在的想法是，我们可以计算每个特性的运行统计数据，并在它们出现时进行缩放。使用<code class="du lb lc ld le b">river</code>的方法是使用<code class="du lb lc ld le b">preprocessing</code>模块中的<code class="du lb lc ld le b">StandardScaler</code>类。</strong></p><p id="271b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用的一些方法如下:</p><ul class=""><li id="1b63" class="kn ko hi ih b ii ij im in iq kp iu kq iy kr jc ks kt ku kv bi translated"><code class="du lb lc ld le b">naive_bayes</code> -这是我们将用来建立文本分类模型的算法。</li><li id="9d7a" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><code class="du lb lc ld le b">preprocessing</code> -它将用于处理我们用来训练模型的数据集。</li><li id="12c5" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><code class="du lb lc ld le b">metrics</code> -用于计算我们模型的准确度分数。</li><li id="e532" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><code class="du lb lc ld le b">stream</code> -它用于模拟我们的数据集成为流数据。</li><li id="6617" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><code class="du lb lc ld le b">anomaly</code> -用于检测模型中的错误和异常。</li><li id="8a56" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><code class="du lb lc ld le b">compose</code> -用于构建流水线，实现机器学习工作流程的自动化。</li></ul><p id="2798" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然我们正在缩放数据，我们可以开始做一些实际的机器学习。</p><h2 id="036c" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">示例1快速入门</h2><p id="5246" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">举个简单的例子，我们将训练一个逻辑回归来对<a class="ae kl" href="https://archive.ics.uci.edu/ml/datasets/Website+Phishing" rel="noopener ugc nofollow" target="_blank">网站钓鱼数据集</a>进行分类。这是数据集中的第一个观察结果。</p><pre class="je jf jg jh fd lf le lg lh aw li bi"><span id="d17a" class="jl jm hi le b fi lj lk l ll lm">&gt;&gt;&gt; from pprint import pprint<br/>&gt;&gt;&gt; from river import datasets</span><span id="4db3" class="jl jm hi le b fi ln lk l ll lm">&gt;&gt;&gt; dataset = datasets.Phishing()</span><span id="96b2" class="jl jm hi le b fi ln lk l ll lm">&gt;&gt;&gt; for x, y in dataset:<br/>...     pprint(x)<br/>...     print(y)<br/>...     break<br/>{'age_of_domain': 1,<br/> 'anchor_from_other_domain': 0.0,<br/> 'empty_server_form_handler': 0.0,<br/> 'https': 0.0,<br/> 'ip_in_url': 1,<br/> 'is_popular': 0.5,<br/> 'long_url': 1.0,<br/> 'popup_window': 0.0,<br/> 'request_from_other_domain': 0.0}<br/>True</span></pre><p id="9a3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们以流的方式在数据集上运行模型。我们依次交错预测和模型更新。与此同时，我们更新了一个性能指标，以查看模型的表现。</p><pre class="je jf jg jh fd lf le lg lh aw li bi"><span id="d819" class="jl jm hi le b fi lj lk l ll lm">&gt;&gt;&gt; from river import compose<br/>&gt;&gt;&gt; from river import linear_model<br/>&gt;&gt;&gt; from river import metrics<br/>&gt;&gt;&gt; from river import preprocessing</span><span id="e941" class="jl jm hi le b fi ln lk l ll lm">&gt;&gt;&gt; model = compose.Pipeline(<br/>...     preprocessing.StandardScaler(),<br/>...     linear_model.LogisticRegression()<br/>... )</span><span id="3695" class="jl jm hi le b fi ln lk l ll lm">&gt;&gt;&gt; metric = metrics.Accuracy()</span><span id="9da1" class="jl jm hi le b fi ln lk l ll lm">&gt;&gt;&gt; for x, y in dataset:<br/>...     y_pred = model.predict_one(x)      # make a prediction<br/>...     metric = metric.update(y, y_pred)  # update the metric<br/>...     model = model.learn_one(x, y)      # make the model learn</span><span id="84e1" class="jl jm hi le b fi ln lk l ll lm">&gt;&gt;&gt; metric<br/>Accuracy: 89.20%</span></pre><h2 id="bf3f" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">示例2不平衡的数据集(信用卡欺诈)</h2><p id="1d8c" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">在机器学习中，处理不平衡数据集是很常见的。在针对欺诈检测和垃圾邮件分类等任务的在线学习中尤其如此。在这两种情况下，这是二进制分类问题，通常0比1多得多，这通常会妨碍我们扔给它们的分类器的性能。</p><p id="091a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，我们将使用river中可用的信用卡数据集。我们将首先使用一个集合。计数器来计算0和1的数量，以了解阶级平衡。</p><pre class="je jf jg jh fd lf le lg lh aw li bi"><span id="d114" class="jl jm hi le b fi lj lk l ll lm">import collections<br/>from river import datasets<br/><br/>X_y = datasets.CreditCard()<br/><br/>counts = collections.Counter(y for _, y in X_y)<br/><br/>for c, count in counts.items():<br/>    print(f'{c}: {count} ({count / sum(counts.values()):.5%})')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es lo"><img src="../Images/ed32ae5f248dc6df5aef95f9d735e23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jFvMVsSGQ6Q5xQ8r2ZizdA.png"/></div></div></figure><h2 id="efa7" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">基线模型</h2><p id="6a39" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">数据集很不平衡。每一个1大约有578个0。现在让我们用默认参数来训练一个逻辑回归，看看效果如何。我们将测量ROC AUC分数。</p><pre class="je jf jg jh fd lf le lg lh aw li bi"><span id="48ce" class="jl jm hi le b fi lj lk l ll lm">from river import linear_model<br/>from river import metrics<br/>from river import evaluate<br/>from river import preprocessing<br/><br/><br/>X_y = datasets.CreditCard()<br/><br/>model = (<br/>    preprocessing.StandardScaler() |<br/>    linear_model.LogisticRegression()<br/>)<br/><br/>metric = metrics.ROCAUC()<br/><br/>evaluate.progressive_val_score(X_y, model, metric)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/2f2b40adae74e8cd755e8e025ee6bd2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*KvsJB09MNUXwgRsz-H47Jg.png"/></div></figure><p id="ab09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">性能已经相当令人满意，但正如我们现在看到的，我们可以做得更好。</p><h2 id="0c33" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">以期望的样本大小和类别分布进行采样</h2><p id="2f5d" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated"><code class="du lb lc ld le b">RandomUnderSampler</code>和<code class="du lb lc ld le b">RandomOverSampler</code>的缺点是你不能控制分类器训练的数据量。通过欠采样或过采样来调整样本的数量，从而可以获得目标分布。但是，您可以同时进行这两项操作，并选择分类器将看到多少数据。为此，我们可以使用<code class="du lb lc ld le b">RandomSampler</code>类。除了期望的类分布，我们还可以指定训练多少数据。为了符合您的约束，样本将会欠采样和过采样。这是强大的，因为它允许您控制类分布和训练数据的大小(从而控制训练时间)。在下面的示例中，我们将对其进行设置，以便模型将使用1%的数据进行训练。</p><h2 id="ac9b" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">河流中的标准标尺</h2><p id="47aa" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">缩放数据，使其平均值和单位方差为零。在引擎盖下，运行均值和运行方差被保持。缩放比例与批量缩放数据时略有不同，因为事先并不知道确切的平均值和方差。然而，从长远来看，这对性能没有不利影响。</p><p id="be02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个转换器支持小批量以及单个实例。在小批量情况下，允许在后续调用之间改变列的数量和顺序。换句话说，即使你每次调用<code class="du lb lc ld le b">learn_many</code>和<code class="du lb lc ld le b">transform_many</code>时添加和/或删除特性，这个转换器也会继续工作。</p><h2 id="5bb8" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">Imblearn参数</h2><ul class=""><li id="6dae" class="kn ko hi ih b ii kg im kh iq lu iu lv iy lw jc ks kt ku kv bi translated"><strong class="ih hj">分类器</strong> ( <a class="ae kl" href="https://riverml.xyz/latest/api/base/Classifier" rel="noopener ugc nofollow" target="_blank"> <em class="km">基)。分类器</em> </a></li><li id="553a" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">desired _ dist</strong>(<em class="km">dict</em>)</li><li id="c850" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">期望的阶级分布。关键字是类别，而值是所需的类别百分比。这些值的总和必须为1。如果设置为<code class="du lb lc ld le b">None</code>，则观察值将被随机均匀采样，这完全等同于使用<code class="du lb lc ld le b">ensemble.BaggingClassifier</code>。</li><li id="6e29" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">采样率</strong> —默认为<code class="du lb lc ld le b">1.0</code></li><li id="c6eb" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">数据与样本的期望比率。</li><li id="3f43" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated"><strong class="ih hj">种子</strong> ( <em class="km"> int </em> ) —默认为<code class="du lb lc ld le b">None</code></li><li id="2a3a" class="kn ko hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">随机种子的再现性。</li></ul><pre class="je jf jg jh fd lf le lg lh aw li bi"><span id="2670" class="jl jm hi le b fi lj lk l ll lm"><em class="km">#Under Sampling &amp; Oversmapling<br/></em>model = (<br/>    preprocessing.StandardScaler() |<br/>    imblearn.RandomSampler(<br/>        classifier=linear_model.LogisticRegression(),<br/>        desired_dist={0: .8, 1: .2},<br/>        sampling_rate=.01,<br/>        seed=42<br/>    )<br/>)<br/><br/>metric = metrics.ROCAUC()<br/><br/>print(evaluate.progressive_val_score(X_y, model, metric))</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/a2c800d5cc2997ecb05ec641f6f6d22c.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*pySzFVwwWXmkNsgPTbPIoQ.png"/></div></figure><p id="9b21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看看我们的分数是如何提高的。</p><h2 id="cac4" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated"><strong class="ak">结论</strong></h2><p id="e519" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">River为不同的流学习问题提供了多种先进的学习方法、数据生成器/转换器、性能指标和评估器。它是Python中两个最流行的流学习包合并的结果:Creme和scikit-multiflow。River引入了一个改进的架构，该架构基于从开创性的包中吸取的经验教训。River的目标是成为对流式数据进行机器学习的首选图书馆</p></div></div>    
</body>
</html>