<html>
<head>
<title>Architectures for Medical Image Segmentation [Part 2: Attention UNet]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医学图像分割的体系结构[第2部分:注意UNet]</h1>
<blockquote>原文：<a href="https://medium.com/codex/architectures-for-medical-image-segmentation-part-2-attention-unet-c96858cc05d3?source=collection_archive---------4-----------------------#2021-06-19">https://medium.com/codex/architectures-for-medical-image-segmentation-part-2-attention-unet-c96858cc05d3?source=collection_archive---------4-----------------------#2021-06-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7eba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嘿，你们好！我开始撰写对医学图像分割有用的网络架构，即UNet及其变体。在第一篇文章中，我已经介绍了基本的UNet和3D UNet。这里可以找到那个<a class="ae jd" rel="noopener" href="/codex/architectures-for-medical-image-segmentation-part-1-unet-9d8bbd8b7518">。在这篇文章中，我将回顾一下注意力。</a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/d2db8961fc34d57ca429d21c992fe45e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i2kBS_7rFHIkWpLF"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">照片由<a class="ae jd" href="https://unsplash.com/@jjying?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"/>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="9409" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">请注意UNet</h1><p id="44d8" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">像UNet这样的完全卷积神经网络(FCNNs)在医学图像分析方面优于传统方法。这主要归因于以下事实:( I)使用随机梯度下降(SGD)优化来学习特定领域的图像特征,( II)在所有像素之间共享学习到的核，以及(III)图像卷积操作很好地利用了医学图像中的结构信息。卷积层通过逐层处理局部信息来逐步提取更高维的图像表示。</p><h2 id="3707" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">图像分析的注意门</h2><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ll"><img src="../Images/d49b7bfff92880dee733b5fc96265967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hy6eUnE-O__cv_nFUorQ7g.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">提议的附加注意门(AG)的示意图[图片由奥克泰、奥赞等人提供]</figcaption></figure><p id="47e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意系数αi ∈ [0，1]识别显著的图像区域，并修剪特征响应以仅保留与特定任务相关的激活。门控向量gi ∈ R^Fg用于每个像素I，以确定聚焦区域。门控向量包含上下文信息，以剪除较低级别的特征响应。附加注意用于获得门控系数。使用了sigmoid激活函数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lm"><img src="../Images/30b985f07b83ce56df7875df0499b978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37eI809cHScwDA9eP5GgUg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">提出的注意力U网分割模型的框图。在网络的编码部分，输入图像被渐进地滤波，并在每个尺度下以因子2下采样(例如，H4 = H1/8)。Nc表示类的数量。注意门(AGs)过滤通过跳过连接传播的特征。AGs中的特征选择性是通过使用在粗尺度中提取的上下文信息(门控)来实现的。(图片由奥克泰、奥赞等人提供)</figcaption></figure><p id="17d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所提出的AGs被合并到标准U-Net架构中，以突出通过跳过连接传递的显著特征。从粗尺度提取的信息用于门控，以消除跳过连接中的不相关和有噪声的响应。这是在拼接操作之前执行的，以便只合并相关的激活。此外，AGs在正向传递和反向传递期间过滤神经元激活。源自背景区域的梯度在反向传递期间被向下加权。这允许浅层中的模型参数主要基于与给定任务相关的空间区域来更新。在每个子AG中，互补信息被提取和融合以定义跳过连接的输出。为了减少可训练参数的数量和AGs的计算复杂度，在没有任何空间支持的情况下执行线性变换(1×1×1卷积),并且输入特征图被下采样到门控信号的分辨率，类似于非局部块。相应的线性变换解耦特征图，并将它们映射到较低维度的空间用于门控操作。</p><h2 id="ae0b" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">密码</h2><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ln"><img src="../Images/94e7240eb7a7949f8301d3877ad141dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VhEqXdJIKG1JnYccWXp0EQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">拟议中的注意力门控声纳网的示意图(图片由奥克泰、奥赞等人提供)</figcaption></figure><p id="7940" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原代码可以在<a class="ae jd" href="https://github.com/ozan-oktay/Attention-Gated-Networks" rel="noopener ugc nofollow" target="_blank">这里</a>找到。下面是简化版。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="81a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Attention U-net已应用于眼部疾病诊断、黑色素瘤、肺癌、宫颈癌、腹部结构分割、胎儿发育和脑组织量化等问题。</p><p id="b017" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请继续关注剩余UNet的下一篇文章。此外，在这里可以找到之前关于基础UNet <a class="ae jd" rel="noopener" href="/codex/architectures-for-medical-image-segmentation-part-1-unet-9d8bbd8b7518">的文章。</a></p><h1 id="6796" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><p id="9ec9" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">医学图像分割的U-Net及其变体:理论与应用。<em class="lr"> arXiv预印本arXiv:2011.01118 </em> (2020)。</p><p id="e04f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">奥赞·奥克泰等着，〈注意u-net:学习在哪里寻找胰腺〉<em class="lr"> arXiv预印本arXiv:1804.03999 </em> (2018)。</p></div></div>    
</body>
</html>