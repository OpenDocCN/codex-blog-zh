<html>
<head>
<title>Linear Regression Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化线性回归</h1>
<blockquote>原文：<a href="https://medium.com/codex/linear-regression-simplified-386de63c5bd7?source=collection_archive---------12-----------------------#2021-04-03">https://medium.com/codex/linear-regression-simplified-386de63c5bd7?source=collection_archive---------12-----------------------#2021-04-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/28920649f9084d21a32690332e391ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*lzgfzj2Q-UPPBb34hYHFXQ.gif"/></div></div></figure><h2 id="25ce" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">线性回归:用一条直线拟合一组观察值。</h2><p id="1b33" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">就是这样。</p><p id="344e" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">这是回归分析最简单的形式</p><p id="76b4" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">例子</strong></p><p id="bc3c" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">我测量了一群人，这些人的两个特征是他们的体重和高水平。</p><p id="3e79" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><em class="ko">明确x轴上的权重和y轴上的高等级。</em></p><p id="b32d" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">绘制人们的<strong class="jq hj">体重与身高的对比图。</strong>和我看到的有线性关系。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/64bba0b30563ceca78b3c6f500195a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GCapDho-tN8tycqiYSvPYQ.png"/></div></div></figure><p id="c3fa" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">我给它画一条直线怎么样？我可以用那条线来<strong class="jq hj"> <em class="ko">预测新的值</em> </strong>。</p><p id="bca1" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">您正在创建一条线，以根据过去的观测值预测新值，时间向后推移。</p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="bbff" class="lb ir hi bd is lc ld le iw lf lg lh ja li lj lk je ll lm ln ji lo lp lq jm lr bi translated">为什么叫回归？</h1><p id="18b7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">所以回归分析没有什么特别“回归”的。这只是对弗朗西斯·高尔顿的误解。欲知更多有趣的阴谋，请阅读其起源:</p><p id="61b1" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><a class="ae ls" href="https://blog.minitab.com/en/statistics-and-quality-data-analysis/so-why-is-it-called-regression-anyway" rel="noopener ugc nofollow" target="_blank"><em class="ko">https://blog . minitab . com/en/statistics-and-quality-data-analysis/so-why-it-called-regression-anyway</em></a><em class="ko">。</em></p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/528146ae74d5e4fb90479b4e09016f53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c2_eXd4k2NfKQClC2qOk3Q.jpeg"/></div></div></figure></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="dfae" class="lb ir hi bd is lc ld le iw lf lg lh ja li lj lk je ll lm ln ji lo lp lq jm lr bi translated">线性回归是如何工作的？</h1><p id="fe00" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">在内部，它使用了一种叫做<strong class="jq hj">最小二乘法</strong>的技术</p><p id="ef0e" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">它的工作方式是试图<em class="ko">最小化每个点和直线之间的平方误差</em>。误差就是每个点和你的直线之间的距离。</p><p id="cd11" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">斜率就是两个变量的相关性乘以y方向的标准差，再除以x方向的标准差。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/baf1bdb7763d621c8075347e5e50008e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*rKSjTfVDl0JU76SUFRHjiQ.gif"/></div></div></figure><p id="58aa" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">请记住，最小二乘法可以最小化从每个点到直线的误差平方和。考虑线性回归的另一种方式是，定义一条线，代表观察线的最大可能性。所以，人们有时称之为最大似然估计。</p><p id="aed4" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">如果你听到有人谈论<strong class="jq hj">最大似然估计，</strong>他们实际上是在谈论回归。</p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="4c90" class="lb ir hi bd is lc ld le iw lf lg lh ja li lj lk je ll lm ln ji lo lp lq jm lr bi translated">线性回归的类型</h1><ol class=""><li id="1604" class="lv lw hi jq b jr js jv jw jb lx jf ly jj lz ki ma mb mc md bi translated"><strong class="jq hj">简单线性回归:</strong>找出<strong class="jq hj">单个自变量</strong>(输入)和<strong class="jq hj">一个对应因变量(输出)之间的关系。</strong></li><li id="b117" class="lv lw hi jq b jr me jv mf jb mg jf mh jj mi ki ma mb mc md bi translated"><strong class="jq hj">多元线性回归:</strong>寻找<strong class="jq hj"> 2个或2个以上自变量(输入)</strong>与对应因变量(输出)之间的关系。</li></ol><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/a5bb5c1c6a8e3e8c8503d4e0130e618f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*R-N6AQaFPY-Wu3tGsiCgeg.jpeg"/></div></figure></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="c1fa" class="lb ir hi bd is lc ld le iw lf lg lh ja li lj lk je ll lm ln ji lo lp lq jm lr bi translated">用R平方测量效率</h1><p id="9379" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">r平方也被称为决定系数。它是你的模型捕捉到的y总变化的一部分。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/ff15cdf8ab4016b35542496f929feab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*o9HK6H9i4T9csBYwMAZ8Rw.png"/></div></figure><p id="1ed3" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">解释r平方的方法，你会得到一个范围从0到1的值。</p><ul class=""><li id="8b56" class="lv lw hi jq b jr kj jv kk jb ml jf mm jj mn ki mo mb mc md bi translated">0(零)意味着你的拟合很差，它没有捕捉到你的数据中的任何变化。</li><li id="24b7" class="lv lw hi jq b jr me jv mf jb mg jf mh jj mi ki mo mb mc md bi translated"><em class="ko"> 1(一)是一个完美的拟合，所以你的数据中的所有变化都被这条线捕获。</em></li></ul><p id="4fb9" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">所以低的r平方值意味着不适合；高r平方值意味着它是一个很好的拟合。</p><p id="e15e" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">您可以使用r平方作为给定回归对一组数据点有多好的定量度量，然后使用它来选择最适合您的数据的模型。</p><blockquote class="mp"><p id="c088" class="mq mr hi bd ms mt mu mv mw mx my ki dx translated"><strong class="ak"> <em class="mz">“梯度衡量的是如果你稍微改变输入，函数的输出会改变多少。”—莱克斯·弗里德曼(麻省理工)</em> </strong></p></blockquote></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="13ed" class="lb ir hi bd is lc ld le iw lf lg lh ja li lj lk je ll lm ln ji lo lp lq jm lr bi translated">关于线性回归的Python实践示例</h1><p id="8ebe" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">让我们以一些数据为例，这些数据显示了页面速度和购买量之间的大致线性关系:</p><pre class="kq kr ks kt fd na nb nc nd aw ne bi"><span id="5900" class="iq ir hi nb b fi nf ng l nh ni">%matplotlib inline<br/>import numpy as np<br/>from pylab import *</span><span id="1319" class="iq ir hi nb b fi nj ng l nh ni">pageSpeeds = np.random.normal(3.0, 1.0, 1000)</span><span id="c0ad" class="iq ir hi nb b fi nj ng l nh ni">purchaseAmount = 100 - (pageSpeeds + np.random.normal(0, 0.1, 1000)) * 3</span><span id="b388" class="iq ir hi nb b fi nj ng l nh ni">scatter(pageSpeeds, purchaseAmount)</span></pre><p id="c061" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">输出:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es nk"><img src="../Images/af26339196361ec21f95bd1d44470b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*u_rLg0f2qeNRoM5a-ua9Ig.png"/></div></figure><p id="eb3f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">所以你可以看到<em class="ko">绝对是线性关系。</em></p><p id="edea" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">因为我们只有两个特性，所以我们可以保持简单，只使用<em class="ko">scipy . state . Lin regression</em>:</p><pre class="kq kr ks kt fd na nb nc nd aw ne bi"><span id="1ed2" class="iq ir hi nb b fi nf ng l nh ni">from scipy import stats</span><span id="adda" class="iq ir hi nb b fi nj ng l nh ni">slope, intercept, r_value, p_value, std_err = stats.linregress(pageSpeeds, purchaseAmount)</span></pre><p id="3bf0" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">毫不奇怪，我们的R平方值显示了非常好的拟合:</p><p id="195b" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">让我们使用从回归中得到的斜率和截距来绘制预测值<strong class="jq hj">和观察值</strong>:</p><pre class="kq kr ks kt fd na nb nc nd aw ne bi"><span id="a717" class="iq ir hi nb b fi nf ng l nh ni">import matplotlib.pyplot as plt</span><span id="d79f" class="iq ir hi nb b fi nj ng l nh ni">def predict(x):<br/>    return slope * x + intercept</span><span id="0247" class="iq ir hi nb b fi nj ng l nh ni">fitLine = predict(pageSpeeds)</span><span id="35dd" class="iq ir hi nb b fi nj ng l nh ni">plt.scatter(pageSpeeds, purchaseAmount)<br/>plt.plot(pageSpeeds, fitLine, c='r')</span><span id="7227" class="iq ir hi nb b fi nj ng l nh ni">plt.show()</span></pre><p id="da2f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">输出:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es nk"><img src="../Images/5a317e2c81260d3204f5fe600b904298.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*9msgj2cuSWVtnOPdC9XoCQ.png"/></div></figure></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><p id="1dfb" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">感谢你阅读这篇文章，我希望你喜欢并且今天学到了一些新的东西。如果您有任何问题，请随时通过我的博客联系我，我将非常乐意帮助您。</p><p id="af1d" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">保持安全和愉快的学习！</p></div></div>    
</body>
</html>