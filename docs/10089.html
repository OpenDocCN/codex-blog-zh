<html>
<head>
<title>How to build a reusable and efficient text classification workflow based on DolphinScheduler and Hugging Face transformers?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何基于DolphinScheduler和拥抱脸变形金刚构建一个可重用的高效文本分类工作流？</h1>
<blockquote>原文：<a href="https://medium.com/codex/build-hugging-face-quickly-by-apache-dolphinscheduler-4f4381543adc?source=collection_archive---------5-----------------------#2022-12-02">https://medium.com/codex/build-hugging-face-quickly-by-apache-dolphinscheduler-4f4381543adc?source=collection_archive---------5-----------------------#2022-12-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/401ceabe470d90fdea88c57002ea612a.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*NyOtrOdkqAOMjjbpyUqs3w.png"/></div></figure><h1 id="afdf" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">摘要</h1><p id="d427" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">拥抱面部变形金刚是一个开源项目，用于构建、训练和部署最先进的NLP模型。</p><p id="8b14" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">本文描述了如何基于DolphinScheduler和Hugging Face transformers构建一个可重用的高效文本分类工作流，并使用MLflow管理实验和模型。</p><p id="4025" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最终产品:您可以一键指定工作流操作参数来训练和管理模型，将模型部署与MLflow相关联，选择模型的名称和版本，并连接到部署工作流。</p><h1 id="bddc" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">装置</h1><h2 id="4213" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">Java8环境</h2><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="df8a" class="lk in hi lg b be ll lm l ln lo">sudo apt-get update<br/>sudo apt-get install openjdk-8-jdk<br/>java -version</span></pre><p id="0cd4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">配置Java环境变量，<code class="du lp lq lr lg b">~/.bashrc</code>或<code class="du lp lq lr lg b">~/.zshrc</code></p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="09d9" class="lk in hi lg b be ll lm l ln lo"># Make sure your jdk catalog，and Configure Java environment varibles<br/>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64<br/>export PATH=$PATH:$JAVA_HOME/bin</span></pre><h2 id="ecff" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">阿帕奇海豚调度程序3.1.1</h2><p id="6181" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">详细安装可登陆官网:<a class="ae ls" href="https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/installation/standalone.html" rel="noopener ugc nofollow" target="_blank">https://dolphin scheduler . Apache . org/en-us/docs/latest/user _ doc/guide/installation/standalone . html</a>下载DolphinScheduler 3.1.1</p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="61b5" class="lk in hi lg b be ll lm l ln lo"># Enter the catalog of DolphinScheduler needs installation<br/>mkdir dolphinscheduler &amp;&amp; cd "$_"<br/>## install DolphinScheduler<br/>wget https://mirrors.tuna.tsinghua.edu.cn/apache/dolphinscheduler/3.1.1/apache-dolphinscheduler-3.1.1-bin.tar.gz<br/>tar -zxvf apache-dolphinscheduler-3.1.1-bin.tar.gz<br/>rm apache-dolphinscheduler-3.1.1-bin.tar.gz</span></pre><p id="b969" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">启动海豚调度程序</p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="3c38" class="lk in hi lg b be ll lm l ln lo">## start DolphinScheduler<br/>cd apache-dolphinscheduler-3.1.1-bin<br/>bash bin/dolphinscheduler-daemon.sh start standalone-server</span></pre><pre class="lt lf lg lu lv aw lw bi"><span id="c1a5" class="kn in hi lg b fi lx ly l lz lo">## You can view the log with the following command<br/># tail -500f standalone-server/logs/dolphinscheduler-standalone.log</span></pre><p id="a3a5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">启动后，等待一段时间，让服务开始进入DolphinScheduler页面</p><p id="97b4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">打开<a class="ae ls" href="http://localhost:12345/dolphinscheduler/ui," rel="noopener ugc nofollow" target="_blank">http://localhost:12345/dolphinscheduler/ui，</a>可以看到dolphin scheduler页面页面账号:<code class="du lp lq lr lg b">admin</code>，密码:<code class="du lp lq lr lg b">dolphinscheduler123</code></p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/9ff5b918c6a5aa333f9f7a377aa67259.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gnJCALveXmxO81pFMcV9oA.png"/></div></div></figure><h2 id="e19e" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">MLflow</h2><p id="5c33" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">启动MLflow跟踪服务器相对简单，只需通过命令d <code class="du lp lq lr lg b">ocker run --name mlflow -p 5000:5000 -d jalonzjg/mlflow:latest just start</code>即可</p><p id="16b0" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">打开<a class="ae ls" href="http://localhost:5000," rel="noopener ugc nofollow" target="_blank"> http://localhost:5000，</a>可以看到MLflow模型和实验管理页面</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mf"><img src="../Images/6b2a8016293d661772098ebf94b19763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1U1UtRgaectzAEjd3FjeIw.png"/></div></div></figure><h1 id="fa1d" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">工作流构建</h1><h2 id="1d17" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">环境准备</h2><p id="eda1" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">拉代码</p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="b846" class="lk in hi lg b be ll lm l ln lo">git clone https://github.com/jieguangzhou/Dolphinscheduler-NLP-Workflow.git <br/>cd Dolphinscheduler-NLP-Workflow</span></pre><p id="a313" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">创建环境<code class="du lp lq lr lg b">transformers-textclassification</code>，安装运行工作流的依赖项</p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="aa9b" class="lk in hi lg b be ll lm l ln lo">conda create -n transformers-textclassification python==3.8 -y <br/>conda activate transformers-textclassification<br/>pip install -r requirements.txt</span></pre><p id="5262" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">配置ds任务执行环境，如下图所示，让python组件的执行环境为transformers- <code class="du lp lq lr lg b">textclassification</code> Conda环境。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/6a54810e7b5b4c2745d989e291aa0f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Srv27vjc-lbXNoRZjt9OFQ.png"/></div></div></figure><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="711a" class="lk in hi lg b be ll lm l ln lo"># Please modify the conda path according to the actual situation of the server<br/>export PATH="~/anaconda3/bin:$PATH"<br/>source activate transformers-textclassification <br/>PYTHON_HOME=$(which python)</span></pre><h2 id="976b" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">提交工作流</h2><p id="310c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">运行以下命令提交工作流</p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="db76" class="lk in hi lg b be ll lm l ln lo"># Configure the connection letter of python gateway<br/>bash init_pyds.sh<br/># Submit workflow<br/>python pyds.py</span></pre><h2 id="49f0" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">工作流定义</h2><p id="cab9" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">有两个工作流，<strong class="jm hj">培训模型工作流</strong>和<strong class="jm hj">部署模型工作流</strong>。本文将重点讨论如何建立可重复的模型训练工作流程。</p><p id="43a4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">培训模型工作流程</strong></p><p id="2b85" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">模型训练的工作流程包括三项任务</p><ul class=""><li id="ffc0" class="mh mi hi jm b jn ki jr kj jv mj jz mk kd ml kh mm mn mo mp bi translated">数据预处理:数据预处理，主要是文本数据中的分词等操作，具体实现</li><li id="4d2a" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">训练:模型训练，主要用于训练文本分类模型。有关详细信息，请参见</li><li id="b86a" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">mlflow_track:将训练好的模型文件、执行参数、评估指标记录到mlflow跟踪服务器，具体实现见mlflow_track.py .</li></ul><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mv"><img src="../Images/4afc33fdc0c3b2d919afeff7a2f6f7be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wBWBawIWR9nIykkPTe3nVA.png"/></div></div></figure><p id="e024" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">构建工作流后，您可以在以下UI界面上启动工作流，其中</p><ul class=""><li id="8681" class="mh mi hi jm b jn ki jr kj jv mj jz mk kd ml kh mm mn mo mp bi translated">数据集名称:数据集名称</li><li id="6ac1" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">pretrained_model:要使用的预训练模型</li><li id="c322" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">远程服务器uri:ml流跟踪服务器地址</li></ul><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mw"><img src="../Images/5b6e21da6a1a0ef9c1ea253ee0a2b9a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3jfrNaMKFLNcIbs6WeDaHQ.png"/></div></div></figure><p id="71e8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">部署模型工作流</strong></p><p id="c3fb" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">部署模型的工作流由4个任务组成</p><ul class=""><li id="4192" class="mh mi hi jm b jn ki jr kj jv mj jz mk kd ml kh mm mn mo mp bi translated">获取模型:从mlflow跟踪服务器获取模型文件的指定版本，请参见详细信息</li><li id="d204" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">check_service:检查模型服务是否启用，如果没有，则报错，如果成功，则继续运行</li><li id="84ee" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">update_model:使用fetch_model拉取的模型文件更新模型服务</li><li id="88f5" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">test_service:更新完成后，运行服务测试</li></ul><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/775b594f68fdad8d13e7e121419856ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ua7B0MGLiZI7Y7TACsWdZQ.png"/></div></div></figure><p id="7f36" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">构建工作流后，您可以在以下UI界面上启动工作流，其中</p><ul class=""><li id="1877" class="mh mi hi jm b jn ki jr kj jv mj jz mk kd ml kh mm mn mo mp bi translated">远程服务器uri:ml流跟踪服务器地址</li><li id="8f64" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">model_name:已部署模型的名称</li><li id="1093" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh mm mn mo mp bi translated">model_version:已部署模型的版本号</li></ul><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mx"><img src="../Images/c9e759c169456e0277644f23ab4e03dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxGsH3bCsfEtk2O-7HimSQ.png"/></div></div></figure><h1 id="f167" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">运行工作流</h1><h2 id="c872" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">模特培训</h2><p id="71bc" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">接下来，我们将使用数据集<code class="du lp lq lr lg b">dataset_name=yelp_review_full</code>训练模型，在工作流执行页面中分别(如果需要并行运行多个，请确认GPU资源是否充足，并修改脚本来指定GPU资源)使用预先训练好的模型<code class="du lp lq lr lg b">bert-base-cased</code>、<code class="du lp lq lr lg b">microsoft/debersta-base</code>、<code class="du lp lq lr lg b">roberta-base</code>运行工作流。</p><p id="e7b9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如果使用Roberta-base，启动界面如下图所示</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es my"><img src="../Images/be250b5caeb0d52db71705661b13414e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MQt98ryhFdUjK76OYI9UYg.png"/></div></div></figure><p id="f6f4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">三个工作流程执行完成后，可以在<code class="du lp lq lr lg b">mlflow tracking server</code>中查看三个与测试相关的指标，如图所示:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mz"><img src="../Images/df0c0b53e4eaea98e69e84c97f6de8ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWpfwvMUYcDTCblsriI_2A.png"/></div></div></figure><p id="14b8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">对应于该模型的三个版本如下</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mf"><img src="../Images/2ee499a1b6b22525da2172b89c5d15d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0eUBm6l-5M27R94-bsEQQ.png"/></div></div></figure><p id="7916" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们可以选择表现最好的车型三(<code class="du lp lq lr lg b">roberta-base</code>，acc为0.62)，注册为<code class="du lp lq lr lg b">production</code>，用于后续车型调配。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es na"><img src="../Images/37e112a7b8c830fecb8a0ab2439f9c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R2zw61HI3RTWW_RjIi__0A.png"/></div></div></figure><h2 id="744b" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">模型部署</h2><p id="0432" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">启动模型服务器，如果打包到docker中，可以根据自己的喜好打包模型服务，或者使用更健壮的模型部署框架如<code class="du lp lq lr lg b">BentoML</code>、<code class="du lp lq lr lg b">Seldon Core</code>等。</p><pre class="lb lc ld le fd lf lg lh bn li lj bi"><span id="090a" class="lk in hi lg b be ll lm l ln lo"># Start the server<br/>uvicorn predict_service:app</span></pre><p id="68db" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">运行工作流，如图所示</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nb"><img src="../Images/89df7b986d79dbd7165af1480c6924f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cX5WtmiTrkuUahL9_wBgBQ.png"/></div></div></figure><p id="ff38" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">工作流完成，如下图所示</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nc"><img src="../Images/4e85889b6720813a00218df301f99743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mFzZZHNthxtLwkFkVY6z3w.png"/></div></div></figure><p id="57da" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">其中，模型服务器在工作流运行期间接收以下请求。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nd"><img src="../Images/b2f06290440d94c799993892394e6e2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jqPjpfvJpsDZf3wHQhJtg.png"/></div></div></figure><h1 id="b6f6" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">总结</h1><p id="948c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">本文主要介绍在Apache DolphinScheduler中使用Hugging Face的<code class="du lp lq lr lg b">transformers</code>库构建文本分类的工作流程。</p><p id="c138" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">基于工作流执行机器学习训练任务并将所有代码写在脚本中(或Jupyter笔记本中)的优势在于:</p><ol class=""><li id="9413" class="mh mi hi jm b jn ki jr kj jv mj jz mk kd ml kh ne mn mo mp bi translated">基于DolphinScheduler调度系统的特点，它可以稳定地执行机器学习的各种任务，容错机制、调度机制和对丰富类型执行任务的支持可以更好地运行机器学习工作流，包括模型训练和模型部署等工作流。</li><li id="66a7" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh ne mn mo mp bi translated">工作流的重用，以及工作流内任务的重用，可以提高算法团队开发的效率。像上面的模型培训工作流程和模型部署工作流程，适应各自团队的特点，是可以长期使用的。</li><li id="9f7b" class="mh mi hi jm b jn mq jr mr jv ms jz mt kd mu kh ne mn mo mp bi translated">在完成的工作流程中，可以使用DolphinScheduler的接口连接企业内部系统，以DolphinScheduler作为AI平台的底层调度系统，然后在业务端实现系统中相应的调用。</li></ol><p id="065a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">📌📌欢迎填写<a class="ae ls" href="https://www.surveymonkey.com/r/7CHHWGW" rel="noopener ugc nofollow" target="_blank">这份调查</a>，给出您对用户体验的反馈或您对Apache DolphinScheduler的想法:)</p><p id="4c16" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><a class="ae ls" href="https://www.surveymonkey.com/r/7CHHWGW" rel="noopener ugc nofollow" target="_blank">https://www.surveymonkey.com/r/7CHHWGW</a></p></div></div>    
</body>
</html>