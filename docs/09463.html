<html>
<head>
<title>Line-by-line explanation of Pytorch classification baseline code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch分类基线代码的逐行解释</h1>
<blockquote>原文：<a href="https://medium.com/codex/line-by-line-explanation-of-pytorch-classification-baseline-code-e9f792dd94c?source=collection_archive---------12-----------------------#2022-10-21">https://medium.com/codex/line-by-line-explanation-of-pytorch-classification-baseline-code-e9f792dd94c?source=collection_archive---------12-----------------------#2022-10-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1fdb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您第一次进入神经网络领域时，最常用的两个python包是Keras和Pytorch。在这两者之间，我将逐行讨论Pytorch的基线代码，主要由<a class="ae jd" href="https://www.kaggle.com/code/smsajideen/tps-nov-pytorch-baseline-nn" rel="noopener ugc nofollow" target="_blank"> SM Sajideen </a>编写。所以跟着走。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/bff1c59cd6a5b0d7c847ef6b5708c312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N_vVf3zkHbcQqWJG"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">照片由<a class="ae jd" href="https://unsplash.com/@jjying?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"/>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="6922" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和往常一样，您首先需要导入必要的包。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/b674d7520c0d631232171d26776f8c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*aTzgUasViZxEzlBpzIifAg.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">导入报表</figcaption></figure><p id="9c7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一个import语句块用于构建Pytorch神经网络过程。在解释这些之前，我将假设你知道神经网络训练如何工作的一般过程。如果你不是，检查下面的<a class="ae jd" href="https://youtu.be/bfmFfD2RIcg?t=33" rel="noopener ugc nofollow" target="_blank">视频</a>。</p><p id="e7c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，“进口火炬”使我们能够在这款笔记本上使用Pytorch。除此之外，我还添加了几个常用的子包。简单解释一下，“nn”包含了基本的构建模块，比如层和激活函数。“Dataset”是一个抽象类，需要__len__()和__getitem__()，它用于向“DataLoader”提供输入和输出，后者负责在epochs期间控制批处理大小。“optim”代表优化器。因此，您可以用它来实现各种优化方法。对于评估指标，我将使用ROC AUC分数，它可以从sklearn包中获得。</p><p id="33aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个模块用于进行分层k折叠以减少训练期间的方差，并缩放数据点以为神经网络创建更好的学习环境。这些都是sklearn包里的。</p><p id="941f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后一块是额外的包装。导入tqdm包是为了在训练时显示进度条。其他的就不言自明了。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/f15ddcb97bfd3c66082f564f032959ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*k7-BUYyR7bpDbcFpWbdH3Q.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">tdqm进度条</figcaption></figure><p id="1910" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">安装并导入这些包后，下一步是导入数据。对于这个笔记本，我用的是<a class="ae jd" href="https://www.kaggle.com/competitions/tabular-playground-series-nov-2021/data" rel="noopener ugc nofollow" target="_blank">表格游乐场系列——2021年11月</a>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jv"><img src="../Images/d86b3eb8f9e143c25f1357d4d9ffeb95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ivXWNigErqxukvhLlsmrw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">导入数据集</figcaption></figure><p id="ae5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，有100个数字特征和1个目标列。因为这篇文章不是关于数据科学的整个过程，所以我不会重复EDA的过程。简单提一下，目标列名是‘target ’,它有0和1的均衡分布。</p><p id="46a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们进入任何神经网络的东西之前，我们需要缩放输入。这一点很重要，因为大的输入值可能会导致大的权重，从而导致网络不稳定。在本例中，我使用了sklearn包中的StandardScaler()。它对值进行缩放，使平均值为0，方差为1。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/0fabdc2babb750992a3f064ef9fb2d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*0hNQi0qFUJAhVtZkf9Rt7Q.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">提取x和y并缩放x</figcaption></figure><p id="f3ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">缩放后，x_train不再是熊猫数据帧。所以以后，当我需要用索引访问它的条目时，我应该记住这一点。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/239078dee29914f5f70ee276213ecc61.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*dXNisi-F2_3bOFt36Zslrg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">拆分和缩放后其数据类型如何变化</figcaption></figure><p id="03a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Pytorch时，您需要的第一个代码是包含您的数据集的CustomDataset。这个CustomDataset类通常继承Pytorch包中名为Dataset的抽象类，它的两个要求是拥有__len__()和__getitem__()。</p><p id="7f85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“if self.y is None”的原因是为了在我们处理没有目标值的测试集时避免错误。而且因为Pytorch接受的是张量数据类型而不是numpy数组，所以我们在用__getitem__()返回值的时候需要把X和y转换成张量。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jx"><img src="../Images/1f9fe80f4282fa4455f645df3cce83b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KN_GJ-j-Faxcg46P7nbn6g.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">自定义数据集的代码</figcaption></figure><p id="76ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">稍后，这个CustomDataset将通过batch_size参数提供给DataLoader，因为如上所述，DataLoader负责在epochs期间控制批处理大小。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jy"><img src="../Images/adbed2346ca66d60162f9ebf25bfdbb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nR05yd5CMl8Rw_Uox9sroQ.png"/></div></div></figure><p id="95cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是建立神经网络模型。但在进入实际模型之前，我创建了返回线性()、路斯()和Dropout()的顺序层的块函数。</p><p id="d366" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性层用作密集层或完全连接层。它采用的两个参数是输入要素和输出要素大小。不像Keras应用程序，如果你熟悉它，它的激活函数，路斯()在这种情况下，位于线性层之外。然后，为了避免过度拟合，我添加了Dropout层，它有0.2的概率使输入张量中的每个元素为零。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jz"><img src="../Images/ada393dea2dfb9a04f8d84e09274fe73.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*qUXgu9ojg2FYF88NVcbiaQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">神经网络的代码</figcaption></figure><p id="9d08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦块函数准备好了，我需要构建我的分类器类。第一步是创建nn.Module的子类，然后，它应该覆盖__init__()和forward()。在__init__()内部，首先要做的是调用super()来使用在父类中完成的初始化。之后，我应该定义我将在神经网络中使用的层。在forward函数中，我使用上面定义的层来构建神经网络如何从起点流向终点。</p><p id="019a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">__init__()和forward()的具体结构取决于问题以及您希望如何实现神经网络。简单解释一下，它调用block函数两次，从100 (num_features)到32个节点。然后，它创建遵循二元分类的一般结构的输出层:1个具有sigmoid激活函数的节点。</p><p id="4c0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为一个旁注，你不需要实现backward()进行反向传播，除非你想计算的不是由<a class="ae jd" href="https://pytorch.org/docs/stable/autograd.html?highlight=autograd#module-torch.autograd" rel="noopener ugc nofollow" target="_blank">亲笔签名的</a>计算的真实梯度，或者使用不由亲笔签名处理的forward()。这是由<a class="ae jd" href="https://discuss.pytorch.org/t/when-to-implement-backward/98067" rel="noopener ugc nofollow" target="_blank">阿尔巴德</a>回答的Pytorch讨论。</p><p id="99c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是明确使用哪种设备，并建立一个培训功能。</p><p id="bd8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一般有两种选择。“cpu”或“cuda”。在这里，“cuda”是一个计算的统一设备架构，允许代码使用Nvidia GPU进行计算。但是如果你和我一样用的是苹果处理器，你需要传入“mps”而不是“cuda”来使用GPU。然而，截至目前，完全使用“mps”仍是一个持续的过程。因此，您需要设置环境变量“<a class="ae jd" href="https://stackoverflow.com/questions/72416726/how-to-move-pytorch-model-to-gpu-on-apple-m1-chips" rel="noopener ugc nofollow" target="_blank">py torch _ ENABLE _ MPS _ FALLBACK = 1</a>”，以便在“MPS”不起作用时使用CPU。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ka"><img src="../Images/f0946e7476022de14213d668fb56b092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SsKeUkZNKSDRMkh5vrDMUQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">培训功能的第一部分</figcaption></figure><p id="ab3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练函数中，train _ losses、train_roc_scores、val _ losses和val_roc_scores是包含长度为零的历元的numpy数组。当我们遍历各个时期时，我将用适当的值替换0来记录训练历史。下一行中的early_stopping用于计算val_loss没有改善的时期，以确定何时停止训练。</p><p id="cf8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，作为开始，我们应该通过设置model.train()将模型设置为训练模式。这一点很重要，因为当它不是的时候，它可能不会更新模型的权重。下一行是两个列表，收集一个时期内每批的列车损失和roc，正如您在上面图像的最后一部分所看到的。请注意，item()用于从0维张量中提取一个数字，cpu()用于在将张量转换为numpy数组以传入roc_auc_score()之前复制张量。</p><p id="ac47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个for循环遍历train_dl给出的批次。如您所见，它给出了批量大小的输入和目标。因为我们将批量大小设置为512，所以第二个for循环每次将加载512个样本。然后，由于使用GPU比使用CPU快得多，所以我通过调用“inputs.to(device)”和“targets.to(device)”将输入和输出传递给我们上面设置的设备。</p><p id="6cd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我应该显式调用“optimizer.zero_grad()”以在每批中执行任何计算之前将梯度设置为0。这一点很重要，因为如果没有“optimizer.zero_grad()”，它将从所有以前的批次中累积梯度，即使它们已经得到反映。因此，学习不会如你所愿。</p><p id="eb91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，我给模型输入数据以产生预测(输出)。但是预测值和真实值(目标值)之间的形状不匹配。因此，我对目标应用了“unsqueeze(1)”。然后，我将预测值和真实值传递给网络将使用的损失函数标准。这是我调用训练函数时给出的一个参数。</p><p id="9943" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后通过调用loss.backward()和optimizer.step()，分别计算和更新渐变值。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kb"><img src="../Images/7f2714fc6fd261e1a5a4f69e0962ebb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-KkXRgsNjWu4ItPOFCQh1A.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">培训功能的第二部分</figcaption></figure><p id="3546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，上面的代码仍然在训练函数的第一个for循环中。在神经网络检查了整个训练集之后，是时候检查模型在验证集上的表现了。在这个过程中，最关键的代码是“with torch.no_grad()”和“model.eval()”，因为这两个代码会阻止神经网络使用验证集更新其权重。</p><p id="54dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，整个过程类似于训练过程，除了缺少一些代码，因为它不打算更新权重。它们是optimizer.zero_grad()、loss.backward()和optimizer.step()。</p><p id="1c6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在检查了整个验证数据之后，它存储了我上面提到的每个时期的训练和验证损失以及ROC AUC分数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kc"><img src="../Images/6c34f58685d9028ff5474937546e3988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZYClm2edCKrWreLQFIQQw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">第三部分培训功能</figcaption></figure><p id="abc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管如此，我们仍然在第一个for循环中。最后一步是检查训练进行得如何，并做出一些决定。第一行根据val_loss的值移动到lr_scheduler的下一步。因此，例如，如果val_loss在过去5个时期没有改善或减少，则改变学习速率以查看是否有任何变化。</p><p id="d6d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个模块检查val_loss与val_best_score相比是否有所改善。如果是，它将val_best_score更新为当前val_loss。如果不是，它将early_stopping递增1，这样当它变成6时，它将停止训练。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/e6cff57f01dbe3398bdf97fdd54affe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*yH5PV14AoNao6PK9cWEZ9A.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">测试功能</figcaption></figure><p id="a6e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我需要的下一个函数是一个测试函数。与训练函数中的验证过程一样，它需要“torch.no_grad()”和“model.eval()”来防止模型改变其渐变。</p><p id="ce8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，这个过程与验证过程非常相似。不同之处在于，它不是计算loss和roc，而是返回输出，即属于类1的概率。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kd"><img src="../Images/a00e33dd4ed9dc1f122f571a589352c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kOtrBsuJTi69N_LzHP2fTQ.png"/></div></div></figure><p id="778a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，它准备好训练神经网络。因为简单地训练一次可能会导致很高的方差，所以我使用了具有5个分割的StratifiedKFold。这意味着我将把训练集分成5个折叠，并用不同的折叠组合训练模型5次。</p><p id="a299" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在for循环中，我首先调用上面创建的分类器类，并将其传递给使用GPU的设备。然后，使用skf.split()提供的索引，我将训练数据分成训练和验证集，并将其放入DataLoader。</p><p id="c240" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于优化器，您可以尝试Pytorch提供的不同优化器函数。完整列表可在<a class="ae jd" href="https://pytorch.org/docs/stable/optim.html#algorithms" rel="noopener ugc nofollow" target="_blank">这里</a>找到。其中，我为这个笔记本实现了Adam。它需要一个名为params的强制参数。因此，我在模型上调用parameters()来传递所需的参数。然后，根据您的选择，您可以修改一些默认值。在我的例子中，我将学习率设置为0.001。</p><p id="9547" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于标准，这取决于你试图解决什么类型的问题。在我的情况下，这是二进制分类，二进制交叉熵损失工作得很好。可用损失函数的完整列表在这个<a class="ae jd" href="https://pytorch.org/docs/stable/nn.html#loss-functions" rel="noopener ugc nofollow" target="_blank">链接</a>中。</p><p id="6efd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于<a class="ae jd" href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="noopener ugc nofollow" target="_blank">学习率调度器</a>，我使用了ReduceLROnPlateau。这意味着当模型停止改进时，降低学习率以微调模型。简单解释一下参数是什么，“factor”是满足条件时减少多少，“patience”是减少学习率之前要等待多少个历元，“min_lr”是学习率的一个下界。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ke"><img src="../Images/72d37b592efa87b5c5e0e2acc4e17ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*7XVU-h_HMBpdVKR_H3vMjQ.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">来自<a class="ae jd" href="https://www.meme-arsenal.com/en/create/meme/2495515" rel="noopener ugc nofollow" target="_blank"> meme军火库</a></figcaption></figure><p id="e510" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我准备运行我在上面创建的训练函数。训练完成后，我加载了训练期间获得的最佳权重，并用测试函数进行了预测。然后，根据您想要的输出，您可以定制您所做的预测。例如，在我的例子中，我需要属于类别1的观察值的概率。所以我把它附加到了test_probabilities列表中。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/82d0f79a4db4399b73d380fd43b35e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*VcxTujM8khj4WsL6sB3KZQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">概率预测是如何与神经网络一起进行的</figcaption></figure><p id="b0df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我取5次折叠的平均值作为我的最终预测。我在这里没有包括它，但是查看folds_train_losses和fold_val_losses来确认训练是否顺利是一个很好的做法。</p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><h1 id="4b14" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">参考</h1><p id="6ebf" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated">[1]<a class="ae jd" href="https://www.kaggle.com/code/smsajideen/tps-nov-pytorch-baseline-nn" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/code/smsajideen/TPS-nov-py torch-baseline-nn</a></p><p id="2f17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]<a class="ae jd" href="https://www.youtube.com/watch?v=bfmFfD2RIcg&amp;t=33s" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=bfmFfD2RIcg&amp;t = 33s</a></p><p id="8212" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[3]<a class="ae jd" href="https://www.kaggle.com/competitions/tabular-playground-series-nov-2021/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/competitions/tabular-playground-series-nov-2021/data</a></p><p id="c316" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[4]<a class="ae jd" href="https://discuss.pytorch.org/t/when-to-implement-backward/98067" rel="noopener ugc nofollow" target="_blank">https://discuse . py torch . org/t/when-to-implement-backward/98067</a></p><p id="a694" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[5]<a class="ae jd" href="https://stackoverflow.com/questions/72416726/how-to-move-pytorch-model-to-gpu-on-apple-m1-chips" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/72416726/how-to-move-py torch-model-to-GPU-on-apple-m1-chips</a></p><p id="7955" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[6]https://pytorch.org/docs/stable/optim.html#algorithms<a class="ae jd" href="https://pytorch.org/docs/stable/optim.html#algorithms" rel="noopener ugc nofollow" target="_blank"/></p><p id="0a29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[7]<a class="ae jd" href="https://pytorch.org/docs/stable/nn.html#loss-functions" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/nn.html#loss-functions</a></p><p id="1ec7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[8]<a class="ae jd" href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="noopener ugc nofollow" target="_blank">https://py torch . org/docs/stable/optim . html # how-to-adjust-learning-rate</a></p></div></div>    
</body>
</html>