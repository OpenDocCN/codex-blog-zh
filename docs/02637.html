<html>
<head>
<title>Scale Up Your Scrapy Projects With Smart Proxy Manager</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用智能代理管理器扩展您的零碎项目</h1>
<blockquote>原文：<a href="https://medium.com/codex/scale-up-your-scrapy-projects-with-smart-proxy-manager-742db37a04c3?source=collection_archive---------17-----------------------#2021-07-29">https://medium.com/codex/scale-up-your-scrapy-projects-with-smart-proxy-manager-742db37a04c3?source=collection_archive---------17-----------------------#2021-07-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2043a03110b9f772222b6c00ab92fd41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KULjbk4EpF_2pg4U.png"/></div></div></figure><p id="fc81" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本教程中，你将学习如何扩大你已经存在的Scrapy项目，以便提出更多的请求和提取更多的网络数据。</p><p id="4742" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Scrapy是一个非常流行的网页抓取框架，如果你是一个网页数据提取开发者，它会让你的生活变得更加容易。Scrapy可以处理许多网络抓取工作，包括URL发现、解析、数据清理、自定义数据管道等……但有一件事Scrapy不能开箱即用，如果你想可靠地提取大量数据，它已经成为一个必须的:代理管理。</p><p id="2862" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了扩大你的Scrapy项目，你需要一个代理解决方案。</p><p id="f7f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我会告诉你如何把你已经存在的Scrapy蜘蛛，并推动它与代理人！</p><h1 id="8fb3" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">入门指南</h1><p id="9e48" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在这个例子中，我将使用包含两个功能的产品提取蜘蛛的“Scrapy版本”:</p><ol class=""><li id="f786" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated">寻找产品网址的爬虫</li><li id="646e" class="ks kt hi is b it lb ix lc jb ld jf le jj lf jn kx ky kz la bi translated">一个真正提取数据的刮刀</li></ol><p id="602b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是Scrapy蜘蛛代码:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="15fd" class="lp jq hi ll b fi lq lr l ls lt">class ProductSpider(CrawlSpider): <br/>name = 'product' <br/>start_urls = ['http://books.toscrape.com/catalogue/category/books/travel_2/index.html'] </span><span id="9970" class="lp jq hi ll b fi lu lr l ls lt">rules = ( Rule(LinkExtractor(restrict_css='article.product_pod &gt; h3 &gt; a'), <br/>callback='populate_item'), <br/>) </span><span id="9241" class="lp jq hi ll b fi lu lr l ls lt">def populate_item(self, response): <br/>item = ProductItem() <br/>book_title = response.css('div.product_main &gt; h1::text').get() price_text = response.css('p.price_color::text').get() <br/>stock_info = response.css('p.availability').get() <br/>item = { <br/>'title': book_title, <br/>'price': self.clean_price(price_text), <br/>'stock': self.clean_stock(stock_info) <br/>} <br/>yield item </span><span id="ff6d" class="lp jq hi ll b fi lu lr l ls lt">def clean_price(self, price_text): <br/>return Price.fromstring(price_text).amount_float </span><span id="cd93" class="lp jq hi ll b fi lu lr l ls lt">def clean_stock(self, stock_info): <br/>return remove_tags(stock_info).strip()</span></pre><p id="d751" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，让我们假设这是你目前拥有的蜘蛛，它工作得很好…为你提供宝贵的数据…一段时间。然后，您希望扩大规模并提出更多请求，最终导致阻塞、低成功率、差的数据质量等…</p><p id="2b64" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">克服障碍和接收高质量web数据的解决方案是代理以及如何使用这些代理。让我们看看如何在这个蜘蛛中集成智能代理管理器！</p><h1 id="89d4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">Scrapy +智能代理管理器(以前的Crawlera)</h1><p id="32e7" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">推荐的集成方式是<a class="ae jo" href="https://github.com/scrapy-plugins/scrapy-zyte-smartproxy" rel="noopener ugc nofollow" target="_blank">官方中间件</a>。您可以这样安装它:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="ade0" class="lp jq hi ll b fi lq lr l ls lt">pip install scrapy-crawlera</span></pre><p id="0678" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，将这些设置添加到您的剪贴簿项目文件中:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="dc30" class="lp jq hi ll b fi lq lr l ls lt">DOWNLOADER_MIDDLEWARES = {'scrapy_crawlera.CrawleraMiddleware': 610} CRAWLERA_ENABLED = True CRAWLERA_APIKEY = '&lt;API key&gt;'</span></pre><p id="de78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请注意，为了使用智能代理管理器，您需要一个API密钥。但是不要担心，我们提供了一个<a class="ae jo" href="https://www.zyte.com/smart-proxy-manager/?utm_campaign=SPMEU&amp;utm_activity=BLO&amp;utm_medium=ORG&amp;utm_content=ScaleScrapySPMblog&amp;utm_primary=SPM&amp;utm_goal=SIN" rel="noopener ugc nofollow" target="_blank"> 14天的免费试用</a>(马克斯·10K在试用期间请求)，所以你可以快速获得你的API密钥，并试用它以确保它为你工作。</p><p id="5e1f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者，如果您请求智能代理管理器的自定义实例，也可以设置代理URL:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="5c11" class="lp jq hi ll b fi lq lr l ls lt">CRAWLERA_URL = 'myinstance.zyte.com:8011' </span><span id="b7da" class="lp jq hi ll b fi lu lr l ls lt">Another way to set up Smart Proxy Manager is directly in the spider, like this: </span><span id="00fc" class="lp jq hi ll b fi lu lr l ls lt">class ProductSpider(CrawlSpider): <br/>crawlera_enabled = True <br/>crawlera_apikey = 'apikey'</span></pre><h1 id="ef65" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">设置建议</h1><p id="b918" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了在使用智能代理管理器时获得更高的爬网率，我们建议禁用自动节流插件并增加最大并发请求数。您可能还想增加下载超时时间。以下是实现该目的的设置列表:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="050e" class="lp jq hi ll b fi lq lr l ls lt">CONCURRENT_REQUESTS = 32 <br/>CONCURRENT_REQUESTS_PER_DOMAIN = 32 <br/>AUTOTHROTTLE_ENABLED = False <br/>DOWNLOAD_TIMEOUT = 600</span></pre><h1 id="372c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">注册智能代理管理器帐户</h1><p id="2002" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">这个简单的集成处理了你用代理扩展你的Scrapy项目所需要的一切。</p><p id="6391" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您厌倦了阻塞或管理不同的代理提供者，请尝试智能代理管理器(以前的Crawlera)。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="3bde" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mc">最初发表于</em><a class="ae jo" href="https://www.zyte.com/blog/scale-up-your-scrapy-projects-with-zyte-smart-proxy-manager-formerly-crawlera/" rel="noopener ugc nofollow" target="_blank">T5【https://www.zyte.com】</a><em class="mc">。</em></p></div></div>    
</body>
</html>