<html>
<head>
<title>Deploy and Serve AI Models (Part 2 — TensorFlow Serving)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">部署和服务人工智能模型(第2部分— TensorFlow服务)</h1>
<blockquote>原文：<a href="https://medium.com/codex/deploy-and-serve-ai-models-part2-tensorflow-serving-f144c4cf5ea7?source=collection_archive---------12-----------------------#2021-07-30">https://medium.com/codex/deploy-and-serve-ai-models-part2-tensorflow-serving-f144c4cf5ea7?source=collection_archive---------12-----------------------#2021-07-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a30fff195c4a061a3d7fe726146f7b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*50sGQftZ4MwUcWvX"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">约书亚·索蒂诺在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="4f44" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是我关于在生产场景中部署AI模型的系列文章的继续(<a class="ae iu" rel="noopener" href="/codex/deploy-and-server-ai-models-part-1-bf309dc41f4b">第一部分</a>)。TensorFlow服务允许开发人员独立于客户端系统配置，将ML模型预测、检测或分类集成到云或本地服务器中。因此应用程序用户不需要担心运行DNN模型所需的大量计算能力。AI应用程序客户端可以在不实际安装TensorFlow甚至不与实际模型有任何联系的情况下对数据进行推断，以及用一个模型实例服务多个客户端的能力。</p><p id="43ac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">如何设置张量流服务</strong></p><p id="237f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，你需要一个模型来为推论服务。我已经用一个TensorFlow模型实现了<a class="ae iu" href="https://github.com/blaueck/tf-mtcnn" rel="noopener ugc nofollow" target="_blank"> MTCNN </a>人脸检测器。在设置服务环境之前，需要将模型从冻结格式转换为SavedModel格式，以便与<a class="ae iu" href="https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple" rel="noopener ugc nofollow" target="_blank"> TensorFlow服务</a>一起使用。</p><p id="9d10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">使用的环境</em></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="b1c3" class="kd ke hi jz b fi kf kg l kh ki">Tensorflow 2.3.1<br/>tensorflow-serving-api 2.3.0</span></pre><p id="3f22" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">冻结MTCNN的Python代码，以保存模型转换</em></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="a282" class="kd ke hi jz b fi kf kg l kh ki">from os.path import join<br/>import tensorflow.compat.v1 as tf</span><span id="7c7c" class="kd ke hi jz b fi kj kg l kh ki">tf.disable_v2_behavior()<br/>tf.compat.v1.disable_eager_execution()<br/>from tensorflow.python.saved_model import signature_constants</span><span id="777a" class="kd ke hi jz b fi kj kg l kh ki">def read_pb_model(pb_model_path):<br/>    with tf.gfile.GFile(pb_model_path, "rb") as f:<br/>        graph_def = tf.GraphDef()<br/>        graph_def.ParseFromString(f.read())<br/>        return graph_def</span><span id="4c27" class="kd ke hi jz b fi kj kg l kh ki">graph_def = read_pb_model(join('models', 'mtcnn.pb'))<br/>builder = tf.saved_model.builder.SavedModelBuilder('./mtcnn/1')</span><span id="41ca" class="kd ke hi jz b fi kj kg l kh ki">sigs = {}<br/>with tf.Session(graph=tf.Graph()) as sess:<br/>    tf.import_graph_def(graph_def, name="")<br/>    graph_model = tf.get_default_graph()<br/>    tf.initialize_all_variables().run()<br/>    input_image_tensor = graph_model.get_tensor_by_name('input:0')<br/>    input_min_size_tensor = graph_model.get_tensor_by_name('min_size:0')<br/>    input_thresholds_tensor = graph_model.get_tensor_by_name('thresholds:0')<br/>    input_factor_tensor = graph_model.get_tensor_by_name('factor:0')</span><span id="c062" class="kd ke hi jz b fi kj kg l kh ki">output_prob_tensor = graph_model.get_tensor_by_name('prob:0')<br/>    output_landmarks_tensor = graph_model.get_tensor_by_name('landmarks:0')<br/>    output_box_tensor = graph_model.get_tensor_by_name('box:0')</span><span id="6534" class="kd ke hi jz b fi kj kg l kh ki">sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \<br/>        tf.saved_model.signature_def_utils.predict_signature_def(<br/>            {'input': input_image_tensor, 'min_size': input_min_size_tensor,<br/>                    'thresholds': input_thresholds_tensor,<br/>                    'factor': input_factor_tensor},<br/>            {'prob': output_prob_tensor, 'landmarks': output_landmarks_tensor,<br/>                     'box': output_box_tensor})<br/>    builder.add_meta_graph_and_variables(<br/>        sess=sess,<br/>        tags=[tf.saved_model.tag_constants.SERVING],<br/>        signature_def_map=sigs)<br/>    builder.save()</span></pre><p id="2b71" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">模型库结构</em></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="f00c" class="kd ke hi jz b fi kf kg l kh ki">mtcnn<br/>  |<br/>  |__ 1<br/>  |     |saved_model.pb<br/>  |     |__variables</span></pre><p id="b1f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">设置张量流服务</em></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="6afb" class="kd ke hi jz b fi kf kg l kh ki">echo "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list</span><span id="ce08" class="kd ke hi jz b fi kj kg l kh ki">curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -</span><span id="5095" class="kd ke hi jz b fi kj kg l kh ki">apt update</span><span id="04ce" class="kd ke hi jz b fi kj kg l kh ki">apt-get install tensorflow-model-server</span></pre><p id="5cb2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">开始TensorFlow发球</em></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="d8b1" class="kd ke hi jz b fi kf kg l kh ki">tensorflow_model_server --rest_api_port=8504 --model_name=mtcnn --model_base_path="/tmp/mtcnn"</span><span id="18e2" class="kd ke hi jz b fi kj kg l kh ki">rest_api_port<!-- -->: The port that you'll use for REST requests</span><span id="2b67" class="kd ke hi jz b fi kj kg l kh ki">model_name<!-- -->: You'll use this in the URL of REST requests. It can be anything.</span><span id="fa76" class="kd ke hi jz b fi kj kg l kh ki">model_base_path<!-- -->: This is the path to the directory where you've saved your model</span></pre><p id="4650" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦Tensorflow服务开始，您就可以检查模型元数据</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="68bd" class="kd ke hi jz b fi kf kg l kh ki">import grpc<br/>from tensorflow_serving.apis import prediction_service_pb2_grpc<br/>from tensorflow_serving.apis import get_model_metadata_pb2</span><span id="debd" class="kd ke hi jz b fi kj kg l kh ki">request = get_model_metadata_pb2.GetModelMetadataRequest()<br/>request.model_spec.name = 'mtcnn'<br/>request.metadata_field.append('signature_def')<br/>channel = grpc.insecure_channel(target='0.0.0.0:8500')<br/>stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)<br/>result = stub.GetModelMetadata(request, 5.0)<br/># Verify response<br/>print(result)</span></pre><p id="0650" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MTCNN元数据的响应，这可以用于准备原始模型推断的输入请求</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="9025" class="kd ke hi jz b fi kf kg l kh ki">model_spec {<br/>  name: "mtcnn"<br/>  version {<br/>    value: 1<br/>  }<br/>}<br/>metadata {<br/>  key: "signature_def"<br/>  value {<br/>    type_url: "type.googleapis.com/tensorflow.serving.SignatureDefMap"<br/>    value: "\n\262\002\n\017serving_default\022\236\002\n$\n\nthresholds\022\026\n\014thresholds:0\020\001\032\004\022\002\010\003\n4\n\005input\022+\n\007input:0\020\001\032\036\022\013\010\377\377\377\377\377\377\377\377\377\001\022\013\010\377\377\377\377\377\377\377\377\377\001\022\002\010\003\n\036\n\010min_size\022\022\n\nmin_size:0\020\001\032\002\030\001\n\032\n\006factor\022\020\n\010factor:0\020\001\032\002\030\001\022\024\n\003box\022\r\n\005box:0\020\001\032\002\030\001\022!\n\004prob\022\031\n\006prob:0\020\001\032\r\022\013\010\377\377\377\377\377\377\377\377\377\001\022/\n\tlandmarks\022\"\n\013landmarks:0\020\001\032\021\022\013\010\377\377\377\377\377\377\377\377\377\001\022\002\010\n\032\032tensorflow/serving/predict"<br/>  }<br/>}</span></pre><h2 id="962a" class="kd ke hi bd kk kl km kn ko kp kq kr ks jg kt ku kv jk kw kx ky jo kz la lb lc bi translated">使用TensorFlow服务运行人脸检测</h2><ul class=""><li id="377b" class="ld le hi ix b iy lf jc lg jg lh jk li jo lj js lk ll lm ln bi translated">开始张量流服务</li><li id="275b" class="ld le hi ix b iy lo jc lp jg lq jk lr jo ls js lk ll lm ln bi translated">创建一个python文件mtcnn_detection.py并导入所有必需的模块</li></ul><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="6499" class="kd ke hi jz b fi kf kg l kh ki">import json<br/><br/>import grpc<br/>import requests<br/>import cv2<br/>import tensorflow as tf<br/>from tensorflow_serving.apis import predict_pb2<br/>from tensorflow_serving.apis import prediction_service_pb2_grpc<br/>from tensorflow_serving.apis import get_model_metadata_pb2</span></pre><ul class=""><li id="50f3" class="ld le hi ix b iy iz jc jd jg lt jk lu jo lv js lk ll lm ln bi translated">从测试文件中读取图像</li></ul><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="d790" class="kd ke hi jz b fi kf kg l kh ki">image = cv2.imread(image_file)</span></pre><ul class=""><li id="70f5" class="ld le hi ix b iy iz jc jd jg lt jk lu jo lv js lk ll lm ln bi translated">为上菜准备输入请求。TensorFlow分别为gRPC和HTTP rest API请求提供公开端口' 8500 '和8504。在此示例中，我们使用gRPC协议从客户端应用程序与TensorFlow服务器进行通信。预期的输入和输出名称将从之前执行的模型元数据中获得。</li></ul><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="9b8a" class="kd ke hi jz b fi kf kg l kh ki">channel = grpc.insecure_channel(target='localhost:8500')<br/>stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)<br/>request = predict_pb2.PredictRequest()<br/>equest.model_spec.name = 'mtcnn'<br/><br/>request.model_spec.signature_name = 'serving_default'</span><span id="1c96" class="kd ke hi jz b fi kj kg l kh ki">input = tf.make_tensor_proto(image, dtype=tf.float32, shape=image.shape)<br/>min_size = tf.make_tensor_proto(40, dtype=tf.float32, shape=())<br/>factor = tf.make_tensor_proto(0.7, dtype=tf.float32, shape=())<br/>thresholds = tf.make_tensor_proto([0.6, 0.7, 0.8], dtype=tf.float32, shape=[3])</span><span id="5387" class="kd ke hi jz b fi kj kg l kh ki">request.inputs['input'].CopyFrom(input)<br/>request.inputs['min_size'].CopyFrom(min_size)<br/>request.inputs['factor'].CopyFrom(factor)<br/>request.inputs['thresholds'].CopyFrom(thresholds)</span></pre><ul class=""><li id="4b1c" class="ld le hi ix b iy iz jc jd jg lt jk lu jo lv js lk ll lm ln bi translated">请求面部检测</li></ul><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="1951" class="kd ke hi jz b fi kf kg l kh ki">result = stub.Predict(request,10.0)</span></pre><ul class=""><li id="dc48" class="ld le hi ix b iy iz jc jd jg lt jk lu jo lv js lk ll lm ln bi translated">将结果转换为数组，并为检测到的人脸绘制边界框</li></ul><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="11fa" class="kd ke hi jz b fi kf kg l kh ki">bbox_data_list = tf.make_ndarray(result.outputs['box'])<br/>for bbox_data in bbox_data_list:<br/>    box = bbox_data.astype('int32')<br/>    img = cv2.rectangle(img, (box[1], box[0]), (box[3], box[2]), (0, 255    , 0), 3)</span></pre><ul class=""><li id="da8a" class="ld le hi ix b iy iz jc jd jg lt jk lu jo lv js lk ll lm ln bi translated">保存图像</li></ul><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="acb0" class="kd ke hi jz b fi kf kg l kh ki">cv2.imwrite('test1.png', image)</span></pre><p id="09d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">结果</em></p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/f7c3fc5af4023c0ebcbf859890b19eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TuljgYn9RVxzQ-xvX89q8g.png"/></div></div></figure><h2 id="83cc" class="kd ke hi bd kk kl km kn ko kp kq kr ks jg kt ku kv jk kw kx ky jo kz la lb lc bi translated">结论</h2><p id="3cac" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">使用TensorFlow进行推理使得将模型投入生产的过程更加容易和快速。它是大规模运行多个模型的理想选择，有助于新模型的部署和<a class="ae iu" href="https://tensorflow.github.io/serving/serving_advanced" rel="noopener ugc nofollow" target="_blank">运行实验</a>，同时保持相同的服务器架构和API。但是，它只支持TensorFlow SavedModel格式，在使用之前需要转换这种格式。</p></div></div>    
</body>
</html>