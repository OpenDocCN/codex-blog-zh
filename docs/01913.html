<html>
<head>
<title>‘Synergistic Image and Feature Adaptation Towards Cross-Modality Domain Adaptation for Medical Image Segmentation’: a summary</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向医学图像分割的跨模态域自适应的协同图像和特征自适应:综述</h1>
<blockquote>原文：<a href="https://medium.com/codex/synergistic-image-and-feature-adaptation-towards-cross-modality-domain-adaptation-for-medical-70867d3d3155?source=collection_archive---------5-----------------------#2021-06-14">https://medium.com/codex/synergistic-image-and-feature-adaptation-towards-cross-modality-domain-adaptation-for-medical-70867d3d3155?source=collection_archive---------5-----------------------#2021-06-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ad3480f1cad058c303bf70207c07e145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*esfr5xf3JHwuNxre"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">艾莉娜·格鲁布尼亚克在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="f27e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">领域自适应是最近深度学习研究中的一个重要课题，其目的是在将神经网络应用于新的测试领域时恢复性能退化。SIFA也称为协同图像和特征适应是一种新的无监督领域适应框架，有效地解决领域转移的问题。</p><h1 id="0c33" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="de2d" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">深度CNN(dcnn)在遇到域转移时面临性能下降的问题，即，试图将学习的模型应用于与训练数据(源域)具有不同分布的测试数据(目标域)。在医学成像领域中，存在几种具有不同物理原理的成像模式，畴变甚至更加严重。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/236453458f27b1e62e4cee11e1030912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfS3VupKYGOd3geXNAXlMQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">以上是在MRI数据上训练的模型性能的图示，同时在CT图像上测试。(图片由陈、程等提供)</figcaption></figure><p id="a72f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">磁畴移动主要在两个方向上处理:</p><ul class=""><li id="9538" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated">图像自适应—通过像素到像素转换对齐域之间的图像外观来实现。以这种方式，在输入级解决了畴变。</li><li id="61fd" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">特征自适应-旨在使用DCNNs提取域不变特征，而不考虑输入域之间的明显差异。这一系列中的大多数方法在对抗性学习场景中辨别源/目标域的特征分布。</li></ul><p id="9a38" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这两种方法也可以在一个统一的框架内同时使用。通过图像变换，源图像朝着目标域的外观进行变换；之后，可以使用特征适应来进一步解决合成目标状图像和真实目标图像之间的剩余间隙。SIFA成功地实现了医学图像。</p><h1 id="fd98" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">方法和框架</h1><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/f814e186d7d6c451743d20c88b32f88c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m-ZEhtzRghFlNfBVcBbOJQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由陈、程等提供。</figcaption></figure><p id="fe27" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上图展示了SIFA提出的模型框架。适应的两个角度被无缝集成到一个统一的模型中，因此，在端到端的培训过程中，这两个方面可以相互受益。</p><ul class=""><li id="6291" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated"><strong class="ix hj">用于外观对齐的图像适应—</strong><strong class="ix hj"/>旨在将源图像向目标图像的外观进行变换，由于域转移，目标图像具有不同的视觉外观。获得的变换图像看起来好像是从目标域绘制的，而具有结构语义的原始内容保持不受影响。为此，使用GAN。生成器(Gt)旨在将源图像转换成类似目标的图像。鉴别器(Dt)与发生器竞争以正确区分假的变换图像和真实的目标图像。因此，在目标域中，Gt和Dt形成一个极大极小双人游戏，并通过对抗学习进行优化。鉴别器试图最大化其目标以区分真实和伪造的图像，而生成器试图最小化该目标以将源图像转换成逼真的类似目标的图像。为了保留变换图像中的原始内容，使用反向生成器来实现循环一致性。</li><li id="8f40" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated"><strong class="ix hj">针对域不变性的特征自适应— </strong>在医学图像的情况下，域偏移严重，图像自适应不足以提高性能。通常，为了使提取的特征域不变，在特征空间中直接使用对抗学习，使得鉴别器不能区分哪个特征来自哪个域。但是特征空间维数高，难以直接对齐。这里，通过使用经由2个紧凑的低维空间的对抗学习来增强域不变性。具体而言，对抗性损失由语义预测空间和生成的图像空间注入。</li></ul><p id="d1dd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里的关键特征是在图像和特征自适应之间共享的特征编码器E。通过图像自适应的观点，利用对抗的和循环的一致性损失来优化e。它还收集从鉴别器向特征适配器反向传播的梯度。所以它适合多任务学习场景。不同的任务带来互补的感应偏差，有助于缓解过拟合问题。</p><p id="ff1e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在每一次训练迭代中，所有模块都按照以下顺序依次更新:Gt → Dt → E → C → U → Ds → Dp。具体来说，</p><ol class=""><li id="279e" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lq lh li lj bi translated">首先更新生成器Gt以获得变换后的类似目标的图像。</li><li id="2ca4" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lq lh li lj bi translated">然后更新鉴别器Dt以区分类似目标的图像和真实的目标图像。</li><li id="c09d" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lq lh li lj bi translated">接下来，更新编码器E，用于从类似目标的图像和真实目标图像中提取特征。</li><li id="aad2" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lq lh li lj bi translated">随后更新分类器C和解码器U，以将提取的特征映射到分割预测并生成类似源的图像。</li><li id="56b4" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lq lh li lj bi translated">最后，更新鉴别器Ds和Dp以对其输入的域进行分类，从而增强特征不变性。</li></ol><h2 id="f7f2" class="lr ju hi bd jv ls lt lu jz lv lw lx kd jg ly lz kh jk ma mb kl jo mc md kp me bi translated">模块的网络配置</h2><p id="684b" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated"><strong class="ix hj">目标发生器Gt </strong>是一个<em class="mf">周期杆</em>。它具有:</p><ul class=""><li id="d6a2" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated">3个Conv层</li><li id="a55a" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">9个剩余块</li><li id="82be" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">2个去卷积层</li><li id="47ec" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">一个最终的Conv层来获得生成的图像</li></ul><p id="6a52" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">源解码器U </strong>有:</p><ul class=""><li id="3688" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated">1 Conv层</li><li id="e29d" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">4个剩余块</li><li id="06b3" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">3个去卷积层</li><li id="3392" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">1个Conv输出层</li></ul><p id="375f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有3个<strong class="ix hj">鉴别器(Dt、Ds、Dp) </strong>遵循<em class="mf"> PatchGAN的配置。</em>网络有:</p><ul class=""><li id="7935" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated">5个Conv层(内核大小为4x4，跨距为2；最后2层使用1)的步幅</li><li id="09bb" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">每层的特征图数量分别为{64，128，256，512，1}。在前四层，每个卷积层之后是实例归一化和用0.2参数化的泄漏ReLU。</li></ul><p id="e0a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">编码器E </strong>使用剩余连接和扩张卷积(扩张率= 2)来扩大感受野的大小，同时保持密集预测的空间分辨率。设{Ck，Rk，Dk}分别表示具有k个信道的卷积层、残差块和扩展残差块。M代表跨度为2的最大池层。</p><ul class=""><li id="e281" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated">编码器模块由{C16，R16，M，R32，M，2×R64，M，2× R128，4×R256，2×R512，2×D512，2×C512}层层叠加而成。</li><li id="8aae" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">每个卷积操作都连接到一个批处理规范化层和ReLU激活。</li></ul><p id="43a4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">分类器C </strong>是一个1×1卷积层，后面是一个上采样层，用于将分割预测的分辨率恢复到原始图像大小。</p><h1 id="3eb3" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">数据集和评估指标</h1><p id="fee1" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">本文在<em class="mf">多模态全心脏分割挑战赛2017数据集</em>上验证了提出的无监督域自适应方法，用于MR和CT图像中的心脏分割(庄和沈2016)。数据集由在不同临床位置收集的不成对的20个MR和20个CT体积组成。</p><p id="9967" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">提供了心脏结构的地面真实遮罩，包括:</p><ul class=""><li id="7814" class="lb lc hi ix b iy iz jc jd jg ld jk le jo lf js lg lh li lj bi translated">升主动脉(AA)，</li><li id="bc96" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">左心房血腔(LAC)，</li><li id="fe19" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">左心室血腔(LVC ),以及</li><li id="e3e2" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lg lh li lj bi translated">左心室的心肌(MYO)</li></ul><p id="b154" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">源域—磁共振图像</p><p id="ddee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">目标域— CT图像</p><p id="b7f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每种形式都是随机的，80%的训练和20%的测试用例。CT的地面实况仅在评估期间使用。</p><h2 id="1337" class="lr ju hi bd jv ls lt lu jz lv lw lx kd jg ly lz kh jk ma mb kl jo mc md kp me bi translated">预处理</h2><ol class=""><li id="4d99" class="lb lc hi ix b iy kr jc ks jg mg jk mh jo mi js lq lh li lj bi translated">所有数据被标准化为0平均值和1方差。</li><li id="77ff" class="lb lc hi ix b iy lk jc ll jg lm jk ln jo lo js lq lh li lj bi translated">用尺寸调整到256×256的冠状视图图像进行训练)并用旋转、缩放和仿射变换进行增强。</li></ol><h2 id="837d" class="lr ju hi bd jv ls lt lu jz lv lw lx kd jg ly lz kh jk ma mb kl jo mc md kp me bi translated">使用的指标</h2><ol class=""><li id="9d69" class="lb lc hi ix b iy kr jc ks jg mg jk mh jo mi js lq lh li lj bi translated"><strong class="ix hj"> Dice系数[%]: </strong>是两个遮罩之间重叠的度量。1表示完全重叠，而0表示没有重叠。</li></ol><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/8b225af79685dbecd78388079cf69ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tOuuQBJFL16zR9JEsW94Lw.png"/></div></div></figure><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="3d93" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。平均表面距离(ASD)[体素]: </strong>平均表面距离是从机器分割区域的边界上的点到地面真值的边界的所有距离的平均值，反之亦然。</p><h2 id="3fc4" class="lr ju hi bd jv ls lt lu jz lv lw lx kd jg ly lz kh jk ma mb kl jo mc md kp me bi translated">密码</h2><p id="a1ca" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">在https://github.com/cchen-cc/SIFA可以找到SIFA纸代码。</p><h1 id="6424" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结果</h1><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/ca12159441d43e65a92030d43e3d8009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zHnUleaz3V0utGSt5ndQwA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">提议的SIFA和其他先进模型之间的比较。(图片由陈、程等提供)</figcaption></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/b6404919a0e00ccb5082b3976a184478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ErZR5berizuP73wKtgL8Ow.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">SIFA和其他最先进的无监督域自适应方法在心脏跨通道分割任务中的性能比较。报告了每个心脏结构的Dice和ASD值以及四个结构的平均值。(注:—表示该方法未报告结果，N/A表示无法计算ASD值，因为没有对该心脏结构的预测。)图片由陈、程等提供。</figcaption></figure><h1 id="3a99" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考</h1><p id="0bba" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">陈，程，等。协同图像和特征适应:走向跨模态域适应医学图像分割。<em class="mf">AAAI人工智能会议论文集</em>。第33卷。№01.2019.</p></div></div>    
</body>
</html>