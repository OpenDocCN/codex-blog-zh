# ä½¿ç”¨ç¥ç»ç½‘ç»œçš„æ•°å­—åˆ†ç±»å™¨

> åŸæ–‡ï¼š<https://medium.com/codex/digit-classifier-using-neural-networks-ad17749a8f00?source=collection_archive---------7----------------------->

![](img/a7937e08cb149fe30ac3ca5157c42feb.png)

æ¥æº:https://www.behance.net/gallery/81929059/Neural-Network

å˜¿ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ç”¨ Python æ„å»ºä¸€ä¸ªåˆå­¦è€…å‹å¥½çš„ç¥ç»ç½‘ç»œæ¡†æ¶ã€‚è¿™æ®µä»£ç çš„ä¸»è¦ç›®çš„æ˜¯å¸®åŠ©æ–°æ‰‹å­¦ä¹ ç¥ç»ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¯†åˆ«æ‰‹å†™æ•°å­—ã€‚ç¥ç»ç½‘ç»œå°†èƒ½å¤Ÿè¡¨ç¤ºå½¢æˆéçº¿æ€§å‡è®¾çš„å¤æ‚æ¨¡å‹ã€‚å¦‚æœè¿™å¯¹ä½ æ²¡æœ‰æ„ä¹‰ï¼Œä¸è¦æ‹…å¿ƒï¼Œè¿™ç¯‡æ–‡ç« ä¼šå¸®åŠ©ä½ ç†è§£ã€‚å¦‚æœä½ å¯¹ç¥ç»ç½‘ç»œä¸ç†Ÿæ‚‰ï¼Œè¯·é˜…è¯»æˆ‘ä¹‹å‰çš„å¸–å­ï¼Œäº†è§£ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ€æƒ³ã€‚( [***ç‚¹å‡»è¿™é‡Œ***](/codex/what-are-neural-networks-3a0965e2ebfb) å¯¼èˆªåˆ°æˆ‘ä¹‹å‰çš„å¸–å­ã€‚)

## æ¨¡å‹è¡¨ç¤º

![](img/820027d66b5df175a37d8cc184c5492e.png)

æ¥æº:ä½œè€…

æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚å®ƒæœ‰ 3 å±‚â†’è¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚ã€‚ç”±äºæˆ‘ä»¬æ­£åœ¨å¤„ç†å›¾ç‰‡ï¼Œæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ— æ³•æ¥å—å›¾åƒä½œä¸ºè¾“å…¥ï¼›ç›¸åï¼Œæˆ‘ä»¬å¿…é¡»æä¾›æ¥è‡ªå›¾åƒçš„åƒç´ ä½œä¸ºè¾“å…¥(**æ³¨æ„:**å›¾åƒæ˜¯ç”±åƒç´ ç»„æˆçš„)ã€‚ä¸ºäº†ç¡®ä¿æ‰€æœ‰å›¾ç‰‡çš„å¤§å°ç›¸åŒï¼Œæˆ‘ä»¬å°†æŠŠå®ƒä»¬ç¼©æ”¾åˆ° 20x20 åƒç´ ã€‚é€šè¿‡å°†å®ƒä»¬å±•å¼€æˆ 1D é˜µåˆ—ï¼Œå®ƒç»™äº†æˆ‘ä»¬ 400D å‘é‡ï¼Œè¯¥å‘é‡å°†ä½œä¸ºæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œçš„è¾“å…¥å±‚å•å…ƒ(ä¸åŒ…æ‹¬æ€»æ˜¯è¾“å‡º+1 çš„é¢å¤–åç½®å•å…ƒ)ã€‚

è®©æˆ‘ä»¬å¯¼å…¥æ‰€éœ€çš„æ¨¡å—å¹¶åŠ è½½æ•°æ®é›†ï¼Œ

```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.io import loadmat
import matplotlib.image as img
```

```
mat = loadmat('ex4data1.mat')
X = mat['X']
y = mat['y']
X.shape, y.shape
```

![](img/16d4943a8c3e650fe9c4a59a8e019802.png)

x å½¢ï¼Œy å½¢

è®©æˆ‘ä»¬é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æ¥å¯è§†åŒ–æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œ

```
fig, axis = plt.subplots(10, 10, figsize=(8, 8))
for i in range(10):
    for j in range(10):
        axis[i, j].imshow(
            X[np.random.randint(0, 5001), :].reshape(20, 20, order='F'), cmap='gray')
        axis[i, j].axis('off')
```

![](img/0f8692aadf064f32bc8b2b2e905986ea.png)

æ¥è‡ªæ•°æ®é›†çš„ç¤ºä¾‹

## ä¹™çŠ¶ç»“è‚ çš„

æˆ‘ä»¬åœ¨ä¹‹å‰çš„å¸–å­ä¸­å·²ç»å¯¹æ­¤è¿›è¡Œäº†æ›´å¤šçš„è®¨è®ºã€‚æ‰€ä»¥ï¼Œæˆ‘å°±ä¸è§£é‡Šäº†ã€‚åŸºæœ¬ä¸Šï¼Œsigmoid æ˜¯ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªå®å€¼è¾“å…¥ï¼Œå¹¶å°†å…¶å‹ç¼©åˆ° 0 åˆ° 1 ä¹‹é—´ã€‚

```
def sigmoid(z):
    return 1/(1+np.exp(-z))
```

## æ­£å‘ä¼ æ’­å’Œæˆæœ¬å‡½æ•°

![](img/c6e6c6eb7a1f3e5deaf5284699897596.png)

æ¥æº:[æ¥è‡ª Researchgate çš„å®‰ä¸œå°¼å¥¥Â·æ‹‰æ–å°”Â·è¨æ¯”åŠªÂ·å¸•æ¢…èµ](https://www.researchgate.net/profile/Antonio-Parmezan)

ä¸Šå›¾æ˜¯ç¥ç»ç½‘ç»œä¸­ä¸€å±‚çš„å‰å‘ä¼ æ’­ã€‚æ­£å‘ä¼ æ’­çš„å…¬å¼å¦‚ä¸‹:

![](img/5bb6ada815a3d199cd0f71434fa9677c.png)

ä¸‰å±‚ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­

æˆ‘ä»¬å°† x(è¾“å…¥)è®¾ä¸º aï¼Œç„¶åå°† a ä¹˜ä»¥Î¸(å³ä¸Šå›¾ä¸­æ‰€ç¤ºçš„æƒé‡ w)å¹¶æ·»åŠ åå·®(å³ b æˆ–Î¸â‚€),æœ€åæˆ‘ä»¬å°† a å’ŒÎ¸çš„ç‚¹ç§¯å‘é€åˆ°æ¿€æ´»å‡½æ•°(åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ä¸º sigmoid å‡½æ•°)ã€‚å¯¹è¾“å…¥å±‚ä¸­çš„æ‰€æœ‰ 400 ä¸ªå€¼å’Œéšè—å±‚ä¸­çš„æ‰€æœ‰å€¼é‡å¤è¿™ä¸€è¿‡ç¨‹ã€‚ä¸ºäº†æ‰¾åˆ°å¥½çš„å‚æ•°ï¼Œä½¿ç”¨ä¸‹é¢çš„æˆæœ¬å‡½æ•°:

![](img/7e1d866bdffe7885341bf68ab7580d53.png)

ä»·å€¼å‡½æ•°

è¿™é‡Œï¼Œæˆæœ¬å‡½æ•°çœ‹èµ·æ¥ç±»ä¼¼äºé€»è¾‘å›å½’çš„æˆæœ¬å‡½æ•°ï¼Œä½†å…·æœ‰é¢å¤–çš„æ­£åˆ™åŒ–é¡¹ï¼Œè¿™æœ‰åŠ©äºæé«˜æˆ‘ä»¬ç®—æ³•çš„å‡†ç¡®æ€§ã€‚è¿™ä¸ªæˆæœ¬å‡½æ•°å¸®åŠ©æˆ‘ä»¬å­¦ä¹ å¥½çš„å‚æ•°ã€‚

## åå‘ä¼ æ’­

åå‘ä¼ æ’­æ˜¯ç”¨äºæ”¹å˜*æƒé‡*å’Œ*åå·®*çš„æŠ€æœ¯ï¼Œä»¥ä¾¿ç¥ç»ç½‘ç»œçš„è¾“å‡ºå˜å¾—æ›´åŠ å‡†ç¡®ã€‚åœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œæˆ‘ä»¬ä»å·¦å‘å³ç§»åŠ¨ï¼Œä½†åœ¨åå‘ä¼ æ’­ä¸­ï¼Œæˆ‘ä»¬ä»å³å‘å·¦ç§»åŠ¨ã€‚è®©æˆ‘ä»¬è€ƒè™‘ç®€å•çš„ç¥ç»ç½‘ç»œ:

![](img/faa2f2db901b59e47b1e85f8120a2fa4.png)

æ¥æº:ä½œè€…

åå‘ä¼ æ’­å°±æ˜¯å¯¹æ­£å‘å‡½æ•°ä»å³æ±‚å¯¼ã€‚å¦‚æœä¸‹é¢çš„æ¨å¯¼å¯¹ä½ æ¥è¯´æ²¡æœ‰æ„ä¹‰ï¼Œä¸è¦æ‹…å¿ƒï¼Œå®ƒè‚¯å®šæ˜¯å¥½çš„ï¼Œä¸‹é¢çš„æ¨å¯¼æ˜¯ä¸ºé‚£äº›ç†Ÿæ‚‰å¾®ç§¯åˆ†çš„äººå‡†å¤‡çš„ã€‚

![](img/539927ecd48368b11280ae32fc69b9f8.png)

æ¥æº:ä½œè€…

**Sigmoid gradient** å¯¹äºè®¡ç®— a(1-a)çš„ Sigmoid çš„æ¢¯åº¦æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å‡½æ•°ã€‚æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­å…¬å¼æ˜¯:

![](img/80b5aa61a758d79ec5c445add1636f65.png)

æ¥æº:ä½œè€…

```
def costFunction(nn_params, X, y, input_layer_size, hidden_layer_size, num_labels, Lambda):

    Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size, input_layer_size+1)
    Theta2 = nn_params[((input_layer_size+1) * hidden_layer_size):].reshape(num_labels, hidden_layer_size+1)

    #Feedforward and Cost Function
    m = X.shape[0]
    X = np.column_stack((np.ones((m ,1)), X)) #5000 x 401
    a2 = sigmoid(X@Theta1.T) #5000 x 25
    a2 = np.hstack((np.ones((m, 1)), a2)) #5000 x 26
    a3 = sigmoid(a2@Theta2.T) #5000 x 10

    y_matrix = np.zeros((m, num_labels)) #5000 x 10
    for i in range(1, num_labels+1):
        y_matrix[:, i-1][:, np.newaxis] = np.where(y==i, 1, 0)

    J = np.sum(np.sum( -y_matrix * np.log(a3) - (1 - y_matrix) * np.log(1 - a3) ))  
    reg = Lambda/(2*m) * (np.sum(Theta1[:, 1:]**2) + np.sum(Theta2[:, 1:]**2))

    J = (1/m) * J
    reg_J = J + reg

    grad1 = np.zeros((Theta1.shape))
    grad2 = np.zeros((Theta2.shape))

    for i in range(m):
        xi = X[i, :] #1 x 401
        a2i = a2[i, :] #1 x 26
        a3i = a3[i, :] #1 x 10

        d3 = a3i - y_matrix[i, :]
        d2 = (Theta2.T @ d3.T) * sigmoidGradient(np.hstack((1, xi @ Theta1.T)))

        grad1 = grad1 + d2[1:][:, np.newaxis] @ xi[:, np.newaxis].T
        grad2 = grad2 + d3.T[:, np.newaxis] @ a2i[:, np.newaxis].T

    grad1 = 1/m * grad1
    grad2 = 1/m * grad2     
    grad1_reg = grad1 + Lambda/m * np.hstack((np.zeros((Theta1.shape[0], 1)), Theta1[:, 1:]))
    grad2_reg = grad2 + Lambda/m * np.hstack((np.zeros((Theta2.shape[0], 1)), Theta2[:, 1:]))

    return J, grad1, grad2, reg_J, grad1_reg, grad2_reginput_layer_size = 400
hidden_layer_size = 25
num_labels = 10

nn_params = np.append(Theta1.flatten(), Theta2.flatten())
J, reg_J = costFunction(nn_params, X, y, input_layer_size, hidden_layer_size, num_labels, 1)[0:4:3]

print(f"Cost at parameters(non-regularized): {J}\nCost at parameters(Regularized): {reg_J}")
```

![](img/5b94da8006b6e02f25029afedd973dcc.png)

## éšæœºåˆå§‹åŒ–

åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬ä¸åº”è¯¥å°†Î¸åˆå§‹åŒ–ä¸ºé›¶ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œå¯¹ç§°(å³ï¼Œæ¯ä¸ªå•å…ƒæ£€æµ‹ç›¸åŒçš„ç‰¹å¾)ï¼Œå½“æˆ‘ä»¬å°†è¾“å…¥ä¹˜ä»¥Î¸(ä¸ºé›¶)æ—¶ï¼Œæˆ‘ä»¬å°†æ€»æ˜¯å¾—åˆ°é›¶ä½œä¸ºè¾“å‡ºã€‚å› æ­¤ï¼Œä¸ºäº†æ‰“ç ´å¯¹ç§°æ€§(å³ï¼Œæ¯ä¸ªå•å…ƒåº”è¯¥æ£€æµ‹ä¸åŒçš„ç‰¹å¾ï¼Œå¦‚è¾¹ç¼˜ã€æ°´å¹³çº¿ç­‰ã€‚ï¼Œ)æˆ‘ä»¬éšæœºåˆå§‹åŒ–Î¸ã€‚éšæœºåˆå§‹åŒ–çš„ä¸€ä¸ªæœ‰æ•ˆç­–ç•¥æ˜¯åœ¨ range[-Ïµáµ¢â‚™áµ¢â‚œ,Ïµáµ¢â‚™áµ¢â‚œ](where Ïµáµ¢â‚™áµ¢â‚œ=0.12).ä¸­å‡åŒ€åœ°éšæœºé€‰æ‹©Î¸å€¼

```
def randomInitailization(L_in, L_out):
    epi = np.sqrt(6)/np.sqrt(L_in+L_out)
    W = np.random.rand(L_out, L_in+1) * 2*epi - epi
    return W initial_Theta1 = randomInitailization(input_layer_size, hidden_layer_size)
initial_Theta2 = randomInitailization(hidden_layer_size, num_labels)
initial_nn_params = np.append(initial_Theta1.flatten(), initial_Theta2.flatten())
```

## æ¢¯åº¦ä¸‹é™

ç”±äºæˆ‘ä»¬è¦å­¦ä¹ Î¸â‚å’ŒÎ¸â‚‚ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•å°†ä¸ä¹‹å‰çš„ç•¥æœ‰ä¸åŒã€‚

![](img/812311169ba938ac5a2e15a138bf93a8.png)

æ¥æº:ä½œè€…

```
def gradientDescent(initial_nn_params, X, y, input_layer_size, hidden_layer_size, num_labels, alpha, num_iters, Lambda):

    Theta1 = initial_nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size, input_layer_size+1)
    Theta2 = initial_nn_params[((input_layer_size+1) * hidden_layer_size):].reshape(num_labels, hidden_layer_size+1)

    m = len(y)
    J_history = []

    for i in range(num_iters):
        nn_params = np.append(Theta1.flatten(), Theta2.flatten())
        cost, grad1, grad2 = costFunction(nn_params, X, y, input_layer_size, hidden_layer_size, num_labels, Lambda)[3:]
        Theta1 = Theta1 - (alpha * grad1)
        Theta2 = Theta2 - (alpha * grad2)
        J_history.append(cost)
    nn_params_final = np.append(Theta1.flatten(), Theta2.flatten())

    return nn_params_final, J_historynn_params, J_history = gradientDescent(initial_nn_params, X, y, input_layer_size, hidden_layer_size, num_labels, 0.8, 800, 1)
Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size, input_layer_size+1)
Theta2 = nn_params[((input_layer_size+1) * hidden_layer_size):].reshape(num_labels, hidden_layer_size+1)
```

## é¢„è¨€

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€æ¬¡æ­£å‘ä¼ æ’­å¾—åˆ°é¢„æµ‹ã€‚

```
def predict(Theta1, Theta2, X):
    m = X.shape[0]
    X = np.hstack((np.ones((m, 1)), X))
    a2 = sigmoid(X @ Theta1.T)
    a2 = np.hstack((np.ones((m, 1)), a2))
    a3 = sigmoid(a2 @ Theta2.T)
    return np.argmax(a3, axis=1)+1pred = predict(Theta1, Theta2, X)
print(f"Accuracy = {np.mean(pred[:, np.newaxis]==y) * 100}%")
```

å®ƒä¼šæ˜¾ç¤º 95%å·¦å³çš„å‡†ç¡®ç‡ã€‚å¯¹æ‰‹å†™æ•°å­—è¿›è¡Œåˆ†ç±»æ˜¯æœ‰å¥½å¤„çš„ã€‚

# ç»“è®º

ä»Šå¤©ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ç¥ç»ç½‘ç»œçš„å†…å¹•ä»¥åŠå®ƒå®é™…ä¸Šæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ç„¶åç”¨ python çš„ numpyï¼Œpandas å’Œ matplotlib ä»å¤´å¼€å§‹åˆ›å»ºã€‚æ•°æ®é›†å’Œæœ€ç»ˆä»£ç ä¸Šä¼ åˆ° githubã€‚

ç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹[ç¥ç»ç½‘ç»œã€‚](https://github.com/jagajith23/Andrew-Ng-s-Machine-Learning-in-Python/tree/gh-pages/Neural%20Networks)

# å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œé‚£ä¹ˆçœ‹çœ‹æˆ‘åœ¨è¿™ä¸ªç³»åˆ—ä¸­çš„å…¶ä»–æ–‡ç« 

## 1.[ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ](/@jagajith23/what-is-machine-learning-daeac9a2ceca)

## 2.[æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ](/codex/what-are-the-types-of-machine-learning-53360b7db8b4)

## 3.[ä¸€å…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-single-variable-f35e6a73dab6)

## 4.[å¤šå…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-multiple-variables-1893e4d940b1)

## 5.[é€»è¾‘å›å½’](/codex/logistic-regression-eee2fd028ffd)

## 6.[ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ](/@jagajith23/what-are-neural-networks-3a0965e2ebfb)

## 7.[åˆ©ç”¨ K å‡å€¼èšç±»è¿›è¡Œå›¾åƒå‹ç¼©](/@jagajith23/image-compression-with-k-means-clustering-48e989055729)

## 8.[ä½¿ç”¨ PCA å¯¹äººè„¸è¿›è¡Œé™ç»´](/@jagajith23/dimensionality-reduction-on-face-using-pca-e3fec3bb4cee)

## 9.[ä½¿ç”¨å¼‚å¸¸æ£€æµ‹æ¥æ£€æµ‹ç½‘ç»œä¸Šçš„æ•…éšœæœåŠ¡å™¨](https://jagajith23.medium.com/detect-failing-servers-on-a-network-using-anomaly-detection-1c447bc8a46a)

# æœ€ååšçš„äº‹

*å¦‚æœä½ å–œæ¬¢æˆ‘çš„æ–‡ç« ï¼Œé¼“æŒğŸ‘æ¥ä¸‹æ¥æ˜¯âš¡neuralisticâš¡å’Œ*åª’ä½“å®£ä¼ è¿™ç¯‡æ–‡ç« æ˜¯æœ‰å¸®åŠ©çš„ï¼Œè¿™æ ·å…¶ä»–äººä¹Ÿå¯ä»¥é˜…è¯»ã€‚*æˆ‘æ˜¯ Jagajithï¼Œæˆ‘ä¼šåœ¨ä¸‹ä¸€é›†é‡ŒæŠ“ä½ä½ ã€‚*