# ä½¿ç”¨å¼‚å¸¸æ£€æµ‹æ¥æ£€æµ‹ç½‘ç»œä¸Šçš„æ•…éšœæœåŠ¡å™¨ï¼

> åŸæ–‡ï¼š<https://medium.com/codex/detect-failing-servers-on-a-network-using-anomaly-detection-1c447bc8a46a?source=collection_archive---------6----------------------->

![](img/2169402578c79ab6fb73f9e36756d2d1.png)

[æ¥æº](https://zindpublic.blob.core.windows.net/public/uploads/blog_post/image/17/big_thumb_4d7a83bc-af4a-4912-81b2-8b95d4b08322.jpg)

å¤§å®¶å¥½ï¼ä½ è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†è®¨è®ºå¼‚å¸¸æ£€æµ‹ï¼Œå¹¶å‘æ‚¨å±•ç¤ºå¦‚ä½•åº”ç”¨å®ƒæ¥æ£€æµ‹ç½‘ç»œä¸Šå‡ºç°æ•…éšœçš„æœåŠ¡å™¨ã€‚æ‰€ä»¥ï¼Œäº‹ä¸å®œè¿Ÿï¼Œæˆ‘ä»¬å¼€å§‹å§ã€‚

## å¼‚å¸¸æ£€æµ‹

å¼‚å¸¸æ£€æµ‹æ˜¯æŒ‡å‘ç°**ä¸å¯»å¸¸çš„äº‹æƒ…ã€äº‹ä»¶æˆ–è§‚å¯Ÿç»“æœ**ï¼Œè¿™äº›äº‹æƒ…ã€äº‹ä»¶æˆ–è§‚å¯Ÿç»“æœä¼šå¼•èµ·å…³æ³¨ï¼Œå› ä¸ºå®ƒä»¬ä¸å…¶ä»–æ•°æ®æœ‰å¾ˆå¤§å·®å¼‚ã€‚

## å•†ä¸šä¸–ç•Œä¸­å¼‚å¸¸æ£€æµ‹çš„ä¾‹å­

*   å…¥ä¾µæ£€æµ‹ï¼Œä¾‹å¦‚è¯†åˆ«ç½‘ç»œæµé‡ä¸­çš„å¥‡æ€ªæ¨¡å¼(è¿™å¯èƒ½æ˜¯é»‘å®¢æ”»å‡»çš„ä¿¡å·)ã€‚
*   åŒ»é™¢å¥åº·ç›‘æ§ç³»ç»Ÿã€‚
*   é“¶è¡Œä¿¡ç”¨å¡äº¤æ˜“ä¸­çš„æ¬ºè¯ˆæ£€æµ‹ã€‚
*   æ“ä½œç¯å¢ƒä¸­çš„æ•…éšœæ£€æµ‹ã€‚
*   æ£€æµ‹äº’è”ç½‘ä¸Šçš„å‡æ–°é—»å’Œé”™è¯¯ä¿¡æ¯ã€‚
*   è¡Œä¸šæŸå®³æ£€æµ‹ã€‚
*   å®‰å…¨å’Œç›‘æ§ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä½¿ç”¨é«˜æ–¯æ¨¡å‹æ¥æ£€æµ‹å¼‚å¸¸çš„ä¾‹å­ã€‚æˆ‘å°†ä» 2D æ•°æ®é›†å¼€å§‹ã€‚åœ¨æ•°æ®é›†ä¸Šï¼Œæˆ‘å°†æ‹Ÿåˆé«˜æ–¯åˆ†å¸ƒï¼Œç„¶åæ‰¾å‡ºå¼‚å¸¸ã€‚

è®©æˆ‘ä»¬å¯¼å…¥å¿…è¦çš„åŒ…:

```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.io import loadmat
```

è®©æˆ‘ä»¬å¿«é€ŸåŠ è½½æ•°æ®é›†å¹¶å°†å…¶å¯è§†åŒ–ï¼Œ

```
mat = loadmat('ex8data1.mat')
X = mat['X']
Xval = mat['Xval']
yval = mat['yval']plt.scatter(X[:, 0], X[:, 1], marker='x', alpha=0.5)
plt.xlim(0,30)
plt.ylim(0,30)
plt.xlabel("Latency (ms)")
plt.ylabel("Throughput (mb/s)")
```

![](img/24294fccf521ecb499ac800cf2aeffdd.png)

è¾“å‡º

æˆ‘ä»¬ä½¿ç”¨**å»¶è¿Ÿ**å’Œ**ååé‡**æ¥æ£€æµ‹ç½‘ç»œä¸Šçš„æ•…éšœæœåŠ¡å™¨ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨å¯»æ‰¾å®ƒä»¬ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸Šé¢çš„è¾“å‡ºä¸­æ³¨æ„åˆ°å®ƒæœ‰ä¸€äº›å¼‚å¸¸ã€‚åœ¨æœ¬æ–‡çš„æœ€åï¼Œæˆ‘ä»¬ä¼šå‘ç°è¿™æ ·çš„å¼‚å¸¸ã€‚

æˆ‘ä½¿ç”¨é«˜æ–¯æ¨¡å‹æ¥å‘ç°å¼‚å¸¸ï¼Œå¦‚æœä½ æ“…é•¿ç»Ÿè®¡ï¼Œä½ å¯ä»¥è·³è¿‡ä¸‹ä¸€éƒ¨åˆ†ã€‚å¦‚æœä½ å·²ç»**å¿˜è®°**ä»€ä¹ˆæ˜¯**é«˜æ–¯åˆ†å¸ƒ**ï¼Œæˆ–è€…ä½ ä¸çŸ¥é“å®ƒæ˜¯ä»€ä¹ˆï¼Œé‚£å°±ç»§ç»­è¯»ä¸‹å»ã€‚è€Œä¸”ä½ ä¸éœ€è¦äº†è§£å¤ªå¤šå°±å¯ä»¥ä½¿ç”¨å®ƒï¼Œä¹Ÿä¸éœ€è¦è®°ä½å…¬å¼ã€‚æ‰€ä»¥ä¸ç”¨æ‹…å¿ƒã€‚

## é«˜æ–¯åˆ†å¸ƒ(æ­£æ€åˆ†å¸ƒ)

æ¯”å¦‚è¯´ x âˆˆ â„ï¼Œå¦‚æœ x æ˜¯ä¸€ä¸ªå‡å€¼ä¸º**Î¼ï¼Œæ–¹å·®ä¸º**Ïƒçš„åˆ†å¸ƒé«˜æ–¯ã€‚****

![](img/94fe5eddce27145aa99d108fa0de949a.png)

è¯¯å·®æ›²çº¿

![](img/870b2187f4931f1050d79df074988706.png)

ä»ä¸Šé¢çš„å…¬å¼æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œè¦ç»˜åˆ¶é«˜æ–¯æ›²çº¿ï¼Œæˆ‘ä»¬éœ€è¦ **Î¼** å’Œ **Ïƒ** æ¥å¯»æ‰¾**å‚æ•°**ï¼Œ

å‡è®¾æ•°æ®é›†åŒ…å«{xâ½ â¾ã€xâ½ â¾ã€â€¦ã€xâ½áµâ¾}ã€xâ½â±â¾ âˆˆ â„.

![](img/a898cfb6994b7a1cd115dc72c7a59d7f.png)

è¿™é‡Œæ©™è‰² X ä»£è¡¨æ•°æ®ç‚¹ï¼ŒÎ¼æ˜¯è¿™äº›æ•°æ®ç‚¹çš„å¹³å‡å€¼ï¼Œæ–¹å·®æ˜¯è¿™äº›ç‚¹çš„æ ‡å‡†åå·®ã€‚è®¡ç®—å¹³å‡å€¼å’Œæ–¹å·®çš„å…¬å¼å¦‚ä¸‹:

## å‚æ•°ä¼°è®¡

![](img/6e76bf4cfb7e21f7d24d5615526d6683.png)

å‡å€¼å’Œæ–¹å·®

```
def estimateGaussian(X):
    m, n = X.shape
    mu = (1/m) * np.sum(X, axis=0)
    sigma2 = (1/m) * np.sum((X - mu)**2, axis=0)
    return mu, sigma2
```

æˆ‘ä»¬ä½¿ç”¨å¯†åº¦ä¼°è®¡æ¥å‘ç°å¼‚å¸¸ã€‚

## å¯†åº¦ä¼°è®¡

![](img/2c8068b598162db5140bc6a8aa585d3a.png)

æˆ‘ä»¬é€šè¿‡å°†é«˜æ–¯æ›²çº¿å…¬å¼ä¸­çš„æ¯ä¸ªæ•°æ®ç‚¹ä»£å…¥æ‰€å¾—åˆ°çš„å€¼ç›¸ä¹˜å¾—åˆ° p(x)ã€‚å¤§å†™Ï€è¡¨ç¤ºä» xâ‚åˆ° xâ‚™.å–å„æ•°æ®ç‚¹çš„**ä¹˜ç§¯**

## åŸºäºé«˜æ–¯åˆ†å¸ƒçš„å¼‚å¸¸æ£€æµ‹ç®—æ³•

1.  é€‰æ‹©åŠŸèƒ½ xáµ¢ï¼›ä½ è®¤ä¸ºå¯èƒ½é¢„ç¤ºç€åå¸¸çš„ä¾‹å­ã€‚
2.  æ‹Ÿåˆå‚æ•°Î¼â‚ï¼Œâ€¦ï¼ŒÎ¼â‚™å’ŒÏƒâ‚ï¼Œâ€¦ï¼ŒÏƒâ‚™

![](img/87c52edc48f1c4aaa94a56f7cbf0d736.png)

3.ç»™å®šæ–°ç¤ºä¾‹ xï¼Œè®¡ç®— p(x):

![](img/4e6cff98d63d14fbc9f0ae60f1d5c4c8.png)

4.å¼‚å¸¸è‹¥ p(x) < Îµ(threshold).

## Algorithm Evaluation

1.  Fit the model p(x) on training set {xâ½Â¹â¾, xâ½Â²â¾, â€¦, xâ½áµâ¾}.
2.  On a cross validation / test set example x, predict

![](img/906fcf2db6eaacfbd5c6eb0970fef704.png)

3\. Possible evaluation metrics:

*   (True, false) positive and negative,
*   Precision / Recall
*   F1 Score

4\. We can also use cross validation set to choose parameter Îµ.

Sometimes, it is hard for gaussian distribution to find anomalies. So, we are going to use ***å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ*** ã€‚

## å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ

åœ¨è¿™é¡¹æŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬ä¸é‡‡å– p(xâ‚)ï¼Œâ€¦ç­‰ã€‚ï¼Œåˆ†å¼€ã€‚å–è€Œä»£ä¹‹çš„æ˜¯æˆ‘ä»¬ä¸€æ¬¡å°±å¾—åˆ° p(x)ã€‚

*   å‡è®¾ x âˆˆ â„ï¼Œä¸è¦æ¨¡ä»¿ p(xâ‚)ï¼Œâ€¦ç­‰ç­‰ã€‚ï¼Œåˆ†å¼€ã€‚
*   å‹å· p(x)ä¸€æ°”å‘µæˆã€‚
*   å‚æ•°:Î¼ âˆˆ â„â¿ï¼ŒÏƒâˆˆâ„â¿Ë£â¿ï¼›è¿™é‡ŒÏƒä»£è¡¨**åæ–¹å·®çŸ©é˜µ**ï¼Œç§°ä¸º**èµ„æœ¬é€‚é©¬ã€‚**

![](img/002932437dfd225a3057008bc9e01188.png)

## ç®—æ³•

1.  é€šè¿‡è®¾ç½®æ¥æ‹Ÿåˆæ¨¡å‹ p(x ):

![](img/a61d56370363231f9d3d541a08465493.png)

2.ç»™å®šä¸€ä¸ªæ–°çš„ä¾‹å­ xï¼Œè®¡ç®— p(x)ã€‚

3.æ ‡å¿—ä¸€ä¸ªå¼‚å¸¸å¦‚æœ p(x)

```
def multivariateGaussian(X, mu, sigma2):
    k = len(mu)
    sigma2 = np.diag(sigma2)
    X = X - mu.T
    p = 1/ ((2*np.pi)**(k/2) * (np.linalg.det(sigma2)**0.5)) * np.exp( -0.5 * np.sum(X @ np.linalg.pinv(sigma2) * X, axis=1))
    return pmu, sigma2 = estimateGaussian(X)
p = multivariateGaussian(X, mu, sigma2)# Visualize Distributionplt.figure(figsize=(8,6))
plt.scatter(X[:,0], X[:,1],marker="x")
X1, X2 = np.meshgrid(np.linspace(0, 35, num=71), np.linspace(0, 35, num=71))
p2 = multivariateGaussian(np.column_stack((X1.flatten().reshape(-1, 1), X2.flatten().reshape(-1, 1))), mu, sigma2)
contour_level = np.power(10, np.array([np.arange(-20, 0, 3, dtype=np.float)]))[0]
plt.contour(X1, X2, p2.reshape(X1.shape), contour_level)
plt.xlim(0,35)
plt.ylim(0,35)
plt.xlabel("Latency (ms)")
plt.ylabel("Throughput (mb/s)")
```

![](img/4503a9898af46119d4fc4da6e346e91f.png)

Output

From the above output, we can see that it has done some pretty distribution.

Now that we have calculated the Gaussian Distribution parameters, we can explore which examples have a very high probability and which examples have a very low probability given this distribution. The examples with a low likelihood are more likely to be anomalies. Selecting a threshold based on a cross validation set is one method for determining whether examples are anomalies.

## Select Threshold

I am not going in too detail about how to select threshold. So, I will give a link to the video, if you want to know more about it.

[**é“¾æ¥ 1**](https://www.youtube.com/watch?v=k1JGvqr56Yk&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=66) ï¼Œ [**é“¾æ¥ 2**](https://www.youtube.com/watch?v=wGw6R8AbcuI&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=67) ï¼Œ [**é“¾æ¥ 3**](https://www.youtube.com/watch?v=W5meQnGACGo&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=68) ï¼Œ [**é“¾æ¥ 4**](https://www.youtube.com/watch?v=5T77nG7YJhk&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=69)

æˆ‘ä»¬ä½¿ç”¨äº¤å‰éªŒè¯é›†ï¼Œå…¶ä¸­æ ‡ç­¾ y=1 å¯¹åº”äºå¼‚å¸¸ç¤ºä¾‹ï¼Œy=0 å¯¹åº”äºæ­£å¸¸ç¤ºä¾‹ã€‚å¯¹äºæ¯ä¸ªäº¤å‰éªŒè¯çš„ä¾‹å­ï¼Œæˆ‘ä»¬è®¡ç®— p(x_cvâ½â±â¾).æ‰€æœ‰å¯èƒ½æ€§çš„å‘é‡è¢«ä¼ é€’åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œç›¸åº”çš„æ ‡ç­¾ä¹Ÿè¢«ä¼ é€’åˆ°è¯¥å‡½æ•°ä¸­ï¼Œè¯¥å‡½æ•°è¿”å›ä¸¤ä¸ªå€¼Îµå’Œ F1 scoreã€‚

![](img/136e38e3b3ca7cc13fa520dca9ce52e2.png)

```
def selectThreshold(yval, pval):
    bestEpsilon = 0
    bestF1 = 0
    step = (max(pval) - min(pval))/1000
    epi_range = np.arange(min(pval), max(pval), step)
    for epsilon in epi_range:

        predictions = (pval < epsilon).reshape(-1, 1)

        true_positive = np.sum(predictions[yval==1]==1)
        false_positive = np.sum(predictions[yval==0]==1)
        false_negative = np.sum(predictions[yval==1]==0)

        precision = true_positive / (true_positive + false_positive)
        recall = true_positive / (true_positive + false_negative)

        F1 = (2*precision*recall)/(precision + recall)

        if F1 > bestF1:
            bestF1 = F1
            bestEpsilon = epsilon
    return bestEpsilon,  bestF1pval = multivariateGaussian(Xval, mu, sigma2)
epsilon, F1 = selectThreshold(yval, pval)
print("Best epsilon found using cross-validation:",epsilon)
print("Best F1 on Cross Validation Set:",F1)
```

é€‰æ‹©å¥½é˜ˆå€¼åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•°æ®é›†ä¸­çš„æ•…éšœæœåŠ¡å™¨ã€‚

```
plt.figure(figsize=(8,6))

plt.scatter(X[:,0],X[:,1],marker="x")

X1,X2 = np.meshgrid(np.linspace(0,35,num=70),np.linspace(0,35,num=70))
p2 = multivariateGaussian(np.hstack((X1.flatten()[:,np.newaxis],X2.flatten()[:,np.newaxis])), mu, sigma2)
contour_level = 10**np.array([np.arange(-20,0,3,dtype=np.float)])[0]
plt.contour(X1,X2,p2[:,np.newaxis].reshape(X1.shape),contour_level)

outliers = np.nonzero(p<epsilon)[0]
plt.scatter(X[outliers,0],X[outliers,1],marker ="o",facecolor="none",edgecolor="r",s=70)

plt.xlim(0,35)
plt.ylim(0,35)
plt.xlabel("Latency (ms)")
plt.ylabel("Throughput (mb/s)")
```

![](img/d3b2652cef6e352d090811e33b450f75.png)

è¾“å‡º

## å¥–é‡‘éƒ¨åˆ†

åœ¨è¿™ä¸ªé¢å¤–çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†åœ¨ä¸€ä¸ªæ›´çœŸå®ã€æ›´å›°éš¾çš„æ•°æ®é›†ä¸Šè¿è¡Œå¼‚å¸¸æ£€æµ‹ç®—æ³•ã€‚åœ¨è¯¥æ•°æ®é›†ä¸­ï¼Œæ¯ä¸ªç¤ºä¾‹ç”± 11 ä¸ªç‰¹å¾æè¿°ï¼Œæ•è·è®¡ç®—æœºæœåŠ¡å™¨çš„æ›´å¤šå±æ€§ã€‚

è®©æˆ‘ä»¬åŠ è½½æ•°æ®é›†å¹¶è·å¾—å‚æ•°Î¼å’ŒÏƒ:

```
mat2 = loadmat("ex8data2.mat")
X2 = mat2["X"]
Xval2 = mat2["Xval"]
yval2 = mat2["yval"]mu2, sigma2_2 = estimateGaussian(X2)
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†é«˜æ–¯åˆ†å¸ƒæ‹Ÿåˆåˆ°æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œå¹¶æ£€æµ‹å…¶ä¸­çš„å¼‚å¸¸æ•°é‡:

```
p3 = multivariateGaussian(X2, mu2, sigma2_2)

pval2 = multivariateGaussian(Xval2, mu2, sigma2_2)

epsilon2, F1_2 = selectThreshold(yval2, pval2)
print("Best epsilon found using cross-validation:",epsilon2)
print("Best F1 on Cross Validation Set:",F1_2)
print("# Outliers found:",np.sum(p3<epsilon2))
```

![](img/800ac97f0b82d1ba3fdf2a9204ed73e1.png)

è¾“å‡º

å®ƒåœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸­å‘ç°äº† 117 å°æ•…éšœæœåŠ¡å™¨ã€‚åœ¨æ–°çš„ä¾‹å­ x ä¸­ï¼Œå®ƒéå¸¸å–„äºå‘ç°ã€‚

## ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆäº†è§£ä»€ä¹ˆæ˜¯å¼‚å¸¸æ£€æµ‹ï¼Œç„¶åæ·±å…¥ç ”ç©¶é«˜æ–¯åˆ†å¸ƒï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§æ¯”é«˜æ–¯åˆ†å¸ƒæ›´å¼ºå¤§çš„å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ(MGD ),æˆ‘ä»¬å°†å…¶æ‹Ÿåˆåˆ°æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œä¹‹åæˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ä¸ªå¥½çš„é˜ˆå€¼å¹¶å¯è§†åŒ–æˆ‘ä»¬çš„å¼‚å¸¸ã€‚åœ¨æˆ‘ä»¬çš„å¥–é‡‘éƒ¨åˆ†ï¼Œæˆ‘ä»¬æ‹Ÿåˆæˆ‘ä»¬çš„æ•°æ®é›†ï¼Œæœ‰æ¯”ä»¥å‰æ›´å¤æ‚çš„æ•°æ®é›†ï¼Œä½¿ç”¨ MGDã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­æ‰¾åˆ°äº†ä¸€äº›ç¦»ç¾¤ç‚¹ã€‚æ•°æ®é›†å’Œæœ€ç»ˆä»£ç ä¸Šä¼ åˆ° Githubã€‚

ç‚¹å‡»æŸ¥çœ‹[ã€‚](https://github.com/jagajith23/Andrew-Ng-s-Machine-Learning-in-Python/tree/gh-pages/Anomaly%20Detection%20%26%20Recommender%20System)

# å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œé‚£ä¹ˆçœ‹çœ‹æˆ‘ä»¥å‰åœ¨è¿™ä¸ªç³»åˆ—ä¸­å…³äº

## 1.[ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ](/@jagajith23/what-is-machine-learning-daeac9a2ceca)

## 2.[æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ](/codex/what-are-the-types-of-machine-learning-53360b7db8b4)

## 3.[ä¸€å…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-single-variable-f35e6a73dab6)

## 4.[å¤šå…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-multiple-variables-1893e4d940b1)

## 5.[é€»è¾‘å›å½’](/codex/logistic-regression-eee2fd028ffd)

## 6.[ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ](/@jagajith23/what-are-neural-networks-3a0965e2ebfb)

## 7.[ä½¿ç”¨ç¥ç»ç½‘ç»œçš„æ•°å­—åˆ†ç±»å™¨](/codex/digit-classifier-using-neural-networks-ad17749a8f00)

## 8.[åˆ©ç”¨ K å‡å€¼èšç±»çš„å›¾åƒå‹ç¼©](/codex/image-compression-with-k-means-clustering-48e989055729)

## 9.[ä½¿ç”¨ PCA å¯¹äººè„¸è¿›è¡Œé™ç»´](/codex/dimensionality-reduction-on-face-using-pca-e3fec3bb4cee)

# æœ€ååšçš„äº‹

å¦‚æœä½ å–œæ¬¢æˆ‘çš„æ–‡ç« ï¼Œè¯·é¼“æŒğŸ‘ä¸€ä¸ªè¿½éšè€…å°†ä¼šæ˜¯â¤ï¸freeï¸â¤ï¸and è¿™æœ‰åŠ©äºåª’ä½“æ¨å¹¿è¿™ç¯‡æ–‡ç« ï¼Œä»¥ä¾¿å…¶ä»–äººèƒ½å¤Ÿé˜…è¯»å®ƒã€‚*æˆ‘æ˜¯ Jagajithï¼Œä¸‹ä¸€é›†å†æ¥æŠ“ä½ ã€‚*