<html>
<head>
<title>Your laptop is a distributed system</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的笔记本电脑是一个分布式系统</h1>
<blockquote>原文：<a href="https://medium.com/codex/your-laptop-is-a-distributed-system-3afb252db0c2?source=collection_archive---------5-----------------------#2021-01-07">https://medium.com/codex/your-laptop-is-a-distributed-system-3afb252db0c2?source=collection_archive---------5-----------------------#2021-01-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8d02e73188c6da9b05a787426163f104.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LMfO6S8kjJsJi2u8"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">迈克尔·泽兹奇在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="a595" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们想到分布式系统时，我们会想象多台机器相互通信以完成一个请求，也许是一个在分布式数据库中存储数据的节点集群，或者更抽象的概念，如<a class="ae iu" href="https://en.wikipedia.org/wiki/CAP_theorem" rel="noopener ugc nofollow" target="_blank"> CAP定理</a>【1】中的一致性。</p><p id="6afa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">但是你亲眼见过分布式系统吗？我不是指建筑图，我是指真正看到它。<br/>我打赌你会，而且你可能会用你的笔记本电脑来阅读这篇文章。如果最后一句让你感到惊讶，继续读下去，我们会明白为什么。</em></strong></p><h1 id="e220" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">一致性</h1><p id="dc4f" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">正如你已经知道的，内存是计算机用来存储数据的设备。内存因其速度、成本和易失性而异。在光谱的一端，我们有快速但昂贵的存储器，如SRAM。另一方面，我们有硬盘驱动器，速度慢(与CPU速度相比)，便宜，非易失性，因为它们不需要电源来保存数据。在中间，我们有<a class="ae iu" href="https://en.wikipedia.org/wiki/Dynamic_random-access_memory" rel="noopener ugc nofollow" target="_blank"> DRAM </a>技术，因其成本效益而受欢迎。<br/>谈到速度，最好了解一下访问存储在内存中的数据所涉及的数字:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/d72211c0f431ab4f90b6a0b662b16b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_Jxj7psjqOqQCLNULjA3g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">延迟数字—通过Github记入<a class="ae iu" href="https://gist.github.com/hellerbarde/2843375" rel="noopener ugc nofollow" target="_blank"> hellerbarde </a>名下</figcaption></figure><ul class=""><li id="deb0" class="lc ld hi ix b iy iz jc jd jg le jk lf jo lg js lh li lj lk bi translated">访问SRAM中的数据需要0.5纳秒</li><li id="fb03" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js lh li lj lk bi translated">从DRAM存取数据需要1000纳秒。大约比SRAM中的访问慢一千倍</li><li id="6173" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js lh li lj lk bi translated">从硬盘读取一个日期需要200万纳秒，也就是2毫秒。大约比访问SRAM慢一百万倍</li></ul><p id="2963" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们假设您有一个1 GHz的CPU，经过一些简化[2]这意味着您的CPU可以每纳秒运行一条指令。在一个简单的实现中，如果我们要访问一个DRAM，CPU将需要等待大约1000个周期，基本上什么也不做，而不是运行1000条指令。<strong class="ix hj"> <em class="jt">大量计算能力被浪费。</em> </strong>如果取而代之，我们使用SRAM，内存将能够跟上CPU，从而不会浪费宝贵的周期。</p><p id="9155" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">理想情况下，我们希望为我们的计算机配备最大容量的高速内存，但不幸的是，高速内存非常昂贵，这给我们带来了一个工程学的基本定理:<strong class="ix hj"> <em class="jt">天下没有免费的午餐</em> </strong>。工程就是在成本和性能之间找到最佳平衡点。</p><p id="901a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">幸运的是，有两个特性可以帮助计算机设计者进行权衡:空间和时间局部性。空间局部性属性表示存储在最近执行的指令附近的指令有很高的执行机会。相反，时间局部性表达了程序在执行过程中多次使用同一块数据的倾向。这些突然出现的特性并不会让我们感到惊讶，因为CPU一个接一个地运行指令，程序在执行过程中往往会多次访问数据。这些有些直观的属性建议按层次组织我们的内存，较快的内存靠近CPU (SRAM通常用于缓存和CPU寄存器)，较慢的内存位于层次的上层(DRAM也称为主内存)。<br/>在读取操作中，CPU试图从缓存中访问数据，如果缓存中有数据，就使用它。如果不是，则需要将数据从主内存复制到缓存中，然后CPU才能使用它。CPU不仅复制它需要的数据，还复制整个连续地址块(空间位置)。<br/>因为高速缓存必须小于主存储器，所以在某个时候它将变满，并且高速缓存中的一些条目必须被逐出。哪些？最常用的策略是删除<a class="ae iu" href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)" rel="noopener ugc nofollow" target="_blank">最近最少使用的项目</a>(时间局部性)，通常根据成本-收益权衡进行一些近似。</p><p id="690e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了获得更好的性能，系统设计人员在同一条物理总线上构建多个CPU互连的系统。每个CPU访问相同的内存，这意味着内存成为共享资源。<br/>总的来说，我们在一条总线上有多个互连的CPU，每个CPU都有自己的高速缓存，它们都访问相同的共享内存:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/d47bdd261fccc7c12e6456db09a93823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BTb5EqVODmO4Hc9uURqSng.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">缓存组织——通过Wikimedia Commons向Kunal Buch<a class="ae iu" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>致谢</figcaption></figure><p id="10a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个CPU根据它需要访问的数据填充缓存，即所谓的数据的本地副本。相同的数据可能被不同的CPU使用，这意味着我们最终可能会在不同的缓存中拥有相同数据的多个副本。但是当其中一个CPU更新其数据的本地副本时会发生什么呢？我们有一个典型的<strong class="ix hj">分布式系统</strong>问题:当其中一个处理器更新其本地副本时，保持相同数据的多个副本同步。这就是分布式系统人们所说的<strong class="ix hj">一致性问题</strong>。相反，对于硬件工程师来说，这是<a class="ae iu" href="https://en.wikipedia.org/wiki/Cache_coherence" rel="noopener ugc nofollow" target="_blank">缓存一致性</a>问题。[3]</p><h1 id="b895" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="cd34" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">我们的笔记本电脑是一个高度耦合的分布式系统，其中每个节点都是一个CPU。<br/>尽管硬件工程师需要解决多机分布式系统中经常遇到的一类问题，但解决这些问题的方式有一个主要区别。在一台计算机中，即使组件不在同一个芯片上，它们也是通过总线相互连接的。多CPU系统不需要处理网络分区、消息重新排序、部分故障以及不可靠网络的所有其他属性。</p><p id="ade7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">事实证明，网络确实是使分布式系统变得困难的原因。</p></div><div class="ab cl lr ls gp lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="hb hc hd he hf"><p id="a1e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在Twitter<a class="ae iu" href="https://twitter.com/napicellatwit" rel="noopener ugc nofollow" target="_blank">上关注我</a>，在你的订阅源中获取新帖子。<br/>封面图片通过<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>归功于<a class="ae iu" href="https://unsplash.com/@lazycreekimages?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Michael Dziedzic </a></p></div><div class="ab cl lr ls gp lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="hb hc hd he hf"><p id="07ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[1] <strong class="ix hj">一致性-可用性-分区容差权衡。</strong>CAP定理的扩展称为<a class="ae iu" href="https://en.m.wikipedia.org/wiki/PACELC_theorem" rel="noopener ugc nofollow" target="_blank">pace LC</a><br/>【2】这种简化没有考虑流水线、多核、需要多个周期才能完成的指令<br/>【3】<strong class="ix hj">乱序执行。我们的笔记本电脑和分布式系统之间的相似之处不止于此。现代CPU采用了另一种技巧来提高CPU性能:允许它们以不同于程序中指定的顺序运行指令。当然，这意味着增加了系统的复杂性，现在系统需要保证按顺序执行的指令的一致性。<br/>【4】当然，这并不意味着CPU设计很容易</strong></p></div></div>    
</body>
</html>