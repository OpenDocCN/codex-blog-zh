<html>
<head>
<title>Principal Component Analysis (PCA) in Machine Learning— You will never find it tough again</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的主成分分析(PCA)——你再也不会觉得它很难了</h1>
<blockquote>原文：<a href="https://medium.com/codex/principal-component-analysis-pca-how-it-works-mathematically-d5de4c7138e6?source=collection_archive---------0-----------------------#2021-06-04">https://medium.com/codex/principal-component-analysis-pca-how-it-works-mathematically-d5de4c7138e6?source=collection_archive---------0-----------------------#2021-06-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fb2781a77cf18e50b4b934f6029e40a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5__A9GwMc0PYZjATyZVDbQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者创造的形象</figcaption></figure><p id="ad1f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">主成分分析(PCA)是一种流行的无监督机器学习技术，用于减少训练数据集中的输入变量数量。这种技术属于降维技术。我认为，如果你已经开始阅读这篇文章，这意味着你知道某种程度的PCA。因此，我不打算讨论它是什么，它的优点或缺点。但是我将集中讨论它是如何工作的。</p><p id="95af" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">尽管Python提供了所有的类和方法来创建您的模型和执行您的操作，无论是回归、分类或聚类问题还是PCA，但是除非您知道幕后发生了什么，否则您将不会拥有作为数据科学家或机器学习爱好者的所有乐趣。</p><p id="64db" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当我在学习PCA的时候，不知何故我遇到的资源不足以让我理解PCA背后的数学。因此，我做了一些研究，重温了我以前的数学和统计技能，在做了所有这些之后，我终于可以理解出色的降维技术背后的魔力，这就是PCA(主成分分析)。在这篇文章中，我将尝试解释使用数学和统计概念在一个小的二维玩具数据集上执行PCA的所有步骤，并将其降维为一维。在手工完成所有这些之后(我指的是数学上的一步一步)，我将向您展示用python以编程方式完成的同样的事情，并验证我们的结果。</p><p id="bb89" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">无论我在这里介绍的是什么，都是使用二维数据集，但这不应该阻止您理解高维大型数据集，因为一旦您可以理解二维概念，您就可以应用更高维的知识。</p><p id="c9d6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在开始之前，让我先向您介绍一些基本的数学和统计概念，以便您可以在本文的后面将它们联系起来。如果您已经熟悉这些概念，那么您可以直接跳到第3部分并继续。但是，如果您有时间，我仍然建议您浏览所有部分。</p><h1 id="7091" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">第一部分:一些数学知识</h1><p id="a699" class="pw-post-body-paragraph iu iv hi iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr hb bi translated"><strong class="iw hj"> 1.1标量:</strong>标量不过是一个有值的数。例如5是标量，2.45是标量。</p><p id="5d3a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.2矢量:</strong>矢量可以认为是一个有大小和方向的物体。二维坐标可以是矢量的一个例子。例如(4，3)。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/24fd3f422cc55b5042fefbf7d8f8044a.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*dOhUm11spTgtlula8jNLzw.gif"/></div></figure><p id="3643" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以从(0，0)到(4，3)画一条线，代表矢量的方向。那么价值或数量会是多少呢？向量的值将是点(0，0)和(4，3)之间的距离。请注意，该值将是一个标量。</p><p id="8111" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在利用毕达哥拉斯定理，我们可以求出距离为:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es la"><img src="../Images/b9cdf2cb2c7e0fc79fa7c84fa17bb067.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*7FEVWIAS-JZh3ik4-gybgg.png"/></div></figure><p id="c3d1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，矢量的大小是5。</p><p id="3d44" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">类似地，对于具有3维(2，5，7)的数据是向量的一个例子。因此，对于n维(1，4，…)的数据。，n)是矢量。</p><p id="d203" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.3矩阵:</strong>矩阵是数字的数组。矩阵可以是正方形或矩形。注意，所有的向量都可以表示为矩阵。在上面的例子中，我们的向量可以表示为矩阵，如下图所示:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/3feb548ddbd84603100d0d7f4e0c27e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:196/1*E9j3GId8JlObqfgFE069-Q.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">2x1矩阵</figcaption></figure><p id="2931" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.4行列式:</strong>表示一个可以从方阵中计算出来的数。例如，如果A是一个方阵，那么|A|表示A的行列式。2x2矩阵的行列式可以计算如下:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/03aab36b9e34d2eb3d97fbfd9537ee64.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/1*qcU0uJ2zVJIulY2QBW1mWQ.gif"/></div></figure><p id="6082" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.5单位矩阵:</strong>单位矩阵(记为<em class="ld"> I </em>)是一个方阵，矩阵的对角元素为1，其余元素为0。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es le"><img src="../Images/3395e114891221918434099825ae5ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/1*5Q1XEphyNYKs-O16wux4UQ.gif"/></div></figure><p id="7845" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.6可逆矩阵:</strong> Z若满足下式，则称其为可逆矩阵(应为方阵):</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/978a482c431aa239e33adba45dd0059a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/1*8EZMjuTEWFszf6f83RbhJw.gif"/></div></figure><p id="59d6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">注:Z的行列式，即|Z| =0当且仅当Z不可逆。</p><p id="650c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.7矩阵乘法:</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/3f269d588cb009f6f48eed85b8377b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*Uc0BZb8PAV7JYZNJS0Fc5g.png"/></div></figure><p id="36fe" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">a，B是两个矩阵，AB是乘法。如果左侧矩阵的列数等于右侧矩阵的行数，则两个矩阵可以进行乘法运算。这里A是2×2，B是2×1矩阵，结果是2×1矩阵。</p><p id="0098" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.8特征向量:</strong>特征向量是一个非零向量(比如v)，当它与另一个方阵(比如A)相乘时，会产生另一个矩阵(也是一个向量)，它是原始向量v的标量倍数。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/c15f8a9eca4191aea783564376587636.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/1*DC2hTJeJ2Y7KNUiFR1HfDA.gif"/></div></figure><p id="e58a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 1.9特征值:</strong>上式中<em class="ld">λ</em>称为特征向量v的特征值。</p><p id="5ab5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们从上面的等式中推导出一个重要的等式:<br/>我们知道，</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es li"><img src="../Images/d32b5a9dfb63857538f02eb19d27724a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*L3L_-2cwIV6FXNE5V7A-Xw.png"/></div></figure><p id="fb5c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们以后会用到这个等式。让我们转到下一部分。</p><h1 id="8a8e" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">第二节:一点统计数据</strong></h1><p id="1f4c" class="pw-post-body-paragraph iu iv hi iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr hb bi translated">一些简短的统计数据。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/13c4285afcd634cf4d26d492738e9b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/1*9u8CwLU-spOKt1R-a2VjrA.gif"/></div></figure><p id="f162" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了更好地理解，您可以将X视为数据集中的一列。</p><p id="91a0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 2.1标准偏差</strong> (S)是一系列数字中数据偏离平均值的程度。计算标准差的公式为:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/77e580b8e808059238f9ac5de0d08372.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/1*itq30767NFYhsUublxYCSw.gif"/></div></figure><p id="d218" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 2.2方差</strong>是标准差的平方。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/85183532106c4f65c75d2ead4c8af65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/1*lh8RDhD77zQHUYtHTHiJvQ.gif"/></div></figure><p id="966a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 2.3协方差</strong>:方差描述的是一列数据的分布，协方差是同一事物的联合形式(与数据集中的两列相关)。</p><p id="1f98" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们用因子的形式写出方差公式(图3)</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/64d1741a0bc782095b9e37622763752c.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/1*o9-tybhwRelHv52eYNz2Kw.gif"/></div></figure><p id="21ed" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">即var(X) =cov(X，X)</p><p id="648e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从相同的公式中，我们可以导出两个变量X和Y(数据集中的两列)的协方差，如下所示</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/a58ff63aec0ab8c04a6ca77b89e79409.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/1*Vx2yHL2E-yXSuajK43vrTA.gif"/></div></figure><p id="ce81" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 2.4 Z-Score: </strong>我们可以使用<strong class="iw hj"> z-score </strong>对一组观察值进行标准化或缩放，从每个观察值中减去平均值，然后除以标准偏差。公式是:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/0c1f44ed6c17e391affeb6f607b7138e.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/1*d8aFgG-aucPdQLbZVxzSWg.gif"/></div></figure><p id="7c53" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">应用Z-score后，新观察数据集的均值变为0。</strong></p><p id="1838" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">到目前为止，您只需记下公式，我们将在下面的示例中真正计算它们。</p><h1 id="f545" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">第三节:PCA背后的数学</strong></h1><p id="c73f" class="pw-post-body-paragraph iu iv hi iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr hb bi translated">现在，你已经知道了一些基本的数学和统计学术语和公式，让我们开始讨论实际的话题。我们将看到如何使用数学一步一步地执行PCA。我将用一个2d数据集来阐述它。</p><p id="1380" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们考虑给定的数据集是具有2列(特征)和6行的数据集。列名是X和y。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/c90b63e512a9cb23075716626caa74fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:116/1*aiuPGF59XHq9jNF8n6XK9A.gif"/></div></figure><p id="ba4a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里注意，(2，3)，(4，5)，(6，5)，(6，7)，(7，8)，(5，8)称为<strong class="iw hj">特征向量</strong>。</p><p id="3369" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">PCA步骤:</strong></p><p id="654c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">第一步:标准化数据</strong></p><p id="01d0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以使用<strong class="iw hj"> z-score </strong>标准化或缩放数据。让我们为每一列计算相应的平均值和标准差。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/f7c0d45c1663270fd1e68bd7bcc022d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-rXoNxMRLdeQC-H-rgZbmQ.gif"/></div></div></figure><p id="e3d8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如第2.4节所述，计算每个观察值的Z得分的公式为</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/a0f52efc6ea3a12dca215ef35c4aab4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/1*qcaW3BE0OsQMH936tOZ9FQ.gif"/></div></figure><p id="d6bb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">利用这一点，让我们将原始数据转换为Z缩放数据:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/7c6a407d864a3a063f24396e6ae8defd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9PM9r_VnmAKubfKcZ7FuQA.gif"/></div></div></figure><p id="ded1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">第二步:求协方差矩阵</strong></p><p id="b2b5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，让我们找到缩放数据的协方差矩阵。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/b0b6a47d801ebb9401d35ec3876334af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*H1nY8MOV3YQBeXR9QTTmPA.gif"/></div></div></figure><p id="4146" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">第三步:求特征值</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/7f62bccb74949351fdc2ff3294fb6cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/1*bSgZaAwFMrLzZKOASNFDYA.gif"/></div></figure><p id="50fb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因为，我们将只考虑一个PCA分量，我们将忽略0.261，因为它非常小，将具有特征值2.139。</p><p id="c4af" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，我们将找到与上面找到的特征值相对应的协方差矩阵的特征向量。</p><p id="eb7c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">第四步:求特征向量</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/bb2385745c3a82dab01065cd7d1c004b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dXNa8UjtiTVDyMKxzUW6Ag.gif"/></div></div></figure><h2 id="7d47" class="lw jt hi bd ju lx ly lz jy ma mb mc kc jf md me kg jj mf mg kk jn mh mi ko mj bi translated"><strong class="ak">步骤5:使用特征向量将现有数据投影到一维中</strong></h2><p id="ce17" class="pw-post-body-paragraph iu iv hi iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr hb bi translated">因为我们执行PCA的主要目的是将数据从较高的维度投影到较低的维度，所以让我们继续我们的示例，并使用上面找到的特征向量将缩放的数据投影到一个维度。</p><p id="15fa" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们再次检查缩放后的数据:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/f2596ce7a34d191a0727b53a02f8cc37.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/1*93RrB4SUJEQ9CI5QdCCAJQ.gif"/></div></figure><p id="7532" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">第一特征向量(-1.837，-1.643)将使用以下公式进行变换:</strong></p><p id="bf48" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">(特征向量的转置)X(特征向量)</strong></p><p id="212c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们把相应的值:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/2b7c39f3d00b3f64c27202f0552ff6a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*bcY6YHvwv-si1qfaV_HwWQ.png"/></div></figure><p id="3351" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">类似地，如果我们投影缩放数据中的所有特征向量，我们将得到以下一维数据集。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/79850e1f49ada368c59f1534bffe81cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*CyY0edM_zQhTqZ2vjL3jLw.png"/></div></figure><p id="df5d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，我们已经完成了对五氯苯甲醚的计算，并得出了上述一维预测数据。</p><h1 id="7a56" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">第4部分:使用Python的PCA</strong></h1><p id="5c52" class="pw-post-body-paragraph iu iv hi iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr hb bi translated">在第3节中，我向您展示了我们如何在玩具数据集中执行PCA。我现在将使用Python执行同样的操作，并验证我们的最终投影数据。</p><p id="692a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这是我的Jupyter笔记本的快照，我在其中创建了数据集并执行了PCA的步骤:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/659043096a0808446e86377ca675da30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjBQcDybYKr9W_qDQPYUgg.png"/></div></div></figure><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/ec031e33002da460f12a319c12c93541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dr_LdScSrQuEoivcBolGew.png"/></div></div></figure><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/231124a54753cd146f9d56cd0d10bbf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4MgoO2Sfl39bGtwEZ4Tbrg.png"/></div></div></figure><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7eee5a7d7e64d5e1a3a0b2f80d302448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ybR-9HA5Dg2t1YTENe8dQw.png"/></div></div></figure><p id="d5b5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，我们可以看到我们获得了相同的数据(大约。)通过手工做数学和通过编程。唯一不同的是符号。两者都是有效的，因为python考虑的是特征向量的负值，而我们考虑的是正值。但是只要特征向量被归一化为长度为1，两者都是正确的。现在，你很容易理解PCA算法背后的数学原理。</p><h1 id="ad3b" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">结论:</strong></h1><p id="9c98" class="pw-post-body-paragraph iu iv hi iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr hb bi translated">我试着在一个很小的二维数据集中展示PCA。在现实生活中，您将拥有一个包含大量维度(列或特征，无论您说什么)的大型数据集，当您不知道哪些特征没有为您的最终模型增加价值时，PCA非常有用。在大型数据集中执行PCA并降低其维度(这就是为什么PCA被称为维度降低技术)后，它将更容易可视化，并为您的进一步建模做好准备。</p><p id="4b54" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我希望你喜欢阅读这篇文章并从中学习。请提供您的宝贵反馈。</p><p id="9a96" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="ld">所有用于计算的图片均由作者创作。</em></p></div></div>    
</body>
</html>