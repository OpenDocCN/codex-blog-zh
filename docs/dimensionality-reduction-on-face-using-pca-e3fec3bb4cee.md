# åŸºäºä¸»æˆåˆ†åˆ†æçš„äººè„¸é™ç»´

> åŸæ–‡ï¼š<https://medium.com/codex/dimensionality-reduction-on-face-using-pca-e3fec3bb4cee?source=collection_archive---------1----------------------->

![](img/06713df5a98fccbe5eb48871668284cc.png)

æœºå™¨å­¦ä¹ æœ‰å„ç§å„æ ·çš„é™ç»´æŠ€æœ¯ã€‚å®ƒæ˜¯æ•°æ®ç§‘å­¦é¢†åŸŸä¸­æœ€é‡è¦çš„æ–¹é¢ä¹‹ä¸€ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»‹ç»å½“ä»Šä½¿ç”¨çš„æœ€é‡è¦çš„é™ç»´æŠ€æœ¯ä¹‹ä¸€ï¼Œå³ä¸»æˆåˆ†åˆ†æ(PCA)ã€‚

ä½†é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦äº†è§£ä»€ä¹ˆæ˜¯é™ç»´ï¼Œä¸ºä»€ä¹ˆå®ƒå¦‚æ­¤é‡è¦ã€‚

## é™ç»´

é™ç»´ï¼Œä¹Ÿç§°ä¸ºé™ç»´ï¼Œæ˜¯å°†æ•°æ®ä»é«˜ç»´ç©ºé—´è½¬æ¢åˆ°ä½ç»´ç©ºé—´ï¼Œä½¿å¾—ä½ç»´è¡¨ç¤ºä¿ç•™åŸå§‹æ•°æ®çš„ä¸€äº›æœ‰æ„ä¹‰çš„å±æ€§ï¼Œæœ€å¥½æ¥è¿‘å…¶åº•å±‚ç»´åº¦ã€‚

![](img/9892070ad578b6d0693985d0493cb577.png)

è¿˜åŸå‰

![](img/4d40f9ecfadb4726315e815688848b5f.png)![](img/e22752b107fbabbf51ecfa8205023e75.png)

è¿˜åŸå

## ä¸ºä»€ä¹ˆæœ‰ç”¨ï¼Ÿ

ç”±äºå„ç§åŸå› ï¼Œä½¿ç”¨é«˜ç»´ç©ºé—´å¯èƒ½ä¸æ–¹ä¾¿ï¼ŒåŒ…æ‹¬åŸå§‹æ•°æ®ç”±äºç»´æ•°ç¾éš¾è€Œç»å¸¸æ˜¯æ¨¡ç³Šçš„ï¼Œå¹¶ä¸”å¤„ç†æ•°æ®é€šå¸¸åœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µçš„ã€‚é™ç»´åœ¨è¯¸å¦‚ä¿¡å·å¤„ç†ã€è¯­éŸ³è¯†åˆ«ã€ç¥ç»ä¿¡æ¯å­¦å’Œç”Ÿç‰©ä¿¡æ¯å­¦ç­‰å¤„ç†å¤§é‡è§‚å¯Ÿå€¼å’Œ/æˆ–å˜é‡çš„é¢†åŸŸä¸­å¾ˆæµè¡Œã€‚

## ä¸»æˆåˆ†åˆ†æ

äºŒç»´ã€ä¸‰ç»´æˆ–æ›´é«˜ç»´åº¦ä¸­çš„â€œæœ€ä½³æ‹Ÿåˆâ€çº¿å¯ä»¥å®šä¹‰ä¸ºæœ€å°åŒ–ä»ç‚¹åˆ°è¯¥çº¿çš„å¹³å‡å‚ç›´è·ç¦»å¹³æ–¹çš„çº¿ã€‚ç¬¬äºŒæ¡æœ€ä½³æ‹Ÿåˆçº¿å¯ä»¥ç”¨åŒæ ·çš„æ–¹æ³•ä»å‚ç›´äºç¬¬ä¸€æ¡çº¿çš„æ–¹å‘é€‰å–ã€‚å¦‚æœè¿™å¯¹ä½ æ¥è¯´ä¼¼ä¹æ˜¯èƒ¡è¨€ä¹±è¯­ï¼Œä¸è¦æ‹…å¿ƒï¼Œæˆ‘ä»¬å°†åœ¨è¿™ç¯‡æ–‡ç« ä¸­çœ‹åˆ°è¿™äº›äº‹æƒ…çš„ç»†èŠ‚ã€‚

![](img/98fb2d3ab1ed2fba24800d5e6e4de8ac.png)

PCA ç¤ºä¾‹

ç»¿ç‚¹æ˜¯å®é™…ç‚¹ï¼Œè€Œè“ç‚¹æ˜¯æŠ•å½±ç‚¹ã€‚
é¦–å…ˆï¼ŒPCA ç¡®å®šæŠ•å½±æ•°æ®çš„æ–¹å‘(çŸ¢é‡ uâ½ â¾ âˆˆ â„â¿),ä»¥æœ€å°åŒ–æŠ•å½±è¯¯å·®ã€‚åœ¨ä¸Šå›¾ä¸­ï¼Œè·ç¦»ç”¨ç²‰è‰²çº¿æ¡è¡¨ç¤ºã€‚PCA åœ¨æœ€å°å¹³æ–¹è¯¯å·®çš„æ–¹å‘ä¸Šé€‰æ‹©ä¸€æ¡çº¿ï¼Œè¯¥æ–¹å‘ç”±æ‰€é€‰æ‹©çš„çº¿å’Œä¸€ä¸ªç‚¹ä¹‹é—´çš„è·ç¦»å†³å®šã€‚ä»ä¸Šå›¾æˆ‘ä»¬è¿˜å¯ä»¥å¾—å‡ºç»“è®ºï¼Œæ©™è‰²çº¿æ˜¯æœ€å·®çš„çº¿ï¼Œå› ä¸ºç‚¹å’Œçº¿ä¹‹é—´çš„è·ç¦»å¾ˆå¤§ã€‚è¿™é‡Œï¼Œè´Ÿæ–¹å‘ä¹Ÿå¯ä»¥é€‰æ‹©ï¼Œä½†æ˜¯è¿™é‡Œæ­£è´Ÿæ–¹å‘éƒ½åœ¨åŒä¸€æ¡çº¿ä¸Šã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œä» n ç»´å‡å°‘åˆ° k ç»´:æ‰¾åˆ° k ä¸ªå‘é‡ uâ½ â¾ï¼Œuâ½ â¾,â€¦.å°†æ•°æ®æŠ•å½±åˆ°å…¶ä¸Šçš„,uâ½áµâ¾ï¼Œä»¥ä¾¿æœ€å°åŒ–æŠ•å½±è¯¯å·®ã€‚

ä¸ºäº†å¸®åŠ©æ‚¨ç†è§£ï¼Œæˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨ä¸€ä¸ªç¤ºä¾‹ 2D æ•°æ®é›†è¿›è¡Œå®éªŒï¼Œä»¥ç›´è§‚åœ°äº†è§£ PCA æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œç„¶ååœ¨æ›´å¤§çš„æ•°æ®é›†ä¸Šä½¿ç”¨å®ƒã€‚

è®©æˆ‘ä»¬åŠ è½½æˆ‘ä»¬çš„æ ·æœ¬æ•°æ®é›†ï¼Œå¹¶ä»¥è¶…å¿«çš„é€Ÿåº¦å°†å…¶å¯è§†åŒ–:

```
mat3 = loadmat('ex7data1.mat')
X3 = mat3['X']plt.scatter(X3[:, 0], X3[:, 1], alpha=0.5)
```

![](img/7277657004cb0e8e50e9abe6c41c6f58.png)

æ•°æ®å¯è§†åŒ–

åœ¨ä½¿ç”¨æˆ‘ä»¬çš„æ•°æ®ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶æ ‡å‡†åŒ–ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä¸ä¼šæ·±å…¥æ¢è®¨æ­£å¸¸åŒ–ã€‚äº†è§£æ›´å¤šå…³äºæ­£å¸¸åŒ– [***ç‚¹å‡»è¿™é‡Œ***](/codex/linear-regression-on-multiple-variables-1893e4d940b1) ã€‚

```
def featureNormalize(X):

    mu = np.mean(X, axis=0)
    sigma = np.std(X, axis=0)
    X_norm = (X - mu)/sigma

    return X_norm, mu, sigma
```

## ä¸»æˆåˆ†åˆ†æç®—æ³•

![](img/57947dc160a2337e47c978ce80a0cc38.png)

ä¸»æˆåˆ†åˆ†æç®—æ³•

## 1.è®¡ç®—åæ–¹å·®çŸ©é˜µ

ä¸¤ä¸ªå˜é‡ä¹‹é—´å…³ç³»çš„åº¦é‡æ˜¯åæ–¹å·®ã€‚å®ƒé‡åŒ–äº†ä¸¤ä¸ªå˜é‡ä¸å…¶å¹³å‡å€¼çš„å·®å¼‚ç¨‹åº¦ã€‚å®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬ç†è§£è¿™ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚

åæ–¹å·®çŸ©é˜µåœ¨ä¸Šå¼ä¸­ç”¨å¸Œè…Šå­—æ¯(sigma)è¡¨ç¤ºï¼Œä¸æ±‚å’Œä¸åŒã€‚é€šè¿‡ä¹˜ä»¥ xâ½â±â¾å’Œ xâ½â±â¾è½¬ç½®ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—åæ–¹å·®çŸ©é˜µã€‚

## 2.è®¡ç®—ç‰¹å¾å‘é‡

è§£é‡Šæ›´å¤šçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ä¼šä½¿è¿™ç¯‡æ–‡ç« å¤ªé•¿ï¼Œæˆ‘å°†åªä½¿ç”¨ numpy çš„ svd()æ–¹æ³•ã€‚ç„¶è€Œï¼Œä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘å°†æŠŠè®¡ç®—ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„è¿‡ç¨‹ç•™åœ¨æ–‡ç« çš„æœ€åã€‚ç®€å•æ¥è¯´ï¼Œç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡å°†å¸®åŠ©æˆ‘ä»¬æ‰¾åˆ° PCA çº¿çš„æŠ•å½±æ–¹å‘ã€‚ [***ç‚¹å‡»è¿™é‡Œ***](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors) äº†è§£æ›´å¤šç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ã€‚è¿™é‡Œ u æ˜¯ uâ½â¾,â€¦.uâ½â¾çš„å‘é‡é›†åˆè¦å°†æ•°æ®æŠ•å½±åˆ°çš„,uâ½áµâ¾ã€‚

![](img/38e7e7169d5f24b586c6a8bc17b195bb.png)

ä½¿ç”¨ svd()åï¼Œæˆ‘ä»¬å¾—åˆ° U ä½œä¸ºä¸Šé¢çš„çŸ©é˜µã€‚è¿”å›çš„ U çŸ©é˜µåŒ…å« n ç»´çš„æ–¹å‘ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹© k å°† n ç»´çŸ©é˜µå‡å°‘åˆ° k ç»´ã€‚k ç»´çŸ©é˜µç§°ä¸º U_reduceã€‚

![](img/a1624aac55c614b54c3f96c38c0d2852.png)

æˆ‘ä»¬å¯ä»¥é€šè¿‡å°† U_reduce è½¬ç½®ä¸ x ç›¸ä¹˜å¾—åˆ°é™ç»´çš„ zï¼Œè¿™å°†å¤§å°ä¸º(nÃ—1)çš„ xâ½â±â¾å‡å°‘åˆ°(kÃ—1)ã€‚

é€šè¿‡å°† U_reduce ä¹˜ä»¥ zï¼Œæˆ‘ä»¬å¯ä»¥è¿‘ä¼¼åœ°å¾—åˆ°åŸå§‹æ•°æ®(Xâ‰ˆXâ‚â‚šâ‚šáµ£â‚’â‚“ = U_reduce â‹… Z)ã€‚åŸå§‹æ•°æ®å’Œè¿‘ä¼¼æ•°æ®å¦‚ä¸‹å›¾æ‰€ç¤º:

![](img/4b121d8e58f23d4ad4a1bd2f3fd28e07.png)

åŸå§‹ä¸è¿‘ä¼¼

```
def PCA(X):
    m, n = X.shape
    cov_matrix = 1/m * X.T @ X
    U, S, V = np.linalg.svd(cov_matrix)
    return U, S, VX_norm, mu, sigma = featureNormalize(X3)
U, S, V = PCA(X_norm)

plt.scatter(X3[:, 0], X3[:, 1], alpha=0.5)
plt.plot([mu[0], (mu + 1.5 * S[0] * U[:, 0].T)[0]], [mu[1], (mu + 1.5 * S[0] * U[:, 0].T)[1]], color="black", linewidth=3)
plt.plot([mu[0], (mu + 1.5 * S[1] * U[:, 1].T)[0]], [mu[1], (mu + 1.5 * S[1] * U[:, 1].T)[1]], color="black", linewidth=3)
plt.xlim(-1,7)
plt.ylim(2,8)
```

![](img/b2b42153d0570e5c6b1f9ba42df96682.png)

PCA æ–¹å‘

```
def projectData(X, U, K):

    m = X.shape[0]
    Z = np.zeros((m, K))
    for i in range(m):
        for j in range(K):
            projection_k = X[i, :] @ U[:, j] #x @ U_reduce
            Z[i, j] = projection_k
    return ZK=1
Z = projectData(X_norm, U, K)def recoverData(Z, U, K):
    z = Z.shape[0]
    u = U.shape[0]
    X_rec = np.zeros((z, u))

    for i in range(z):
        for j in range(u):
            X_rec[i, j] = Z[i, :] @ U[j, :K]
    return X_recX_rec  = recoverData(Z, U, K)plt.scatter(X_norm[:,0],X_norm[:,1],marker="o",label="Original",facecolors="none",edgecolors="b",s=15)
plt.scatter(X_rec[:,0],X_rec[:,1],marker="o",label="Approximation",facecolors="none",edgecolors="r",s=15)
plt.title("The Normalized and Projected Data after PCA")
plt.legend()
```

![](img/bf80f7ac2dc6aadffa7ff7a5e61349fb.png)

åŸå§‹å€¼ä¸è¿‘ä¼¼å€¼

## é€‰æ‹© k(ä¸»æˆåˆ†æ•°)

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹å¼é€‰æ‹© k:

![](img/0ae89933fcac648a5323dd21d37f0a7a.png)

ä¿ç•™ 95%åˆ° 99 %çš„å·®å¼‚æ˜¯å¥½çš„å’Œå¯æ¥å—çš„ã€‚

## åº”ç”¨ PCA

1.  xâ½â±â¾ â†’zâ½â±â¾çš„æ˜ å°„åº”è¯¥é€šè¿‡ä»…åœ¨è®­ç»ƒé›†ä¸Šè¿è¡Œ PCA ***æ¥å®šä¹‰ã€‚***
2.  ä¸è¦ä½¿ç”¨ PCA å°†ç‰¹å¾çš„æ•°é‡å‡å°‘åˆ° kã€‚è¿™å¯èƒ½è¡Œå¾—é€šï¼Œä½†ä¸æ˜¯è§£å†³è¿‡åº¦æ‹Ÿåˆçš„å¥½æ–¹æ³•ã€‚
3.  åœ¨å®ç° PCA ä¹‹å‰ï¼Œé¦–å…ˆå°è¯•è¿è¡Œæ‚¨æƒ³å¯¹åŸå§‹æ•°æ®åšçš„ä»»ä½•äº‹æƒ…ã€‚åªæœ‰å½“å®ƒä¸åšä½ æƒ³è¦çš„ï¼Œç„¶åå®æ–½ PCAã€‚

è¿™éœ€è¦å¤§é‡çš„ä»£æ•°å’Œæ•°å­¦è¿ç®—ï¼Œè®©æˆ‘ä»¬æ·±å…¥åˆ°ä½¿ç”¨ä¸»æˆåˆ†åˆ†æçš„äººè„¸é™ç»´ä¸­ã€‚

è®©æˆ‘ä»¬å¿«é€ŸåŠ è½½å’Œå¯è§†åŒ–æ•°æ®é›†:

```
mat4 = loadmat('ex7faces.mat')
X4 = mat4['X']fig, ax = plt.subplots(nrows=10,ncols=10,figsize=(8,8))
for i in range(0,100,10):
    for j in range(10):
        ax[int(i/10),j].imshow(X4[i+j,:].reshape(32,32,order="F"),cmap="gray")
        ax[int(i/10),j].axis("off")
```

![](img/12bd4985d5f3c3f871445e8216a2bfa6.png)

è®©æˆ‘ä»¬å¯¹è¯¥æ•°æ®é›†åº”ç”¨ä¸»æˆåˆ†åˆ†æå¹¶å°†å…¶å¯è§†åŒ–:

```
X_norm2, mu2, sigma2 = featureNormalize(X4)
U2, S2, V2 = PCA(X_norm2)
U_reduced = U2[:,:36].T
fig2, ax2 = plt.subplots(6,6,figsize=(8,8))
for i in range(0,36,6):
    for j in range(6):
        ax2[int(i/6),j].imshow(U_reduced[i+j,:].reshape(32,32,order="F"),cmap="gray")
        ax2[int(i/6),j].axis("off")
```

![](img/d1d8c1282df7002a4f025be1917f5d6b.png)

è®©æˆ‘ä»¬å°†é¢çš„å°ºå¯¸ä» 1024 å‡å°‘åˆ° 100:

```
K2 = 100
Z2 = projectData(X_norm2, U2, K2)
print("The projected data Z has a size of:",Z2.shape)
X_rec2  = recoverData(Z2, U2, K2)
fig3, ax3 = plt.subplots(10,10,figsize=(8,8))
for i in range(0,100,10):
    for j in range(10):
        ax3[int(i/10),j].imshow(X_rec2[i+j,:].reshape(32,32,order="F"),cmap="gray")
        ax3[int(i/10),j].axis("off")
```

![](img/3be858309b5f2e6e9e8592d20e416582.png)

é¢„è®¡æ•°æ®

## å…³äºç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„è¡¥å……è¯´æ˜

æ±‚ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„ç¨‹åº:
1ã€‚æ±‚ç‰¹å¾æ–¹ç¨‹ã€‚
2ã€‚æ±‚è§£ç‰¹å¾æ–¹ç¨‹å¾—åˆ°ç‰¹å¾æ ¹ã€‚å®ƒä»¬ä¹Ÿè¢«ç§°ä¸ºç‰¹å¾å€¼æˆ–æ½œåœ¨æ ¹ã€‚
3ã€‚ä¸ºäº†æ‰¾åˆ°ç‰¹å¾å‘é‡ï¼Œå¯¹äºä¸åŒçš„Î»å€¼æ±‚è§£(A-Î»I)X= 0ã€‚

# ç»“è®º

ä»Šå¤©ï¼Œæˆ‘ä»¬çœ‹åˆ°äº† PCA çš„å†…å¹•ä»¥åŠå®ƒå®é™…ä¸Šæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ç„¶åç”¨ python çš„ numpyï¼Œpandas å’Œ matplotlib ä»å¤´å¼€å§‹åˆ›å»ºã€‚å®ƒåœ¨è®¸å¤šåº”ç”¨ä¸­æ›´æœ‰ç”¨ï¼Œæœ‰åŠ©äºä»¥éå¸¸ä½çš„æ•°æ®æŸå¤±æ¥é™ä½æ•°æ®çš„ç»´åº¦ã€‚æ•°æ®é›†å’Œæœ€ç»ˆä»£ç ä¸Šä¼ åˆ° Githubã€‚

ç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹ [PCA](https://github.com/jagajith23/Andrew-Ng-s-Machine-Learning-in-Python/tree/gh-pages/Unsupervised%20Machine%20Learning) ã€‚

# å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œé‚£ä¹ˆçœ‹çœ‹æˆ‘ä»¥å‰åœ¨è¿™ä¸ªç³»åˆ—ä¸­å…³äº

## 1.[ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ](/@jagajith23/what-is-machine-learning-daeac9a2ceca)

## 2.[æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ](/codex/what-are-the-types-of-machine-learning-53360b7db8b4)

## 3.[ä¸€å…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-single-variable-f35e6a73dab6)

## 4.[å¤šå…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-multiple-variables-1893e4d940b1)

## 5.[é€»è¾‘å›å½’](/codex/logistic-regression-eee2fd028ffd)

## 6.[ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ](/@jagajith23/what-are-neural-networks-3a0965e2ebfb)

## 7.[ä½¿ç”¨ç¥ç»ç½‘ç»œçš„æ•°å­—åˆ†ç±»å™¨](/codex/digit-classifier-using-neural-networks-ad17749a8f00)

## 8.[åˆ©ç”¨ K å‡å€¼èšç±»çš„å›¾åƒå‹ç¼©](/codex/image-compression-with-k-means-clustering-48e989055729)

## 9.[ä½¿ç”¨å¼‚å¸¸æ£€æµ‹æ¥æ£€æµ‹ç½‘ç»œä¸Šçš„æ•…éšœæœåŠ¡å™¨](https://jagajith23.medium.com/detect-failing-servers-on-a-network-using-anomaly-detection-1c447bc8a46a)

# æœ€ååšçš„äº‹

å¦‚æœä½ å–œæ¬¢æˆ‘çš„æ–‡ç« ï¼Œè¯·é¼“æŒğŸ‘ä¸€ä¸ªè¿½éšè€…ä¼šæ˜¯ğŸ¤˜ç»Ÿä¸€ğŸ¤˜è€Œä¸”æœ‰åŠ©äºåª’ä½“æ¨å¹¿è¿™ç¯‡æ–‡ç« ï¼Œè®©å…¶ä»–äººä¹Ÿèƒ½é˜…è¯»ã€‚*æˆ‘æ˜¯ Jagajithï¼Œä¸‹ä¸€é›†å†æ¥æŠ“ä½ ã€‚*