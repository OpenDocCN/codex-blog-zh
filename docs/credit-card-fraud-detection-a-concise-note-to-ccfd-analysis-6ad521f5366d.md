# 信用卡欺诈检测:CCFD 分析笔记

> 原文：<https://medium.com/codex/credit-card-fraud-detection-a-concise-note-to-ccfd-analysis-6ad521f5366d?source=collection_archive---------6----------------------->

由[彼得梁](https://www.linkedin.com/in/zicong-peter-liang/)

![](img/35e15fae082befc7ba86fba465ba5758.png)

由[马库斯·斯皮斯克](https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

# **一、背景**

由于最近的一次采访，我的注意力被吸引到使用 ML 算法进行信用卡欺诈检测的问题上，在准备过程中，我看到了由[Yann-al Le Borgne](https://yannael.github.io/)和 [Gianluca Bontempi](https://mlg.ulb.ac.be/wordpress/members-2/gianluca-bontempi/) 撰写的开源笔记本 [*用于信用卡欺诈检测的机器学习-实用手册*](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html) 。这些材料对我非常有帮助，对于任何想了解信用卡欺诈检测的人来说，都是清晰、翔实的材料。我决定把这篇文章作为一个空间来组织我的思想和信用卡欺诈检测分析的简明指南。

# **二。业务理解**

信用卡欺诈检测问题自成一类，因为它具有许多区别于其他分类或聚类问题的独特属性，例如，信用卡交易的数据高度不平衡，这意味着欺诈交易在所有交易中的比例与真实交易的比例不可比，欺诈交易的比例通常低于 1%，因此不仅在用于预测的方法方面，而且在适当的性能指标的设计方面都存在许多挑战。除此之外，由于业务问题的性质，在算法检测到可疑交易/账户后，调查过程需要人工检查以进行后续工作，这意味着预测的高假阳性率是不可接受的，否则，调查人员不可能执行检测系统发出的如此大量的警报。这些挑战只是我们在处理信用卡欺诈检测问题时所面临的独特挑战的一小部分。以下是在 [*用于信用卡欺诈检测的机器学习——实用手册*](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html) *中总结的独特挑战列表。*我在这里挑选了一些与我的案例最相关的挑战。

**类别不平衡**:正如我上面提到的，数据集中合法交易远远多于欺诈交易，在现实生活场景中，欺诈交易的百分比很可能不到 1%。不平衡类将对最常用的机器学习算法提出挑战，因为它们不是为处理不平衡数据而设计的。

**概念漂移**:这仅仅意味着欺诈交易的模式会随着时间的推移而改变。两个方面造成了概念漂移。首先，用户的行为会随着时间而改变，例如，用户的行为从白天到晚上、从工作日到周末是不同的，或者由于疫情，用户会更频繁地在互联网上购买。用户行为模式的改变将导致概念漂移。第二，欺诈者将更新他们的技术来打击信用卡欺诈检测工作，这意味着使用历史数据从旧模式和训练模型中学习可能无助于发现欺诈交易中使用的新技术。

**分类特征:**这是一个挑战，因为机器学习算法不理解或不能处理分类变量，但在信用卡欺诈的情况下，许多信息被存储为分类变量，例如，账号、卡类型、交易终端等。应该考虑特征工程/聚合，将分类变量转换为数字变量，以处理这些变量。例如，我们可以将事务时间戳转换为二进制变量，以指示事务是发生在白天还是晚上，是发生在工作日还是周末。或者将 RFM 变量(新近性、频率和货币值)添加到数据集。

**顺序建模**:由于信用卡交易的性质，数据是顺序的，每个持卡人的记录或每个终端的记录都是顺序数据流，因此有必要对这一特征进行建模，并在模型中纳入顺序数据的特征。为此，我们可以创建随时间变化的聚合变量，例如，移动窗口(比如 7 天)内的交易计数、7 天内每笔交易金额的移动平均值、每天交易的移动平均数等。

**性能度量**:由于信用卡交易的数据是高度不平衡的，分类问题的标准度量标准，如平均误分类率，将是对模型在信用卡欺诈检测问题中性能的误导性度量。例如，如果在 100 个交易的样本中只有一个欺诈性交易，即使我们应用最笨的模型预测每个交易都是合法的，错误分类率也只有 1%。此外，由于与欺诈交易相关的成本结构的复杂性，没有简单的方法来为混淆矩阵中的每种类型的错误分配适当的成本。除此之外，我们还必须考虑到调查资源是有限的，因此假阳性率也是一个重要的考虑因素。总体目标是最大限度地检测欺诈性交易，并最大限度地减少误报，由于业务问题的复杂性以及计算资源、调查资源和与欺诈性交易相关的各种成本的权衡，这要求我们使用多个性能指标来评估模型。

# **三。数据理解和特征转换**

以下是信用卡交易的典型原始数据表格。它包含每笔交易的唯一 id、时间戳、标识单个用户的客户 ID、交易的货币金额以及交易是否欺诈的指示符(0 表示有效交易，1 表示欺诈交易)

![](img/cea1e8a612052a914424396161bdbf97.png)

图来自[欺诈检测笔记本](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_3_GettingStarted/BaselineFeatureTransformation.html)

虽然该表对我们来说似乎很直观，但机器学习算法不理解分类变量(如客户 ID、终端 ID)或非数字变量(如日期时间)的含义。

> 机器学习算法通常需要 ***数值*** 和 ***命令*** 特征。数值意味着变量的类型必须是整数或实数。有序意味着变量值的顺序是有意义的。

基于对问题的业务理解，我们通常可以进行三种类型的转换，将这些变量转换为有助于预测的数字变量。

1.  二进制编码
2.  RFM(近期、频率、货币价值)
3.  风险/频率编码

第一个处理时间戳，正如我在上一节中提到的。我们可以从 timestamp 创建两个特性，指示事务是发生在白天还是晚上、工作日还是周末。这将是有帮助的，因为客户的信用卡交易行为将根据日期和时间而变化，因此添加这两个特征将有助于算法更好地捕捉用户的活动模式。

第二个处理客户 ID，也将创建描述用户行为模式的特性。按照 RFM 方法，它为每个用户 ID 创建变量，记录每笔交易的平均支出以及三种窗口大小(1 天、7 天、30 天)下每个 ID 的平均交易数

最后一个处理终端 ID，将创建两种类型的特征来捕获每个终端的状态。与我们对客户 id 所做的类似，我们可以创建变量来跟踪不同窗口(1 天、7 天、30 天)的交易数量和欺诈交易数量。

# **四。型号选择**

各种 ML 算法被用于信用卡欺诈检测领域。下图总结了 CCFD 问题研究中最常用的机器学习算法。

![](img/1dff52979571eaa8f8afa17cc5d7a0e2.png)

图来自 Priscilla 等人，2019 年

正如我们可以看到的，监督和非监督学习方法都用于欺诈交易的检测。这里的区别是，监督学习需要一个带标签的 Y 变量，这意味着每个记录/交易都需要被标记为合法或欺诈交易。使用不同的方法既有优点也有缺点，简而言之，监督学习方法的最大优点是它们高度准确和可靠，但缺点是它们只从历史数据中学习，只揭示过去的模式，这意味着当涉及到检测欺诈者使用的新技术时，调查人员需要时间来收集信息，用户需要时间来报告，算法需要时间来学习。我将在后面的部分中介绍一些最常用的监督学习算法，但是让我们先来快速了解一下无监督学习。

a.无监督学习

与监督学习不同，非监督学习不需要每个记录上的标签，并且由于非监督学习不需要对数据进行标记，因此它可以更快地对算法未知的新出现的欺诈模式做出响应，并且算法背后的内容很简单，无论数据点被分类到大组还是小组， 很明显，被分类到一个极小的组中的数据点更有可能是欺诈性交易，因为实际数据本质上具有不平衡的类别，只有不到 1%的交易是欺诈性的。 无监督学习主要关注数据点的相似性，并试图将相似的数据点分类和划分到同一组中，而为了确定相似性，像 K-means 这样的算法通常会计算两个数据点之间的距离。从一个到另一个的距离越短，相似性越大，它们就越有可能在同一组中。

b.监督学习

监督学习的目标是使用过去的数据来找到自变量/输入变量(描述交易的特征，如用户 ID、时间戳、终端 ID、交易金额)和因变量/输出变量(交易标签，欺诈或真实)之间的关系。在 CCFD 的上下文中，目标是使用输入特征来预测交易是否是欺诈性的。

四种监督学习算法在信用卡欺诈检测领域使用最多。它们是:

1.  决策树
2.  逻辑回归
3.  随机森林
4.  梯度推进

我将在下一节给出每个算法的简要概述。

**a .决策树**

决策树方法是**分类和回归树(CART)方法**的一部分，因为它用于二元变量的预测，所以它是 CART 方法的分类部分。决策树的思想是基于不同的预测器对数据进行划分，在每次划分时，CART 会将数据划分为更小的组，并递归地执行。这个过程也被称为**递归分区**。决策很容易想象，下面是一个决策树的例子。

![](img/f125512752a9c70fd6b0f625daaacf24.png)

决策树的可视化示例

该决策树采用花瓣长度和花瓣宽度的输入来预测花的种类。从图中，我们可以看到决策树有三个组成部分，决策节点、分支和叶节点。在这种情况下，花瓣长度和花瓣宽度是决策节点，Setosa、Versicolor 和 Virginica 是叶节点。树从上到下生长，第一个决策节点，花瓣长度，是树的“根”，而最小的子群，Setosa，Versicolor 和 Virginica，是“叶”。树中的每个决策节点都是用于进行预测的输入变量/预测器。在每个节点，算法将选择最佳变量以及适用于分割的截止点。变量和截止值的决定基于“杂质”的计算，这意味着目标是在分割后在每个亚组中实现最大的相似性/同质性。为了测量分类设置中的杂质，我们使用了 [*基尼指数*](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) 和 [*熵*](https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain) *(信息增益)。另一个关键问题是何时停止分裂，你可能想知道为什么我们不开发整个树，然后问题就解决了？两个主要原因是，首先，根据数据，由于数据大小和变量数量，树可能太大而无法生长，因此最终分类器的复杂性会使该过程不具成本效益；第二，更重要的原因是，一个复杂的树将遭受“过度拟合”，从而在推广到看不见的数据时表现不佳。然而，如果树太一般，它将遭受高方差，也就是说，我们在过度拟合的风险和预测的高方差的风险之间进行权衡。为了找到这种平衡，我们通常按照中的定义生长一棵非常大的树，然后"**修剪**"它以找到一棵最优的子树。这篇文章不会探索如何最好地保持平衡，如果你对这个话题感兴趣，媒体出版物[对数据科学](https://towardsdatascience.com/)应该可以让你开始。决策树(或购物车)有其优点和缺点。对于支持者来说，决策树很容易解释，并且在训练之后，预测过程很快，并且计算量很小；决策树还告诉我们哪些变量对预测是重要的——只要看一下用哪些变量来构建决策树就知道了。决策树的缺点也是显而易见的，正如我提到的，复杂的树会有过度拟合的问题，而简单的树会导致高方差。*

**b .逻辑回归**

逻辑回归模型有一个**响应变量 Y，它是分类的**和允许我们根据一个或多个预测变量(Xs)来估计分类响应的概率。它允许人们说预测因子的存在以特定的百分比增加(或减少)了给定结果的概率。逻辑回归比最常用的线性回归更适合信用欺诈检测问题的原因是，虽然正常的线性回归可以给出定量响应，但它不适用于定性响应，并且线性回归将产生低于或高于 1 的值的预测，但违约/欺诈的概率应该在 1 和 0 之间，因此，线性回归的结果是不合理的。逻辑回归在某种程度上更有意义，因为它的响应变量总是落在范围[0，1]内。逻辑回归估计值的**系数**在**对数优势标度上表征了预测变量和响应变量之间的**关系**。**

**c .随机森林**

随机森林是一种 **ensemble** 学习方法，意思是算法训练多个学习者，让他们一起解决同一个问题。在随机森林的情况下，基本学习器是决策树，它被称为随机森林，因为它训练多个去相关的“树”，从而成为“森林”。随机森林被称为“随机的”,它不同于决策树，因为它引入了两个随机成分。第一个随机部分是引入了 bootstrap 采样，这意味着用于生长每棵树的数据互不相同，因此与仅使用单棵树相比，减少了方差，并且可以显著提高准确性。这个过程也被称为“装袋”。随机森林引入的第二个随机部分是考虑每个决策节点/分割中的变量。Bagging tress 会考虑数据集中的每一个输入变量，并选择减少杂质最多的一个，但这导致了这样的情况:虽然每棵树都在使用不同的数据进行生长，但它们的结构会彼此相对相似，不同树的结果会彼此高度相关。随机森林引入了**分裂变量随机化**来解决**树相关性**的问题，这意味着每次随机森林为决策节点搜索分裂变量时，它只考虑独立变量的随机子集，而不是使用所有独立变量。两个随机组件的引入导致了出包性能的提高，这意味着随机森林通常表现良好，并且在使用看不见的数据进行测试时将显著优于单个决策树。当然，随机森林也有缺点。使用大型数据集训练随机森林将需要很长时间，尤其是如果想要训练森林中的大量树木。此外，最常提到的一个缺点是，与前面提到的其他算法相比，随机森林的可解释性较差。

**d .梯度推进机**

梯度提升也是一种集成学习方法。它不同于随机森林-随机森林使用多棵树来生成预测，而增强使用弱模型作为基础模型，并构建连续的弱模型来改进以前的模型，但当这些弱模型组合时，它们通常会生成一个幂模型，并可以实现高精度。GBM 的基本思想是，它首先将一个向基数倾斜的模型与数据相适应。它通常是一个“弱模型”，通常是一个决策树。下一步是拟合另一个弱学习器，以从第一次预测的残差中学习(残差=实际值-预测值)，并且我们将这个新的弱学习器添加到先前的基础模型中。继续将弱学习者添加到先前的模型中，直到我们达到某一水平或某些标准告诉我们停止。如果没有在正确的位置停止，梯度推进也可能导致过拟合问题，并且决定何时停止也是调整模型时的重要步骤。

# **五、绩效指标**

**答:基于阈值的指标**

典型的欺诈检测问题将依赖于对欺诈或真实交易概率的预测，这意味着机器学习模型将仅产生欺诈案件的可能性，而不是预测真实或欺诈，在这种情况下，为确定类别设置适当的阈值是重要的。这可能很棘手，因为如果我们将阈值设置得太高，许多潜在的高风险欺诈性交易将不会被标记为欺诈性交易，从而导致很高的假阴性率；另一方面，如果我们将阈值设置得太低，这意味着我们的标准太严格，我们会将许多低风险交易误分类为欺诈交易，导致高假阳性率，并增加后期调查过程的负担。

在我们设置了阈值 I 之后，分类的结果可以被总结在一个被称为混淆矩阵的 2 乘 2 的表中。列上是实际的类，行上是预测的案例。看起来像下图。

![](img/ea0a1a065a03df65c6387e9fc95fba05.png)

混淆矩阵的一个例子

在表中，有四种可能的结果，

TN:真阴性，其中分类器正确预测真实交易

TP:真阳性，分类器正确预测欺诈交易

FP:假阳性，即分类器错误地将真实交易预测为欺诈交易

FN:假阴性，即分类器错误地预测欺诈交易为真实交易

许多度量可以从混淆矩阵中导出，例如，最直接的度量是平均误分类误差(MME)。MME 的计算方法是不正确预测的总和除以数据集的大小。虽然很直观，但对于信用卡欺诈检测来说，这是一个误导性的指标。请记住，数据集本身是高度不平衡的，这意味着欺诈性交易将远远少于真实交易，但在 MME 的计算中，给予假阴性和假阳性的权重是相同的。这与现实生活中两个欺诈案例的错误分类与两个真实案例的错误分类不同的情况相矛盾。一个简单的例子可以更清楚地说明这一点。想象一个有 100 笔交易的数据集，其中只有 2 笔交易是欺诈性的。我们在这里测试的两个不同的阈值是 1 和 0.3。第一个意味着模型预测所有交易都是真实的，因此，它仅错误分类了两种情况(两个假阴性),并且具有 2%的 MME 如果第二个正确地预测了 2 个欺诈性交易，但是错误地将两个真实案例预测为欺诈性的(两个假阳性)，MME 仍然是 2%。基于 MME，这两种情况是一样的但是我们都知道第一种完全没用。

除了 MME，我们还可以从混淆矩阵中获得其他基于阈值的度量。查看**列**，可以有**真阳性率**和**真阴性率**。这两个矩阵的分母是列的和，一个是所有真实案例的和，另一个是所有欺诈案例的和。

***TPR = Recall/sensitivity = TP/P(全部欺诈)= TP/(TP + FN)***

它测量被正确识别的营养成分的比例。

*TNR = TN / N(全正版)= TN / (TN + FP)*

它衡量被正确识别的正版的比例。

也可以计算它们的互补度量，

*假阳性率(FPR) = 1 — TNR*

它衡量的是被错误识别为欺诈的正版的比例。

*假阴性率(FNR) = 1 — TPR*

它衡量被错误识别为真实交易的欺诈交易的比例。

我们也有行方式的度量。对于逐行度量，分母将是预测的真实和预测的欺诈的总和。

**精度= TP / (TP + FP) = TP / P_hat(预测为欺诈)**

它测量被预测为欺诈的类别的正确比例。

其他行方式的度量没有那么重要，为了避免更多的混淆，我现在不会提到它们。

由于这里的业务问题是 CCFD 问题，并且数据是高度不平衡的，所以被称为 F1-score 的度量被认为适合于这里的不平衡问题。其定义为:

f1-得分= 2 *(精确度*召回)/(精确度+召回)

所有上述措施只有在我们有了混淆矩阵之后才可用，这意味着需要一个确定的阈值。

**b .无阈值指标**

如果我们不能为混淆矩阵确定一个适当的阈值，情况会怎样？如何评估分类器的结果和性能？评估阈值范围的无阈值指标在这种情况下会有所帮助。最常用的两个指标是接收操作特性(ROC)曲线和查准率-召回率(PR)曲线。

1.  **AUC ROC**

ROC 是[0，1]中所有阈值的 TPR 与 FPR 曲线。我们可以看到，在所有的点上，实心黑线都在断开的背线上，这意味着 K 线(黑线)支配着 W 线(虚线)，在这种情况下，K 线是明显的赢家。在不存在支配关系的情况下，我们使用曲线下面积(AUC)来衡量性能。对角灰线的 AUC 为 0.5，对所有情况进行随机猜测的分类器将具有该灰线的 ROC 曲线。

![](img/c3ce1329d6c2a92767cf4f858975a16f.png)

ROC 曲线的一个例子

**2 .精度-召回曲线(PR 曲线)**

ROC 是所有阈值[0，1]的精度与 TPR(召回)的关系图。此指标的优势在于，它有助于选择同时具有高真阳性率和高精度的分类器。与 AUC ROC 类似，曲线本身有时不是我们可以用来比较分类器的最直接的度量，对于 RP 曲线，我们可以使用平均精度。AP 定义如下:

> 我们将使用平均精确度(AP)，其将这样的图概括为在每个阈值处实现的精确度的加权平均值，而从前一阈值的召回增加被用作权重[ [BEP13](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_References/bibliography.html#id40) 、 [FZ11](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_References/bibliography.html#id39) 。
> 
> AP =∑(R _ n-R _ n-1)↉Pn
> 
> 其中 Pn 和 Rn 是在第 n 个阈值处的精确度和召回率。

**3 .精密顶级 K 指标**

此方法主要涉及公司调查欺诈检测系统发出的警报的能力。假设公司调查人员可以检查的最大警报数为 K，则指标按以下方式计算:

d 天的 Precision top-k 真正数的警报数/ K

该指标被称为 precision top-k，因为它按欺诈概率降序排列交易，并且只计算前 K 个交易的精度。假设 K 为 100，如果在 d 天，前 100 个最高欺诈风险交易中有 25 个交易被分类器标记为欺诈，则 d 天的精度 top-k 为 0.25

与 Precision top-k 类似，我们也可以将卡 Precision top-k 作为一个有用的指标。这里的想法是，我们使用账户/卡作为单位，而不是交易。要实现这一点，只需修改前面的指标。我们可以将卡精度 top-k 作为账户/卡上真正肯定的警报数量/ K，其中 K 是调查人员一天可以检查的客户 ID 的数量。交易的排序过程变成了客户 ID 的排序，其中分配给每个账户的风险是记录在客户 ID 下的交易的最大欺诈概率。

# 不及物动词尾注

总结信用卡欺诈检测问题的完整过程并不是一件容易的事情，这篇文章也绝不是对这个主题的全面覆盖。然而，这篇文章至少应该为初学者指出在该领域进一步研究的方向。这个帖子的大部分内容是来自《信用卡欺诈检测机器学习手册 的 [*的内容、我对这个主题的理解以及我的一些课堂笔记的混合，如果你发现帖子中的任何错误或有任何问题，请不要犹豫地评论！*](https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook)

# **七世。参考**

1.  用于信用卡欺诈检测的机器学习——实用手册

```
@book{leborgne2021fraud,
title={Machine Learning for Credit Card Fraud Detection - Practical Handbook},
author={Le Borgne, Yann-A{\"e}l and Bontempi, Gianluca},
url={https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook},
year={2021},
publisher={Universit{\'e} Libre de Bruxelles}
}
```

2.维多利亚·普里西拉和帕德玛·普拉巴。信用卡欺诈检测:系统综述。在*信息、通信和计算技术国际会议*，290–303。斯普林格，2019。

3.张，中恒。2016.*决策树建模使用 r .*转化医学年报 4 (15)。