# 我的数据科学之旅

> 原文：<https://medium.com/codex/my-journey-into-data-science-46642a676d1c?source=collection_archive---------11----------------------->

![](img/80bc19c5be0954e1585c4aa8df84c909.png)

美国国家航空航天局的漫游车“好奇号”和“机遇号”在我们太阳系非常著名的火星着陆。我总是很好奇想看看他们的图像、动作和落地技术。但是，这种好奇心是为了看到现代科学的冒险和魔力。我是一名计算机科学的学生，并试图了解它的现代技术。我一直在思考漫游者在现代信息技术中的作用。我总是在想一些问题，比如他们会送什么给 NASA，他们如何适应现代计算机科学等等。我访问了美国宇航局的网站，并了解到那些漫游者将发送与地质条件相关的数据或信息，如大范围的岩石和土壤，水，微生物生命等。

> 美国宇航局好奇号火星车的数据让我好奇，因为知道了机遇号火星车在数据科学中寻求机遇的愿景。

# 数据管道让我兴奋不已

通过应用 Python、Pandas、NumPy 等的代码，我开始处理不同的数据集。我开始对数据应用不同的技术，如数据清理、整形、聚合、同步，以查询不同来源的数据，处理结构化和非结构化数据，推入不同的数据源，可视化等。

在一次会议上，我从一位高效熟练的团队成员那里了解到了数据管道。现代数据管道的概念让我很好奇，也很有趣。作为个人贡献者，团队成员为我提供了学习、设计和实施的机会。我开始学习，并努力在短时间内高效地达到以下技能:

*   数据管道的体系结构和概念
*   数据管道的重要性和实时性
*   像 Apache Airflow、Domino Data Lab 等作业自动化工具。
*   自动气象站红移和 S3 水桶。
*   REST API 消费机制。
*   Bash 脚本。
*   与数据管道中的几个组件和数据源集成。
*   内存在处理作业和大量数据时的重要性。
*   数据管道将如何向 ML 模型提供数据？

现在，我是设计高效数据管道架构的专家。

# 高效的 Python 脚本将我从不眠之夜中拯救出来

我学会了编写高效的 Python 脚本以及不同的库，如 Pandas、NumPy、Flask 等。我为数据科学项目编写了几个脚本，并将它们与自动化作业代理集成在一起。管道中的那些作业代理高效地执行，并按照要求执行它们的操作。

我在下面提到的数据科学脚本中学习并实现了几种技术:

*   数据清理和重复数据消除
*   数据聚合、整形、连接和合并
*   标准化数据
*   数据编码
*   处理 CSV、excel 和其他数据源

# 机器学习模型向我展示了数据清理的重要性

数据清洗是机器学习数据科学的一个重要步骤，因为在现代世界中，数据可以是结构化的，也可以是非结构化的。机器学习模型期望高度准确的训练数据集，否则你就不能指望良好的评分和准确性。

我学会了通过给观察值或行添加有意义的标签或类来标记数据。这些标签可以来自观察或询问人们或专家的数据。

数据清理对企业来说也非常重要，因为它通常保存着关于企业、员工、顾客或客户等的大量重要信息。因此，我们必须确保企业的个人信息安全有序。

# 了解分析和可视化的重要性

分析是与数据科学相关的，它依赖于数据。它用于分析原始数据以推断信息。因此，学习了自动化原始数据的方法，以便企业或专家可以应用分析和可视化数据。

我开始了解数据分析师的职责:

*   数据解释、分析和应用统计技术。
*   保持统计效率和质量。
*   从主要和次要数据源获取数据并维护数据库。

# 结论

数据科学非常重要，它通过应用统计、机器学习、深度学习等多种技术，成功地为所有商业模式增值。我开始了我的数据科学之旅，并通过努力工作和奉献精神取得了许多成就。