<html>
<head>
<title>Implementing “Multi-Variable Linear Regression” algorithm in Python.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现“多元线性回归”算法。</h1>
<blockquote>原文：<a href="https://medium.com/codex/implementing-multi-variable-linear-regression-algorithm-in-python-46fe50f31e5d?source=collection_archive---------4-----------------------#2021-04-06">https://medium.com/codex/implementing-multi-variable-linear-regression-algorithm-in-python-46fe50f31e5d?source=collection_archive---------4-----------------------#2021-04-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f398d1445be2a514571068439e24d6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6CpP2r5m1gMVxVxM"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">潘卡杰·帕特尔在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="a60b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习算法在过去十年中获得了巨大的普及。今天，这些算法被用于各种数据处理和预测的多个工作领域。</p><p id="08d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本教程中，我们将实现最基本的机器学习算法，称为“<strong class="ix hj"><em class="jt"/></strong>”。如果我们用一行文字来描述线性回归，大概是这样的:</p><blockquote class="ju"><p id="155a" class="jv jw hi bd jx jy jz ka kb kc kd js dx translated"><strong class="ak"> <em class="ke">“通过您的数据点拟合一条直线</em>”</strong></p></blockquote><p id="709c" class="pw-post-body-paragraph iv iw hi ix b iy kf ja jb jc kg je jf jg kh ji jj jk ki jm jn jo kj jq jr js hb bi translated">这是一个有监督的机器学习算法。如果你想了解无监督算法，<a class="ae iu" href="https://writersbyte.com/datascience/implementing-k-means-clustering-with-k-means-initialization-in-python/" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="9595" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本教程将包括<strong class="ix hj"> 3个主要部分</strong>:</p><p id="7222" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">逐步理解和实现算法。</p><p id="675a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将构建的算法应用于二维数据(为了更好的可视化)。</p><p id="91e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对n维数据应用算法。</p><p id="e0d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">* *本教程中使用的全部代码可以在下面的</strong> <a class="ae iu" href="https://github.com/Moosa-Ali/Linear-Regression-Implementation.git" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> GitHub库</strong> </a> <strong class="ix hj"> **中找到。</strong></p><p id="c3cd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们开始吧。</p><h1 id="0de1" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">分步实施</strong></h1><h2 id="bda7" class="li kl hi bd km lj lk ll kq lm ln lo ku jg lp lq ky jk lr ls lc jo lt lu lg lv bi translated"><strong class="ak">基本理解</strong></h2><p id="0ffc" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">正如我们之前所讨论的，线性回归就像在我们的数据上拟合一条直线一样简单，因此为了基本的理解，我们需要重温一些基本的数学知识，看看直线的方程。</p><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/f9a62469817fc1fc422bc00a5bad43e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*v4kTY9F6QfVYg3OiVq5emg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">直线的方程式</figcaption></figure><p id="eb3b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上式中，<strong class="ix hj"> <em class="jt"> X </em> </strong>和<strong class="ix hj"> <em class="jt"> Y </em> </strong>为数据点，<strong class="ix hj"> <em class="jt"> m </em> </strong>和<strong class="ix hj"> <em class="jt"> c </em> </strong>分别为斜率和Y轴截距。我们需要'<strong class="ix hj"> m </strong>'和'<strong class="ix hj"> c </strong>'的适当值，以便创建一条适当的直线。</p><p id="1827" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设我们有多个值'<strong class="ix hj"> <em class="jt"> X </em> </strong>'，我们有一个单独的'<strong class="ix hj"> <em class="jt"> Y </em> </strong>'，那么我们可以改变上面的等式来创建一个更一般的等式，如下所示:</p><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/33493a064f5bc93f2e81fc77b3dd4452.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*3jTXA3zoyXVjNL7vrPBn9w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">n变量线性方程</figcaption></figure><p id="70ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们需要的不是m和c，而是c和从a_0到a_n的所有系数，这就是多元线性回归的完整概念。</p><h2 id="109b" class="li kl hi bd km lj lk ll kq lm ln lo ku jg lp lq ky jk lr ls lc jo lt lu lg lv bi translated"><strong class="ak">实施</strong></h2><p id="69ff" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们将需要以下基本数学功能和可视化库。</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="a21b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们定义一个函数，它将从c和a的一些给定值中返回Y的预测值(习惯上称为<strong class="ix hj"> Y-hat </strong>)</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="a885" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们需要计算我们离y的原始值有多远。用机器学习的术语来说，这叫做计算<strong class="ix hj">成本</strong>。定义了几种不同的成本函数，但对于我们的情况，我们将使用传统的"<strong class="ix hj">均方误差"</strong>。<strong class="ix hj"> MSE </strong>的作用是:</p><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/590b16395221ac5bdd4792a199153070.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*ZiqXGLT-sSYTvVnXYa0BkQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">计算均方误差的公式</figcaption></figure><p id="8ab9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们把这个编码下来:</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="9244" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的目标是最小化由上述函数计算的成本，以便尽可能接近原始值。</p><p id="cc9c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为此，我们需要了解我们的每个参数如何影响总成本。这可以通过<strong class="ix hj"> <em class="jt">计算每个参数的变化率来实现，也称为梯度</em> </strong>。这些方程式是:</p><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/3706c5451c1b6cfbceb1170f9767cbd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*cfWJ7wu2swge8XUYgvcfrw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">关于偏差和系数的梯度</figcaption></figure><p id="29f6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了使成本最小化，我们需要进行一个叫做<strong class="ix hj">“梯度下降”</strong>的过程。下图显示了相对于参数值绘制的特定参数的成本。为了达到最小的成本，我们必须改变我们的参数值，这就是我们的更新方程使用的地方。</p><figure class="mc md me mf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/ee9111798be5960033417bf7eb940f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrFZV7pKPcc5dzLaWvngtQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来源:<a class="ae iu" href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png" rel="noopener ugc nofollow" target="_blank">http://rasbt . github . io/mlx tend/user _ guide/general _ concepts/gradient-optimization _ files/ball . png</a></figcaption></figure><p id="775d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更新我们的参数值的最终等式如下，</p><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/db44d9ed4fdb3d011e648853f6a12146.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*6xMv5giplODPR_TndQ0SpA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">更新相关参数的方程式</figcaption></figure><p id="5354" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上式中的<strong class="ix hj">α</strong>称为<strong class="ix hj"> <em class="jt">学习率。</em> </strong>其值需要优化设置，过小的值会使参数更新非常缓慢，过大的值会导致更新后的参数过冲，永远不会收敛到全局最小值。</p><p id="9811" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们以通用方式编码这些更新方程，使得n个参数可以被更新。</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="3d8c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有了所有的函数，我们只需要创建一个调用这些函数的训练例程，以最小化成本并找到合适的参数。</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h1 id="61f4" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">测试</strong></h1><p id="78c7" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">现在是时候测试我们的算法了。我们将首先在一个更简单的数据集上进行测试。数据集可以从<a class="ae iu" href="https://www.kaggle.com/andonians/random-linear-regression?select=train.csv" rel="noopener ugc nofollow" target="_blank">这里</a>免费下载。数据的过滤和可视化步骤在下面执行。</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="mc md me mf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/46251d4632acd24633e9f826a64df286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ppjuq1wTXJpWOXz4RObOQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">样本数据值</figcaption></figure><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/3603e53b1b5b12e83eaec735a078ca4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*_m9DZ-hmlRwqlPhhJE0EZg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">这些数据似乎有一个清晰的线性关系，因此它将为我们提供一个很好的洞察我们的算法如何工作。</figcaption></figure><p id="5ceb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用<strong class="ix hj">最小-最大缩放技术</strong>对数据进行标准化。让我们为最小-最大缩放定义一个函数。(有几个库可以帮你做到这一点，但是编写代码更有趣)</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><pre class="mc md me mf fd mo mp mq mr aw ms bi"><span id="d241" class="li kl hi mp b fi mt mu l mv mw">data_scaled = min_max_scaler(data_train)</span></pre><p id="76fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">标准化完成后，我们可以开始在模型上拟合数据。</p><pre class="mc md me mf fd mo mp mq mr aw ms bi"><span id="3b5e" class="li kl hi mp b fi mt mu l mv mw">X_train = data_scaled["x"].values.reshape(-1,1)<br/>y_train = data_scaled["y"].values.reshape(-1,1)<br/>coeff, intercept, preds = fit(X_train, y_train, iterr = 3000)</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/6c0a880cb8a7df8f087ca0c2383ef53e.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*hRiNmfEOw9vdybjTNCHu5w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">最后成本</figcaption></figure><p id="4248" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们运行我们的过程3000次迭代。我们的最终损失是一个非常低的值，所以我们可以说这是一个很好的拟合。让我们想象一下结果。</p><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es my"><img src="../Images/8bf78aaeb6bb31898758c6a3991872fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*WL9nQBmYbJjKDUUqojJSfg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">适合训练数据</figcaption></figure><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/e75d1f252ca487b71fae3e272e91a103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*ElUTqRmk-ZCv4EibvecAhA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">符合测试数据</figcaption></figure><p id="c31f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，我们的模型在训练集上非常准确，在测试集上也相当不错。如果对模型进行更多迭代训练，结果可能会有所改善。(实验由你决定😀)</p><p id="cf21" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">测试检查我们模型的另一个好方法是<strong class="ix hj"><em class="jt">【R平方值】</em> </strong>也称为<strong class="ix hj"> <em class="jt">【拟合优度】。为此，我们将使用sklearn库(因为有时你会厌倦编码😅).</em></strong></p><pre class="mc md me mf fd mo mp mq mr aw ms bi"><span id="bc12" class="li kl hi mp b fi mt mu l mv mw"><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.metrics</strong> <strong class="mp hj">import</strong> r2_score  <br/>print("R_square Score:",r2_score(data_test["y"],y_pred))</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es na"><img src="../Images/3d162a4fca5a92d657fec04e36bdf2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*SKkWo6jsZgjgDzqGh-KHLQ.png"/></div></figure><p id="8669" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的分数表明<strong class="ix hj"> 92.6%的拟合优度</strong>是一个相当好的数字。</p><h1 id="b651" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">对n维数据的测试</strong></h1><p id="4b47" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">现在来看看我们的算法是否真的适用于n维数据。为此，我们使用了<strong class="ix hj"> <em class="jt">房价数据集</em> </strong>。(原始数据集有许多特征，但我们只选择了其中的几个进行测试)</p><figure class="mc md me mf fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="50a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于大多数特征都是<em class="jt">字符串</em>类型，我们将它们转换成数字标签。</p><figure class="mc md me mf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/534ded7a211ebc47ce70683f89e9a7b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XJQ_EJRYKbFPwmsxx3WczA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">房价数据集</figcaption></figure><p id="a711" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们像以前一样标准化数据集，并将其设置为训练2000个时期。</p><pre class="mc md me mf fd mo mp mq mr aw ms bi"><span id="cfe9" class="li kl hi mp b fi mt mu l mv mw">weights, biases, y_predicted = fit(X_train,y_train, iterr = 2000)</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/f4012d2287a4977a890b97a7c1a950be.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*kBN0E90zvyRv1pjxf4P-hg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">住房数据的最终成本</figcaption></figure><p id="f34c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所料，最终的成本还是很低。现在让我们检查一下"<strong class="ix hj"> <em class="jt"> R的平方值</em> </strong>"</p><pre class="mc md me mf fd mo mp mq mr aw ms bi"><span id="30df" class="li kl hi mp b fi mt mu l mv mw"><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.metrics</strong> <strong class="mp hj">import</strong> r2_score<br/>print(r2_score(y_test,predicted))</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/3450376337ed5f29e056304b601ed3ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*p9KkKAtT9FWUz9XxUeog9g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">27.9%的拟合优度</figcaption></figure><p id="9293" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">拟合优度</em>似乎很低，这可能有多种原因；运行算法进行更多次迭代可能会增加分数，或者随着输入参数数量的增加，数据的复杂性也会增加，因此数据之间很难存在线性关系。</p><h1 id="199f" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">结论</strong></h1><p id="d4cf" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们已经使用<strong class="ix hj"> Python </strong>成功实现了<strong class="ix hj">线性回归</strong>算法，并在我们的初始数据集上实现了相当好的拟合。我们在第二个(多变量)数据集上没有得到很好的分数，因为如此复杂的数据集很难遵循线性趋势。对于像这样的数据集，有诸如“<strong class="ix hj">多项式回归</strong>或<strong class="ix hj"> SVM </strong>的算法。这些算法稍微复杂一点，但是它们获得了好得多的分数。</p></div></div>    
</body>
</html>