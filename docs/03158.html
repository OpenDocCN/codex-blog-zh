<html>
<head>
<title>Nonspecific streaming data pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非特定流数据管道</h1>
<blockquote>原文：<a href="https://medium.com/codex/nonspecific-streaming-data-pipelines-71d8ff2227ed?source=collection_archive---------16-----------------------#2021-08-20">https://medium.com/codex/nonspecific-streaming-data-pipelines-71d8ff2227ed?source=collection_archive---------16-----------------------#2021-08-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d649" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想与大家分享的主题是关于多用途流数据管道的配置。其背后的主要思想是将现有的“*nix”核心组件与第三方应用程序有效集成，以创建一个可靠且易于维护的数据收集和处理基础架构。</p><h2 id="56cb" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">高级架构:逻辑块</h2><p id="8fc5" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">下图从左至右显示了与流数据管道相关的通用功能。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kd"><img src="../Images/a027c69a4cad674da65cd20b9b6a83ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*qkCTYyjtxDCR12mjIdg34g.jpeg"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">流式数据管道</figcaption></figure><p id="0a0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们简单地放大一下它们:</p><ul class=""><li id="86d4" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated"><strong class="ih hj">查询</strong>:这是指从特定来源收集信息的实际行为。通常，会涉及SNMP或IPFIX/Netflow等标准化协议，并且会采用数据轮询或数据推送策略(或两者都采用)。然而，我想指出的是，将数据传送到收集站点的动作也可以通过多种其他方式实现(有时是非传统的):例如让<a class="ae ky" href="https://man.openbsd.org/openrsync.1" rel="noopener ugc nofollow" target="_blank"> rsync </a>定期将数据转储到收集站点的预定义文件夹中。</li><li id="b79b" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><strong class="ih hj">格式化</strong>:为了便于以后的数据处理，以结构化的方式对即将到来的信息进行格式化是非常有效的。(最终添加一些像时间戳这样的关键字段)。</li><li id="bd00" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><strong class="ih hj">操作</strong>(可选):可能需要根据特定的需求来操作字段值的选择。例如，您可能希望对传输信息应用一些数学函数。</li><li id="72aa" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><strong class="ih hj">排队/存储</strong>:流式数据按照其语义进行消费和分类，并根据您的数据保留要求准备存储。</li><li id="f32f" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><strong class="ih hj">可视化</strong>:最后但同样重要的是，你现在可以定义你的<strong class="ih hj">K</strong>ey<strong class="ih hj">P</strong>performance<strong class="ih hj">I</strong>indicators并可视化地表示它们。</li></ul><h2 id="c17d" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">深入的特定用例描述</h2><p id="6eeb" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">主要出于稳定性原因，我应该能够持续监控超过30K MPLS CPEs的CPU和内存水平，主要是CISCO IOS和IOS-XE设备。下面我将描述我是如何将上述<a class="ae ky" href="#header1" rel="noopener ugc nofollow">通用函数</a>应用到这个特定用例中的。我将包括对所用工具及其主要配置的简短描述。</p><p id="cceb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="le">为了完整起见，我想强调的是，下面的配置只是示例，不一定100%符合特定的使用情形。</em></p><h2 id="0586" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">SNMP(v3)轮询器</h2><p id="f0d0" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">由于规模原因，串行收集性能指标不是一个可行的选择，这就是为什么我决定使用<a class="ae ky" href="https://pysnmp.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> pysnmp的API</a>&amp;<a class="ae ky" href="https://docs.python.org/3.7/library/asyncio.html" rel="noopener ugc nofollow" target="_blank">asyncio框架</a>来开发一个并发的<a class="ae ky" href="https://github.com/scuzzilla/snmp-poller" rel="noopener ugc nofollow" target="_blank"> snmp-poller </a>。</p><p id="e4aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SNMP(v3)轮询器基本上是在<a class="ae ky" href="#querying" rel="noopener ugc nofollow">‘查询’</a>通用函数中完成的。它的使用非常简单，它的帮助在某种程度上是自我注释的:</p><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="eb6a" class="jd je hi lg b fi lk ll l lm ln">SHELL$./snmp-poller.py -h<br/>usage: snmp-poller.py [-h] -s &lt;SNMPv3 parameters&gt; -l &lt;hostname/IPv4 list&gt; -o SNMP oid list<br/><br/>SNMP Poller<br/><br/>optional arguments:<br/>  -h, --help            show this help message and exit<br/><br/>mandatory arguments:<br/>  -s &lt;SNMPv3 parameters&gt;<br/>                        load the SNMPv3 required parameters from the selected file (YAML format)<br/>  -l &lt;hostname/IPv4 list&gt;<br/>                        load the hosts from the selected file (CSV format)<br/>  -o SNMP oid list      load the oid list from the selected file (YAML format)</span></pre><p id="82cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应该提供三个强制输入:</p><ul class=""><li id="b921" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">YAML文件包含SNMPv3的验证/加密参数以及发起轮询请求的IP地址。</li></ul><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="b8a1" class="jd je hi lg b fi lk ll l lm ln">---<br/>userName: nix<br/>authKey: nix1234567<br/>privKey: nix1234567<br/>localAddress: 192.168.122.1</span></pre><ul class=""><li id="8e7b" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">要轮询的SNMP oid列表(最终关联到特定的主机组)。</li></ul><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="b58d" class="jd je hi lg b fi lk ll l lm ln">---<br/>GRP_A:<br/>  - oid0: 1.3.6.1.4.1.9.9.109.1.1.1.1.8.1<br/>  - oid1: 1.3.6.1.4.1.9.9.48.1.1.1.6.1<br/>GRP_B:<br/>  - oid0: 1.3.6.1.4.1.9.9.109.1.1.1.1.8.7<br/>  - oid1: 1.3.6.1.4.1.9.9.221.1.1.1.1.20.7000.1<br/>  - oid2: 1.3.6.1.4.1.9.9.109.1.1.1.1.19.7</span></pre><ul class=""><li id="ca23" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">要轮询的主机列表(最终按组划分)。</li></ul><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="f373" class="jd je hi lg b fi lk ll l lm ln">host1,A,<br/>host2,A,<br/>host3,B,<br/>host4,A,</span></pre><p id="bc42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SNMP(v3)轮询器可以根据特定的轮询要求作为cron作业方便地执行。</p><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="585d" class="jd je hi lg b fi lk ll l lm ln">SHELL$ crontab -l<br/><br/>SHELL=/bin/sh<br/>*/1 * * * * . /snmp-poll/bin/activate &amp;&amp; /snmp-poll/snmp-poll.py -s /snmp-poll/data/nix_snmp_data.yml -l /snmp-poll/csv/nix_records.csv -o /snmp-poll/data/nix_oids_data.yml &gt;&gt; /snmp-poll/logs/snmp-poll-app.log 2&gt;&amp;1</span></pre><h2 id="a8ff" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">Rsyslog</h2><p id="acdd" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">默认情况下，SNMP(v3)轮询器将收集的指标发送到<a class="ae ky" href="https://datatracker.ietf.org/doc/html/rfc5424" rel="noopener ugc nofollow" target="_blank"> syslog </a>工具<strong class="ih hj"> local1 </strong>。</p><p id="cefc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每一个相关的组，接收到的信息包括过去五分钟内CPU的整体繁忙百分比和仍然可用的内存量，以及其他一些信息字段。</p><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="8b58" class="jd je hi lg b fi lk ll l lm ln"># --- code snippet from snmp-poller.py --- #<br/><br/>json_structure = {<br/>   "device":                     str(host),<br/>   "snmp_data_grp":              str(records[host]),<br/>   "poller_instance":            str("snmp-poll-mpls-cpe"),<br/>   "a_oid0_cpmCPUTotal5minRev":  None,<br/>   "a_oid1_ciscoMemoryPoolFree": None,<br/>   "b_oid0_cpmCPUTotal5minRev":  None,<br/>   "b_oid1_cpmCPUMemoryHCFree":  None,<br/>   "b_oid2_cempMemPoolHCFree":   None<br/>}<br/><br/>if len(varBinds) == MAX_OIDS_GRP_A:<br/>    json_structure['a_oid0_cpmCPUTotal5minRev'] = int(varBinds[0][1])<br/>    json_structure['a_oid1_ciscoMemoryPoolFree'] = int(varBinds[1][1])<br/>elif len(varBinds) == MAX_OIDS_GRP_B:<br/>    json_structure['b_oid0_cpmCPUTotal5minRev'] = int(varBinds[0][1])<br/>    json_structure['b_oid1_cpmCPUMemoryHCFree'] = int(varBinds[1][1])<br/>    json_structure['b_oid2_cempMemPoolHCFree'] = int(varBinds[2][1])<br/><br/>syslog.openlog(facility=syslog.LOG_LOCAL1)<br/>syslog.syslog(json.dumps(json_structure, indent=2))</span></pre><p id="bddc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此时，我们已经免除了<a class="ae ky" href="#formatting" rel="noopener ugc nofollow">‘Formatting’</a>通用函数:流数据现在用JSON结构进行整形。然而，在流出到<a class="ae ky" href="#manipulating" rel="noopener ugc nofollow">“操纵”</a>逻辑块之前，我想执行数据浓缩，以完全符合syslog标准格式。</p><p id="ea76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Rsyslog是一个非常强大的工具，它允许定义模板，这些模板可以用来改进我们的数据流。正如您可以验证的那样，定义的模板保留了JSON格式，并添加了一些其他重要的字段，包括时间戳。</p><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="b5ea" class="jd je hi lg b fi lk ll l lm ln">root@collector:/etc/rsyslog.d# cat 01-syslog-facilities.conf <br/><br/>template(name="json-syslog-facilities"<br/>  type="list") {<br/>    constant(value="{")<br/>      constant(value="\"timestamp\":\"")      property(name="timereported" dateFormat="unixtimestamp")<br/>      constant(value="\",\"message\":\"")     property(name="msg" format="json")<br/>      constant(value="\",\"sysloghost\":\"")  property(name="hostname")<br/>      constant(value="\",\"severity\":\"")    property(name="syslogseverity-text")<br/>      constant(value="\",\"facility\":\"")    property(name="syslogfacility-text")<br/>      constant(value="\",\"programname\":\"") property(name="programname")<br/>      constant(value="\",\"procid\":\"")      property(name="procid")<br/>    constant(value="\"}\n")<br/>}</span></pre><p id="21b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">丰富的数据可以传送到<a class="ae ky" href="https://www.elastic.co/logstash/" rel="noopener ugc nofollow" target="_blank"> logstash </a>，它正在UDP端口10515监听传入的连接。</p><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="ace1" class="jd je hi lg b fi lk ll l lm ln">root@collector:/etc/rsyslog.d# cat 20-snmp-poll.conf <br/><br/>local1.* @127.0.0.1:10515;json-syslog-facilities</span></pre><h2 id="1a35" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">Logstash</h2><p id="be32" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">logstash配置在逻辑上可以分为三个部分:输入、过滤和输出。</p><ul class=""><li id="2e59" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated"><strong class="ih hj">输入</strong> : logstash正在监听127.0.0.1:10515 (UDP)的传入连接，接收到的数据用JSON编码&amp;并用“snmp”标签标记。如你所料，标签是用来唯一识别数据流的。</li></ul><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="c83b" class="jd je hi lg b fi lk ll l lm ln">input {<br/>  udp {<br/>   host =&gt; "127.0.0.1"<br/>   port =&gt; 10515<br/>   codec =&gt; "json"<br/>   type =&gt; "snmp"<br/>  }<br/>}</span></pre><ul class=""><li id="df53" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated"><strong class="ih hj">过滤器</strong>:实际的<a class="ae ky" href="#manipulating" rel="noopener ugc nofollow">【操纵】</a>通用函数在这里发生。由于之前添加的标签，我可以很容易地选择我想要执行一些特定操作的数据流。Logstash提供了大量现成的过滤函数，但是对于非常特殊的用例，您最终可以使用<a class="ae ky" href="https://www.ruby-lang.org/en/" rel="noopener ugc nofollow" target="_blank"> Ruby </a>编程语言编写自己的函数。</li></ul><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="9112" class="jd je hi lg b fi lk ll l lm ln">filter {<br/>  if [type] == "snmp" {<br/>    mutate { <br/>      gsub =&gt; [ "message", '#012', '' ]<br/>      convert =&gt; { "timestamp" =&gt; "integer" }<br/>    }   <br/>    json {<br/>      source =&gt; "message"<br/>      remove_field =&gt; "message"<br/>    }   <br/>  }<br/>}</span></pre><ul class=""><li id="2727" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated"><strong class="ih hj">输出</strong>:选择的数据现在被输出到Kafka。因为信息是AVRO编码的，所以作为第一步，我必须首先注册相关的AVRO模式。目前，标准的<a class="ae ky" href="https://www.elastic.co/guide/en/logstash/current/plugins-codecs-avro.html" rel="noopener ugc nofollow" target="_blank"> Logstash的AVRO编解码器</a>不包含任何将模式注册到远程模式注册表的选项。幸运的是，这个函数包含在一个名为<a class="ae ky" href="https://github.com/revpoint/logstash-codec-avro_schema_registry" rel="noopener ugc nofollow" target="_blank">Logstash Codec-Avro Schema Registry</a>的第三方插件中。</li></ul><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="b0d6" class="jd je hi lg b fi lk ll l lm ln">output {<br/>  if [type] == "snmp" {<br/>    kafka {<br/>      topic_id =&gt; "lab.dev.snmp-avro"<br/>      codec =&gt; avro_schema_registry {<br/>        endpoint =&gt; "https://schema-registry.net:443"<br/>        schema_uri =&gt; "/etc/logstash/kafka/avsc/collectors_snmp.avsc"<br/>        subject_name =&gt; "lab.dev.snmp-avro-value"<br/>        register_schema =&gt; true<br/>      }   <br/>      bootstrap_servers =&gt; "lab.kafka.net:9093"<br/>      security_protocol =&gt; SSL <br/>      ssl_keystore_location =&gt; "/etc/logstash/kafka/snmp-poll-keystore.jks"<br/>      ssl_keystore_password =&gt; "kafka123"<br/>      ssl_truststore_location =&gt; "/etc/logstash/kafka/snmp-poll-truststore.jks"<br/>      ssl_truststore_password =&gt; "kafka123"<br/><br/>      value_serializer =&gt; "org.apache.kafka.common.serialization.ByteArraySerializer"<br/>    }<br/>  }<br/>  stdout { codec =&gt; rubydebug }<br/>}</span></pre><h2 id="d834" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">卡夫卡/德鲁伊</h2><p id="132e" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">此时，数据流已准备好接受<a class="ae ky" href="#queuing_storing" rel="noopener ugc nofollow">“排队&amp;存储”</a>通用函数的“处理”。</p><p id="3dc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在不深入Kafka/Druid技术细节的情况下，我能说的是数据流被转发到Kafka的集群中配置的<strong class="ih hj">主题</strong>。使用卡夫卡的术语，我们可以把Logstash定义为生产者，而德鲁伊是消费者，T21。</p><p id="d02f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">定义的AVRO模式隐式地执行一种数据验证，因为每个字段的数据类型都是严格编码的。</p><pre class="ke kf kg kh fd lf lg lh li aw lj bi"><span id="45bf" class="jd je hi lg b fi lk ll l lm ln">{<br/>  "name": "CollectorsSNMP",<br/>  "type": "record",<br/>  "namespace": "org.alfanetti.datapipelines",<br/>  "fields": [<br/>    {<br/>      "name": "device",<br/>      "type": "string"<br/>    },<br/>    {<br/>      "name": "snmp_data_grp",<br/>      "type": "string"<br/>    },<br/>    {<br/>      "name": "poller_instance",<br/>      "type": "string"<br/>    },<br/>    {<br/>      "name": "timestamp",<br/>      "type": "long"<br/>    },<br/>    {<br/>      "name": "a_oid0_cpmCPUTotal5minRev",<br/>      "type": ["int", "null"]<br/>    },<br/>    {<br/>      "name": "a_oid1_ciscoMemoryPoolFree",<br/>      "type": ["long", "null"]<br/>    },<br/>    {<br/>      "name": "b_oid0_cpmCPUTotal5minRev",<br/>      "type": ["int", "null"]<br/>    },<br/>    {<br/>      "name": "b_oid1_cpmCPUMemoryHCFree",<br/>      "type": ["long", "null"]<br/>    },<br/>    {<br/>      "name": "b_oid2_cempMemPoolHCFree",<br/>      "type": ["long", "null"]<br/>    }<br/>  ]<br/>}</span></pre><p id="34b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">潜在地，在这个阶段，我们还可以在Kafka级别执行额外的在途数据操作，实现特定的处理作业。然而，在这个特定的用例中，这是不必要的。</p><h2 id="449f" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">在枢轴上转动</h2><p id="81e8" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">Pivot由<a class="ae ky" href="https://imply.io/" rel="noopener ugc nofollow" target="_blank"> Imply </a>开发，这是一家在数据分析领域极具前景的科技公司。有了Pivot，我可以轻松地使用不同的图形表示来“可视化”我的数据，其中包括表格、折线图和直方图。</p><p id="249e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了清楚起见，我决定使用所谓的“网格”格式来可视化MPLS CPEs的CPU级别。根据CPE所属的组来可视化数据。在这种情况下，分类的主要驱动因素是CPE的操作系统和硬件模型。</p><ul class=""><li id="50bd" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">CPU级别—属于A组的CPE:</li></ul><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es lo"><img src="../Images/73d437b3731c5ad1b9107ec8e05062aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*73lFbqIQPxPfKFNJrfBBXQ.jpeg"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">CPU级别—属于A组的CPE</figcaption></figure><ul class=""><li id="8a67" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">CPU级别—属于B组的CPE:</li></ul><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="ab fe cl lp"><img src="../Images/adef1070aed6fb226a74c0e5ebacc406.png" data-original-src="https://miro.medium.com/v2/0*fC9JB0e_KYB82Uc3"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">CPU级别—属于B组的CPE</figcaption></figure><p id="7924" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你可以想象的那样，对于记忆水平，完全相同的可视化可以很容易地创建。</p><h2 id="a0ce" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">参考资料和资源</h2><h2 id="e128" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">克隆和测试</h2><ul class=""><li id="a0df" class="kp kq hi ih b ii jy im jz iq lq iu lr iy ls jc ku kv kw kx bi translated"><a class="ae ky" href="https://github.com/scuzzilla/snmp-poller" rel="noopener ugc nofollow" target="_blank"> SNMP(v3)轮询器</a></li></ul><h2 id="aef3" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">证明文件</h2><ul class=""><li id="2b4a" class="kp kq hi ih b ii jy im jz iq lq iu lr iy ls jc ku kv kw kx bi translated"><a class="ae ky" href="https://www.rsyslog.com/doc/v8-stable/" rel="noopener ugc nofollow" target="_blank"> Rsyslog </a></li><li id="46e8" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><a class="ae ky" href="https://www.elastic.co/guide/en/logstash/current/index.html" rel="noopener ugc nofollow" target="_blank"> Logstash </a></li><li id="fd22" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><a class="ae ky" href="https://github.com/revpoint/logstash-codec-avro_schema_registry" rel="noopener ugc nofollow" target="_blank">日志存储编解码器AVRO(模式注册表)</a></li><li id="a266" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><a class="ae ky" href="https://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">卡夫卡</a></li><li id="ed54" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><a class="ae ky" href="https://avro.apache.org/docs/current/" rel="noopener ugc nofollow" target="_blank"> Avro模式定义</a></li><li id="dd4c" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><a class="ae ky" href="https://druid.apache.org/docs/latest/design/index.html" rel="noopener ugc nofollow" target="_blank">德鲁伊</a></li><li id="1310" class="kp kq hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><a class="ae ky" href="https://docs.imply.io/latest/pivot-overview/" rel="noopener ugc nofollow" target="_blank">枢轴</a></li></ul></div></div>    
</body>
</html>