<html>
<head>
<title>Async Support for TensorFlow Backend in FFmpeg</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FFmpeg中TensorFlow后端的异步支持</h1>
<blockquote>原文：<a href="https://medium.com/codex/async-support-for-tensorflow-backend-in-ffmpeg-695998cd439c?source=collection_archive---------10-----------------------#2021-08-19">https://medium.com/codex/async-support-for-tensorflow-backend-in-ffmpeg-695998cd439c?source=collection_archive---------10-----------------------#2021-08-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="fa2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇博文总结了我的<strong class="ih hj">谷歌代码2021之夏</strong>项目和<strong class="ih hj">英特尔Linux视频和音频</strong>。这个夏天充满了大量的实践学习，一些我无法想象的事情。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/dff54d78450a4e4f27301bd67356562a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXMbXgg4ZLFUh6q5F16OuQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">谷歌代码2021之夏，英特尔视频和音频Linux版</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="4feb" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">该项目</h2><p id="f248" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">该项目主要致力于在<strong class="ih hj"> FFmpeg深度神经网络</strong> (DNN)模块的后端实现一个异步推理机制，尽管它也有其他可选的可交付成果。您可以点击查看原提案<a class="ae la" href="https://docs.google.com/document/d/1J79_Id4XDYfMSJh94q11kHm1SjewYoLAOEX15uwNkhU/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="f23a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">DNN模块有三个主要过滤器:</p><ol class=""><li id="1b77" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lg lh li lj bi translated"><code class="du lk ll lm ln b"><strong class="ih hj">vf_dnn_processing</strong></code>用于使用深度学习模型应用过滤器</li><li id="f0d7" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><code class="du lk ll lm ln b"><strong class="ih hj">vf_dnn_detect</strong></code>用于物体检测</li><li id="ca51" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><code class="du lk ll lm ln b"><strong class="ih hj">vf_dnn_classify</strong></code>用于图像分类</li></ol><p id="595f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有另外两种滤镜——<code class="du lk ll lm ln b">vf_sr</code>(用于超分辨率滤镜)和<code class="du lk ll lm ln b">vf_derain</code>(用于去雨滤镜)，不过为了使用完整的功能<code class="du lk ll lm ln b">vf_dnn_processing</code>应该是首选。</p><h2 id="e33a" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">技术堆栈</h2><p id="8d16" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">当任何人看到一个项目时，他们问的第一件事就是它建立在什么样的技术基础上。在我的例子中，项目完全是用C语言<strong class="ih hj"><em class="lt"/></strong>编写的，并使用了用于多线程的<em class="lt"/><strong class="ih hj"><em class="lt">pthread</em></strong>库。</p><h2 id="ceed" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated"><strong class="ak">交付成果</strong></h2><ol class=""><li id="a5c9" class="lb lc hi ih b ii kv im kw iq lu iu lv iy lw jc lg lh li lj bi translated"><strong class="ih hj">准备异步支持(必需)</strong> —我们切换到基于任务的机制，其中每个任务对应一个输入帧，为异步模式做准备。这种方法现在在所有三个后端中都很常见。</li><li id="a9aa" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><strong class="ih hj">TensorFlow后端中的异步支持(必需)——</strong>最初，tensor flow后端仅支持模型推理的同步模式。</li><li id="7fd5" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><strong class="ih hj">从过滤器的角度统一执行模式(可选)</strong> —目前，后端为过滤器中使用的异步和同步模式提供不同的功能。有了这个可交付的产品，选择执行模式的控制权就在后端了。该交付成果还将进一步帮助扩展同步模式下的批处理执行模式。</li><li id="8999" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><strong class="ih hj">原生后端的异步支持(可选)——</strong>当目标系统不支持OpenVino或TensorFlow后端时，原生后端用于模型推断。这个后端也只支持同步模型执行，但是我们可以使用相同的机制将异步支持扩展到本地后端。</li><li id="44fb" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><strong class="ih hj">tensor flow后端支持批处理模式(可选)——</strong>将多个图像帧作为单个批处理加载，并立即推断它们，在系统上比逐个处理所有帧的开销更低。如果与异步模式结合使用，为模型推理启用批量推理将显著提高TensorFlow后端的性能。</li></ol><h2 id="b03d" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">项目中完成的工作</h2><p id="f364" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">以下拉式请求包含与此项目相关的工作。每个拉请求在其描述中都包含与补丁程序集相关的提交列表。</p><ol class=""><li id="7a4b" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lg lh li lj bi translated"><a class="ae la" href="https://github.com/intel-media-ci/ffmpeg/pull/407" rel="noopener ugc nofollow" target="_blank">对TensorFlow后端的异步支持</a></li><li id="e486" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><a class="ae la" href="https://github.com/intel-media-ci/ffmpeg/pull/423" rel="noopener ugc nofollow" target="_blank">异步和同步模式的统一</a></li><li id="6a61" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><a class="ae la" href="https://github.com/intel-media-ci/ffmpeg/pull/425" rel="noopener ugc nofollow" target="_blank">对本地后端的异步支持</a></li><li id="1d2a" class="lb lc hi ih b ii lo im lp iq lq iu lr iy ls jc lg lh li lj bi translated"><a class="ae la" href="https://github.com/intel-media-ci/ffmpeg/pull/427" rel="noopener ugc nofollow" target="_blank">tensor flow后端批量执行</a></li></ol><blockquote class="lx ly lz"><p id="7f01" class="if ig lt ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj">什么是完整的？</strong>截至提交时，所有必需的交付件已完全合并，可选交付件已准备就绪，可供审查。</p></blockquote><p id="c801" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除了这个项目的这些主要补丁，我还贡献了一些文档给本地后端层函数，并修复了后端中的一些小的内存泄漏，可以在这里查看<a class="ae la" href="https://git.ffmpeg.org/gitweb/ffmpeg.git/search?s=Shubhanshu+Saxena;st=author" rel="noopener ugc nofollow" target="_blank"/>。为了改进错误处理，我们从这个补丁集中的<a class="ae la" href="https://github.com/intel-media-ci/ffmpeg/pull/438" rel="noopener ugc nofollow" target="_blank">DNN后端返回特定的错误代码。</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/5380d30ccdec77c4235e5f2e25b875fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08qvR2R2UK31MOrkcXco1Q.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">我的合并补丁FFmpeg DNN模块。<a class="ae la" href="https://bit.ly/3mdeluB" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3mdeluB</a></figcaption></figure><blockquote class="lx ly lz"><p id="6c65" class="if ig lt ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj">为什么拉取请求被关闭而不是被合并？</strong> <br/>这是因为导师们审查了GitHub上的PR，英特尔CI测试也在GitHub上运行，以检查补丁是否正常工作。然后补丁被发送到FFmpeg邮件列表进行最终审查，然后补丁被合并。</p></blockquote><h2 id="1099" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">异步推理背后的思想</h2><p id="9344" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">让我在这里给出一点背景。DNN后端使用TensorFlow C API和OpenVINO推理引擎来加载和执行深度学习模型。</p><p id="dda4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在同步模式下，它们调用<code class="du lk ll lm ln b">ff_dnn_execute_model</code>函数，输入帧期待一个输出帧返回。在异步模式下，过滤器使用<code class="du lk ll lm ln b">ff_dnn_execute_model_async</code>发送输入帧，后端开始推理并返回成功。重复该过程，直到所有帧都被发送到后端。在特定时间，最多可以同时执行<code class="du lk ll lm ln b">nireq</code>个异步请求。</p><p id="9939" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在过滤器开始为输出帧调用<code class="du lk ll lm ln b">ff_dnn_get_async_result</code>。这个函数按顺序返回后端接收到的帧，而不管推断何时完成。</p><p id="e455" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，由于TensorFlow C API不像OpenVINO那样提供任何异步函数，我们不得不实现一种机制，使模型推断与主FFmpeg过滤器线程异步发生。</p><p id="5d6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们添加了<code class="du lk ll lm ln b">DNNAsyncExecModule</code>，它在不同的线程上从后端执行<code class="du lk ll lm ln b">RequestItem</code>。该线程在开始同一<code class="du lk ll lm ln b">RequestItem</code>的后续推理之前加入。如果最后一次推理失败，退出状态被捕获，我们取消当前会话的所有进一步执行。</p><blockquote class="lx ly lz"><p id="ee46" class="if ig lt ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj">为什么要加入线程？我们不能拆开这些线吗？早先的计划是使用分离的线程，但是为了扩展对Windows构建的支持和更好的错误处理，我们转向使用可连接的线程。</strong></p></blockquote><h2 id="a291" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">结果</h2><p id="e55b" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">TensorFlow后端显示了异步补丁集应用程序的性能提升。对于一个2GB内存的普通GPU来说，CPU版本的改进可能比TensorFlow C API的GPU版本更大。</p><p id="41d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此<a class="ae la" href="https://git.ffmpeg.org/gitweb/ffmpeg.git/commit/0985e9283ca2fe85dd0744f97c869bf24fbf14b5" rel="noopener ugc nofollow" target="_blank">补丁</a>中记录了四核CPU上的CPU变体在10秒视频中仅使用异步模式所带来的性能提升。</p><h2 id="6cc2" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">信用</h2><p id="7749" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">我要感谢谷歌和GSoC团队为我提供了这个绝佳的机会。我要真诚地感谢导师郭，他在整个项目过程中给予了指导，并帮助我消除了我的疑虑。特别感谢导师Ting Fu对patchset的测试以及英特尔媒体团队的支持。</p></div></div>    
</body>
</html>