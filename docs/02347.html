<html>
<head>
<title>Distributed Training On Multiple GPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多个GPU上的分布式培训</h1>
<blockquote>原文：<a href="https://medium.com/codex/distributed-training-on-multiple-gpus-e0ee9c3d0126?source=collection_archive---------6-----------------------#2021-07-14">https://medium.com/codex/distributed-training-on-multiple-gpus-e0ee9c3d0126?source=collection_archive---------6-----------------------#2021-07-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="58ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着数据规模和模型规模的不断增大，训练会花费大量的时间，尤其是对于单个GPU。因此，有必要使用多个GPU来加速训练处理。</p><p id="a5e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di">在</span>这篇博文中，我将首先介绍分布式训练的理论基础，然后分<code class="du jm jn jo jp b">nn.DataParallel</code>和<code class="du jm jn jo jp b">nn.DistributedDataParalllel</code>两种方式用PyTorch在多个GPU上实现分布式训练。</p><h1 id="76b6" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">理论基础</h1><h2 id="ac60" class="ko jr hi bd js kp kq kr jw ks kt ku ka iq kv kw ke iu kx ky ki iy kz la km lb bi translated">训练循环</h2><p id="80f3" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">首先，让我们回顾一下训练神经网络通常是如何工作的。训练神经网络时，每个循环都有四个主要步骤:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lh"><img src="../Images/1ef1bbe96e25b935fef9a222953e8a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*i9X0moskmOR-Qgrj_5r-wg.gif"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">梯度下降优化算法的5个步骤。由<a class="ae lx" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> HuggingFace </a>创建的图像</figcaption></figure><ol class=""><li id="35a7" class="ly lz hi ih b ii ij im in iq ma iu mb iy mc jc md me mf mg bi translated">正向传递，其中输入由神经网络处理；</li><li id="a5e9" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc md me mf mg bi translated">计算损失函数，将预测标签与地面实况标签进行比较；</li><li id="e5e7" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc md me mf mg bi translated">完成反向传递，基于损耗计算每个参数的梯度(使用反向传播)；<code class="du jm jn jo jp b">loss.backward()</code></li><li id="090b" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc md me mf mg bi translated">使用梯度更新参数。<code class="du jm jn jo jp b">optimizer.step()</code></li></ol><h2 id="d88c" class="ko jr hi bd js kp kq kr jw ks kt ku ka iq kv kw ke iu kx ky ki iy kz la km lb bi translated">模型并行和数据并行</h2><ul class=""><li id="71c4" class="ly lz hi ih b ii lc im ld iq mm iu mn iy mo jc mp me mf mg bi translated"><strong class="ih hj">模型并行</strong>:不同的GPU输入相同的数据，运行模型的不同部分，比如一个多层网络的不同层；</li><li id="802f" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc mp me mf mg bi translated"><strong class="ih hj">数据并行</strong>:不同的GPU输入不同的数据，运行相同的完整模型。</li></ul><p id="8ded" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当模型非常大，一个GPU已经无法存储时，可以使用模型并行将模型的不同部分分配到不同的机器上，但是这样会带来很大的通信开销。而且模型的并行部分有一定的依赖性，可扩展性差。所以当一个模型可以放在一个模型上时，通常采用数据并行，各部分独立，扩展性好。</p><h2 id="bf94" class="ko jr hi bd js kp kq kr jw ks kt ku ka iq kv kw ke iu kx ky ki iy kz la km lb bi translated">同步更新和异步更新</h2><p id="6c22" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">对于数据并行，由于每个GPU负责一部分数据，所以涉及到更新参数的问题，可以分为同步更新和异步更新两种方法。</p><ul class=""><li id="6e8c" class="ly lz hi ih b ii ij im in iq ma iu mb iy mc jc mp me mf mg bi translated"><strong class="ih hj">同步更新</strong>:每批所有GPU计算完成后，统一计算新的权重，然后所有GPU同步新值，再进行下一轮计算。</li><li id="f71b" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc mp me mf mg bi translated"><strong class="ih hj">异步更新</strong>:每个GPU计算完梯度后，无需等待其他更新，整体权重立即更新同步。</li></ul><p id="d165" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同步更新有等待时间，速度取决于最慢的GPU异步更新没有等待时间，但是当遇到更复杂的梯度时，就会出现丢包和抖动大的问题。因此，在实践中，一般采用同步更新的方法。</p><h2 id="346d" class="ko jr hi bd js kp kq kr jw ks kt ku ka iq kv kw ke iu kx ky ki iy kz la km lb bi translated">参数服务器和环AllReduce</h2><p id="5085" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">假设我们有N个GPU:</p><ul class=""><li id="e0a9" class="ly lz hi ih b ii ij im in iq ma iu mb iy mc jc mp me mf mg bi translated"><strong class="ih hj">参数服务器</strong> : GPU 0(作为Reducer)将数据分成五份，分配给各个GPU。每个GPU负责自己的小批量训练。<strong class="ih hj"> <em class="mq">得到渐变后，返回GPU 0进行累加，得到更新后的权重参数。</em> </strong>然后分发到各个GPU。</li><li id="66b9" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc mp me mf mg bi translated"><strong class="ih hj"> Ring AllReduce </strong> : N个GPU连接成一个环。每个GPU都有一个左侧通道和一个右侧通道。一个负责接收，一个负责发送。<strong class="ih hj"> <em class="mq">循环(N-1)次(分散减少)完成梯度累加，循环(N-1)次(全部聚集)再次同步更新参数。</em>T11】</strong></li></ul><blockquote class="mr ms mt"><p id="2b19" class="if ig mq ih b ii ij ik il im in io ip mu ir is it mv iv iw ix mw iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">参数服务器有两个缺点</em> </strong></p></blockquote><ol class=""><li id="3078" class="ly lz hi ih b ii ij im in iq ma iu mb iy mc jc md me mf mg bi translated">每一轮训练迭代都需要所有GPU同步数据，并在结束前进行缩减。当并行GPU较多时，木桶效应会非常严重，计算效率较低。</li><li id="7230" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc md me mf mg bi translated">所有GPU都需要与Reducer进行数据、梯度和参数通信。当模型很大或者数据很大时，通信开销很高。</li></ol><p id="116b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设有N个GPU，通信一个完整参数所需的时间为K，那么使用PS架构，花费的通信开销为<strong class="ih hj"> <em class="mq"> T = 2(N-1)K </em> </strong>。</p><p id="40d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di"> T </span>参数服务最大的问题是通信开销与GPU的数量成线性关系。Ring AllReduce的通信开销与GPU数量无关。环形全部减少分为两步:<strong class="ih hj"> <em class="mq">分散减少和全部聚集</em> </strong>。</p><ul class=""><li id="b6c0" class="ly lz hi ih b ii ij im in iq ma iu mb iy mc jc mp me mf mg bi translated"><strong class="ih hj">分散减少</strong>:首先我们把参数分成N份，相邻的GPU传递不同的参数。通过N-1次后，就可以得到各部分参数的累加(在不同的GPU上)。</li></ul><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mx"><img src="../Images/41f0e43807b9d0f54eeb2a849616f7eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*RZCutf2YGx5vkmzGhgWISg.gif"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated"><strong class="bd js">分散减少</strong></figcaption></figure><ul class=""><li id="4751" class="ly lz hi ih b ii ij im in iq ma iu mb iy mc jc mp me mf mg bi translated"><strong class="ih hj">全部聚集</strong>:得到每个参数的累积后，再做一遍，同步到所有GPU。</li></ul><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es my"><img src="../Images/58437d45f99a0665c51e0857325c0355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*yd80V119leyH2FV10l1vNw.gif"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated"><strong class="bd js">全体集合</strong></figcaption></figure><p id="6218" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据这两个过程，我们可以计算出环AllReduce的通信代价为<strong class="ih hj"> <em class="mq"> T = 2(N-1)K/N </em> </strong>。</p><h1 id="6b3a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">PyTorch示例</h1><ul class=""><li id="ec58" class="ly lz hi ih b ii lc im ld iq mm iu mn iy mo jc mp me mf mg bi translated"><strong class="ih hj"> DataParallel (DP) </strong>:参数服务器模式，一个GPU就是一个reducer，实现也超级简单，一行代码。</li><li id="058c" class="ly lz hi ih b ii mh im mi iq mj iu mk iy ml jc mp me mf mg bi translated"><strong class="ih hj">DistributedDataParallel(DDP)</strong>:All-Reduce模式，原本是为了分布式训练，但也可以用于单机多GPU。</li></ul><h2 id="fe4d" class="ko jr hi bd js kp kq kr jw ks kt ku ka iq kv kw ke iu kx ky ki iy kz la km lb bi translated">数据并行</h2><pre class="li lj lk ll fd mz jp na nb aw nc bi"><span id="eaef" class="ko jr hi jp b fi nd ne l nf ng">if torch.cuda.device_count() &gt; 1:<br/>    print("Let's use", torch.cuda.device_count(), "GPUs!")<br/>    # only one line of code<br/>    model = nn.DataParallel(model)</span></pre><p id="d409" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="mq">运行命令:</em> </strong></p><pre class="li lj lk ll fd mz jp na nb aw nc bi"><span id="2a85" class="ko jr hi jp b fi nd ne l nf ng">python train.py</span></pre><h2 id="8b0b" class="ko jr hi bd js kp kq kr jw ks kt ku ka iq kv kw ke iu kx ky ki iy kz la km lb bi translated">分布式数据并行</h2><pre class="li lj lk ll fd mz jp na nb aw nc bi"><span id="457a" class="ko jr hi jp b fi nd ne l nf ng">'''Only five steps'''</span><span id="8dc7" class="ko jr hi jp b fi nh ne l nf ng"><em class="mq"># 1) Initialize the backend of computation</em></span><span id="190b" class="ko jr hi jp b fi nh ne l nf ng">torch.distributed.init_process_group(backend="nccl")</span><span id="58ce" class="ko jr hi jp b fi nh ne l nf ng"><em class="mq"># 2） </em>Configure the gpu of each process</span><span id="ef6a" class="ko jr hi jp b fi nh ne l nf ng">local_rank = torch.distributed.get_rank()<br/>torch.cuda.set_device(local_rank)<br/>device = torch.device("cuda", local_rank)</span><span id="e990" class="ko jr hi jp b fi nh ne l nf ng"><em class="mq"># 3）Use DistributedSampler to distribute data to each gpu </em></span><span id="6f4b" class="ko jr hi jp b fi nh ne l nf ng">from torch.utils.data.distributed import DistributedSampler<br/>sampler = DistributedSampler(dataset)<br/>data_loader = DataLoader(dataset=dataset,<br/>                         batch_size=batch_size,<br/>                         sampler=sampler)</span><span id="121e" class="ko jr hi jp b fi nh ne l nf ng"># 4<em class="mq">）</em>Move the model to each gpu</span><span id="e613" class="ko jr hi jp b fi nh ne l nf ng">model.to(device)</span><span id="ada8" class="ko jr hi jp b fi nh ne l nf ng"># 5<em class="mq">）</em>Wrap up model</span><span id="dac0" class="ko jr hi jp b fi nh ne l nf ng">if torch.cuda.device_count() &gt; 1:<br/>    print("Let's use", torch.cuda.device_count(), "GPUs!")<br/>    model = torch.nn.parallel.DistributedDataParallel(model,device_ids=[local_rank],output_device=local_rank)</span></pre><p id="7f76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="mq">运行命令:</em> </strong></p><pre class="li lj lk ll fd mz jp na nb aw nc bi"><span id="cf3b" class="ko jr hi jp b fi nd ne l nf ng">CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 train.py</span></pre><p id="3a8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="mq">完整的DDP示例代码:</em> </strong></p><figure class="li lj lk ll fd lm"><div class="bz dy l di"><div class="ni nj l"/></div></figure><h1 id="f33e" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">参考</h1><p id="f4f9" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi">【分布式训练】单机多卡的正确打开方式（一）：理论基础 — Nicolas的文章 — 知乎 <a class="ae lx" href="https://zhuanlan.zhihu.com/p/72939003" rel="noopener ugc nofollow" target="_blank">https://zhuanlan.zhihu.com/p/72939003</a></p><p id="1612" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">【分布式训练】单机多卡的正确打开方式（三）：PyTorch <a class="ae lx" href="https://fyubang.com/2019/07/23/distributed-training3/" rel="noopener ugc nofollow" target="_blank">https://fyubang.com/2019/07/23/distributed-training3/</a></p><p id="d1c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lx" href="https://towardsdatascience.com/how-to-scale-training-on-multiple-gpus-dae1041f49d2" rel="noopener" target="_blank">https://towards data science . com/how-to-scale-training-on-multi-GPU-da e1041 f 49d 2</a></p><p id="794a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lx" rel="noopener" href="/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255">https://medium . com/hugging face/training-large-batches-practical-tips-on-1-GPU-multi-GPU-distributed-settings-EC 88 C3 e 51255</a></p><p id="65cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lx" href="https://pytorch.org/docs/master/generated/torch.nn.DataParallel.html?highlight=dataparallel#torch.nn.DataParallel" rel="noopener ugc nofollow" target="_blank">https://py torch . org/docs/master/generated/torch . nn . data parallel . html？highlight = data parallel # torch . nn . data parallel</a></p><div class="nk nl ez fb nm nn"><a href="https://pytorch.org/docs/master/generated/torch.nn.parallel.DistributedDataParallel.html#distributeddataparallel" rel="noopener  ugc nofollow" target="_blank"><div class="no ab dw"><div class="np ab nq cl cj nr"><h2 class="bd hj fi z dy ns ea eb nt ed ef hh bi translated">分布式数据并行- PyTorch 1.9.0文档</h2><div class="nu l"><h3 class="bd b fi z dy ns ea eb nt ed ef dx translated">class torch . nn . parallel . distributed data parallel(module，device_ids=None，output_device=None，dim=0…</h3></div><div class="nv l"><p class="bd b fp z dy ns ea eb nt ed ef dx translated">pytorch.org</p></div></div></div></a></div></div></div>    
</body>
</html>