<html>
<head>
<title>How to Deal With Pagination in Python Step-by-Step Guide [Full Code]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何处理Python分步指南中的分页[完整代码]</h1>
<blockquote>原文：<a href="https://medium.com/codex/how-to-deal-with-pagination-in-python-step-by-step-guide-full-code-6c4f4ef3be84?source=collection_archive---------11-----------------------#2022-02-17">https://medium.com/codex/how-to-deal-with-pagination-in-python-step-by-step-guide-full-code-6c4f4ef3be84?source=collection_archive---------11-----------------------#2022-02-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4ea2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原载于<a class="ae jd" href="https://www.scraperapi.com/blog/how-to-deal-with-pagination-in-python-step-by-step-guide-full-code/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/663920e3951d4f58138fbe85a4b42ce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a0xXgwYFSegE2KOS.jpg"/></div></div></figure><p id="fff5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你正在做一个大型的网络抓取项目(比如抓取产品信息)，你可能会偶然发现分页页面。电子商务和内容网站的标准做法是将内容分成多个页面，以改善用户体验。然而，网页抓取分页给我们的工作增加了一些复杂性。</p><p id="4bda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，您将学习如何在几分钟内构建一个分页web抓取器，并且不会被任何反抓取技术所阻碍。</p><p id="9939" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管你可以在没有任何先验知识的情况下阅读本教程，但在你开始之前，最好先看看我们的<a class="ae jd" href="https://www.scraperapi.com/blog/scrapy-web-scraping/" rel="noopener ugc nofollow" target="_blank">初学者指南</a>以获得对该框架更深入的解释。</p><p id="61da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">事不宜迟，让我们直接开始吧！</p><h1 id="dab7" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">使用Python Scrapy抓取带有分页的网站</h1><p id="5644" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">对于本教程，我们将抓取<a class="ae jd" href="https://www.snowandrock.com/" rel="noopener ugc nofollow" target="_blank"> SnowAndRock </a>男式帽子类别，提取所有产品名称、价格和链接。</p><p id="53c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个小小的免责声明——我们是用Mac写这篇文章的，所以你必须做一点调整才能在PC上工作。除此之外，一切都应该是一样的。</p><p id="f75a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> TLDR:这里有一个使用“下一步”按钮在Scrapy中处理分页的快速代码片段</strong>:</p><p id="8ec3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">next_page = response.css('a[rel=next]').attrib['href']</code></p><p id="2803" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">if next_page is not None:</code></p><p id="2d1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield response.follow(next_page, callback=self.parse)</code></p><p id="cc90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请继续阅读关于如何在您的脚本中实现该代码的深入解释，以及如何在没有下一步按钮的情况下处理页面<em class="kx">。</em></p><h1 id="9e13" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">1.设置您的开发环境</h1><p id="787e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在我们开始编写任何代码之前，我们需要设置我们的环境来使用<a class="ae jd" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>，这是一个为web抓取而设计的Python库。它允许我们从网站抓取和提取数据，将原始数据解析为结构化格式，并使用CSS和/或XPath选择器选择元素。</p><p id="f76e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，让我们创建一个新目录(我们称之为pagination-scraper ),并使用命令python -m venv venv在其中创建一个python虚拟环境。其中第二个venv是您的环境的名称——但是您可以随意称呼它。</p><p id="48d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要激活它，只需输入source venv/bin/activate。您的命令提示符应该如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/b1059e785c38e69cf58804ff140a07d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ho7YP0Ikz8f1vgRg.png"/></div></div></figure><p id="11ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，安装Scrapy就像输入pip3 install scrapy一样简单——下载并安装它可能需要几秒钟。</p><p id="271f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦准备好了，我们将输入cd venv并创建一个新的Scrapy项目:<code class="du kt ku kv kw b">scrapy startproject scrapypagination</code>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/14c6b6c0b74df2a1ec89ef05b4030015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4h4nADVjkG33A8_w.png"/></div></div></figure><p id="feec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在你可以看到Scrapy通过安装所有必要的文件为我们启动了我们的项目。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/34bffaecfa4a091af2d8ffb2d8d8bcb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hzd2E2xiqgmSJWA7.png"/></div></div></figure><h1 id="114e" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">2.设置ScraperAPI以避免禁令</h1><p id="3dbd" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">处理分页页面最难的部分不是编写脚本本身，而是如何不让我们的bot被服务器阻塞。</p><p id="c338" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们需要创建一个函数(或一组函数)，在多次尝试后轮换我们的IP地址(这意味着我们还需要访问一个IP地址池)。此外，一些网站使用先进的技术，如验证码和浏览器行为分析。</p><p id="2feb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了节省我们的时间和麻烦，我们将使用ScraperAPI，这是一个API，它使用机器学习、巨大的浏览器农场、第三方代理和多年的统计分析来处理我们的脚本可能会自动遇到的每一个反机器人机制。</p><p id="ea9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最棒的是，<a class="ae jd" href="https://www.scraperapi.com/blog/web-scraping-best-practices/" rel="noopener ugc nofollow" target="_blank">在我们的项目</a>中设置ScraperAPI非常简单:</p><p id="bd4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">import scrapy</code></p><p id="36ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">from urllib.parse import urlencode</code></p><p id="8975" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">API_KEY = '51e43be283e4db2a5afb62660xxxxxxx'</code></p><p id="cf44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def get_scraperapi_url(url):</code></p><p id="d691" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">payload = {'api_key': API_KEY, 'url': url}</code></p><p id="988b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">proxy_url = 'http://api.scraperapi.com/?' + urlencode(payload)</code></p><p id="4d89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">return proxy_url</code></p><p id="a629" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如您所看到的，我们正在定义get_scraperapi_url()方法来帮助我们构造将向其发送请求的url。首先，我们在顶部添加了我们的依赖项，然后添加了包含我们的API密钥的API_KEY变量——要获得您的密钥，只需<a class="ae jd" href="https://www.scraperapi.com/signup" rel="noopener ugc nofollow" target="_blank">注册一个免费的ScraperAPI帐户</a>,您就会在您的仪表板上找到它。</p><p id="ccd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该方法将为我们的抓取器找到的每个URL的请求构建URL，这就是为什么我们这样设置它，而不是像这样直接将所有参数添加到URL中的更直接的方法:</p><p id="c47f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">start_urls = ['http://api.scraperapi.com?api_key={yourApiKey}&amp;url={URL}']</code></p><h1 id="7fc2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">3.了解网站的URL结构</h1><p id="1cb1" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">每个网站的URL结构都非常独特。开发人员倾向于使用不同的结构，以使导航更容易，在某些情况下，优化搜索引擎爬虫(如Google)和真实用户的导航体验。</p><p id="7126" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要抓取分页的内容，我们需要了解它是如何工作的，并相应地进行规划，没有比检查页面并查看URL本身如何从一个页面变化到下一个页面更好的方法了。</p><p id="bbe3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，如果我们转到<a class="ae jd" href="https://www.snowandrock.com/c/mens/accessories/hats.html" rel="noopener ugc nofollow" target="_blank">https://www.snowandrock.com/c/mens/accessories/hats.html</a>并滚动到列出的最后一个产品，我们可以看到它使用了一个编号分页和一个“下一步”按钮。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/56f4b9570651eda67f0a5e77326ab7e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*svfuu0y2FxNY-NST.jpg"/></div></div></figure><p id="e8df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个好消息，因为在每一页上选择下一页按钮将比循环浏览每一页更容易。尽管如此，让我们看看当点击第二页时URL是如何变化的。</p><p id="c839" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是我们的发现:</p><ul class=""><li id="b622" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">第1页:<a class="ae jd" href="https://www.snowandrock.com/c/mens/accessories/hats.html?page=0&amp;size=48" rel="noopener ugc nofollow" target="_blank">https://www.snowandrock.com/c/mens/accessories/hats.html?page=0 &amp; size=48 </a></li><li id="37ff" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">第2页:<a class="ae jd" href="https://www.snowandrock.com/c/mens/accessories/hats.html?page=1&amp;size=48" rel="noopener ugc nofollow" target="_blank">https://www.snowandrock.com/c/mens/accessories/hats.html?page=1 &amp; size=48 </a></li><li id="40e3" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">第3页:<a class="ae jd" href="https://www.snowandrock.com/c/mens/accessories/hats.html?page=2&amp;size=48" rel="noopener ugc nofollow" target="_blank">https://www.snowandrock.com/c/mens/accessories/hats.html?page=2 &amp; size=48 </a></li></ul><p id="8031" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，当您使用导航返回页面时，第一页的URL会发生变化，变为page=0。尽管我们将使用“下一步”按钮来导航该网站的分页，但这并不总是那么简单。</p><p id="eed7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理解这种结构将有助于我们构建一个函数来改变URL中的页面参数并将其增加1，从而允许我们在没有下一页按钮的情况下进入下一页。</p><p id="d023" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>并非所有页面都遵循相同的结构，因此请确保始终检查哪些参数发生了变化以及如何变化。</p><p id="4176" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们知道了请求的初始URL，我们可以创建一个定制的蜘蛛。</p><h1 id="9d1f" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">4.使用Start_Requests()方法发送初始请求</h1><p id="553d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">对于最初的请求，我们将创建一个蜘蛛类，并将其命名为<code class="du kt ku kv kw b">Pagi</code>:</p><p id="1fc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">class PaginationScraper(scrapy.Spider):</code></p><p id="b267" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">name = "pagi"</code></p><p id="e40f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们定义start_requests()方法:</p><p id="2aa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def start_requests(self):</code></p><p id="562c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">start_urls = ['https://www.snowandrock.com/c/mens/accessories/hats.html']</code></p><p id="7ccc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">for url in start_urls:</code></p><p id="b88e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield scrapy.Request(url=get_scraperapi_url(url), callback=self.parse)</code></p><p id="f595" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，在运行我们的脚本之后，它将把找到的每个新URL发送给这个方法，其中新URL将与<code class="du kt ku kv kw b">get_scraperapi_url()</code>方法的结果合并，通过ScraperAPI服务器发送请求，并对我们的项目进行防弹处理。</p><h1 id="26d2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">5.构建我们的解析器</h1><p id="7fed" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在用<a class="ae jd" href="https://docs.scrapy.org/en/latest/topics/shell.html" rel="noopener ugc nofollow" target="_blank"> Scrapy Shell </a>测试了我们的选择器之后，这些是我们想到的选择器:</p><p id="cd5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def parse(self, response):</code></p><p id="d339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">for hats in response.css('div.as-t-product-grid__item'):</code></p><p id="1758" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield {</code></p><p id="5395" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'name': hats.css('.as-a-text.as-m-product-tile__name::text').get(),</code></p><p id="a08f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'price': hats.css('.as-a-price__value--sell strong::text').get(),</code></p><p id="d996" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'link': hats.css('a').attrib['href'],</code></p><p id="fb40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">}</code></p><p id="9c2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你不熟悉Scrapy Shell或Scrapy，查看我们的<a class="ae jd" href="https://www.scraperapi.com/blog/scrapy-web-scraping/" rel="noopener ugc nofollow" target="_blank">完整Scrapy教程</a>可能是个好主意，在那里我们涵盖了你需要知道的所有基础知识。</p><p id="5adf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，我们基本上是选择所有包含我们想要的信息的divs】，然后提取名称、价格和产品链接。</p><h1 id="61e2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">4.让Scrapy在分页中移动</h1><p id="00c3" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">太好了！我们已经从第一页得到了我们需要的信息，现在做什么呢？嗯，我们需要告诉我们的解析器以某种方式找到新的URL，并将其发送给我们之前定义的<code class="du kt ku kv kw b">start_requests()</code>方法。换句话说，我们需要找到一个ID或类来获取next按钮内部的链接。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/7663d4f69c27aa4daef094cfcfae160b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BBSZk8rNRyeilO4_.jpg"/></div></div></figure><p id="0ccb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从技术上讲，我们可以使用类<code class="du kt ku kv kw b">‘.as-a-btn.as-a-btn--pagination as-m-pagination__item’</code>，但是幸运的是，我们有一个更好的目标:rel=next。它不会与任何其他选择器混淆，用Scrapy选择属性很简单。</p><p id="9b94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">next_page = response.css('a[rel=next]').attrib['href']</code></p><p id="ca88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">if next_page is not None:</code></p><p id="63c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield response.follow(next_page, callback=self.parse)</code></p><p id="43d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，它将在页面之间迭代，直到分页中不再有页面——所以我们不需要设置任何其他停止机制。</p><p id="13e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您一直在跟进，您的文件应该是这样的:</p><p id="17fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">import scrapy</code></p><p id="c723" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">from urllib.parse import urlencode</code></p><p id="86fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">API_KEY = '51e43be283e4db2a5afb62660xxxxxx'</code></p><p id="eb2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def get_scraperapi_url(url):</code></p><p id="d041" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">payload = {'api_key': API_KEY, 'url': url}</code></p><p id="55ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">proxy_url = 'http://api.scraperapi.com/?' + urlencode(payload)</code></p><p id="1614" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">return proxy_url</code></p><p id="a502" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">class PaginationScraper(scrapy.Spider):</code></p><p id="0766" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">name = "pagi"</code></p><p id="a828" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def start_requests(self):</code></p><p id="528f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">start_urls = ['https://www.snowandrock.com/c/mens/accessories/hats.html']</code></p><p id="103f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">for url in start_urls:</code></p><p id="9c05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield scrapy.Request(url=get_scraperapi_url(url), callback=self.parse)</code></p><p id="44d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def parse(self, response):</code></p><p id="37bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">for hats in response.css('div.as-t-product-grid__item'):</code></p><p id="a7b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield {</code></p><p id="736e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'name': hats.css('.as-a-text.as-m-product-tile__name::text').get(),</code></p><p id="4485" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'price': hats.css('.as-a-price__value--sell strong::text').get(),</code></p><p id="d6b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'link': hats.css('a').attrib['href'],</code></p><p id="2194" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">}</code></p><p id="0c1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">next_page = response.css('a[rel=next]').attrib['href']</code></p><p id="bced" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">if next_page is not None:</code></p><p id="8319" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield response.follow(next_page, callback=self.parse)</code></p><p id="6e8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它现在可以运行了！</p><h1 id="a63c" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">处理没有下一步按钮的分页</h1><p id="fe45" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">到目前为止，我们已经看到了如何构建一个web scraper，它使用next按钮内的链接在分页中移动——请记住，Scrapy实际上不能与页面进行交互，因此如果必须单击按钮才能显示更多内容，它将不起作用。</p><p id="85d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，当它不是一个选项时会发生什么呢？换句话说，我们如何在没有下一步按钮的情况下导航分页。</p><p id="94a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理解网站的URL结构就派上了用场:</p><ul class=""><li id="3022" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">第1页:<a class="ae jd" href="https://www.snowandrock.com/c/mens/accessories/hats.html?page=0&amp;size=48" rel="noopener ugc nofollow" target="_blank">https://www.snowandrock.com/c/mens/accessories/hats.html?page=0 &amp; size=48 </a></li><li id="9399" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">第二页:【https://www.snowandrock.com/c/mens/accessories/hats.html? T21】page=1 &amp; size=48 </li><li id="036d" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">第3页:<a class="ae jd" href="https://www.snowandrock.com/c/mens/accessories/hats.html?page=2&amp;size=48" rel="noopener ugc nofollow" target="_blank">https://www.snowandrock.com/c/mens/accessories/hats.html?page=2 &amp; size=48 </a></li></ul><p id="8478" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">URL之间唯一变化的是page参数，每下一页增加1。这对我们的剧本意味着什么？首先，我们必须通过添加一个新变量来改变发送初始请求的方式:</p><p id="ec69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">class PaginationScraper(scrapy.Spider):</code></p><p id="132d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">name = "pagi"</code></p><p id="04a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">page_number = 1</code></p><p id="0df1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">start_urls = ['http://api.scraperapi.com?api_key=51e43be283e4db2a5afb62660xxxxxxx&amp;url=https://www.snowandrock.com/c/mens/accessories/hats.html?page=0&amp;size=48']</code></p><p id="3e58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们还使用了ScraperAPI的直接cURL结构，因为我们只是改变了一个参数——这意味着没有必要构建一个全新的URL。这样每次它改变时，它仍然会通过ScraperAPI的服务器发送请求。</p><p id="8dd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们需要在最后改变我们的条件来匹配新的逻辑:</p><p id="8281" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">next_page = 'http://api.scraperapi.com?api_key=51e43be283e4db2a5afb62660xxxxxxx&amp;url=https://www.snowandrock.com/c/mens/accessories/hats.html?page=' + str(PaginationScraper.page_number) + '&amp;size=48'</code></p><p id="9512" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">if PaginationScraper.page_number &lt; 6:</code></p><p id="abcb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">PaginationScraper.page_number += 1</code></p><p id="70c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield response.follow(next_page, callback=self.parse)</code></p><p id="e66c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里发生的事情是，我们从<code class="du kt ku kv kw b">PaginationScraper()</code>方法中访问page_number变量来替换URL中的page参数值。</p><p id="f3fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，它将检查page_number的值是否小于6——因为在第5页之后就没有结果了。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/86853acba12e41a3f8112f42957f8da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6_SGpmnUwXIgMdfn.jpg"/></div></div></figure><p id="2fb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">只要满足条件，就会将<code class="du kt ku kv kw b">page_number</code>值加1并发送URL进行解析和抓取，以此类推，直到<code class="du kt ku kv kw b">page_number</code>为6或更大。</p><p id="9928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是没有下一步按钮的情况下抓取分页页面的完整代码:</p><p id="6c67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">import scrapy</code></p><p id="2d6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">class PaginationScraper(scrapy.Spider):</code></p><p id="ea7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">name = "pagi"</code></p><p id="6495" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">page_number = 1</code></p><p id="dca9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">start_urls = ['http://api.scraperapi.com?api_key=51e43be283e4db2a5afb62660xxxxxxx&amp;url=https://www.snowandrock.com/c/mens/accessories/hats.html?page=0&amp;size=48']</code></p><p id="297f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">def parse(self, response):</code></p><p id="2d72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">for hats in response.css('div.as-t-product-grid__item'):</code></p><p id="af52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield {</code></p><p id="797f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'name': hats.css('.as-a-text.as-m-product-tile__name::text').get(),</code></p><p id="900c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'price': hats.css('.as-a-price__value--sell strong::text').get(),</code></p><p id="15aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">'link': 'https://www.snowandrock.com/' + hats.css('a').attrib['href']</code></p><p id="c7a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">}</code></p><p id="ecd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">next_page = 'http://api.scraperapi.com?api_key=51e43be283e4db2a5afb62660fc6ee44&amp;url=https://www.snowandrock.com/c/mens/accessories/hats.html?page=' + str(PaginationScraper.page_number) + '&amp;size=48'</code></p><p id="582f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">if PaginationScraper.page_number &lt; 6:</code></p><p id="583b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">PaginationScraper.page_number += 1</code></p><p id="f0c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">yield response.follow(next_page, callback=self.parse)</code></p><h1 id="0cb3" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">包扎</h1><p id="84e2" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">无论你是在<a class="ae jd" href="https://www.scraperapi.com/blog/real-estate-web-scraping/" rel="noopener ugc nofollow" target="_blank">汇编房地产数据</a>还是<a class="ae jd" href="https://www.scraperapi.com/blog/how-to-scrape-etsy/" rel="noopener ugc nofollow" target="_blank">抓取像Etsy </a>这样的电子商务平台，处理分页都是常事，你需要准备好变得有创意。</p><p id="ecaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">替代数据已经成为世界上几乎每个行业的必备工具，拥有创建复杂高效的刮刀的能力将为您带来巨大的竞争优势。</p></div></div>    
</body>
</html>