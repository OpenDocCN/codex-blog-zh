<html>
<head>
<title>An overview into InterFaceGAN: Edit facial attributes of people using GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">界面GANs概述:使用GANs编辑人的面部属性</h1>
<blockquote>原文：<a href="https://medium.com/codex/an-overview-into-interfacegan-edit-facial-attributes-of-people-using-gans-34f2273d5941?source=collection_archive---------5-----------------------#2021-08-24">https://medium.com/codex/an-overview-into-interfacegan-edit-facial-attributes-of-people-using-gans-34f2273d5941?source=collection_archive---------5-----------------------#2021-08-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6452e3c6b1dc841e77a08492c4f414f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W1KF5ls5mHEY1Oe3mjyGfg.png"/></div></div></figure><p id="4a6d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们如何使用GANs编辑图像的语义属性？比如改变一个人的年龄或者性别，同时保留大致的脸型等属性？两幅图像的潜在向量之间的典型扭曲展示了面部特征的平滑过渡，但是多个特征纠缠在一起，并且对特定属性的精确控制几乎是不可能的。</p><p id="1785" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">尽管GANs可以生成质量惊人的图像，但在理解和操纵潜在空间方面却做得不多。以前使用GANs进行语义图像编辑的工作包括使用精心设计的损失函数、附加属性标签或特殊架构进行再训练。我们不能使用现有的高质量图像生成器来编辑给定的图像吗？正如论文所建议的，我们必须从理论和经验上理解个人面部特征是如何在潜在空间中被编码的。</p><p id="682d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/codex/how-to-edit-images-with-gans-controlling-the-latent-space-of-gans-afde630e53d1">在之前的</a>中，我们回顾了Image2StyleGAN，其中我们讨论了将给定图像映射到StyleGAN潜在空间的方法，这通常被称为GAN反转。我们将回顾一种在多个语义中解开和隔离变化的方法。该论文提出了一个由一组技术组成的流水线，以在潜在空间中解开语义级别的人脸属性，并实现对属性的精确控制。</p><p id="ef2d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇论文…</p><ul class=""><li id="8296" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">分析和测量不同的语义属性在潜在空间中是如何编码的。</li><li id="23bb" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">使用<em class="kd">子空间投影</em>解开这些语义属性。</li><li id="311a" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">提出了一种人脸编辑管道，能够改变一个属性而不影响其他属性。</li></ul><p id="6dea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://arxiv.org/pdf/2005.09635.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="kd">官方论文:InterFaceGAN:解读GANs </em> </a>学到的被解开的人脸表征</p><h2 id="cd7e" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">性能</h2><p id="d0a6" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">论文中考虑了以下<em class="kd">性质</em>😨。但是不要害怕，因为直觉很简单😆。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es le"><img src="../Images/88e29ef261d28c7739be0d5b989dbf20.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*cukN9e4php-Blmf_5afHtg.png"/></div></figure><p id="765a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">n维空间的超平面是能把原空间分开的(n-1)维子空间。例如，2D平面可以分离3D空间，1D线可以分离2D平面。</p><p id="eb66" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一个性质表明，当我们定义法向量n^T z=0的超平面时，n^T z&gt;0的向量点在超平面的特定边上。想象一个被线性方程分割的2D平面。</p><h2 id="0bdd" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">了解GAN的潜在空间</h2><p id="412c" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">GAN中的生成器可以被视为函数g: Z → X，其中Z通常是高斯分布，X是图像空间。考虑一个<em class="kd">语义空间</em> S ⊆ R^m，具有m <em class="kd">语义</em>和一个<em class="kd">语义得分函数</em> f_S: X → S，直观地，一个潜在的语义得分度量为f_S(g(z))。</p><p id="656d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该论文提出，当我们在两个潜在代码之间进行线性插值时，我们观察到图像中包含的语义的线性变化。假设只有一个语义(m=1)。考虑一个具有法向量n的超平面。我们将到样本z的“距离”定义为d(n，z) = n^T z。我们期望距离与语义得分成比例，f(g(z)) = λ d(n，z)。</p><p id="24f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据性质2，任何潜在的z ~ N (0，Id)都有可能接近给定的超平面。因此，我们可以将一个语义建模到线性子空间n中。</p><p id="887c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们考虑具有多个m&gt;1语义的一般情况。考虑s = [s_1，… s_m]作为生成图像的真实语义得分，s≈f _ s(g(z))= λn^t z其中λ是常数向量，n是包含m个分离边界的矩阵。使用基本的统计规则，我们可以计算平均值和协方差统计值，如下所示</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/1e5b652a3735dc98c5feb0b6df68e94d.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*rQS_pxTvi832LgSJurvnWA.png"/></div></figure><p id="e291" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后我们可以得出结论，s实际上是从一个正态分布s ~ N (0，σs)中采样的。直观上，对于s中的每个向量，要完全解开，σs必须是对角矩阵。(n_i)^T (n_j)也可以用来度量第I个和第j个语义之间的纠缠。</p><p id="5c37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="kd"> *n^T表示向量n的转置。</em></p><h2 id="c9f7" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">条件操纵</h2><p id="f9e0" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">假设我们找到了某个语义的决策边界n。我们用z_edit = z + αn编辑原始潜在代码z，当多个语义纠缠在一起时，编辑一个语义可以影响其他属性。例如，在n1方向上移动一个点不仅会影响属性1，还会改变属性2的距离。为了抵消这一点，本文应用<em class="kd">投影</em>使N^T N成为语义相互独立的对角矩阵。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/3ec58b245c2eeb4d09af9ed14c05d0fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*qx9cIM7bQYAtAFlEzl2X0g.png"/></div></figure><p id="047a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑具有法向量n1和n2的两个超平面，投影方向n1(n1^t N2)N2(黑色向量)改变属性1而不影响属性2。对于两个以上的属性，我们减去从原始方向(n1)到由所有条件方向构成的<em class="kd">平面上的投影。</em></p><h2 id="46f4" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">寻找语义边界</h2><p id="8772" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">如何在潜在空间中定义面部属性的语义边界？我们训练一个<strong class="is hj">线性</strong> SVM来预测给定潜在代码的某个二元语义(例如男人和女人的图像)。<strong class="is hj">线性</strong>模型本身定义了潜在空间上的超平面，并且法向量n可以从该模型中导出。</p><p id="5bd1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">潜在代码上的事实属性的标签使用在CelebA属性上训练的辅助分类器来分配。在500，000幅合成图像中，对每个标签具有最高置信度的10K图像(例如，10K男人和10K女人图像)被采样作为训练和验证集。这一过程将在第3.3节中详细说明。论文的“实施细则”。</p><h2 id="c616" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">操纵真实图像</h2><p id="a352" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">我们如何将学到的语义应用到给定的图像上，以进行编辑应用呢？这通过两种方法实现:GAN反转和进一步训练。</p><p id="4d6e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">GAN反转将目标面映射回潜在代码。这可能具有挑战性，因为gan不能捕获完整的图像分布，并且经常会丢失信息。我们在<a class="ae jo" rel="noopener" href="/codex/how-to-edit-images-with-gans-controlling-the-latent-space-of-gans-afde630e53d1?source=your_stories_page-------------------------------------">之前的</a>文章中讨论了GAN反转的一般情况和一种强大的GAN反转方法。</p><p id="0899" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在GAN反演的两种方法中，该论文使用LIA作为基于编码器的反演的基线，并搜索W+空间用于基于优化的反演，由Image2StyleGAN和其他论文提出。与基于编码器的方法相比，基于优化的方法性能更好，但速度慢得多。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/87787b749a006704e3843b8ea1b84861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXY3305bxiIb8cAJdgqY9g.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">基于GAN反转的方法</figcaption></figure><p id="f019" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一种方法是使用学习接口GAN在合成生成的成对数据集上训练<em class="kd">附加模型</em>。InterFaceGAN模型可以生成无限的高质量<em class="kd">配对</em>数据。这个想法是在生成的数据上训练一个图像到图像的翻译模型，比如pix2pixHD。为了实现连续操作，翻译模型首先学习一个相同的映射网络和一个微调到属性翻译的网络。在推断时，我们在从相同模型到微调模型的模型权重之间进行插值。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/5ee4ddb4197b07974564a3eb71c38153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-MWOpLRvru8jMIvq-1zXUg.png"/></div></div></figure><p id="e1d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种方法具有更快的推理速度和完全保留附加信息的能力，因为它消除了重建的需要。但由于pix2pixHD固有的局限性，模型无法学习到pose、微笑等较大的动作。因此，应用受到限制。</p><h2 id="ecff" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">结果和实验</h2><p id="a59e" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">在上述方法的公式中有许多假设。语义在潜在空间中真的是线性表示的吗？线性模型可以适当学习语义边界吗？每个语义子空间真的是相互独立的吗？子空间投影真的能解开复杂的语义吗？学习到的语义边界可以推广到现实世界的图像吗？这些关于假设的问题将在本节中进行评估。</p><p id="99b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，潜在空间可以被线性边界或超平面分离吗？下图显示了线性SVM的分类性能。对于验证集上的PGGAN(渐进GAN)和SyleGAN W空间，线性边界实现了约95%的准确度。这表明，对于二元语义，近似线性超平面确实存在。</p><p id="0468" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在一系列实验中，论文观察到W空间中的插值比Z空间中的插值更好。在<em class="kd">整个集合</em>上的结果是低的，因为它们包括语义不太重要的图像。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/5b03c8284d4d8562766b65615371b2c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p9O4hqS_4PBR9FZTn18tLA.png"/></div></div></figure><p id="89f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下图基于法向量直接插值一个潜在代码，没有解纠缠。我们可以清楚地看到，每个属性都被正确地应用和删除。这进一步证明了潜在空间是线性可分的，InterFaceGAN可以成功地找到分离超平面。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/063f3cc2225224e0d3e83bc2fb579249.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*xovZKRdjkAH_0mSIsE7Lcg.png"/></div></figure><p id="0a4f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们回答这个问题，这些语义边界是否推广到编辑真实图像。如果我们观察下图，结果是令人震惊的。我对模特如何学会画“强”眼镜和“弱”眼镜感到特别惊讶。GAN似乎在潜在空间中学习了一些可解释的语义。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/6adb1d5f5f8d21d1510d95b2e514eaca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-HYeVvsFMv6vMDzIpNooDw.png"/></div></div></figure><p id="3aa4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">他们观察到，当潜在样本距离边界和自然潜在分布太远时，会引入其他属性的变化。如下图中的示例所示。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/80e7836eebed010f58124542ca115a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rQpg4maE27eov9CcmXxTg.png"/></div></div></figure><p id="00da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用提出的方法，语义真的被解开了吗？为了评估语义之间的相关性，本文提出了几个度量去纠缠的方法。</p><p id="fc44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">被训练来预测属性的预测器被用于测量真实数据中两个属性之间的相关系数。这可以用来衡量两个属性之间的纠缠度。计算了合成数据的相关系数，并与实际数据的相关系数进行了比较。最后，可以使用潜在边界的法向量之间的余弦相似性。直觉上，这些方法应该能够测量解缠结。</p><p id="e727" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些方法实际上都显示出相似的结果。在下面的表格中，我们观察到某些属性之间的高度纠缠，例如年龄、性别和眼镜。我们还观察到在CelebA-HQ上训练的PGGAN和在FF-HQ上训练的StyleGAN之间的纠缠差异。我们可以在FF-HQ特有的数据中观察到一些偏差比如微笑和性别的纠结。另一个有趣的观察结果是，与z空间相比，W空间明显更清晰。然而，z空间中的这种纠缠可以通过提议的条件操作来减轻，如下图最后一行所示。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/6e56fcca44271bad5dc1c37750ea0f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzCCP3rwSUfZ9-N_NBNt7g.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">对PGGAN，CelebA-HQ的解纠缠分析</figcaption></figure><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/ce55e7d235c5227bb14aae245c460737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rwo6_oc4TILwofCPk-Ikyw.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">对StyleGAN，FF-HQ的解纠缠分析</figcaption></figure><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/43aea69106e9e73f58d7cc5fe728012b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*coFr6XYqffi5QJL_4Vf7SQ.png"/></div></div></figure><h2 id="98be" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">结论</h2><p id="418c" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">本文通过假设语义的线性变化来理解甘的潜在空间。观察的结论是，每个语义被表示为基于超平面的法向量的正态分布。通过考虑可以根据语义属性线性分离潜在空间的超平面，我们可以使用线性分类器对该超平面建模。从潜在标签到语义标签的线性SVM可以定义潜在空间中语义属性的“方向”。这是用子空间投影解开的。</p><p id="80df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在理解神经网络如何解释人脸方面，本文提出的见解非常有趣。我对投影如何能够理清各种语义感到特别震惊。</p></div></div>    
</body>
</html>