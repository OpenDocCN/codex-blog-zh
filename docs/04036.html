<html>
<head>
<title>Ch 7. Decoding Black Box of CNNs using Feature Map Visualizations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第七章。使用特征映射可视化解码CNN的黑盒</h1>
<blockquote>原文：<a href="https://medium.com/codex/ch-7-decoding-black-box-of-cnns-using-feature-map-visualizations-45d38d4db1b0?source=collection_archive---------3-----------------------#2021-10-19">https://medium.com/codex/ch-7-decoding-black-box-of-cnns-using-feature-map-visualizations-45d38d4db1b0?source=collection_archive---------3-----------------------#2021-10-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0fdf" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">如何向CNN架构提出有用的问题，以深入了解他们的行为</h2></div><p id="0303" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">* * 2020年2月10日编辑:我已经用PyTorch发布了这篇文章中涉及的可视化工具的开源库，可以用<code class="du jt ju jv jw b">pip install FeatureMapVisualizer</code>安装。您还可以查看:</p><ul class=""><li id="a60c" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js kc kd ke kf bi translated"><a class="ae kg" href="https://nbviewer.org/github/lukysummer/FeatureMapVisualizer/blob/main/Colab_notebook/Feature_Map_Visaulizations.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> Colab笔记本</strong> </a>示例(分步说明)</li><li id="a4d3" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated"><a class="ae kg" href="https://github.com/lukysummer/FeatureMapVisualizer" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> Github </strong>资源库</a></li><li id="3c29" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated"><a class="ae kg" href="https://pypi.org/project/FeatureMapVisualizer/1.0.3/" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> PyPi </strong>页面</a>为FeatureMapVisualizer <strong class="iz hj">包</strong></li></ul><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es km"><img src="../Images/270415a299ca22a8484d80d75b39a724.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55BZ3fw4sQREyDflqiYKjA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">我们怎样才能找到钥匙🔑进入CNN架构的黑匣子？</figcaption></figure><h1 id="1a40" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">动机:CNN不是固有的黑匣子</h1><p id="04e9" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">你曾经想问动物一个问题吗？🐈由于我们还没有想出一种精确的方法来与其他动物交流，他们经常感觉像一个黑匣子。人与人之间的交流感觉更加透明，因为我们可以问问题和交换想法。因此，某样东西不可能<em class="lz">固有地</em>是黑盒；我们只是还没有找到一种以可理解的方式提问和获得答案的方法。</p><p id="af2a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">那么为什么深度学习模型经常成为<a class="ae kg" href="https://en.wikipedia.org/wiki/Black_box" rel="noopener ugc nofollow" target="_blank">黑箱问题</a>的目标呢？因为由于<em class="lz">人机</em> <em class="lz">的语言障碍，</em>我们不知道如何问他们合适的问题。在本帖中，我将讨论如何使用<strong class="iz hj">功能图可视化</strong>向CNN架构提出有用的问题，以便深入了解他们的行为。以下是我在问答环节中向CNN提出的五个问题:</p><ol class=""><li id="e4c7" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js ma kd ke kf bi translated">为什么你用肌肉来识别每个目标类别？</li><li id="5795" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">你能给我画一把小刀吗？</li><li id="c150" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">你在看图像的哪个部分？</li><li id="b2fa" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">你真的不知道枪是什么样子吗？</li><li id="21f3" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">一个类的顶级特征地图对于那个类真的是唯一的吗？</li></ol><h1 id="e108" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">Q1——你用哪块肌肉来识别每个目标类别？</h1><h2 id="cda6" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated"><em class="mp">翻译</em>:当模型看到特定类别的图像时，最后一个卷积层的哪些特定特征图被激活得最多？</h2><h2 id="9fe4" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(1.1)动作的专门肌肉💪</h2><p id="6079" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">从很小的时候，我们就训练我们的肌肉来控制不同的身体部位，以产生各种各样的运动。当我们学习一项新的体力任务时，我们会有选择地使用和训练该特定任务所需的肌肉。例如，如果一个成年人正在学习弹钢琴，手指、手腕和手臂的肌肉将被激活。如果这个人在弹钢琴时感到疼痛或僵硬，对手指或手腕进行检查比做一般的健康检查更有意义。</p><h2 id="8399" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(1.2)一个类的专用特征图</h2><p id="5486" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">CNN架构的情况类似，即:</p><ul class=""><li id="77a2" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js kc kd ke kf bi translated">在包含<a class="ae kg" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"> 1000个类别</a>的ImageNet数据集上进行预训练(广泛的运动范围)</li><li id="3b6d" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated">在包含少于1000个类的新数据集上进行微调(新的物理任务)</li></ul><p id="3587" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当输入图像通过CNN架构传播时，每个卷积层会产生数百甚至数千个特征图(即输出激活)。我们可以研究<strong class="iz hj"> <em class="lz">特殊化</em>特征地图的子集，而不是查看所有这些地图，这些地图的激活对于每类 </strong>图像的<em class="lz">来说是最大化的。这比一些流行的可视化技术更有效，例如<a class="ae kg" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> Grad-CAM </a>采用所有特征地图激活的<em class="lz">平均值</em>。</em></p><h2 id="af68" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(1.3)来自最后一个卷积层的特征图</h2><p id="646b" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">特别是，我从模型的<strong class="iz hj">最后一个卷积层</strong>、<strong class="iz hj">、</strong>中找到了最活跃的特征图，因为我对最后几层捕获的<strong class="iz hj">高级特征</strong>(例如物体部分或形状)更感兴趣。早期图层捕捉边缘和纹理等低级特征。</p><h2 id="38a7" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(1.4)程序</h2><p id="6b81" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">以下是从最后一个卷积层中查找特征映射的过程，对于每个目标类，该卷积层的激活最大化。我将把它们分别称为<strong class="iz hj"> <em class="lz">【顶级特征地图】</em> </strong>用于每个职业。</p><ol class=""><li id="d143" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js ma kd ke kf bi translated">设置<code class="du jt ju jv jw b">N1</code> : #顶特征图为每张图像选择<strong class="iz hj">，设置<code class="du jt ju jv jw b">N2</code> : #顶特征图为每类</strong>图像选择<strong class="iz hj">。</strong></li><li id="039c" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">按类别组织图像。</li><li id="69f8" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">对于每个类，将每个类图像逐个通过一个模型，并为每个图像聚合一个带有<code class="du jt ju jv jw b">N1</code>顶部激活特征映射的列表。例如，如果类别<em class="lz">类别</em>具有3个图像，<code class="du jt ju jv jw b">N1</code>是3，并且每个图像的前3个激活的特征映射的列表是[1，2，4]，[1，3，4]和[1，5，6]，则聚集列表变成[1，1，1，2，3，4，4，5，6]。</li><li id="e332" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">从每个类别的汇总列表中，选择<code class="du jt ju jv jw b">N2</code>最常见的特征地图。同样的例子，如果<code class="du jt ju jv jw b">N2</code>是2，类别<em class="lz">类别</em>的顶部特征映射的列表变成[1，4]。这一步的输出是顶部特征地图的<code class="du jt ju jv jw b">n_classes</code>列表，每个长度为<code class="du jt ju jv jw b">N2</code>。</li><li id="8c69" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">从每个类的顶级要素地图列表中移除同时出现在另一个类的顶级列表中的任何要素地图。如果类别<em class="lz">狗</em>的顶部特征映射列表为[1，10]，则<em class="lz">猫</em>和<em class="lz">狗</em>的列表将减少为[4]和[10]，因为1在两个列表中都存在。</li></ol><h2 id="1638" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(1.5)伪代码</h2><p id="f128" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">以下是该算法的伪代码:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mq"><img src="../Images/550ca1cf3496cf1366a1ebe8fadc1244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uW1tgI7DsFyAm_oAktCVqg.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">为每个类查找前N个特征图的伪代码</figcaption></figure><p id="cdc6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我使用了<code class="du jt ju jv jw b">N1 = 25</code>和<code class="du jt ju jv jw b">N2 = 25</code>，这意味着我查看了每张图片和每个目标类别的25个独特的顶级特征地图。在ResNet50针对二进制分类进行微调的情况下，要研究的特征图的数量从2，048个(ResNet50的最后一个卷积层中的过滤器数量)减少到50个(= 25*2)。</p><h1 id="e08e" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">Q2——你能给我画一把小刀吗？</h1><h2 id="8a33" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">翻译:刀类的顶级特征图捕捉到了什么样的图案或形状？</h2><h2 id="a1c3" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(2.1)基本思想</h2><p id="d1ce" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">在缩小了每个类别的特定特征图之后，我调查了<strong class="iz hj">每个单独的顶部特征图</strong>捕捉了哪些突出的形状或物体部分。受<a class="ae kg" href="https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030" rel="noopener" target="_blank">这篇文章</a>的启发，这个想法是首先使用如下所示的<code class="du jt ju jv jw b">np.random.uniform</code>生成一个小的随机图像(我使用了33乘33像素)，然后<strong class="iz hj">在最大化所选特征图激活的方向上迭代调整它的像素</strong>。这是通过最小化等于特征映射激活总和的负值的损失来实现的。在每次迭代中，在优化之后，图像还会使用<code class="du jt ju jv jw b">cv2.resize</code>以一个小的因子放大。重复这些优化和升级步骤，直到某些图案在图像中变得可见。</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div class="er es mr"><img src="../Images/d68070580804c74b2259484d90940c6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*PNvUSSu3ojNa0G86BPItuw.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">一个小的随机图像</figcaption></figure><h2 id="0878" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(2.2)伪代码</h2><p id="7fa6" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">以下是该算法的伪代码:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ms"><img src="../Images/3470c8f9833b02e53d2811b3134f306f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z6vT86Qkp7HF43TmIxHOqg.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">用于可视化由单个特征图捕获的模式的伪代码(灵感来自:<a class="ae kg" href="https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030" rel="noopener" target="_blank">https://towardsdatascience . com/how-to-visualize-convolatile-features-in-40-line of-code-70b7d 87 b 0030</a>)</figcaption></figure><p id="a881" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我使用了20个优化步骤，20个升级步骤，以及1.2的升级系数。我将使用ImageNet上预先训练的模型分享一些生成的图像，并针对<strong class="iz hj">枪与刀的二元分类</strong>进行微调。他们很有趣，很像概念派的<a class="ae kg" href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" rel="noopener ugc nofollow" target="_blank">AI艺术</a>。</p><h2 id="0492" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(2.3)给我画一把刀。</h2><p id="ac9f" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">该图像显示了由<strong class="iz hj"> <em class="lz">刀</em> </strong>类的顶部特征图捕获的图案:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mt"><img src="../Images/b8f7e1d9e684e9f0f57c574d35256cfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5BCzxya9dcb9tIlbdX-l5Q.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">“刀”类的顶级特征图捕获的模式</figcaption></figure><p id="e315" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">很酷吧。有趣的是，这张特征图反复捕捉到了刀片的尖三角形。如果你仔细观察，会发现一些微小的重复的方形形状，里面有一些看起来像眼睛的东西👁。根据猜测，这可能是与ImageNet数据集的动物类别相关的工件，这意味着对于ImageNet的1000个类别的分类，该特征图可能专门用于通过观察动物的眼睛来识别动物类别。</p><p id="cba4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该图像显示了由<strong class="iz hj"> <em class="lz">刀</em> </strong>类的另一个顶部特征图捕获的图案:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mu"><img src="../Images/250a7137275348ce6318b41f63f79e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJFhESgHXFOq4biG57-J3Q.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">类别“刀”的另一个顶部特征图捕获的模式</figcaption></figure><p id="fb91" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这一张也捕捉到了尖尖的刀尖的图案，但这次比上一张更长更弯曲。可能这个特征图更专门识别有曲线刃的刀。</p><h2 id="97bd" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">给我画一把枪。</h2><p id="eec1" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">现在，这里有一个图像显示了由<strong class="iz hj"> <em class="lz">枪</em> </strong>类的顶部特征图捕获的模式:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mu"><img src="../Images/61ee435b6a0ad428fdeef550fc34cc87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uestiwMQHr6xeo7Xz9b71w.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">“gun”类的顶级特征图捕获的模式</figcaption></figure><p id="402a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这张特征图似乎捕捉到了枪管的圆柱形状。我还猜测，类似翅膀羽毛的重复圆形可能是枪图像中经常出现的子弹形状。</p><p id="245c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该图像是用<strong class="iz hj"> <em class="lz">枪</em> </strong>类的另一个顶部特征图生成的:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mv"><img src="../Images/06f59fd27a87e087d13cdd682e66c2ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjts3oGgtyyLiwdZo08hbQ.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">类别“gun”的另一个顶级特征图捕获的模式</figcaption></figure><p id="bdae" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这张特征图捕捉到了整支枪更多的直角形状，可能还有双筒的形状。值得注意的是，不同方向和大小的重复枪形状反映了<strong class="iz hj">模型在</strong> <strong class="iz hj">检测对象时的鲁棒性，而不管其在图像中的方向或大小</strong>。</p><p id="1490" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下图显示了<strong class="iz hj"> <em class="lz">枪</em> </strong>和<strong class="iz hj"> <em class="lz">刀</em> </strong>类的其他顶级特征地图捕获的图案:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mw"><img src="../Images/3dc95b780c192f6bda03094b5816c5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JG41IBf62wI5LEcsNNpgRA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">由“gun”类的其他顶级特征地图捕获的模式</figcaption></figure><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es mw"><img src="../Images/fe1d21516251b4d8fea274000eae9f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwDJNF7hk4GhiaZwCwSN7w.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">“刀”类的其他顶级特征图捕获的模式</figcaption></figure><h2 id="cb99" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(2.5)人类与AI的视觉感知</h2><p id="54da" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">通过这种可视化方法，模型似乎在回答“你能给我画一把刀(枪)吗？”。生成的图像与我们将要绘制的图像大不相同，很可能是单个物体的整个形状，而不是特定部分的重复。但是当我们给一个物体拍照时，我们确实记得上面一些顶级特征地图捕捉到的它的轮廓或突出的形状(刀片，桶)。因此，关于广为流传的神经网络是为了模仿我们的大脑而发明的概念，值得思考人类和CNN的视觉感知是如何接近的。</p><h1 id="3547" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated"><strong class="ak">Q3——你在看图像的哪个部分？</strong></h1><h2 id="2aee" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">翻译:当将图像分类为特定类别时，特征图关注图像的哪些部分？</h2><h2 id="0473" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(3.1)单个图像，多个特征地图</h2><p id="8e32" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">另一个有用的技术是找到对于一个<strong class="iz hj">单个图像</strong>激活最大化的特征地图，并通过将其激活地图覆盖在图像顶部来突出显示每个地图最受关注的图像区域。前面提到的<a class="ae kg" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> Grad-CAM </a>可视化算法回答了一个类似的问题，即<em class="lz">整个最后一个卷积层</em>正在关注图像的哪些部分，但它不会像查看每个单独的特征图那样具体。</p><h2 id="9a03" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(3.2)程序</h2><ol class=""><li id="c593" class="jx jy hi iz b ja lu jd lv jg mx jk my jo mz js ma kd ke kf bi translated">通过模型转发图像。</li><li id="6406" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">使用:<code class="du jt ju jv jw b">torch.nn.modules.module.register_forward_hook(hook_function)</code> (PyTorch)保存来自最后一个卷积层的<em class="lz">所有</em>特征图的正向传播激活。</li><li id="a00b" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">挑选N个具有最大激活的特征地图(也称为前N个特征地图)。</li><li id="97f1" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">使用<code class="du jt ju jv jw b">cv2.resize</code>放大前N个特征图(通常类似于7×7)以匹配输入图像大小(例如224×224)。</li><li id="78f5" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js ma kd ke kf bi translated">将N个放大的特征地图中的每一个叠加在图像的顶部，并按照从最大到最小的激活顺序绘制它们。</li></ol><p id="748f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">* <strong class="iz hj">重要提示</strong>:步骤3中的前N个特征图(针对单个图像)与第1节中的前N个特征图(针对整个类别)不同。这里，我们正在寻找对于单个<strong class="iz hj"><em class="lz"/><em class="lz">图像</em> </strong>其激活最大化的顶级特征图，而在第1部分中，我们从属于那个类别的所有图像的顶级特征图的聚集列表中找到了对于单个类别<strong class="iz hj"><em class="lz"/></strong>的顶级特征图。</p><h2 id="6fe6" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(3.3)刀图像的顶部特征图</h2><p id="6537" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">在这里，我使用相同的枪与刀二元分类模型，可视化了包含刀和其他对象的图像的前60个特征映射的激活:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div class="er es na"><img src="../Images/0d0239158b2f17580144445c2d293452.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/0*u5xwbWYMKT28qQHj"/></div></figure><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nb"><img src="../Images/a8eb428f56f4af8949ccfb84d99ca0bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cPbYGRZCZ_jVDHFf"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated"><strong class="bd le">刀图像的前60个特征图。</strong>红色方框中的两个特征图表示使用第1节中的算法找到的刀具类别的前两个特征图。</figcaption></figure><p id="c692" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一些特征地图会高亮显示图像中的刀，而另一些则会高亮显示胡萝卜、土豆或砧板。两个红色的方框(第4和第9个最上面的特征地图)表示在第1部分中找到的<strong class="iz hj"> <em class="lz">刀</em> </strong>职业的最上面的两个特征地图。这两张特征图都在突出刀，尤其是顶端尖的部分，这一事实证实了它们确实对刀尖的形状很敏感。</p><h2 id="e239" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(3.4)具有大的白色背景的图像的顶部特征图</h2><p id="61ef" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">在这里，我使用相同的枪与刀二元分类模型可视化了顶部特征地图，这次是针对具有大型白色背景的图像:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div class="er es na"><img src="../Images/1506f19f0bf11105f5b30e63d1a55d71.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/0*WYiwHF1r8XC6t9Yc"/></div></figure><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nb"><img src="../Images/013908070dc26dddf0ca84aac8681dbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OK5Yo8NO3yZ0nLBL"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated"><strong class="bd le">刀图像的前90个激活特征图。</strong>红色方框中的两个特征图表示使用第1节中的算法找到的刀类的前两个特征图。</figcaption></figure><figure class="kn ko kp kq fd kr er es paragraph-image"><div class="er es na"><img src="../Images/3771f4ab94a4153f26f748adbc00a910.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/0*WROow239CrYCKiy3"/></div></figure><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nb"><img src="../Images/16772dfa0d74da295ced7eac4d426013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P_zmeaXv5kQxT_iO"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated"><strong class="bd le">枪械图像的前60个激活特征图。</strong>包围在红框中的顶部两个特征图也是使用第1节中的算法找到的枪类的顶部两个激活的特征图。</figcaption></figure><h2 id="fe90" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(3.5)刀图像的顶部特征图的奇怪性</h2><p id="6a10" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">在查看刀图像的热门特征地图的关注区域时，我发现了一些奇怪的事情。它们中的许多<strong class="iz hj">突出了白色背景的部分而不是刀</strong>，而大多数枪图像的顶部特征地图突出了枪而不是白色背景。此外，<strong class="iz hj"> <em class="lz">刀</em> </strong>类的第1部分的前两个特征图(用红框包围)在图中更靠下(前53和90个特征图)，相比之下<strong class="iz hj"> <em class="lz">枪</em> </strong>类的前两个特征图(也用红框包围)与该枪图像的前两个特征图重合。这是怎么回事？</p><h2 id="051f" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(3.6)为什么你把一个篮球的图像归类为高置信度的刀？</h2><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nc"><img src="../Images/d0bd403becb902b51bed02f27c46a7cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nusRtl2GsYLjQKdPnkZpCw.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">枪对刀二元分类模型有把握地将大多数不包含任何类别的图像分类为刀。</figcaption></figure><p id="5fda" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我之前的<a class="ae kg" rel="noopener" href="/@lucrece.shin/chapter-3-2-transfer-learning-with-resnet50-from-performance-analysis-to-unexpected-riddle-abe2da3b4e8f">第四章的帖子</a>中，我提到了枪与刀二元分类模型的不直观行为，它自信地将大多数不包含任何类别的图像归类为刀，如上所示。我很难理解为什么在分类一幅完全不相关的图像时，模型会如此倾向于刀。</p><p id="169f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我相信3.5节的观察为这种奇怪的行为提供了一种可能的解释。<strong class="iz hj">模型可能已经学会将固体背景感知为<em class="lz">刀类的典型特征之一</em> </strong> <em class="lz"> </em>(可能不一定是人类所知的“刀对象”的特征，而是“1类”的特征。我在<a class="ae kg" rel="noopener" href="/@lucrece.shin/chapter-4-using-t-sne-plots-as-human-ai-translator-c5ef9c2f2fa4#7ebb"> my Ch.5 post </a>中讨论过这个黑白二元决策边界。因此，当它看到一个不包含枪并且具有大的实心背景的图像时，它将其分类为刀。</p><p id="051b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">那么为什么纯色背景被公认为<strong class="iz hj"> <em class="lz">刀</em> </strong>类的特色特征之一呢？让我们考虑一下数据，即刀和枪的训练图像之间会有什么不同。可能是<strong class="iz hj">刀图像一般包含较大的背景空间</strong>。因为所有的输入图像都具有正方形尺寸，所以正方形图像使得细长形状的刀比较粗的弯曲形状的枪更少地填充图像空间。这是一个特定于特征地图的可视化如何为我们提供一些关于CNN如何感知图像的线索的例子:从字面上，像素方面，并对背景和前景给予公平的关注。</p><h1 id="d582" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">你真的不知道枪是什么样子吗？</h1><h2 id="e1af" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">翻译:当给定一组相同类别的图像时，该类别的顶部特征图能在所有图像中找到该对象吗？</h2><h2 id="262c" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(4.1)多个图像，单个特征地图</h2><p id="9595" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">这种方法与前一种方法(第3节)相似，但这次我们将一个<strong class="iz hj">单一特征图</strong>的激活图叠加在一组<strong class="iz hj">同类图像上。</strong>我在第1节中为每个类使用了顶级特征地图。</p><h2 id="9340" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(4.2)目标域混淆矩阵</h2><p id="1cc5" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">在进入可视化之前，这里是为枪与刀二元分类训练的VGG16模型的目标域混淆矩阵:</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nd"><img src="../Images/f0b9f68dfbf0d887e450db5b20d1af5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R45K3nvTDRmILb0eNcKq9A.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">目标(x射线)域混淆矩阵</figcaption></figure><p id="1ef2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个“目标域”混淆矩阵显示了模型<strong class="iz hj">在源域上训练并在目标域</strong>上测试的性能。在这种情况下，源域指的是枪和刀的正常相机图像(“网”图像，因为它们是从网上刮下来的)，而目标域指的是包含枪和刀的行李的x光图像。</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ne"><img src="../Images/ddc04cac0ce042ba25d4f6e79de7a56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-vp8unCRjQonMkfV.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">包含刀和枪的Web图像(源域)和x射线图像(目标域)</figcaption></figure><p id="3d5e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于从网页图像到x光图像的明显的<strong class="iz hj"> <em class="lz">纹理</em><em class="lz"/></strong>偏移，混淆矩阵表现不佳:</p><ul class=""><li id="3532" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js kc kd ke kf bi translated">枪支召回率只有24%。</li><li id="a3fd" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated">刀召回率是100%，但是该模型将100%的良性x射线图像(既不包含枪也不包含刀)和87%的x射线枪图像分类为刀。</li></ul><p id="ef25" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，如果我们只看混淆矩阵，我们最有可能得出的结论是<strong class="iz hj">模型未能很好地学习枪或刀的形状。</strong></p><h2 id="7b0a" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(4.3)用于枪图像的枪类顶部特征图的激活图</h2><p id="b74e" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">我使用第1节中的过程中的源域(web)图像找到了<strong class="iz hj"> <em class="lz">枪</em> </strong>类的顶部特征图。下图显示了一组x射线枪图像中<strong class="iz hj"> <em class="lz">枪</em> </strong>级的顶部特征图。有趣的是，这张特殊的特征地图在突出图像中的枪支方面做得很好！</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nf"><img src="../Images/19e31d68e0df482948a5ca7d76decea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ic14SjYzCnYcqI-Z-jVbA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">为x射线枪图像激活一个枪级的顶部特征地图</figcaption></figure><p id="57d6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们仅通过查看显示24%枪支召回率的混淆矩阵来判断该模型，我们会怀疑该模型是否能够在x射线图像中检测到枪支。然而，这个可视化说明<strong class="iz hj">存在一些来自模型的最后一个卷积层的非常具体的特征图，这些特征图对枪的形状特别敏感。</strong>这个特征图几乎充当了枪的对象识别器。</p><p id="b2a4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是另一个改进了枪支召回的模型的相同可视化。你可以看到这个模型是如何在x光图像中比之前的模型更清晰地突出了枪。</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ng"><img src="../Images/9298c1ee5a3129ae60645e691aff2791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jWwK73iveLT5G_StWO4mA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">为另一个具有改进的枪支召回的模型激活一个枪支级别的x射线枪图像的顶部特征地图</figcaption></figure><h2 id="7b3d" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(4.4)替代预测算法</h2><p id="a674" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">通过以上观察，一个灯泡💡关于一种可能的新预测算法。为了将x射线图像分类为枪支，而不是在最后一个卷积层之后通过完全连接层和softmax层，我们可以检查该枪支检测特征图是否在某个阈值以上被激活。这个想法让我想到了第五种可视化技术。</p><h1 id="6590" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated"><strong class="ak">Q5—一个类别的顶级特征地图对该类别来说真的是唯一的吗？</strong></h1><h2 id="bd94" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(5.1)绘制每个图像的顶级特征映射的激活总和</h2><p id="6451" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">这里，对于每个类别，我<strong class="iz hj">将每个测试图像</strong>的所有25个类别方式的顶部特征图(在第1节中找到)的激活相加，并在相同的图中用不同的颜色表示不同的类别。我使用了从第一节的网络图像中找到的顶级特征地图，并添加了它们对x射线图像的激活以进行绘制。这有助于检查每个类别的顶部特征贴图是否仅针对该类别最大化激活<strong class="iz hj">，即使有web→x射线纹理偏移</strong>。</p><p id="3d77" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将展示三种不同型号的图进行比较。所有三个模型都用三种不同类别的图像进行了测试:良性、枪和刀。对比剧情后我会揭晓模特的身份。这些图的轴代表以下内容:</p><ul class=""><li id="e18e" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js kc kd ke kf bi translated"><strong class="iz hj"> x轴</strong>:每个类别的图像数量(示例中为300个良性图像、100个枪图像和30个刀图像)</li><li id="9cd8" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated"><strong class="iz hj"> y轴</strong>:特征地图激活总数</li></ul><h2 id="d4b0" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(5.2)型号1</h2><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nh"><img src="../Images/94d5f104f113c2dfee6761f63607f98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAOm0wAkcgAABEIYgMGK9w.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">使用<strong class="bd le">型号#1 </strong>的<strong class="bd le">枪类(左)</strong>和<strong class="bd le">刀类(右)</strong>的顶部特征图激活总和图</figcaption></figure><p id="11ee" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">左图为<strong class="iz hj"> <em class="lz">枪</em> </strong>类顶级特征地图，显示蓝色线条(枪x射线图像)高于红色和粉色线条(刀和良性x射线图像)。相比之下，右图为<strong class="iz hj"> <em class="lz">刀</em> </strong>类顶级特征图，在所有三种颜色中显示了较大的重叠<strong class="iz hj"> </strong>。也许这个模型对枪的记忆比对刀的记忆更好。</p><h2 id="d4b6" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(5.3)型号2</h2><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ni"><img src="../Images/37671c9986bb96a2085fc4d80b45e1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*09jRoZXg0IS5XSc6"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">使用<strong class="bd le">型号#2 </strong>绘制<strong class="bd le">枪类(左)</strong>和<strong class="bd le">刀类(右)</strong>的顶部特征图激活总和图</figcaption></figure><p id="b17d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">模型#2显示了对<strong class="iz hj"> <em class="lz">刀</em> </strong>类的改进，右图显示红线(刀x射线图像)高于蓝线和粉线。左图；但是，显示了蓝色(枪x射线图像)和其他线条之间的一些重叠。</p><h2 id="5268" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(5.4)型号3</h2><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es nj"><img src="../Images/d2dc3309b4da6c6d318fb146221fde90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jS45nnwo4JD_Pmze"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">使用<strong class="bd le">型号#3绘制<strong class="bd le">枪类(左)</strong>和<strong class="bd le">刀类(右)</strong>的顶部特征图激活总和图。</strong>虚线表示可能的阈值，如果总和超过该阈值，则该模型可以对威胁对象的可能存在发出警报。</figcaption></figure><p id="7a27" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于<strong class="iz hj"> <em class="lz">枪</em> </strong>和<strong class="iz hj"> <em class="lz">刀</em> </strong>这两个类别，模型#3显示出具有明显更高激活总和的两个图的巨大改进。这款车型一定是两个级别中召回率最高的。</p><h2 id="6bef" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(5.5)三种模型的同一性</h2><p id="c3e3" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">以下是三款车型的身份:</p><h2 id="d4fe" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">型号# 1</h2><ul class=""><li id="bd55" class="jx jy hi iz b ja lu jd lv jg mx jk my jo mz js kc kd ke kf bi translated">VGG16在ImageNet上进行了预培训</li><li id="0b51" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated">针对枪与刀的二元分类进行了微调</li></ul><h2 id="cbf0" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">型号#2</h2><ul class=""><li id="9ed8" class="jx jy hi iz b ja lu jd lv jg mx jk my jo mz js kc kd ke kf bi translated">ResNet50在<a class="ae kg" href="https://arxiv.org/abs/1811.12231" rel="noopener ugc nofollow" target="_blank">风格化的ImageNet </a>上进行了预培训</li><li id="4149" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated">微调为良性对枪对刀<a class="ae kg" rel="noopener" href="/@lucrece.shin/ch-6-optimizing-data-for-flexible-and-robust-image-recognition-23f4dcce3af7">多标签分类</a></li></ul><h2 id="eb06" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">型号3</h2><ul class=""><li id="b0a3" class="jx jy hi iz b ja lu jd lv jg mx jk my jo mz js kc kd ke kf bi translated">ResNet50在<a class="ae kg" href="https://arxiv.org/abs/1811.12231" rel="noopener ugc nofollow" target="_blank">风格化的ImageNet </a>上进行了预培训</li><li id="0585" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated">微调为良性对枪对刀<a class="ae kg" rel="noopener" href="/@lucrece.shin/ch-6-optimizing-data-for-flexible-and-robust-image-recognition-23f4dcce3af7">多标签分类</a></li><li id="af5f" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated">用<a class="ae kg" href="https://arxiv.org/abs/1702.05464" rel="noopener ugc nofollow" target="_blank">对抗性判别域适应(ADDA) </a>用网络图像(源域)&amp;x光图像(目标域)训练</li></ul><p id="e51d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您可以看到数据或模型调整(如使用多标注和域自适应)如何使最终图层要素地图对每个类对象的独特特征更加敏感，从而增强模型的分类能力。</p><h2 id="33e5" class="mb ld hi bd le mc md me li mf mg mh lm jg mi mj lo jk mk ml lq jo mm mn ls mo bi translated">(5.6)替代威胁检测算法</h2><p id="338a" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">这些图还为枪和刀提出了另一种威胁检测算法。给定一个测试图像，我们可以首先计算每个威胁类别的顶级特征映射激活的总和。然后，如果总和高于某个阈值(例如由模型#3图中的虚线指示的阈值)，则模型可以对威胁对象的可能存在发出警报。</p><h1 id="f975" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">结束语:ML研究是一个反复的过程</h1><p id="5b67" class="pw-post-body-paragraph ix iy hi iz b ja lu ij jc jd lv im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">问答环节怎么样？特征地图可视化有助于你更好地理解CNN架构的内部工作吗？他们为我做了很多。他们成为了ML问题解决中<strong class="iz hj"><em class="lz"/></strong>迭代过程的一部分，让我<em class="lz">思考</em>关于:</p><ul class=""><li id="d5ab" class="jx jy hi iz b ja jb jd je jg jz jk ka jo kb js kc kd ke kf bi translated"><strong class="iz hj">如何<em class="lz"> I </em>识别图像中的物体</strong>——通过视觉线索:形状、轮廓、纹理、颜色和非视觉线索:思考物体的物理用途，无意识地应用物理定律(桌子上方的浮动刀很奇怪，而白色背景的浮动刀是可以的)</li><li id="e5e6" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated"><strong class="iz hj">如何设计数据、模型架构和损失函数</strong>以训练模型有效检测视觉线索(即缩小人类和CNN视觉感知之间的差距:在<a class="ae kg" rel="noopener" href="/@lucrece.shin/ch-6-optimizing-data-for-flexible-and-robust-image-recognition-23f4dcce3af7"> my Ch.6 post </a>中讨论)</li><li id="1d3f" class="jx jy hi iz b ja kh jd ki jg kj jk kk jo kl js kc kd ke kf bi translated"><strong class="iz hj">查看可视化效果后如何改进设计</strong>可视化效果有助于理解模型用于图像分类的机制</li></ul><p id="f467" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae kg" rel="noopener" href="/@lucrece.shin/ml-masters-research-project-history-a4823a1411b5">在做硕士</a>之前，我比较注重结果，每隔几周就完成一个又一个深度学习项目。但是当我在硕士期间整整一年致力于一个研究项目时，我对模型的行为产生了好奇，并花了更多的时间研究<strong class="iz hj"> <em class="lz">为什么</em> </strong>模型给出了好或坏的结果。我的钥匙是什么🔑进入CNN架构的黑匣子？正是这种<strong class="iz hj">好奇心</strong>和<strong class="iz hj">坚持不懈地去探究我对模型</strong>不了解的地方。</p><p id="197d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，这篇文章中讨论的方法的分步说明和代码(PyTorch中)在我的<a class="ae kg" href="https://nbviewer.org/github/lukysummer/FeatureMapVisualizer/blob/main/Colab_notebook/Feature_Map_Visaulizations.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> Colab笔记本</strong> </a>和<strong class="iz hj"> </strong> <a class="ae kg" href="https://github.com/lukysummer/FeatureMapVisualizer" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> Github资源库</strong> </a>中。如有任何问题或反馈，您可以<a class="ae kg" href="mailto:lucrece.shin@mail.utoronto.ca" rel="noopener ugc nofollow" target="_blank">联系我</a>😊。感谢阅读！🌸</p><p id="df19" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">-☾₊˚.</p></div></div>    
</body>
</html>