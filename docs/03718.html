<html>
<head>
<title>Thoughts on Speech-based Language Model from Facebook</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对脸书基于语音的语言模型的思考</h1>
<blockquote>原文：<a href="https://medium.com/codex/thoughts-on-speech-based-language-model-from-facebook-7db7f11f810b?source=collection_archive---------6-----------------------#2021-09-18">https://medium.com/codex/thoughts-on-speech-based-language-model-from-facebook-7db7f11f810b?source=collection_archive---------6-----------------------#2021-09-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3a0758dac967f16f834b7f1a5222412e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*secLL0ZugwixCN_PeBrO2w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">马特·博茨福德在<a class="ae iu" href="https://unsplash.com/s/photos/mic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="2574" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最近，脸书发布了一个新的语言模型——GSLM(生成口语模型)，它只使用“原始音频”，没有标签，文本，也没有自动识别。</p><p id="dbb1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在过去几年中，基于“文本”训练数据的超大型语言模型——如BERT、RoBERTa和GPT-3——相继出现，并显示出令人印象深刻的结果。通过成功的训练，这些模型可以生成非常合理的单词，这些单词将跟随给定的输入句子，这些模型出现在许多自然语言处理应用程序的生产站点中，例如情感分析、翻译、文本摘要、文章生成等。</p><p id="e654" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，这些模型的局限性在于它们需要大的文本数据集来进行训练。西方世界的代表性语言，包括英语，以及亚洲地区的代表性语言，如CJK语(中文、日语、朝鲜语)，在数据集的大小方面不会有任何大问题，但许多其他不太为人所知的“本土语言”——除了在人工智能的帮助下保存和继承本土语言的努力——确实存在用于适当训练的“不够”数据集的问题。</p><p id="285b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个更基本的(尽管有争议)限制来自“文本”数据的固有问题。虽然我们以可互换的方式使用了几个概念，如“文本”、“语言”和“语言活动”，但如果你仔细观察，它们都是非常不同的概念。“文本”是“语言”的一个方面，虽然它包含了大量与人类“语言活动”相关的信息，但它并不代表其整体。因此，人工智能模型用‘文本’学习的世界的‘表征’与人类有很大不同。</p><p id="13e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">脸书AI这次发布的GSLM (Generative口语模型)，只用‘原始音频’训练语言模型，没有‘标签’也没有‘文本’。它可以应用于难以获得大量文本数据的语言。甚至在具有大量数据的语言的情况下，我们可以很容易地想象许多应用程序(模型使用音频作为训练数据，使用音频作为直接输入/输出)取代现有的NLP应用程序。如果你想一想，很快就会发现，当我们将语音转换为文本时，许多信息都在中间丢失了——就像我们通过信使相互交谈时，有时必须解释更多才能传递文本的细微差别。这种来自话语的信息可能会被像脸书的GSLM一样创建的应用程序很好地保存和再现，并且允许更广泛的复杂的细微差别和表达。考虑到我们人类在婴儿时期是如何学习语言的，这种方法可能是一种真正的“端到端”训练神经网络的方法。神经网络可能会像我们从自己的“语言活动”中学习一样，学习更好的世界表达方式。</p><p id="936c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据脸书·艾的说法，基线GSLM模型由三个部分组成:编码器(将语音音频转换为声音单元)、LM(语言模型:经过训练可以预测下一个声音单元的模型)和解码器(将声音转换为语音)。据说GSLM模型已经接受了6000小时的原始音频训练。欲了解更多关于这款车型的信息，请访问<a class="ae iu" href="https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/d9c59a7060fb588412e33dda7fd7041f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*k23Vak17naPZo14S"/></div></figure><p id="f526" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将发现这种新方法将如何传播，以及随着时间的推移它将产生什么影响，但已经有许多研究人员在Twitter和其他社交网络上交换意见。</p><p id="78e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如BIU大学的约夫·戈德堡教授在推特上说的，“另一个很好的例子是，经过充分数据训练的大型网络可以真正学会模仿非常复杂的分布。[不确定它所说的“语言理解”是什么，但从学习表示复杂分布的角度来看非常非常令人印象深刻]”，这是一个令人惊讶的实验和发现。6000小时(250天)的原始音频似乎也不算多。</p><p id="5cfb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果这个模型能够很好地作为一个预先训练的模型作为基础，与下游过程中的一些标记数据相结合(正如脸书AI透露的未来研究方向之一)，这种新方法将对自然语言处理系统的当前生态系统产生重大影响。</p><p id="c35d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，有观点认为，这种新的语言模型与2011年基于RNN的现有语言模型没有根本区别，只是这种模型使用音频而不是文本。CMU大学的Graham Neubig教授(在Yoav教授的推文中的一个帖子中)说:“我同意神经网络能够直接从语音中生成连贯的单词令人印象深刻。但是从语义上来说，生成的内容和2011年的RNNLM一样连贯:)我想还有一段路要走。”</p><p id="7bdc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">就我个人而言，我不认为这种模式会在不久的将来演变成类似“AGI”的东西，也不相信这是一种接近“语言理解”的东西，但毫无疑问，这是一种将我们从“文本”中解放出来的新方法——文本同时是祝福和缰绳。</p><p id="9faa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">期待从这一努力中开启深度学习应用的新视野。</p></div></div>    
</body>
</html>