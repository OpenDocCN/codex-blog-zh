<html>
<head>
<title>The Execution Process of a Tensor in a Deep Learning Framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习框架中张量的执行过程</h1>
<blockquote>原文：<a href="https://medium.com/codex/the-execution-process-of-a-tensor-in-a-deep-learning-framework-a4d853645d5b?source=collection_archive---------8-----------------------#2022-02-25">https://medium.com/codex/the-execution-process-of-a-tensor-in-a-deep-learning-framework-a4d853645d5b?source=collection_archive---------8-----------------------#2022-02-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8ec08523c29ef00c17c7c73aa1f95493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VSH5Pv2D8KgAK_n21__cXQ.jpeg"/></div></div></figure></div><div class="ab cl iq ir gp is" role="separator"><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv"/></div><div class="hb hc hd he hf"><p id="0b0d" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj"> <em class="jv">张筱雨写的；翻译:刘小珍，徐晨阳，周亚坤</em> </strong></p><blockquote class="jw jx jy"><p id="9c85" class="ix iy jv iz b ja jb jc jd je jf jg jh jz jj jk jl ka jn jo jp kb jr js jt ju hb bi translated">T <!-- -->他的这篇文章关注的是深度学习框架<a class="ae kc" href="https://github.com/Oneflow-Inc/oneflow" rel="noopener ugc nofollow" target="_blank"><strong class="iz hj"><em class="hi">one flow</em></strong></a>中一个张量的执行背后发生的事情。以运算符“oneflow.relu”为例，介绍执行该运算符需要依赖的解释器和VM机制。希望本文对深度学习框架的系统设计有所启发。</p></blockquote><p id="7e90" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">首先，我们来看看PyTorch中的以下代码:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="aec1" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">用PyTorch运行它，我们得到:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="44e4" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在上面的代码中，输入张量<code class="du kj kk kl km b">x</code>被馈送给操作符<code class="du kj kk kl km b">relu</code>，结果被打印出来。一切看起来简单又正常。但是如果有人问你是否清楚这背后发生了什么，以及<code class="du kj kk kl km b">relu</code>对应的Cuda内核是什么时候被GPU调用的，你可能就不那么清楚了。我们习惯于直接使用深度学习框架，并没有对它进行更多的思考，所以我们可能对其背后的原理并没有深刻的理解。</p><p id="3e66" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">然而在这篇文章中，我将试图解开这个问题。但我不会用PyTorch作为例子，而是用OneFlow。为什么用OneFlow做例子？那是因为首先我在OneFlow inc工作，比PyTorch更了解它的执行机制，也就是说在调用链追踪的时候我的操作会更流畅。第二，执行机制的很多设计思路在OneFlow中都是独一无二的，所以相信这篇文章会对读者在深度学习框架的系统设计上有所启发。</p><p id="71eb" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">那么，我们来看看OneFlow深度学习框架中一个张量的执行过程。为简单起见，本文只考虑单节点单GPU模式，不涉及OneFlow独有的一致模式(分布式相关)。</p><h1 id="9c67" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">Python和C++之间的桥梁</h1><p id="dcb3" class="pw-post-body-paragraph ix iy hi iz b ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq lp js jt ju hb bi translated">如果我们使用OneFlow运行以下代码:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="2e35" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">系统首先在GPU上创建一个输入张量，然后调用导出到Python的c++函数接口<code class="du kj kk kl km b">relu</code>。这里涉及到Python包装器和C++ <code class="du kj kk kl km b">relu</code>函子，都与pybind11绑定有关。上面Python代码中的操作符<code class="du kj kk kl km b">flow.relu</code>最终调用ReLU C++ Functor实现。让我们看一下代码:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="3f2f" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在这段代码中，<code class="du kj kk kl km b">op_</code>是一个指向<code class="du kj kk kl km b">OpExpr</code>的指针，它调用构造函数中的OpBuilder函数来创建一个新的OpExpr。从实际调用代码<code class="du kj kk kl km b">OpInterpUtil::Dispatch&lt;Tensor&gt;(*op_, {x});</code>中我们可以看到，构造和运算符的执行是分开的(因为调度函数同时分配OpExpr，input Tensor，和其他，并不直接分配执行的结果Tensor，所以运算符的真正执行还没有开始)。这里的<code class="du kj kk kl km b">OpInterpUtil::Dispatch</code>是分配OpExpr，input Tensor，和其他参数(运算符ReLU除了input参数没有其他参数)，也意味着真正的执行还没有开始。</p><p id="5a3c" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">OpExpr可以简单理解为OneFlow操作符的统一抽象。opExpr可以大致分为BuiltinOpExpr、FunctionOpExpr和其他种类的OpExpr，其中BuiltinOpExpr可以细分为UserOpExpr和非UserOpExpr，用户可以通过OpBuilder构建UserOpExpr。</p><p id="a401" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">我们不必完全理解OpExpr的定义，只需要知道这里OpBuilder构建了一个新的OpExpr，新的OpExpr有Op名称、<code class="du kj kk kl km b">UserOpConf proto_</code>的ProtoBuf对象、输入输出张量名称等关键信息。然后，顺着这个调度函数，我们可以发现<code class="du kj kk kl km b">GetInterpreter</code>函数的<code class="du kj kk kl km b">Apply</code>方法在<code class="du kj kk kl km b">oneflow/core/framework/op_interpreter/op_interpreter_util.cpp</code>中被调用。</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="ac2c" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在这里，OpExprInterpContext对象将存储操作符的动态属性、设备信息、分发信息等。这里我们不关注这个对象，因为它对于<code class="du kj kk kl km b">Relu</code>函子是空的。接下来，我们可以分析解释器对象。</p><h1 id="7d54" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">解释者</h1><p id="f3c7" class="pw-post-body-paragraph ix iy hi iz b ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq lp js jt ju hb bi translated">从上面的调用过程中我们可以看到，Python层的运算符实际上调用的是导出到Python的functor接口。Functor接口会将OpExpr、输入张量和动态属性<code class="du kj kk kl km b">attr</code>提交给解释器进行处理，因为上面的<code class="du kj kk kl km b">GetInterpreter</code>函数是指获取一个解释器对象。解释器类是专门用来解释操作符执行过程的，上面Relu函子中的调度函数就是把任务分配给解释器执行。OneFlow的解释器又进一步划分为Eager镜像解释器、Eager一致解释器、LazyInterpreter等类型。本文中的例子不涉及分布式相关信息，所以输入张量都是镜像张量，并调用Eager镜像解释器。镜像张量独立于每个秩，类似于PyTorch张量。</p><p id="a0df" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">上面代码中的下一个<code class="du kj kk kl km b">Apply</code>实际上调用了<code class="du kj kk kl km b">oneflow/core/framework/op_interpreter/eager_mirrored_op_interpreter.cpp</code>文件中的<code class="du kj kk kl km b">NaiveInterpret</code>函数。<code class="du kj kk kl km b">NaiveInterpret</code>函数首先接受OpExpr对象、输入和输出张量以及一个<code class="du kj kk kl km b">OpExprInterpContext</code>对象来导出操作符的设备、输出数据类型和输出形状等。</p><p id="4f25" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">然后基于导出的元信息(元信息对应TensorMeta类对象，其中放了张量的基本信息如形状、数据类型、步距等。成类便于管理)，它分别构建了输入和输出对应的<code class="du kj kk kl km b">BlobObject</code>、<code class="du kj kk kl km b">input_eager_blob_objects</code>、<code class="du kj kk kl km b">output_eager_blob_objects</code>(可以解释为输入输出张量的数据指针)。</p><p id="6d54" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">最后，执行内核、输入输出张量数据指针和<code class="du kj kk kl km b">OpExprInterpContext</code>对象以指令的形式发送到OneFlow的虚拟机(可以解释为OneFlow的Eager runtime)执行并获得结果。</p><p id="6edb" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">让我们看看<code class="du kj kk kl km b">NaiveInterpret</code>函数是如何分段实现最终结果的。第一段代码如下所示:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="5fdf" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这段代码遍历输入张量列表，将每个输入张量的设备与函数传递的默认设备进行比较。一旦发现输入张量的设备与默认设备不同，就会抛出异常。例如，输入张量在CPU上，而<code class="du kj kk kl km b">nn.Module</code>在GPU上，可以执行错误检查并打印错误消息，通知设备不匹配。如果设备匹配，输入张量的<code class="du kj kk kl km b">eager_blob_objects</code>将被添加到<code class="du kj kk kl km b">input_eager_blob_objects</code>列表中。输入张量的<code class="du kj kk kl km b">eager_blob_object</code>是一个<code class="du kj kk kl km b">EagerBlobObject</code>类型的指针，这是一个指向输入张量的数据指针，稍后它将帮助与OneFlow的虚拟机(VM)进行交互。</p><blockquote class="jw jx jy"><p id="aff2" class="ix iy jv iz b ja jb jc jd je jf jg jh jz jj jk jl ka jn jo jp kb jr js jt ju hb bi translated"><em class="hi">这里补充说明一下OneFlow中Tensor、TensorImpl、TensorMeta和BlobObject之间的关系。张量和张量积使用桥模式设计。张量负责和Python接口，向上亲笔签名；TensorImpl负责向下的真实数据。TensorMeta将张量的形状、数据类型、步距等基本信息提取成一个类型，放在一起便于管理。BlobObject是实际的数据对象，有数据指针。虚拟机使用这种类型来完成所指示的计算任务。</em></p></blockquote><p id="fc2e" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">第二段代码如下:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="9abe" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">首先，代码声明一个类型为<code class="du kj kk kl km b">EagerBlobObjectList</code>的指针<code class="du kj kk kl km b">output_eager_blob_objects</code>和<code class="du kj kk kl km b">output_tensor_metas</code>，它存储输出张量的元信息。然后，它遍历输出张量列表，以确定“<code class="du kj kk kl km b">i</code> th”张量是否已经有值。</p><p id="8aa8" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">否则，将请求一个MirroredTensor类型的指针，并将其初始化为<code class="du kj kk kl km b">tensor_impl</code>。并且索引<code class="du kj kk kl km b">i</code>处的<code class="du kj kk kl km b">output_tensor_metas</code>的值会更新为<code class="du kj kk kl km b">tensor_impl</code>的张量元信息，为下一次的形状和类型派生做准备(如果有值，就是原地调用。另外，我们可以发现带值的<code class="du kj kk kl km b">BlobObject</code>和某个输入的<code class="du kj kk kl km b">BlobObject</code>是同一个对象。</p><p id="6fde" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">如果输出张量已经有值(在位模式)，判断它是否有类型<code class="du kj kk kl km b">EagerBlobObject</code>的数据指针。如果是，将这个数据指针放入列表中刚刚请求的<code class="du kj kk kl km b">EagerBlobObjectList</code>类型的<code class="du kj kk kl km b">output_eager_blob_objects</code>中。后续的形状派生和dtype派生也会用到这个<code class="du kj kk kl km b">output_eager_blob_objects</code>。</p><p id="60e2" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">第三段代码:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="d682" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这个代码是Op对设备、形状和数据类型的派生。<code class="du kj kk kl km b">user_op_expr.has_device_infer_fn()</code>用于判断当前OpExpr是否具有设备信息导出功能。否则，输出张量的设备信息将更新为当前的<code class="du kj kk kl km b">default_device</code>。</p><p id="3cda" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">如果有，直接从<code class="du kj kk kl km b">user_op_expr</code>获取设备信息。在注册用户操作符时，已经确定了它是否是在这里派生的。我们在<code class="du kj kk kl km b">oneflow/core/framework/op_expr.cpp</code>文件的<code class="du kj kk kl km b">UserOpExpr::Init</code>中查看寄存器是否有器件派生功能。另外，我们可以在<code class="du kj kk kl km b">oneflow/ir/include/OneFlow/OneFlowUserOps.td</code>文件中看到哪些操作符实现了设备派生功能。</p><p id="9b8c" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">接下来调用OpExpr中的<code class="du kj kk kl km b">InferPhysicalShapeAndDType</code>完成输出张量的形状和dtype推导。对<code class="du kj kk kl km b">InferPhysicalShapeAndDType</code>函数的跟踪显示，它调用了注册用户操作符时定义的形状派生和数据类型派生函数。</p><p id="d823" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">然后迭代<code class="du kj kk kl km b">output_eager_blob_objects</code>，根据已经导出的张量元更新或检查对象(张量元检查是上面提到的inplace可能存在的结果，Inplace前后的张量元不能改变)。</p><p id="4d42" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">最后一段代码:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="52d1" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">当解释器与VM交互时，最后一段代码是最关键的步骤。<code class="du kj kk kl km b">user_op_expr.MutKernel4Device</code>在<code class="du kj kk kl km b">op_device</code>上构建StatefulOpKernel，并将<code class="du kj kk kl km b">output_eager_blob_objects</code>中每个<code class="du kj kk kl km b">EagerBlobObject</code>对象的<code class="du kj kk kl km b">is_shape_synced_</code>值设置为False。<code class="du kj kk kl km b">is_shape_synced_</code>设置为False意味着输出张量的形状在运行时确定。输出张量的形状可以在核执行后得到。</p><p id="b74e" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">为什么要默认设置为False？因为对于一个Op来说，它的形状是否需要导出是Op的属性，所以默认会为False。StatefulOpKernel中有一个标志，从中可以知道哪些操作符处于动态形状。如果不是，它的标志设置为True，这意味着它是同步的(不需要同步)。<code class="du kj kk kl km b">builder-&gt;LocalCallOpKernel</code>功能是为虚拟机建立指令。而PhysicalRun负责将这条指令发送给VM，并执行它得到最终结果。</p><h1 id="d467" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">虚拟机简介</h1><p id="2dce" class="pw-post-body-paragraph ix iy hi iz b ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq lp js jt ju hb bi translated">OneFlow Eager的运行时被抽象为虚拟机(VM)。当我们运行代码<code class="du kj kk kl km b">flow.relu(x)</code>时，上面的解释器会向VM发送一条<code class="du kj kk kl km b">LocalCallOpKernel</code>指令。VM在执行这条指令时为输出张量请求内存，调用ReLU的Cuda内核来执行计算，并将结果写入输出张量。</p><p id="2ed7" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">让我们先了解一下VM的一些概念，然后看看关键代码，以便进一步理解。</p><p id="472a" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在OneFlow程序运行期间，虚拟机不断在后台轮询，如果有新指令，则执行新指令，如果没有，则继续轮询。虚拟机有两种类型的线程:调度器线程和工作线程(如果我们运行Python脚本，脚本在主线程中运行)。虚拟机的轮询是在调度程序线程中，而工作线程处理阻塞操作，这很慢，不适合调度程序线程。</p><p id="075c" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">指令是虚拟机执行的最小单位。OneFlow中的指令类型有<code class="du kj kk kl km b">AccessBlobByCallback</code>、<code class="du kj kk kl km b">LocalCallOpKernel</code>、<code class="du kj kk kl km b">ReleaseTensor</code>等。<code class="du kj kk kl km b">AccessBlobByCallback</code>是读取和修改一个Blob的值，<code class="du kj kk kl km b">LocalCallOpKernel</code>是运行一个Op，<code class="du kj kk kl km b">ReleaseTensor</code>是释放声明周期已经结束的张量的内存。每条指令都携带一个<code class="du kj kk kl km b">parallel_desc</code>指示该指令在哪些设备上执行(例如只在设备1上执行，或者在所有设备上执行)，并绑定一个StreamType指示该指令在哪个流上执行(文章开头ReLU对应的<code class="du kj kk kl km b">LocalCallOpKernel</code>在一个CudaStream上执行)。</p><p id="ceb4" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">以<code class="du kj kk kl km b">LocalCallOpKernel</code>为例，根据流类型的不同，有以下类型的指令:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="57c6" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">根据<code class="du kj kk kl km b">cpu.LocalCallOpKernel</code>指令，其stram_type被绑定到<code class="du kj kk kl km b">CpuStreamType</code>，在<code class="du kj kk kl km b">oneflow/core/eager/cpu_opkernel_instruction_type.cpp</code>中定义如下:</p><p id="0ad8" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><a class="ae kc" href="https://gist.github.com/YakunZhou/7370c732248302e5b20a245370f0450a" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/YakunZhou/7370 c 732248302 e5b 20 a 245370 f 0450 a</a></p><p id="31d8" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">每个流类型可以设置该流是否在调度器线程上工作，设置初始化、查询指令状态和完成指令计算等作业。</p><blockquote class="jw jx jy"><p id="9f76" class="ix iy jv iz b ja jb jc jd je jf jg jh jz jj jk jl ka jn jo jp kb jr js jt ju hb bi translated"><em class="hi">流是虚拟机中的设备抽象，每个流对应一个设备。此外，指令有推断和计算过程。Infer是元信息的推导，compute是启动计算内核进行执行。</em></p></blockquote><p id="2955" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">接下来，我们将看看指令之间的依赖关系。虚拟机指令是无序执行的，但是对具有依赖性的指令的执行顺序有要求。例如，如果用户发出两条指令“a”和“b”，“a”指令需要修改Blob“c”的值，而“b”指令需要读取Blob“c”的值，则“a”指令必须在“b”指令之前执行。</p><p id="4a03" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">那么指令之间的依赖是如何构造的呢？指令之间的依赖性是通过依赖指令所携带的操作数来实现的。操作数的主要类型有const、mut和mut2。const对应输入(读)，mut和mut2对应输出(写)。</p><p id="2cff" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">上面的指令‘a’有一个mut操作数‘c’，指令‘b’有一个const操作数‘c’。这样，通过检查指令“a”和“b”中“c”的类型，可以在“a”和“b”之间建立“a”依赖性:</p><p id="2531" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">“b”的推断必须在“a”的推断之后完成，“b”的计算必须在“a”的计算之后完成。mut2操作数处理某些运算(如unique ),其输出形状只能在计算阶段确定。例如，如果a以mut2操作数“a”的形式持有“c”，那么“b”的推断和计算都需要在计算“a”之后发生。</p><p id="78ab" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">从<code class="du kj kk kl km b">oneflow/core/eager/local_call_opkernel_phy_instr_operand.h</code>中定义的<code class="du kj kk kl km b">LocalCallOpKernelPhyInstrOperand</code>指令开始，重载了<code class="du kj kk kl km b">ForEachConstMirroredObject</code>、<code class="du kj kk kl km b">ForEachMutMirroredObject</code>、<code class="du kj kk kl km b">ForEachMut2MirroredObject</code>三个方法，分别对应const、mut、mut2操作。在每个重载的方法中，调用传入的回调函数(<code class="du kj kk kl km b">const std::function&lt;void(vm::MirroredObject* compute)&gt;&amp; DoEach</code>)来建立指令之间的依赖关系。我们以const为例:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="386f" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这一行代码<code class="du kj kk kl km b">for (int64_t index : opkernel().input_tuple_indexes4const_ibns())</code>用于遍历StatefulOpKernel对象中的const操作数。它在输入元组中获取它的下标，从而得到<code class="du kj kk kl km b">index</code>。然后根据<code class="du kj kk kl km b">index</code>检索这个下标对应的<code class="du kj kk kl km b">EagerBlobObject</code>对象。</p><p id="3852" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">然后在<code class="du kj kk kl km b">EagerBlobObject</code>上调用<code class="du kj kk kl km b">compute_local_dep_object</code>上的回调<code class="du kj kk kl km b">DoEach</code>，相当于以const的方式消耗这个<code class="du kj kk kl km b">compute_local_dep_object</code>。mut和mut2类似。</p><p id="c4d0" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这里还解释了虚拟机的指令间依赖关系是如何建立的。在<code class="du kj kk kl km b">oneflow/core/vm/virtual_machine_engine.cpp</code>的<code class="du kj kk kl km b">HandlePending</code>成员函数中，<code class="du kj kk kl km b">ConsumeMirroredObjects</code>函数<code class="du kj kk kl km b">for (const auto&amp; operand : operands)</code>为每个操作数调用<code class="du kj kk kl km b">ForEachMutMirroredObject</code>函数。例如，对于mut:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="0870" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">DoEachT是<code class="du kj kk kl km b">ConsumeMutMirroredObject</code>，消耗<code class="du kj kk kl km b">Mut Mirrored Object</code>。继续跟踪<code class="du kj kk kl km b">ConsumeMutMirroredObject</code>的实施情况:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="8a71" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><code class="du kj kk kl km b">AccessMirroredObject</code>添加到将访问<code class="du kj kk kl km b">mirrored_object</code>的指令列表中。</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="7fbf" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><code class="du kj kk kl km b">RwMutexedObject</code>锁定<code class="du kj kk kl km b">mirrored_object</code>的读写。有了指令依赖之后，我们就可以构造指令边了。在构建了指令边缘之后，虚拟机可以执行由指令节点组成的Dag。处理Dag的一个有效方法是拓扑排序，但在OneFlow的虚拟机中，这是通过<code class="du kj kk kl km b">ready_instruction_list</code>和<code class="du kj kk kl km b">pending_instaruction_list</code>来完成的。当调度器轮询时，它只需要连续处理这两个列表。在<code class="du kj kk kl km b">ConsumeMirroredObjects</code>的这一部分中，我们再来看一下建造过程的说明部分:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="a179" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">它会分析两个指令之间的关系，比如一个读一个写，或者两个读一个写，分别构造指令边，把两个指令连接起来。</p><p id="664b" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">因此，虚拟机的指令依赖性没有嵌入到虚拟机中。而是通过消耗指令的操作数来实现。除了消耗操作数来构造指令依赖，它还可以消耗设备。以<code class="du kj kk kl km b">LocalCallOpKernelPhyInstrOperand</code>指令的mut操作数为例，这里会得到StatefulOpKernel对应的设备，比如cuda。那么每个设备方法也有一个<code class="du kj kk kl km b">local_dep_object</code>成员；每条指令以mut <code class="du kj kk kl km b">local_dep_object</code>的形式消耗<code class="du kj kk kl km b">local_dep_object</code>成员。这样前后两条指令在同一台设备上执行。所以这两条指令的执行顺序一定是需要按照发射顺序执行的依赖关系，因为它们在mut中都消耗了相同的<code class="du kj kk kl km b">local_dep_object</code>。</p><blockquote class="jw jx jy"><p id="7ac0" class="ix iy jv iz b ja jb jc jd je jf jg jh jz jj jk jl ka jn jo jp kb jr js jt ju hb bi translated"><em class="hi">这里的</em> <code class="du kj kk kl km b"><em class="hi">local_dep_object</em></code> <em class="hi">是专门用来帮助虚拟机构建指令端的对象。EagerBlobObject和Device持有此对象。然后按顺序使用它，建立指令之间的联系。</em></p></blockquote><h1 id="ea12" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">VM和解释器的整体调用链</h1><p id="1968" class="pw-post-body-paragraph ix iy hi iz b ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq lp js jt ju hb bi translated">这一部分从宏观上贯穿Interpter和虚拟机的调用链。首先，Python层调用OneFlow的Op将通过解释器发送，以构建VM指令并执行它们。以ReLU为例，解释器的最后一步是:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="4841" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">然后跟进LocalCallOpKernel的实现:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="6306" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><code class="du kj kk kl km b">auto instruction = intrusive::make_shared&lt;vm::InstructionMsg&gt;...</code>这段代码构造了一个新的指令，并将一个<code class="du kj kk kl km b">parallel_desc</code>绑定到它，指示在哪些设备上执行(例如，只在0号卡上执行，或者在所有卡上执行)以及一个StreamType，指示在哪个流上执行该指令。而这段代码上面的<code class="du kj kk kl km b">auto phy_instr_operand = JUST(vm::LocalCallOpKernelPhyInstrOperand::New...</code>用来绑定指令和操作数。现在说明已经有了。下一步是基于这些新创建的指令与VM进行交互，以构建指令端并执行它。这个交互的界面是<code class="du kj kk kl km b">PhysicalInterpreter::Run</code>(从<code class="du kj kk kl km b">PhysicalRun</code>跳转)。</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="35c9" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">跳转到<code class="du kj kk kl km b">RunPhysicalInstruction</code>的定义，在<code class="du kj kk kl km b">oneflow/core/eager/eager_oneflow.cpp</code>中:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="ea30" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">它的输入参数是在我们构造指令的地方定义的全局<code class="du kj kk kl km b">InstructionsBuilder</code>对象的<code class="du kj kk kl km b">mut_instruction_list</code>和<code class="du kj kk kl km b">eager_symbol_list</code>(虚拟机中的对象)。跳到<code class="du kj kk kl km b">RunPhysicalInstruction(instruction_list, eager_symbol_list)</code>查看以下定义:</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="1285" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这里的<code class="du kj kk kl km b">virtual_machine-&gt;Receive(instr_msg_list)</code>将获得刚刚构造的指令。</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="b2bc" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">一旦获得指令，就可以在轮询虚拟机的调度程序线程时处理它们，即<code class="du kj kk kl km b">oneflow/core/vm/virtual_machine_engine.cpp</code>中的<code class="du kj kk kl km b">VirtualMachineEngine::Schedule</code>功能。</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="kh ki l"/></div></figure><p id="cd23" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">调度功能不断轮询。整体功能可分为接受主线程指令、轮询指令完成、处理阻塞指令和分派就绪指令。事实上，当我们点击进入HandlePending时，可以发现它正在消耗我们的<code class="du kj kk kl km b">local_dep_opbject</code>进行指令构造和指令边缘链接，这与上面分析的过程相对应。</p><h1 id="63e7" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">NSYS结果显示</h1><p id="688b" class="pw-post-body-paragraph ix iy hi iz b ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq lp js jt ju hb bi translated">关于解释器和VM的细节比我们想象的要复杂得多。最后我放一张某网络训练时生成的NSYS图。</p><p id="6ffa" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">您可以看到虚拟机正在工作，调度程序线程正在分发就绪指令，并启动Adam的cuda内核来执行参数更新。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/fe5c0c90ae01b9a35eb7e8ad956dcf60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aqa9b0rjdD-H4S-L.png"/></div></div></figure><h1 id="414b" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">摘要</h1><p id="0dbb" class="pw-post-body-paragraph ix iy hi iz b ja ll jc jd je lm jg jh ji ln jk jl jm lo jo jp jq lp js jt ju hb bi translated">本文以操作符<code class="du kj kk kl km b">oneflow.relu</code>为例，介绍执行该操作符需要依赖的解释器和VM机制。希望对那些渴望了解OneFlow执行机制的人也有所帮助。</p><h1 id="5a73" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">参考</h1><ul class=""><li id="15f0" class="lr ls hi iz b ja ll je lm ji lt jm lu jq lv ju lw lx ly lz bi translated">设计模式桥梁模式:<a class="ae kc" href="https://segmentfault.com/a/1190000041225650" rel="noopener ugc nofollow" target="_blank">https://segmentfault.com/a/1190000041225650</a></li><li id="5101" class="lr ls hi iz b ja ma je mb ji mc jm md jq me ju lw lx ly lz bi translated"><a class="ae kc" href="https://github.com/Oneflow-Inc/oneflow" rel="noopener ugc nofollow" target="_blank">https://github.com/Oneflow-Inc/oneflow</a></li></ul></div><div class="ab cl iq ir gp is" role="separator"><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv"/></div><div class="hb hc hd he hf"><p id="7c93" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj"> <em class="jv">相关文章:</em> </strong></p><ol class=""><li id="394f" class="lr ls hi iz b ja jb je jf ji mf jm mg jq mh ju mi lx ly lz bi translated"><a class="ae kc" href="https://oneflow2020.medium.com/the-autotest-framework-makes-the-operator-alignment-task-for-deep-learning-frameworks-easy-7e47143b7606" rel="noopener"><strong class="iz hj"><em class="jv">AutoTest框架使得深度学习框架的操作者对齐任务变得容易</em> </strong> </a></li><li id="3fd0" class="lr ls hi iz b ja ma je mb ji mc jm md jq me ju mi lx ly lz bi translated"><a class="ae kc" href="https://oneflow2020.medium.com/the-development-of-credit-based-flow-control-part-2-f04b76010a16" rel="noopener"> <strong class="iz hj"> <em class="jv">基于信用的流量控制的发展(下)</em> </strong> </a></li></ol><p id="b57e" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><em class="jv">欢迎访问OneFlow上的</em><strong class="iz hj"><em class="jv"/></strong><a class="ae kc" href="https://github.com/Oneflow-Inc/oneflow" rel="noopener ugc nofollow" target="_blank"><strong class="iz hj"><em class="jv">GitHub</em></strong></a><strong class="iz hj"><em class="jv"/></strong><em class="jv">并关注我们上的</em><strong class="iz hj"><em class="jv"/></strong><a class="ae kc" href="https://twitter.com/home" rel="noopener ugc nofollow" target="_blank"><strong class="iz hj"><em class="jv">推特</em></strong></a><strong class="iz hj"><em class="jv"/></strong><em class="jv">和</em> 【T5 </p><p id="3bdc" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">还有，欢迎加入我们的<a class="ae kc" href="https://discord.gg/4kpjGA5bZY" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> <em class="jv">不和谐群</em></strong></a><strong class="iz hj"><em class="jv"/></strong>讨论和提问OneFlow相关问题，与OneFlow贡献者和全球用户联系。</p></div></div>    
</body>
</html>