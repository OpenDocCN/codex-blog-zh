<html>
<head>
<title>Hybrid Quantum-Classical Neural Network for classification of images in FashionMNIST dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">混合量子-经典神经网络用于时尚主义者数据集中的图像分类</h1>
<blockquote>原文：<a href="https://medium.com/codex/hybrid-quantum-classical-neural-network-for-classification-of-images-in-fashionmnist-dataset-7274364f7dcd?source=collection_archive---------7-----------------------#2021-08-15">https://medium.com/codex/hybrid-quantum-classical-neural-network-for-classification-of-images-in-fashionmnist-dataset-7274364f7dcd?source=collection_archive---------7-----------------------#2021-08-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9f990e4d316a082d56af6af35e7f83bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TU-_m27ggIceqzzqVGBP2w.png"/></div></div></figure><p id="a091" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了在为期两周的关于量子机器学习的IBM Qiskit全球暑期学校2021之后开始我的量子之旅，我探索了Qiskit混合PyTorch经典-量子神经网络架构，该架构在<a class="ae jo" href="https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html" rel="noopener ugc nofollow" target="_blank"> Qiskit </a>中可用。对于任何想要探索量子计算并启动其量子之旅的人来说，探索如何将量子元素嵌入到您已经存在的AI/ ML工作流中，并从实验量子计算中获得更快的实际结果，是一个很好的起点。</p><p id="ffd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">量子计算的核心优势是利用量子力学现象如干涉、叠加和纠缠来获得计算优势。与经典计算相比，它有望提供指数级的计算速度，解决否则不可能解决的复杂问题。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jp"><img src="../Images/1ed97dcc5b3dc4d57ee7266ce0fed40f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-FkJSwpq8SpIh5uf-qg-iA.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">来自<a class="ae jo" href="https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html" rel="noopener ugc nofollow" target="_blank"> Qiskit教科书</a>的混合架构插图</figcaption></figure><p id="ad42" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本案例研究的范围是建立一个基本的混合量子经典神经网络架构，用于对FashionMNIST数据集中的图像进行分类。Qiskit的TorchConnector将用于将量子神经网络(QNN)层集成到PyTorch工作流中。QNN将作为PyTorch模块提供，无需额外考虑即可共同训练。Qiskit教科书中的上图很好地展示了混合架构。案例研究的代码可以在<a class="ae jo" href="https://github.com/Q-MAB/Qiskit-FashionMNIST-Case/edit/main/FashionMNIST%20case%20study.py" rel="noopener ugc nofollow" target="_blank"> Github </a>中找到。如果你想深入研究量子计算，请查阅参考文献。</p><h1 id="709d" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">量子经典神经网络</h1><p id="9973" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">将要使用的PyTorch架构是一个前馈神经网络。传统节点层的输入是(实值)向量。网络的隐藏层将是一个参数化的量子电路，它接受经典层的输出。量子电路的每个门的旋转角度将由经典输入向量的分量来指定。QNN的工作方式不同于传统的神经网络。输入数据被编码成量子位，而不是使用神经元、权重和偏差。最终的目标是一样的，最小化损失函数。然而，在QNN的情况下，其完成方式略有不同。一系列量子门，相当于传统电路的经典逻辑门，但在这种情况下是量子逻辑门，被应用于量子位。以最小化损失函数的方式改变门参数。它实际上将最小化网络预测和输入标签之间的差异。<a class="ae jo" href="https://www.amazon.com/Dancing-Qubits-quantum-computing-change/dp/1838827366" rel="noopener ugc nofollow" target="_blank">门操作</a>实际上是酉算子，是量子电路的构建模块。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/527a358c23288e19fb071018edf58738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y0wwEAYZje2dbvQaG7YCdQ.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">量子数据(蓝色/橙色显示两个映射标签)呈现在<a class="ae jo" rel="noopener" href="/from-the-diaries-of-john-henry/qml-6a5b68fb95d9">布洛赫球</a>(左)和一个<a class="ae jo" href="https://arxiv.org/abs/quant-ph/0207171v1" rel="noopener ugc nofollow" target="_blank">经典比特对量子比特</a>(右)的表示上</figcaption></figure><blockquote class="lc ld le"><p id="86d2" class="iq ir lf is b it iu iv iw ix iy iz ja lg jc jd je lh jg jh ji li jk jl jm jn hb bi translated">需要注意的是，在量子计算中，信息的基本单位是由一个量子位来表示的。与经典比特不同，量子比特在计算过程中始终只由0和1表示，量子比特可以通过形成其状态的线性组合<a class="ae jo" href="http://mmrc.amss.cas.cn/tlb/201702/W020170224608149940643.pdf" rel="noopener ugc nofollow" target="_blank"> |ψ⟩ = α|0⟩ + β |1⟩ </a>而进入叠加状态。只有在进行测量时，它才必须被很好地定义，要么以概率|α|坍缩到0，要么以概率|β|坍缩到1。这听起来可能违反直觉，因为量子位在测量之前可能存在于|0⟩和|1⟩之间的连续统中，但由于这一特性，它可能一次需要指数级的多个<em class="hi"> </em> <a class="ae jo" href="https://quantum-computing.ibm.com/composer/docs/iqx/guide/" rel="noopener ugc nofollow" target="_blank">逻辑状态</a>。纠缠是另一个有趣的属性，高度相关的两个量子态<a class="ae jo" href="http://mmrc.amss.cas.cn/tlb/201702/W020170224608149940643.pdf" rel="noopener ugc nofollow" target="_blank"> |ψ⟩ = |a⟩|b⟩ </a>无法独立描述，这使得<a class="ae jo" href="https://qiskit.org/textbook/ch-algorithms/superdense-coding.html" rel="noopener ugc nofollow" target="_blank">超密集</a>编码成为可能。本案例研究将使用线性纠缠。在测量中存在一定的随机性和不确定性，因此测量的输出将是它将处于的最可能的量子状态。</p></blockquote><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/97fa3463de81daa01da515718ebe513e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s-B6R7aotSrH7mjAH-FzXA.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated"><a class="ae jo" href="https://arxiv.org/pdf/2003.02989.pdf" rel="noopener ugc nofollow" target="_blank"> QNN建筑</a></figcaption></figure><p id="9ae9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了从混合架构中的经典数据到量子态，通过使用量子特征映射，经典数据(<em class="lf">【xᵢ】</em>)被编码到量子态空间(|<em class="lf">【ϕ(xᵢ】</em>【⟩】)中。然后经典数据在希尔伯特空间中以量子态<a class="ae jo" href="https://arxiv.org/pdf/1803.07128.pdf" rel="noopener ugc nofollow" target="_blank">表示，并可以作为我们参数化量子circuit⁸.的输入在这种情况下，ZZFeatureMap被构造并用于将经典特征向量映射到量子态。</a></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/d73a3f533ac354d3994b7fe8cffb2e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dF57fqqLb3b4te_jJACJ2A.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">一个<a class="ae jo" href="https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html" rel="noopener ugc nofollow" target="_blank"> ZZFeatureMap </a>的更详细的例子，带有哈达玛和CNOT门操作</figcaption></figure><p id="1d5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后使用Qiskit的TwoLayerQNN类创建一个两层QNN，并作为隐藏层嵌入PyTorch架构中。TwoLayerQNN通过提供构造的ZZFeatureMap和Ansatz(量子状态将仅具有实振幅)加上量子位的数量来初始化。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="9435" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输入梯度被设置为真，以允许混合梯度反向传播。实现了线性纠缠，并且在这种情况下<a class="ae jo" href="https://qiskit.org/documentation/apidoc/qiskit.aqua.operators.expectations.html" rel="noopener ugc nofollow" target="_blank">泡利期望</a>用于计算相对于状态函数的可观察的期望值。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/77eecda0552a77b458e257011eba977b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4r_g066zCMBe09rMrEhUcQ.png"/></div></div></figure><p id="7536" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整的FashionMNIST数据集包含10个类别的60000幅图像和10000幅时尚对象的测试图像。在这种情况下，只有两个标签从训练数据集中过滤出来，即t恤和裤子。一旦建立了一个工作的混合框架，下一步可能是通过添加更多的量子位和门操作来扩展到多标签预测(和时间，我在EuroPython 2021大会期间利用业余时间进行了这个案例研究，多标签预测需要更多的时间)。过滤后的数据被上传到PyTorch的DataLoader中，它在数据集周围包装了一个iterable，以便于访问样本。</p><p id="2f9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">经典的卷积神经网络(CNN)是由完全连接的层创建的，其中嵌入了QNN。简单地定义一下神经网络中的卷积:“对两个函数进行数学运算以产生第三个函数，其中参数被共享以提高计算效率”(<a class="ae jo" href="https://businessdatascience.nl/deep-learning-summer-course" rel="noopener ugc nofollow" target="_blank"> Raviv，E </a>)。在每个操作中，下一层的大小相对于当前层减小。CNN的每个神经元都被输入一个乘以不同权重的输入向量。该操作的结果被评估并被转发到下一层。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="7bea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最大池用于下采样操作，ReLu用作激活函数。输入层的输出被转发到QNN，然后转发到输出层以获得最终预测。TorchConnector功能支持将QNN集成到经典CNN中。沿着布洛赫球的Z轴在QNN末端进行的测量实际上将量子数据转换成经典数据。模型的优化是用<a class="ae jo" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank">亚当</a>优化器完成的。</p><h1 id="3c95" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结果</h1><p id="99de" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">代码在jupyter-notebook上实现。混合分类器表现得足够好。虽然，一开始精确度可能不是很高。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/a1944d1ba7b4951f49c553c052a1bcb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yuIQl67j-WRROz4gh1Z0Cw.png"/></div></div></figure><p id="aee9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">启用线性纠缠后，模型预测的准确度为96.2%。人们希望获得更高的精度，但我们不得不把它放在一边，以便进一步研究。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/3776d3a3c49d66dba040fdb5e0102f96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQOlR9MCv2M0LRAmshTvMA.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">由混合CNN-QNN架构预测的图像</figcaption></figure><p id="5b0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果可能不会像一开始承诺的那样显示出巨大的量子优势。量子层实际上是在经典计算机上计算/模拟的(还不是在量子计算机本身上)，计算量子计算机在理想情况下会做什么。这一简短案例研究的范围是探索一种具有TorchConnector和两层QNN的初始混合架构，这种架构可以在以后的进一步研究和开发中进行优化或改进。此外，该项目可以扩展到多类预测。</p><p id="0147" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在等待容错量子计算机创造真正的量子优势时，利用当前<a class="ae jo" href="https://quantumcomputing.stackexchange.com/questions/1885/what-is-meant-by-noisy-intermediate-scale-quantum-nisq-technology" rel="noopener ugc nofollow" target="_blank">嘈杂的中等规模量子</a>设备可以做很多事情来创建概念证明(这将是具有大约百万量子位的量子计算机，参见<a class="ae jo" href="https://www.ibm.com/blogs/research/2021/02/quantum-development-roadmap/" rel="noopener ugc nofollow" target="_blank">IBM</a>的路线图)。因此，现在是时候开始考虑为你的企业或组织制定一个量子战略，如何及时采用和集成量子计算来为你带来优势。</p><h1 id="be90" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">短暂旅程的终点..</h1><p id="02e6" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">当我们在2021年夏天接近我的量子旅程的终点时，这同时也是一个更大旅程的开始。考虑到目前大型企业在量子计算方面的发展和重大投资，以及数千名对量子计算充满热情和兴趣的研究人员和开发人员，我对量子计算的未来及其将开启的许多可能性和它将创造的许多机会感到非常兴奋。我很高兴我能加入这个激动人心的伟大旅程。</p><h1 id="6fbe" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="9574" class="lq lr hi is b it kw ix kx jb ls jf lt jj lu jn lv lw lx ly bi translated"><a class="ae jo" href="https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html" rel="noopener ugc nofollow" target="_blank">https://qi skit . org/textbook/ch-machine-learning/machine-learning-qi skit-py torch . html</a></li><li id="4ef1" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated">Sutor，R (2019)“与量子位共舞:量子计算如何工作以及它如何改变世界”，Packt。</li><li id="09d1" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated">Loredo，R (2020)“用Python和IBM量子经验学习量子计算”，Packt。</li><li id="4cae" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated"><a class="ae jo" rel="noopener" href="/from-the-diaries-of-john-henry/qml-6a5b68fb95d9">https://medium . com/from-the-diaries of-the-John-Henry/qml-6a 5b 68 FB 95d 9</a></li><li id="2934" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated">克尼尔，W (2008)《量子信息处理导论》，<a class="ae jo" href="https://arxiv.org/abs/quant-ph/0207171v1" rel="noopener ugc nofollow" target="_blank">arXiv:quant-ph/0207171 v1</a>。</li><li id="4bbf" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated"><a class="ae jo" href="https://www.ibm.com/blogs/research/2021/02/quantum-development-roadmap/" rel="noopener ugc nofollow" target="_blank">https://www . IBM . com/blogs/research/2021/02/quantum-development-roadmap/</a>。</li><li id="0406" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated"><a class="ae jo" rel="noopener" href="/qiskit/building-a-quantum-variational-classifier-using-real-world-data-809c59eb17c2">https://medium . com/qi skit/building-a-quantum-variation-classifier-using-real-world-data-809 c 59 EB 17 c 2</a>。</li><li id="256f" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated">Schuld，M. (2018)“特征希尔伯特空间中的量子机器学习”，【https://arxiv.org/pdf/1803.07128.pdf】T2。</li><li id="c18e" class="lq lr hi is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly bi translated">Nielsen，M. &amp; Chuang I. (2010)《量子计算与量子信息》，剑桥大学出版社。</li></ol></div></div>    
</body>
</html>