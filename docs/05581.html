<html>
<head>
<title>Beginners Guide to Classification Models (Catch Credit Card Fraud)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类模型初学者指南(捕捉信用卡欺诈)</h1>
<blockquote>原文：<a href="https://medium.com/codex/beginners-guide-to-classification-models-catch-credit-card-fraud-fe5a73a3401f?source=collection_archive---------2-----------------------#2022-03-13">https://medium.com/codex/beginners-guide-to-classification-models-catch-credit-card-fraud-fe5a73a3401f?source=collection_archive---------2-----------------------#2022-03-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="867e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">异常检测</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/146dc0e5200df1d57f485252601decf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TdJNCu2UybFoWPeXptUq-w.png"/></div></div></figure><p id="70bc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您是否知道，一个典型的组织每年因欺诈而损失约5%的收入？然而，用户行为中也有微妙和隐藏的事件，这些事件可能不明显，但仍然预示着可能的欺诈。机器学习允许创建处理具有许多变量的大型数据集的算法，并帮助找到用户行为和欺诈行为可能性之间的隐藏相关性。与基于规则的系统相比，机器学习系统的另一个优势是更快的数据处理和更少的人工工作。例如，智能算法非常适合行为分析，有助于减少验证步骤的数量。</p><h2 id="45c7" class="kf kg hi bd kh ki kj kk kl km kn ko kp js kq kr ks jw kt ku kv ka kw kx ky kz bi translated">本文的目的:</h2><blockquote class="la lb lc"><p id="a24e" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">本文面向数据科学领域的初学者&amp;旨在演示如何系统地解决这个问题，并开始使用为欺诈检测相关的不平衡分类问题而设计的技术。<strong class="jl hj">当类别不平衡时，我们将着重于选择合适的模型评估指标。我会尝试触及各种常见的话题，但也会尽可能地简化概念。</strong></p></blockquote><h1 id="ff35" class="lh kg hi bd kh li lj lk kl ll lm ln kp io lo ip ks ir lp is kv iu lq iv ky lr bi translated">数据集描述:</h1><blockquote class="la lb lc"><p id="efa0" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">数据集fraud_data.csv是从Coursera网站下载的。fraud_data.csv中的每一行都对应于一笔信用卡交易。</p><p id="cfe9" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">2.功能包括机密变量V1到V28以及交易金额。</p><p id="fc6d" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">3.目标存储在“class”列中，对于欺诈性交易，该列的值为1，否则为0。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ls"><img src="../Images/4e360cf47dae0a15eaa19814921d7f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VoWkr7oR7EA1zVnNGULCg.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">取样前几行</figcaption></figure><blockquote class="la lb lc"><p id="5dfd" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">4.我们可以看到第一列是时间，是整数，倒数第二列是购买金额。我们可以看到PCA变换后的特征是正负的，包含了很多浮点精度。</p><p id="3bc7" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">5.时间列不太可能有用，可能会被删除。PCA变量和美元数量之间的比例差异表明，数据缩放应该用于那些对输入变量的比例敏感的算法。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/2928e61a75220a084710d3fafc5f26d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TruJGiJXVaaHlCLOOXG8ng.png"/></div></div></figure><h1 id="6256" class="lh kg hi bd kh li lj lk kl ll lm ln kp io lo ip ks ir lp is kv iu lq iv ky lr bi translated"><strong class="ak">数据探索</strong></h1><p id="cce6" class="pw-post-body-paragraph jj jk hi jl b jm ly ij jo jp lz im jr js ma ju jv jw mb jy jz ka mc kc kd ke hb bi translated">在这里，我们将检查fraud_data.csv数据集的汇总统计数据&amp;我们将在这一部分花很多时间。在构建任何东西之前，了解数据是很重要的。</p><p id="6c6e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">稍后，我们将把数据集分成训练集和测试集来训练几个模型，在下一节中，我们将评估它们在检测信用卡交易欺诈方面的有效性。</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="f483" class="kf kg hi me b fi mi mj l mk ml">df <strong class="me hj">=</strong> read_transactions_data()<br/><br/><strong class="me hj">print</strong>(round(df<strong class="me hj">.</strong>describe()<strong class="me hj">.</strong>transpose(), 3))<br/><strong class="me hj">print</strong>('\nThe number of missing values across all attributes and samples: ', df<strong class="me hj">.</strong>isnull()<strong class="me hj">.</strong>sum()<strong class="me hj">.</strong>sum())</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/660520f109b51e403100e765b1746eda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VPKuDJ0lbnohIvqPjDEFJA.png"/></div></div></figure><p id="43cd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">观察结果1: </strong>下面的汇总统计显示，数据中有284806笔交易，其中0.17%是欺诈性的(即欺诈类仅代表观察结果的一小部分)。</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="0f27" class="kf kg hi me b fi mi mj l mk ml">#This code is for the bar graph above<br/>ax = df[‘Class’].value_counts().plot(kind=’bar’, figsize=(10, 6), fontsize=13, color=’#087E8B’)<br/>ax.set_title(‘Count of Valid vs Fraud Transactions’, size=20, pad=30)<br/>ax.set_ylabel(‘Count’, fontsize=14)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/e998c39daffa56451c02d2845473d2c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fvHeiDkdiNMV_eAEBO0YTA.png"/></div></div></figure><p id="4fcd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">为什么不平衡数据会引起关注？</strong></p><blockquote class="la lb lc"><p id="c900" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">如果目标变量的至少一个类仅构成非常小的少数，则数据集是不平衡的。在监督机器学习模型中，目标变量中的类别不平衡会导致严重偏向多数类别，并降低可预测性。不平衡数据在银行、保险、工程和许多其他领域普遍存在。只需知道，在欺诈检测中，不平衡的比例通常为100:1。</p></blockquote><p id="327b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">观察结果2: </strong>平均交易金额大大高于中位数，表明有相对少量的非常大的交易推动平均值上升。数据集没有缺失值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/d78a1bf8387b1a6707e2751df3943489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xAK__76sVo3rR-4c5Ioy9g.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">汇总统计</figcaption></figure><p id="606c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">观察三:</strong></p><p id="a5c6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在“数量”列中，我们可以看到大多数数量都很小，平均值约为88，中间50%的观察值介于5和77之间。最大值约为25，691，这似乎是一个异常值，当然会提高分布。</p><p id="e138" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">观察四:</strong></p><p id="fc81" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">大多数PCA分量的分布是高斯型的，并且许多可能以零为中心，这表明变量被标准化为PCA变换的一部分。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/e5ded78e574536e811a7845c3957b09d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7SVbd6qEYHiMbItYAGv7A.png"/></div></div></figure><p id="4ae8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">重要注意事项:</strong></p><ol class=""><li id="6fbe" class="mq mr hi jl b jm jn jp jq js ms jw mt ka mu ke mv mw mx my bi translated">在我们训练模型之前，需要对特征进行缩放。</li></ol><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="d45a" class="kf kg hi me b fi mi mj l mk ml"><em class="ld"># Split the data into X_train, X_test, y_train, y_test</em><br/>X <strong class="me hj">=</strong> df<strong class="me hj">.</strong>iloc[:,:<strong class="me hj">-</strong>1]<br/>y <strong class="me hj">=</strong> df<strong class="me hj">.</strong>iloc[:,<strong class="me hj">-</strong>1]<br/><br/>X_train, X_test, y_train, y_test <strong class="me hj">=</strong> train_test_split(X, y, random_state <strong class="me hj">=</strong> 0)</span></pre><p id="53da" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">2.该代码将使一个定标器适合训练数据，并使用适合的定标器转换训练和测试数据。(注:定标器应仅适用于训练数据，以防止测试数据中的信息泄漏。)</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="a1f3" class="kf kg hi me b fi mi mj l mk ml">scaler <strong class="me hj">=</strong> StandardScaler()<strong class="me hj">.</strong>fit(X_train)<br/>X_train <strong class="me hj">=</strong> scaler<strong class="me hj">.</strong>transform(X_train)<br/>X_test <strong class="me hj">=</strong> scaler<strong class="me hj">.</strong>transform(X_test)</span></pre><h2 id="dc70" class="kf kg hi bd kh ki kj kk kl km kn ko kp js kq kr ks jw kt ku kv ka kw kx ky kz bi translated">你为什么要关心阶级不平衡及其在选择度量标准中的作用？</h2><p id="b700" class="pw-post-body-paragraph jj jk hi jl b jm ly ij jo jp lz im jr js ma ju jv jw mb jy jz ka mc kc kd ke hb bi translated">只有一小部分交易是欺诈性的，预测每个交易不是欺诈性的分类器将达到99%的准确度分数。这样的分类器对我们没有价值。因此，在类别不平衡的情况下，应该考虑准确性以外的度量。这些度量包括精确度、召回率以及这两个度量的组合(F2)。</p><h1 id="8925" class="lh kg hi bd kh li lj lk kl ll lm ln kp io lo ip ks ir lp is kv iu lq iv ky lr bi translated">拟合和评估ML模型一般</h1><p id="9e34" class="pw-post-body-paragraph jj jk hi jl b jm ly ij jo jp lz im jr js ma ju jv jw mb jy jz ka mc kc kd ke hb bi translated">这是对我们初看时如何处理这个问题的回顾</p><p id="4b9a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">步骤1 </strong>:我们训练一个虚拟分类器，将所有事物分类为训练数据的主要类别(即，所有交易都不是欺诈性的)</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="58eb" class="kf kg hi me b fi mi mj l mk ml"><strong class="me hj">def</strong> <strong class="me hj">dummy_classifier</strong>():<br/>    <br/>    dummy_majority <strong class="me hj">=</strong> DummyClassifier(strategy <strong class="me hj">=</strong> 'most_frequent')<strong class="me hj">.</strong>fit(X_train, y_train)<br/>    accuracy <strong class="me hj">=</strong> dummy_majority<strong class="me hj">.</strong>score(X_test, y_test)<br/>    <br/>    <strong class="me hj">return</strong> accuracy</span></pre><p id="8a49" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">虚拟分类器练习的主要收获</strong></p><blockquote class="la lb lc"><p id="835f" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">1)正如所讨论的，该函数返回超过99%的准确度分数。</p><p id="064b" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">2)同时，召回率(换句话说，所有欺诈交易中被正确预测为欺诈的部分)是0%。这是因为该模型不是为了将任何交易归类为欺诈而设计的。因此，尽管准确度分数很高，但模型表现不佳。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/9265f548afbd56db0a0900f24a93b482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0VWL-EuxdXuq4qya667x8A.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">虚拟分数</figcaption></figure><p id="0ea5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">步骤2 SVC → </strong>接下来，我们使用默认参数训练支持向量分类器(SVC ):</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="6ad8" class="kf kg hi me b fi mi mj l mk ml"><strong class="me hj">def</strong> <strong class="me hj">SVC_classifier</strong>():<br/><br/>    svm <strong class="me hj">=</strong> SVC()<strong class="me hj">.</strong>fit(X_train, y_train)<br/>    y_pred <strong class="me hj">=</strong> svm<strong class="me hj">.</strong>predict(X_test)<br/>    accuracy <strong class="me hj">=</strong> svm<strong class="me hj">.</strong>score(X_test, y_test)<br/>    precision <strong class="me hj">=</strong> precision_score(y_test, y_pred)<br/>    recall <strong class="me hj">=</strong> recall_score(y_test, y_pred)<br/>    <br/>    <strong class="me hj">return</strong> (accuracy, recall, precision)</span></pre><p id="3033" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">准确度、召回率和精确度现在分别是0.995、0.67和0.96。召回率从零增加到0.67表明SVC比简单的多数类规则执行得好得多。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es na"><img src="../Images/ef4df009899ac35d72d32eee53c7797a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-9oLhaIw9szbADQ75mGyaQ.png"/></div></div></figure><p id="ceda" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">步骤3 - &gt;混淆矩阵</strong></p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="a085" class="kf kg hi me b fi mi mj l mk ml"><strong class="me hj">def</strong> <strong class="me hj">confusion_mtrx</strong>():<br/>    <br/>    svm <strong class="me hj">=</strong> SVC()<strong class="me hj">.</strong>fit(X_train, y_train)<br/>    y_pred <strong class="me hj">=</strong> svm<strong class="me hj">.</strong>predict(X_test)<br/>    confusion <strong class="me hj">=</strong> confusion_matrix(y_test, y_pred)<br/>    <br/>    <strong class="me hj">return</strong> confusion<br/><br/><strong class="me hj">print</strong>(confusion_mtrx())</span></pre><p id="c194" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">一张图胜过千言万语，你可以这样解释:</p><p id="4921" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">三个假阳性不构成威胁，但33个假阴性是算法无法准确分类的欺诈案件。</p><div class="iy iz ja jb fd ab cb"><figure class="nb jc nc nd ne nf ng paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/07571f1d4b13aeb01736e0acd0c3719d.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*WrGF2G2UbWFtcdYt6xd0mg.png"/></div></figure><figure class="nb jc nh nd ne nf ng paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/5690aa9d590b96cf2c41b5901ee29f6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*KjOWxMU4ueaCD9lsbQpRAQ.png"/></div></figure></div><p id="660f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">步骤4 - &gt; </strong>让我们试着跳过SVC &amp;代之以用默认参数训练逻辑回归分类器。对于这个分类器，我们然后使用测试数据创建一个精确召回曲线和一个ROC曲线。但是，在我们开始深入研究代码之前，您需要了解一些事情:</p><blockquote class="la lb lc"><p id="85ba" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">注意:一条<strong class="jl hj">精确-召回曲线</strong>显示了召回和精确之间的权衡。</p><p id="2533" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">注:<strong class="jl hj"> ROC曲线</strong>当真阳性率增加时，以假阳性率衡量成本。</p><p id="deea" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">注意:信用卡公司旨在优化召回。当我在一家保险公司工作时，我们通常会优化精确度。召回只是所有实际欺诈案例中预测欺诈案例的一小部分。换句话说，我们抓到了多少诈骗案？这就转化成了𝑅𝑒𝑐𝑎𝑙𝑙=𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠/𝑇𝑟𝑢𝑒𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑠+𝐹𝑎𝑙𝑠𝑒𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒𝑠公式</p><p id="0d94" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">Davis和Goadrich在这篇<a class="ae ni" href="http://ftp.cs.wisc.edu/machine-learning/shavlik-group/davis.icml06.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中提出，在处理高度倾斜的数据集时，精确召回(PR)曲线将比ROC提供更多信息。PR曲线描绘了精确度与召回率的关系(FPR)。因为精度直接受到类别不平衡的影响，所以精度-召回曲线更好地突出了高度不平衡数据集的模型之间的差异。当您比较具有不平衡设置的不同模型时，精确度-召回曲线下的区域将比ROC曲线下的区域更敏感。</p></blockquote><p id="9572" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在我谈论更多的PR曲线之前，让我先谈谈阈值的概念。</p><h2 id="bcf1" class="kf kg hi bd kh ki kj kk kl km kn ko kp js kq kr ks jw kt ku kv ka kw kx ky kz bi translated">PR曲线的阈值设置</h2><p id="ae1c" class="pw-post-body-paragraph jj jk hi jl b jm ly ij jo jp lz im jr js ma ju jv jw mb jy jz ka mc kc kd ke hb bi translated">通常，分类模型预测概率。在我们的例子中，我们正在寻找给定记录的欺诈概率。通过将概率值与阈值进行比较(例如，如果概率超过80%，则标记为欺诈)，我们可以将记录分类。这意味着我们需要首先定义规则。</p><p id="b9be" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">为什么会在意门槛和职业？</strong></p><blockquote class="la lb lc"><p id="87c5" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">当构建混淆矩阵和计算准确率和召回率时，我们需要预测的类别而不是概率分数。这就是原因。</p></blockquote><p id="7e14" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您应该在任何想要可视化假阳性和假阴性之间的权衡的时候可视化精度-召回曲线。大量的假阳性导致低精度，大量的假阴性导致低召回率。</p><p id="a45a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您应该以高精度和高召回模型为目标，但在现实中，一个指标更重要(在这种情况下召回，我们不想忽略任何欺诈者)，因此您可以随时为它进行优化。优化后，相应调整分类阈值。</p><p id="5eda" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们将使用推荐的精确召回曲线下面积指标或PR AUC。以下是你如何在脑海中形象化和合理化这个方法:</p><blockquote class="la lb lc"><p id="99b3" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">让我们开始写一些代码:</p></blockquote><p id="b9d9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在我们知道了什么是精度、召回率和阈值，一旦我们计算了多个阈值的精度和召回率，我们就在x轴上绘制召回率，在y轴上绘制精度-召回率曲线。</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="0fde" class="kf kg hi me b fi mi mj l mk ml">lr = LogisticRegression().fit(X_train, y_train)<br/>#use logistic regression model to make predictions<br/>y_score = lr.decision_function(X_test)<br/>precision, recall, thresholds = precision_recall_curve(y_test, y_score)<br/>#create precision recall curve<br/>fig, ax = plt.subplots()<br/>ax.plot(recall, precision, color='purple')</span><span id="e7b3" class="kf kg hi me b fi nj mj l mk ml">#add axis labels to plot<br/>ax.set_title('Precision-Recall Curve')<br/>ax.set_ylabel('Precision')<br/>ax.set_xlabel('Recall')</span><span id="085b" class="kf kg hi me b fi nj mj l mk ml">#display plot<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/093be7a3989dc66e24efeabc4a51ba28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FbZVv5fbMd5XhnMbUr9jvA.png"/></div></div></figure><p id="3159" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这表明召回率为0.82(82%的欺诈交易在测试数据中被识别为欺诈交易)，其中20%被预测为欺诈的交易被错误地预测)</p><h2 id="6f9b" class="kf kg hi bd kh ki kj kk kl km kn ko kp js kq kr ks jw kt ku kv ka kw kx ky kz bi translated">让我们从不同的角度来看这个问题。</h2><blockquote class="la lb lc"><p id="663f" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">第一步:我们将让算法首先预测一个概率或类似概率的度量。</p><p id="87fe" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">步骤2:然后在不同的阈值范围内使用精度和召回率来评估预测的概率，以将概率映射到类别标签，并且作为最后一步</p><p id="9491" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">步骤3:这些阈值曲线下的面积被报告为模型的性能。</p><p id="08c6" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">最终结果:这允许最终模型的操作者选择将概率映射到类别标签(欺诈或非欺诈交易)的阈值，该阈值最好地平衡最终模型的精确度和召回率。</p><p id="658f" class="jj jk ld jl b jm jn ij jo jp jq im jr le jt ju jv lf jx jy jz lg kb kc kd ke hb bi translated">我们将如何做第一步:当涉及到评估模型时，我们将使用<strong class="jl hj">重复k-fold交叉验证和分层</strong>。为什么我们要这样做？在k折叠中具有大约十个折叠，其中每个折叠包含284807/10 = 28480个示例，这将比单个训练测试分割做得好得多。这将确保模型性能不会偏向于非欺诈案例。<strong class="jl hj">使用分层</strong>就像锦上添花，我们将能够保护99.8%到0.2%的正常和欺诈交易。<strong class="jl hj">简单地说，重复3次</strong>意味着评估过程将被多次执行，以避免结果的偶然性，并更好地捕捉所选模型的变化。</p></blockquote><p id="a786" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">第一步:让算法预测</strong></p><p id="a19c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这里，我们将依次定义每个模型，并将它们添加到一个列表中，以便我们可以按顺序对它们进行评估。下面的<em class="ld"> get_models() </em>函数定义了用于评估的模型列表，以及用于稍后绘制结果的模型简称列表。</p><p id="7005" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这种情况下，我们可以看到，所有测试的算法都具有这种技能，实现了高于默认值0.5的PR AUC。结果表明，决策树算法的集成在这个数据集上都做得很好。</p><p id="ee0c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">创建一个图形，显示每个算法的一个方框和须状图。该框显示中间的50%数据，每个框中间的橙色线显示样本的中值，每个框中的绿色三角形显示样本的平均值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/c1268c16750166c0b444c26006616a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GOn8BTQzi6P-55t8FSFp7w.png"/></div></div></figure><p id="7c70" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们可以看到，决策树的RF和系综的分数分布是紧密的，并且平均值似乎与中位数一致，这表明分布可能是对称的，并且可能是高斯分布，并且分数可能是相当稳定的。上述代码如下所示:</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="0d4a" class="kf kg hi me b fi mi mj l mk ml"># spot check machine learning algorithms on the credit card fraud dataset<br/>from numpy import mean<br/>from numpy import std<br/>from pandas import read_csv<br/>from matplotlib import pyplot<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.model_selection import RepeatedStratifiedKFold<br/>from sklearn.metrics import precision_recall_curve<br/>from sklearn.metrics import auc<br/>from sklearn.metrics import make_scorer<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.ensemble import ExtraTreesClassifier<br/>from sklearn.ensemble import BaggingClassifier<br/> <br/># load the dataset<br/>def load_dataset(full_path):<br/> # load the dataset as a numpy array<br/> data  = pd.read_excel(full_path,index_col= None, header= 0)<br/> # retrieve numpy array<br/> data = data.values<br/> # split into input and output elements<br/> X, y = data[:, :-1], data[:, -1]<br/> return X, y<br/> <br/># calculate precision-recall area under curve<br/>def pr_auc(y_true, probas_pred):<br/> # calculate precision-recall curve<br/> p, r, _ = precision_recall_curve(y_true, probas_pred)<br/> # calculate area under curve<br/> return auc(r, p)</span><span id="0d78" class="kf kg hi me b fi nj mj l mk ml"># evaluate a model<br/>def evaluate_model(X, y, model):<br/> # define evaluation procedure<br/> cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)<br/> # define the model evaluation the metric<br/> metric = make_scorer(pr_auc, needs_proba=True)<br/> # evaluate model<br/> scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)<br/> return scores</span><span id="8e15" class="kf kg hi me b fi nj mj l mk ml">def get_models():<br/> models, names = list(), list()<br/> # CART<br/> models.append(DecisionTreeClassifier())<br/> names.append('CART')</span><span id="44e4" class="kf kg hi me b fi nj mj l mk ml">models.append( LogisticRegression())<br/> names.append('LR')<br/> # RF<br/> models.append(RandomForestClassifier(n_estimators=100))<br/> names.append('RF')</span><span id="4478" class="kf kg hi me b fi nj mj l mk ml">return models, names</span><span id="89a1" class="kf kg hi me b fi nj mj l mk ml"># define the location of the dataset<br/>full_path = 'creditcard.xlsx'<br/># load the dataset<br/>X, y = load_dataset(full_path)<br/># define models<br/>models, names = get_models()<br/>results = list()<br/># evaluate each model<br/>for i in range(len(models)):<br/> # evaluate the model and store results<br/> scores = evaluate_model(X, y, models[i])<br/> results.append(scores)<br/> # summarize performance<br/> print('&gt;%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))<br/># plot the results<br/>pyplot.boxplot(results, labels=names, showmeans=True)<br/>pyplot.show()</span></pre><p id="afc6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们将使用RF模型作为我们的最终模型，因为它实现了高PR AUC。</p><p id="4efd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">正如我们可能希望的那样，使用F分数作为度量标准，大多数示例都可以通过默认阈值0.5正确预测。</p><pre class="iy iz ja jb fd md me mf mg aw mh bi"><span id="43e9" class="kf kg hi me b fi mi mj l mk ml"><br/>model = RandomForestClassifier(n_estimators=100)<br/>model.fit(trainX, trainy)<br/># predict probabilities<br/>yhat = model.predict_proba(testX)<br/># keep probabilities for the positive outcome only<br/>yhat = yhat[:, 1]<br/># calculate roc curves<br/>precision, recall, thresholds = precision_recall_curve(testy, yhat)<br/># convert to f score<br/>fscore = (2 * precision * recall) / (precision + recall)<br/># locate the index of the largest f score<br/>ix = argmax(fscore)<br/>print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))<br/># plot the roc curve for the model<br/>no_skill = len(testy[testy==1]) / len(testy)<br/>pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')<br/>pyplot.plot(recall, precision, marker='.', label='RF')<br/>pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')<br/># axis labels<br/>pyplot.xlabel('Recall')<br/>pyplot.ylabel('Precision')<br/>pyplot.legend()<br/># show the plot<br/>pyplot.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/6724f2f1890c02be1143c6d5dba9f22e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tC0rR2P3yeursVmmDOub1g.png"/></div></div></figure><p id="fd5b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">拟合最终模型包括在拟合模型之前定义管道来缩放数值变量。</p><p id="cf3a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然后，可以使用管道直接对新数据进行预测，并使用与对训练数据集执行的操作相同的操作来自动缩放新数据。</p><h1 id="b0e3" class="lh kg hi bd kh li lj lk kl ll lm ln kp io lo ip ks ir lp is kv iu lq iv ky lr bi translated"><strong class="ak">结论</strong></h1><p id="037f" class="pw-post-body-paragraph jj jk hi jl b jm ly ij jo jp lz im jr js ma ju jv jw mb jy jz ka mc kc kd ke hb bi translated">总之，我们学习了如何用强大的测试工具系统地评估一套机器学习模型&amp;如何拟合最终模型，并使用它来预测特定案例中的欺诈概率。</p></div></div>    
</body>
</html>