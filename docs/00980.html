<html>
<head>
<title>How I turned my vacuum cleaner into a semi-autonomous camera operator.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我是如何把我的吸尘器变成一个半自动相机操作者的。</h1>
<blockquote>原文：<a href="https://medium.com/codex/how-i-turned-my-vacuum-cleaner-into-a-semi-autonomous-camera-operator-c54bb65fb12f?source=collection_archive---------13-----------------------#2021-03-28">https://medium.com/codex/how-i-turned-my-vacuum-cleaner-into-a-semi-autonomous-camera-operator-c54bb65fb12f?source=collection_archive---------13-----------------------#2021-03-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="f2fb" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph"><a class="ae ge" href="http://medium.com/codex" rel="noopener">法典</a></h2><div class=""/><blockquote class="io ip iq"><p id="d5da" class="ir is it iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hb bi translated">当导演是个酒鬼，音乐家是个瘾君子，程序员变得疯狂，而你的摄影师是个吸尘器。</p></blockquote><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es jq"><img src="../Images/9e8953974fac93736b7434c7c3ee4b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dZ8PHXkCIwB5nhwhluv5uQ.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">接线员。</figcaption></figure><p id="2fb8" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">是的，不开玩笑——Roomba确实被迫向我提供了一些原始视频资料，但首先要做的是。我怎么会变成那样？几年前，我熬过了最黑暗的时刻，所以我需要一些我能投入全部思想和精力的东西，而不是不停地胡思乱想。发现了YouTube。</p><p id="2f59" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">我从来没有计划或任何意愿成为一个youtuber，但当我又发了一个我自己覆盖任何乐队的视频时，我的朋友们真的很生气。他们恳求要么停下来，要么开辟一条通道。我选择了后者，这最终迫使我提高了质量，所以我接受了挑战。无论有多少乐器，无论我演奏得有多糟糕，每次都让它活起来。独自完成:没有其他人参与(可能除了适量的酒精)。当然，从一个视频到另一个视频都要保持创意。所以在某个时候，我发挥了我的创作能力去做静态图片。在坚持自己动手的过程中，需要一些创造性的行动，Roomba也是如此。</p><figure class="jr js jt ju fd jv"><div class="bz dy l di"><div class="kj kk l"/></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">结果。</figcaption></figure><h1 id="8454" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">人工智能方法。</h1><p id="4c10" class="pw-post-body-paragraph ir is hi iu b iv lj ix iy iz lk jb jc kg ll jf jg kh lm jj jk ki ln jn jo jp hb bi translated">第一个使用人工智能的想法。为什么不呢？这个想法很简单——在我表演的时候强迫它跟着我。强迫生物移动没什么大不了的，但让它那样做..</p><p id="3468" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">首先，我研究了如何接近视频部分。结果我可以用OpenCV +一些神经网络来解决这个问题。找到了一些我可以使用的简单例子，我自己尝试了一些，最终被认为更像猫而不像人。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es lo"><img src="../Images/ad20d82c1fbd64463f728d32bd385ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qBpnGlZhrISd3tE2eKQJWw.jpeg"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">你真好，OpenCV！</figcaption></figure><p id="41b7" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">不太可靠，但是很好，很管用。那是我笔记本电脑的摄像头，但我需要分析RPi的摄像头流。让我们来看看您的第一订单中有哪些相机选项:</p><ul class=""><li id="3547" class="lp lq hi iu b iv iw iz ja kg lr kh ls ki lt jp lu lv lw lx bi translated"><strong class="iu hs">拉斯皮维德</strong></li><li id="b5ac" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp lu lv lw lx bi translated"><strong class="iu hs">拉斯平佩格</strong></li><li id="e918" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp lu lv lw lx bi translated"><strong class="iu hs"> RPi Cam Web界面</strong></li></ul><p id="151d" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">我最后用了后者。最终，它位于<strong class="iu hs"> <em class="it"> raspimpeg </em> </strong>之上，但通过老式PHP提供给你的非常老式的用户界面，为你的相机提供了一套非常好的控制。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es md"><img src="../Images/d8e16cfd2c4e6f3d51657bf72cd0b643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*Ojz6baXOc7Z9Oy_9VHuk1g.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">对于millesimals来说，这看起来可能很难看，但它确实有效。</figcaption></figure><p id="18cd" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">不幸的是它没有API，不是吗？如果你够固执的话，就一定会的！这就是<a class="ae me" href="https://github.com/silvanmelchior/RPi_Cam_Web_Interface/blob/master/www/cam_pic.php" rel="noopener ugc nofollow" target="_blank">cam.php</a>里面的东西:</p><pre class="jr js jt ju fd mf mg mh mi aw mj bi"><span id="c40b" class="mk km hi mg b fi ml mm l mn mo">&lt;?php  <br/>  header("Access-Control-Allow-Origin: *");  <br/>  header("Content-Type: image/jpeg");   <br/>    if (isset($_GET["pDelay"]))   <br/>    {      <br/>        $preview_delay = $_GET["pDelay"];   <br/>    } else {      <br/>        $preview_delay = 10000;   <br/>    }   <br/>    usleep($preview_delay);   <br/>    readfile("/dev/shm/mjpeg/cam.jpg"); <br/>?&gt;</span></pre><p id="630a" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">原来有一个端点，它实际上给了你存储在<strong class="iu hs"> /dev/shm/mjpeg/cam.jpg </strong>中的当前帧。就像我之前说的，这个项目很好地位于<strong class="iu hs"><em class="it">raspinpeg</em></strong>的顶部，这是它存储从RPi的cam捕获的内容的地方。从某种意义上说，这是一个幻灯片。但是我不在乎它是什么，只要它可以通过HTTP到达。的确如此。太好了。非常合适。</p><p id="e2ee" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">下一件事是改变示例服务器的代码，以便它可以分析我的流，而不是捕获网络摄像头的流。简单地说，我明白了<a class="ae me" href="https://github.com/datitran/object_detector_app" rel="noopener ugc nofollow" target="_blank">这个例子</a>是如何工作的:它从任何来源获取帧，并将它们放入一个队列中，另一个线程从这个队列中读取它们，并将其发送到一个神经网络，在这方面，神经网络会返回一个带有标签的地图以及它们可能出现在帧中的概率。神经网络是预先训练好的，所以我还没有在这个问题上做任何事情。我刚刚采用了stream类，它用于从网络摄像头捕捉帧，并模仿它，使它具有相同的接口，但会通过幸运地找到的端点从我的RPi的cam捕捉帧。</p><pre class="jr js jt ju fd mf mg mh mi aw mj bi"><span id="ede1" class="mk km hi mg b fi ml mm l mn mo">class RPIStreamInput:</span><span id="6f75" class="mk km hi mg b fi mp mm l mn mo">    URL = "http://{rpi}:8083/html/cam_pic.php"</span><span id="d10e" class="mk km hi mg b fi mp mm l mn mo">    def __get_frame(self):<br/>        res = requests.get(self.URL)<br/>        arr = numpy.asarray(bytearray(res.content), dtype="uint8")<br/>        frame = cv2.imdecode(arr, -1)<br/>    <br/>        return frame</span><span id="2d0b" class="mk km hi mg b fi mp mm l mn mo">    def __init__(self):<br/>        self.stopped = False<br/>        self.frame = self.__get_frame()<br/>        self.grabbed = self.frame is not None</span><span id="1712" class="mk km hi mg b fi mp mm l mn mo">    def start(self):<br/>        # start the thread to read frames from the video stream<br/>        Thread(target=self.update, args=()).start()<br/>    <br/>        return self</span><span id="b968" class="mk km hi mg b fi mp mm l mn mo">    def update(self):<br/>        # keep looping infinitely until the thread is stopped<br/>        # if the thread indicator variable is set, stop the thread<br/>        while True:<br/>            if self.stopped:<br/>                return<br/>    <br/>        self.frame = self.__get_frame()<br/>        self.grabbed = self.frame is not None</span><span id="8280" class="mk km hi mg b fi mp mm l mn mo">    def read(self):<br/>        # return the frame most recently read<br/>        return self.frame</span><span id="3f86" class="mk km hi mg b fi mp mm l mn mo">    def stop(self):<br/>        # indicate that the thread should be stopped<br/>        self.stopped = True</span></pre><p id="34d8" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">它只是调用我的RPi来按需获取帧。其余的只是我能够谷歌的克隆，并被迫为我做正确的事情。</p><p id="5ae6" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">现在，强迫生物做它的事情意味着不仅能够在画面中认出我是一个人(不是一只猫！)，还要确定我有多远才能出招。或者不做——那要看情况。在这里，我回到了OpenCV focuses。读了一些关于此事的论文，发现了<a class="ae me" href="https://www.pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/" rel="noopener ugc nofollow" target="_blank">的方法</a>。让我现在假装聪明，那个狗屁叫做<strong class="iu hs"> <em class="it">一个</em> <em class="it">的三角形相似度。</em> </strong> <em class="it"> </em>简而言之:如果你知道一个物体的大小，你提前知道了距离，你就能得出一个等式，最终会给你一个乘数，你将在计算中进一步使用它。</p><p id="7bd2" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">每次我试图计算到已知大小的物体的距离，并且网络能够识别这些物体，我都没有得到稳定的结果。我够固执的，转而采用b计划。</p><p id="93d7" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">我知道框架的大小。我也知道我在画面中的位置。所以我有多远只不过是我在画面中的百分比有多小。也就是说，没有什么能阻止我把这个百分比的我放在画面中，如果，比方说，它达到了某个阈值——是时候行动了。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es mq"><img src="../Images/f685382008bdae53af8e9a8070e3e5e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*uwWmA6k5wButS-K_WvWzOQ.gif"/></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">人工智能方法。</figcaption></figure><p id="1282" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">这最终奏效了！正如你所看到的，我离得越远，这个生物就越靠近我，反之亦然。</p><p id="0751" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">让我感到困扰的是，我的笔记本电脑在做人工智能的事情时会自己烧焦。我不骗你。它有一个储物柜的塑料支架，由于我的笔记本电脑底部温度过高，几乎完全熔化。不知道我是否能向我当时的雇主解释清楚为什么公司资产会熔化，这是怎么发生的？而且它仍然很难控制，因为缺乏更好的术语，相机运动的创造性。人们迫切需要不那么花哨但更简单易用的解决方案。</p><h1 id="c01a" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">Roomba运动。</h1><p id="d77f" class="pw-post-body-paragraph ir is hi iu b iv lj ix iy iz lk jb jc kg ll jf jg kh lm jj jk ki ln jn jo jp hb bi translated">在我们继续我的思考过程之前，让我们先了解一下我们在硬件方面所处理的问题。这是一个650 Roomba，幸运的是，它有一个串行端口，所以你最终可以进行一些控制。有一个奇特的机器人在那里为它编程，所以它有一个图书馆和一个巨大的支持。我的是一个农民，而不是一个爱好者，因此图书馆来自社区。感谢这个社区。我遇到的唯一恼人的问题是有一个<a class="ae me" href="https://github.com/pomeroyb/Create2Control/blob/ed84db37eebc4aa555f63c3ca697251e8beb1ecb/create2api.py#L110" rel="noopener ugc nofollow" target="_blank"> USB输入硬编码</a>，所以它会导致一些重启的问题，如果你的连接不知何故处于不稳定状态。</p><p id="062e" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">我想我知道如何修理它。或许你也知道。那个女孩和她的小伙子也是。不管怎样，到目前为止还没有人采取行动…</p><p id="2022" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">总之，你可以控制方向、速度和角度。那你还需要什么？嗯，读取一堆对任务至关重要的传感器。</p><h1 id="fe37" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">创造性轨迹方法。</h1><p id="6152" class="pw-post-body-paragraph ir is hi iu b iv lj ix iy iz lk jb jc kg ll jf jg kh lm jj jk ki ln jn jo jp hb bi translated">一旦我放弃使用人工智能方法..不，说真的。这不是一个选项——更大的想法是带来一些快乐，治愈需要治愈的东西，而不是增加痛苦。所以我决定将这种生物的自主性限制在特定的轨迹上，它会来回移动，记录路上的任何东西。</p><p id="3a08" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">但是首先，让我们弄清楚有哪些接口在起作用。下面是一个如何初始化机器人并做一些琐碎动作的例子:</p><pre class="jr js jt ju fd mf mg mh mi aw mj bi"><span id="3dbf" class="mk km hi mg b fi ml mm l mn mo">&gt;&gt;&gt; import create2api<br/>&gt;&gt;&gt; bot = create2api.Create2()<br/>/dev/ttyUSB0<br/>opened port<br/>Loaded config and opcodes<br/>&gt;&gt;&gt; bot.start()<br/>&gt;&gt;&gt; bot.safe()<br/>&gt;&gt;&gt; bot.drive_straight(20)<br/>&gt;&gt;&gt; bot.drive_straight(0)<br/>&gt;&gt;&gt; bot.destroy()</span></pre><p id="b805" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">事情是这样的，我们创建了一个机器人，启动它，初始化安全模式(如果出现问题，如发现障碍或路上的深渊，立即停止)，以每秒20毫米的速度直线行驶，然后停止并摧毁一个机器人。</p><p id="88ff" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">我们可能需要更多的API:</p><ul class=""><li id="28cb" class="lp lq hi iu b iv iw iz ja kg lr kh ls ki lt jp lu lv lw lx bi translated"><strong class="iu hs"> get_packet </strong> —读取传感器</li><li id="10da" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp lu lv lw lx bi translated"><strong class="iu hs">逆时针</strong>——名字很好听，就不多说了</li><li id="a650" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp lu lv lw lx bi translated"><strong class="iu hs">驾驶</strong>——在考虑半径的情况下，更智能的驾驶方式</li></ul><h2 id="d43c" class="mk km hi bd kn mr ms mt kr mu mv mw kv kg mx my kz kh mz na ld ki nb nc lh ho bi translated">搭讪台词。</h2><p id="efe7" class="pw-post-body-paragraph ir is hi iu b iv lj ix iy iz lk jb jc kg ll jf jg kh lm jj jk ki ln jn jo jp hb bi translated">除非在宜家货架的顶部进行移动，否则直线移动毫无创意可言。没错。我需要一些好的角度，在某种程度上嘲笑人类。架子的高度刚刚好。唯一的问题是如何不崩溃。嗯，在现实世界的操作中，Roomba以知道何时停止而闻名。怎么会？传感器。它配备了四个:两个在侧面，两个在前面。我是怎么学会的？通过在向后移动时折叠它——后面没有传感器，因为在现实世界中它是向前移动的。顺便说一句，这是我们所有人的好榜样。无论如何，为了不让它倒塌，我不能依靠我所做的距离计算(而且，它又一次倒塌了)。我必须依靠传感器。</p></div><div class="ab cl nd ne gp nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="hb hc hd he hf"><p id="9735" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">如果四个“悬崖”传感器之一读取的值低于阈值，就会发生所谓的“发现悬崖”事件。我做了几轮实验，找到了最佳点，此时“悬崖”就要到了，但事件没有被触发，这就不会导致停止。然后我编写了一个小算法:它向前移动，如果“悬崖”是向左还是向右，它就修正方向，然后停下来，当找到“前面的悬崖”时，它就掉头，然后再来一遍。这种运动的副作用导致了一个非常好的拍摄，而它做它的转身。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es nk"><img src="../Images/4cdf7f3a26206b4ce65072b2cf6979d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Y8xA8gqHkix9qlwNV6sp-w.gif"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">这是一个小一点的架子，但是你明白了。</figcaption></figure><p id="bac2" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">所以代码很简单:</p><pre class="jr js jt ju fd mf mg mh mi aw mj bi"><span id="ee4c" class="mk km hi mg b fi ml mm l mn mo">import time<br/>import create2api</span><span id="a419" class="mk km hi mg b fi mp mm l mn mo">from datetime import datetime</span><span id="61d3" class="mk km hi mg b fi mp mm l mn mo">CLIFF_LIMIT = 1550<br/>CLIFF_LIMIT_FRONT = 2800</span><span id="db13" class="mk km hi mg b fi mp mm l mn mo">def create_bot():<br/>    bot = create2api.Create2()<br/>    bot.start()<br/>    bot.safe()<br/>    return bot</span><span id="12c0" class="mk km hi mg b fi mp mm l mn mo">def destroy_bot(bot):<br/>    bot.destroy()</span><span id="63ab" class="mk km hi mg b fi mp mm l mn mo">def pickup_line(timeout):<br/>    bot = create_bot()<br/>    start = datetime.now()<br/>    diff = 0<br/>    speed = 80<br/>    while diff &lt; timeout:<br/>        bot.drive_straight(speed)<br/>        time.sleep(0.01)<br/>        bot.get_packet(100)<br/>        if bot.sensor_state['cliff front left signal'] &lt; CLIFF_LIMIT_FRONT or bot.sensor_state['cliff front right signal'] &lt; CLIFF_LIMIT_FRONT:<br/>            bot.drive_straight(-30)<br/>            time.sleep(2)<br/>            bot.turn_counter_clockwise(-40)<br/>            time.sleep(6.5)<br/>            bot.drive_straight(speed)<br/>        elif bot.sensor_state['cliff left signal'] &lt; CLIFF_LIMIT:<br/>            bot.drive_straight(-25)<br/>            time.sleep(2)<br/>            bot.turn_counter_clockwise(-25)<br/>            time.sleep(1)<br/>        elif bot.sensor_state['cliff right signal'] &lt; CLIFF_LIMIT:<br/>            bot.drive_straight(-25)<br/>            time.sleep(2)<br/>            bot.turn_counter_clockwise(25)<br/>            time.sleep(1)<br/>        else:<br/>            bot.drive_straight(speed)</span><span id="af21" class="mk km hi mg b fi mp mm l mn mo">        timediff = datetime.now() - start<br/>        diff = timediff.total_seconds()<br/>        if diff &gt; timeout:<br/>            bot.drive_straight(0)<br/>    <br/>    destroy_bot(bot)</span></pre><p id="f19a" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">所有的常数都是凭经验算出的。</p><h2 id="6a27" class="mk km hi bd kn mr ms mt kr mu mv mw kv kg mx my kz kh mz na ld ki nb nc lh ho bi translated">曲线。</h2><p id="cf18" class="pw-post-body-paragraph ir is hi iu b iv lj ix iy iz lk jb jc kg ll jf jg kh lm jj jk ki ln jn jo jp hb bi translated">这个很简单，但还是能拍出好照片。只是一条曲线，随着时间改变角度，直到到达某一点。在我的例子中，我只是通过暂停强迫它做运动，所以每次的轨迹都不一样，这又一次以一种绝妙的方式嘲笑了人类。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es nk"><img src="../Images/e79055807ab09cdf9b2a2edcde31c556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*03uY50k9qUuWy7FA4ly8EA.gif"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">曲线。</figcaption></figure><pre class="jr js jt ju fd mf mg mh mi aw mj bi"><span id="ddd3" class="mk km hi mg b fi ml mm l mn mo">def curve(timeout):<br/>    bot = create_bot()<br/>    start = datetime.now()<br/>    speed = 100<br/>    radius = -450<br/>    diff = 0<br/>    iteration_time = 26<br/>    while diff &lt; timeout:<br/>        bot.drive(speed, radius)<br/>        time.sleep(26)<br/>        timediff = datetime.now() - start<br/>        diff = timediff.total_seconds()<br/>        if diff &gt; timeout:<br/>            bot.drive_straight(0)<br/>            speed = -speed</span></pre><p id="b95a" class="pw-post-body-paragraph ir is hi iu b iv iw ix iy iz ja jb jc kg je jf jg kh ji jj jk ki jm jn jo jp hb bi translated">如上所述，所有的常数都是经验性的。</p><h1 id="ab28" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">结果。</h1><p id="4fa6" class="pw-post-body-paragraph ir is hi iu b iv lj ix iy iz lk jb jc kg ll jf jg kh lm jj jk ki ln jn jo jp hb bi translated">嗯，超出了我的预期。我不仅做了我想做的事情，还得到了我在接下来的视频中肯定会用到的工具。但是当我有了可以在地面上随意移动的东西时，我开始考虑飞行物体。敬请关注，感谢您的关注！</p><h1 id="e624" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">使用的链接:</h1><ol class=""><li id="9b47" class="lp lq hi iu b iv lj iz lk kg nl kh nm ki nn jp no lv lw lx bi translated"><a class="ae me" href="https://towardsdatascience.com/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32" rel="noopener" target="_blank">https://towards data science . com/building-a-real-time-object-recognition-app-with-tensor flow-and-opencv-b 7 a2 B4 ebdc 32</a></li><li id="a4f9" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp no lv lw lx bi translated">【https://github.com/datitran/object_detector_app T2】号</li><li id="ad33" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp no lv lw lx bi translated"><a class="ae me" href="https://www.pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2015/01/19/find-distance-camera-object marker-using-python-opencv/</a></li><li id="a94e" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp no lv lw lx bi translated"><a class="ae me" href="https://www.raspberrypi.org/documentation/raspbian/applications/camera.md" rel="noopener ugc nofollow" target="_blank">https://www . raspberrypi . org/documentation/raspbian/applications/camera . MD</a></li><li id="ea5d" class="lp lq hi iu b iv ly iz lz kg ma kh mb ki mc jp no lv lw lx bi translated">https://elinux.org/RPi-Cam-Web-Interface<a class="ae me" href="https://elinux.org/RPi-Cam-Web-Interface" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>