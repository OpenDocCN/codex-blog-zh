<html>
<head>
<title>Building a Mixed Type Preprocessing Pipeline with scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用scikit-learn构建混合型预处理流水线</h1>
<blockquote>原文：<a href="https://medium.com/codex/building-a-mixed-type-preprocessing-pipeline-with-scikit-learn-f4d90f5919fa?source=collection_archive---------7-----------------------#2021-09-06">https://medium.com/codex/building-a-mixed-type-preprocessing-pipeline-with-scikit-learn-f4d90f5919fa?source=collection_archive---------7-----------------------#2021-09-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3397e596d5f4c7c4e4134c1ef177e3ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jDsr_A6ceKDgAWt-ghZZpA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://specialpipingmaterials.com/" rel="noopener ugc nofollow" target="_blank">https://specialpipingmaterials.com/</a></figcaption></figure><p id="9327" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我可以自豪地承认，在过去的一年里，我对<strong class="ix hj">数据泄露</strong>产生了<strong class="ix hj">恐惧</strong>。虽然这听起来有点不健康，但这种恐惧一直让我保持警惕，并激励我不断检查我的项目中可能的数据泄漏问题。这绝对不是一个坏习惯，但有时会变得费力和疲惫。</p><p id="9df0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">今年早些时候，我在做坦桑尼亚水井的三元分类项目。目的是使用其他特征，如记录日期、出资人、安装者、经度、纬度、区域、流域、子村庄、来源、提取类型、付款类型等，将供水点分为三组，即<strong class="ix hj">功能性</strong>、<strong class="ix hj">功能性需求修复</strong>和<strong class="ix hj">非功能性</strong>。我想在训练期间进行交叉验证，以监控模型在看不见的数据上的表现。然而，这也意味着为了避免数据泄露，对于每一轮，我都必须将转换器安装到训练部分，然后使用它们来手动转换训练和验证部分。对于一个包含39列混合数据类型(数值型、分类型、日期时间型)的数据集，每一列都需要略微不同的转换方法，并且k倍值仅为5，这将需要大量的重复工作，更不用说在此过程中引入人为错误的风险了。</p><p id="24ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">幸运的是，<strong class="ix hj"> scikit-learn </strong>提供了一种将所有这些步骤无缝集成到管道中的方法。出于演示目的，我将使用相同的坦桑尼亚水点数据集。</p><h1 id="4a63" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">导入库</h1><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9559" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">from</strong> <strong class="kw hj">sklearn.preprocessing</strong> <strong class="kw hj">import</strong> OneHotEncoder, MinMaxScaler<br/><strong class="kw hj">from</strong> <strong class="kw hj">sklearn.compose</strong> <strong class="kw hj">import</strong> ColumnTransformer<br/><strong class="kw hj">from</strong> <strong class="kw hj">sklearn.base</strong> <strong class="kw hj">import</strong> BaseEstimator, TransformerMixin<br/><strong class="kw hj">from</strong> <strong class="kw hj">sklearn.impute</strong> <strong class="kw hj">import</strong> SimpleImputer<br/><strong class="kw hj">from</strong> <strong class="kw hj">sklearn.pipeline</strong> <strong class="kw hj">import</strong> Pipeline, make_pipeline, FeatureUnion<br/><strong class="kw hj">from</strong> <strong class="kw hj">geopy.distance</strong> <strong class="kw hj">import</strong> geodesic<br/><strong class="kw hj">from</strong> <strong class="kw hj">sklearn.model_selection</strong> <strong class="kw hj">import</strong> cross_val_score</span></pre><h1 id="d369" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">添加额外功能</h1><h2 id="56d3" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">1.从记录日期提取月/年和年龄记录信息</h2><p id="b4bf" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">在探索性数据分析(EDA)过程中，我注意到在所有不同类型的水源中，<strong class="ix hj">雨水收集</strong>没有太多的井，然而<code class="du lx ly lz kw b">functional</code>井在该组中的百分比相对较高(60%对平均53%)。这让我想到，也许井的功能也部分受到检查/测量记录时间的影响。</p><p id="b046" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">进一步的调查表明，6月<strong class="ix hj">日</strong>似乎记录了最高数量的<code class="du lx ly lz kw b">functional</code>口井，最低数量的<strong class="ix hj">口干井</strong>口井。这一发现与坦桑尼亚主要的长雨季相吻合，雨季持续于三月、四月和五月。因此，我决定从<code class="du lx ly lz kw b">date_recorded</code>中提取记录的月份和年份，以及井的年龄，并将它们转化为单独的特征。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="3456" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">class</strong> <strong class="kw hj">DateTransformer</strong>(BaseEstimator, TransformerMixin):<br/>    <em class="ma">"""Extracts information from date_recorded column to create new features</em><br/><br/><em class="ma">    Returns:</em><br/><em class="ma">        - month_recorded: first 3 character of name of the month recorded</em><br/><em class="ma">        - year_recorded: four-digit year</em><br/><em class="ma">        - age_recorded: difference between construction year and year recorded</em><br/><em class="ma">    """</em><br/><br/>    <strong class="kw hj">def</strong> fit(self, X, y=<strong class="kw hj">None</strong>):<br/>        <strong class="kw hj">return</strong> self<br/><br/>    <strong class="kw hj">def</strong> transform(self, X, y=<strong class="kw hj">None</strong>):<br/>        X['date_recorded'] = pd.to_datetime(X['date_recorded'])<br/>        X['month_recorded'] = X.date_recorded.dt.month_name().str.slice(stop=3)<br/>        X['year_recorded'] = X.date_recorded.dt.year<br/>        X['age_recorded'] = X['year_recorded'] - X['construction_year']<br/>        <strong class="kw hj">return</strong> self</span></pre><h2 id="6054" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">2.添加关于最近大都市地区的额外要素</h2><p id="d7f0" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">井水污染的少数原因之一是来自附近大型住宅区以及工厂、厂房、建筑工地等的污染。虽然比赛本身不允许使用外部数据，但我认为有一些有意义的方法可以将外部数据纳入到改善模型的整体预测能力和可解释性中，特别是当这个数据集中有如此大量的缺失信息时。因此，我决定在我自己的研究中使用外部数据，然后在对比赛的测试数据进行预测时，从管道中移除这种转换。</p><p id="d410" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在获得坦桑尼亚最大城市的数据、地理空间信息和人口后，我挑选出人口超过100，000的城市，并将它们保存到一个名为<code class="du lx ly lz kw b">tz_pop_above100k</code>的独立数据框架中。</p><p id="2c66" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下函数有助于定位距离给定坐标集最近的大都市区域:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9de8" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">def</strong> closest_point(x):<br/>    <em class="ma">'''</em><br/><em class="ma">    Returns: a tuple</em><br/><em class="ma">        - tuple[0]: name of nearest big city (population over 100000)</em><br/><em class="ma">        - tuple[1]: geodesic distance from point x to nearest big city (tuple[0])</em><br/><em class="ma">    '''</em><br/>    <br/>    output = <strong class="kw hj">None</strong><br/>    <strong class="kw hj">for</strong> _, city <strong class="kw hj">in</strong> tz_pop_above100k.iterrows():<br/>        distance = geodesic(x, city.coordinates).km<br/>        city_name = city.city<br/>        <strong class="kw hj">if</strong> (output <strong class="kw hj">is</strong> <strong class="kw hj">None</strong>) <strong class="kw hj">or</strong> (distance &lt; output[1]):<br/>            output = (city_name, distance)<br/>    <strong class="kw hj">return</strong> output</span></pre><p id="d0ea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我将上述函数应用到我的自定义转换器中，以获得每个供水点的名称、距离以及最近大都市的人口:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="2c2f" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">class</strong> <strong class="kw hj">FeatureGenerator</strong>(BaseEstimator, TransformerMixin):<br/>    <em class="ma">"""Generate extra features from water wells' coordinates</em><br/><em class="ma">    </em><br/><em class="ma">    Returns:</em><br/><em class="ma">        - nearest_big_city_name: name of the nearest city with population over 100,000</em><br/><em class="ma">        - nearest_big_city_distance: distance to nearest city with population over 100,000</em><br/><em class="ma">        - nearest_big_city_population: population of nearest big city</em><br/><em class="ma">    """</em><br/>   <br/>    <strong class="kw hj">def</strong> fit(self, X, y=<strong class="kw hj">None</strong>):<br/>        <strong class="kw hj">return</strong> self<br/><br/>    <strong class="kw hj">def</strong> transform(self, X, y=<strong class="kw hj">None</strong>):<br/>        names = []<br/>        distances = []<br/>        populations = []<br/>        <strong class="kw hj">for</strong> idx, row <strong class="kw hj">in</strong> X.iterrows():<br/>            coordinates = (row['latitude'], row['longitude'])<br/>            n, d = closest_point(coordinates)<br/>            p = tz_pop_above100k[tz_pop_above100k.city == n].population_2021.values[0]<br/>            names.append(n)<br/>            distances.append(d)<br/>            populations.append(p)<br/>        X['nearest_big_city_name'] = names<br/>        X['nearest_big_city_distance'] = distances<br/>        X['nearest_big_city_population'] = populations<br/>        <strong class="kw hj">return</strong> self</span></pre><h1 id="c243" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">特征预处理</h1><h2 id="40a7" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">1.在某些分类&amp;布尔变量中用字符串<code class="du lx ly lz kw b">"NaN"</code>填充缺失值</h2><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9c62" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">class</strong> <strong class="kw hj">NaNImputer</strong>(BaseEstimator, TransformerMixin):<br/>    <em class="ma">"""</em><br/><em class="ma">    Replaces missing values np.nan with the string "NaN"</em><br/><em class="ma">    in 3 features 'public_meeting', 'scheme_management', and 'permit'</em><br/><em class="ma">    """</em><br/>    <br/>    <strong class="kw hj">def</strong> fit(self, X, y=<strong class="kw hj">None</strong>):<br/>        <strong class="kw hj">return</strong> self<br/><br/>    <strong class="kw hj">def</strong> transform(self, X, y=<strong class="kw hj">None</strong>):<br/>        to_fillna = ['public_meeting', 'scheme_management', 'permit']<br/>        X[to_fillna] = X[to_fillna].fillna(value='NaN')<br/>        X[to_fillna] = X[to_fillna].astype(str)  <br/>        <strong class="kw hj">return</strong> X</span></pre><h2 id="02cc" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">2.估算经度</h2><p id="6717" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">这一步的目标是使用<code class="du lx ly lz kw b">region_code</code>将经度中的0值替换为区域的聚合平均值。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="05ea" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">class</strong> <strong class="kw hj">LongitudeImputer</strong>(BaseEstimator, TransformerMixin):<br/>    <em class="ma">"""</em><br/><em class="ma">        Replaces invalid longitude value (0) with the aggregated means by region</em><br/><em class="ma">        using region_code</em><br/><em class="ma">    """</em><br/>    <strong class="kw hj">def</strong> __init__(self):<br/>        super().__init__()<br/>        self.lng_means_ = {}<br/><br/>    <strong class="kw hj">def</strong> fit(self, X, y=<strong class="kw hj">None</strong>):<br/>        self.lng_means_ = X.groupby(['region_code']).longitude.mean()<br/>        <strong class="kw hj">return</strong> self<br/><br/>    <strong class="kw hj">def</strong> transform(self, X, y=<strong class="kw hj">None</strong>):<br/>        <em class="ma"># replace 0 with average longitude</em><br/>        <strong class="kw hj">for</strong> key, value <strong class="kw hj">in</strong> self.lng_means_.items():<br/>            X.loc[((X.longitude == 0) &amp; (X.region_code == key)), 'longitude'] = value<br/>        <strong class="kw hj">return</strong> X</span></pre><h2 id="a745" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">3.宁滨<code class="du lx ly lz kw b">funder</code> &amp; <code class="du lx ly lz kw b">installer</code>分为2组——大调和小调</h2><p id="c900" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">这两个变量中的每一个都包含超过1000个可能的类别，这意味着如果我将它们全部包含到模型中，在一次热编码后，我将得到超过4000个特征。处理这两个变量的高基数的一种方法是将它们宁滨成更大的组:</p><ul class=""><li id="d6a5" class="mb mc hi ix b iy iz jc jd jg md jk me jo mf js mg mh mi mj bi translated"><strong class="ix hj">主要</strong> —前100名资助者或安装者——负责用于拟合的数据集中约80%的水井</li><li id="88b2" class="mb mc hi ix b iy mk jc ml jg mm jk mn jo mo js mg mh mi mj bi translated"><strong class="ix hj">次要</strong> —不在100强列表中的任何实体</li></ul><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="e20c" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">class</strong> <strong class="kw hj">FunderBinner</strong>(BaseEstimator, TransformerMixin):<br/>    <em class="ma">"""</em><br/><em class="ma">    Categorize funders into 2 groups 'major' or minor'</em><br/><em class="ma">    - 'major': top 100 funders in the fitted dataset</em><br/><em class="ma">    - 'minor' - any entities that are not in the top 100 list</em><br/><em class="ma">    """</em><br/><br/>    <strong class="kw hj">def</strong> __init__(self):<br/>        super().__init__()<br/>        self.top_100_funder = []<br/><br/>    <strong class="kw hj">def</strong> fit(self, X, y=<strong class="kw hj">None</strong>):<br/>        self.top_100_funder = X.funder.value_counts()[:100].index<br/>        <strong class="kw hj">return</strong> self<br/><br/>    <strong class="kw hj">def</strong> transform(self, X, y=<strong class="kw hj">None</strong>):<br/>        <strong class="kw hj">for</strong> idx, row <strong class="kw hj">in</strong> X.iterrows():<br/>            <strong class="kw hj">if</strong> row['funder'] <strong class="kw hj">in</strong> self.top_100_funder:<br/>                val = 'major' <br/>            <strong class="kw hj">else</strong>:<br/>                val = 'minor'<br/>            X.loc[idx, 'funder'] = val<br/>        <strong class="kw hj">return</strong> X</span><span id="a02f" class="la ju hi kw b fi mp lc l ld le"><strong class="kw hj">class</strong> <strong class="kw hj">InstallerBinner</strong>(BaseEstimator, TransformerMixin):<br/>    <em class="ma">"""</em><br/><em class="ma">    Categorize installers into 2 groups 'major' or minor'</em><br/><em class="ma">    - 'major': top 100 funders in the fitted dataset</em><br/><em class="ma">    - 'minor' - any entities that are not in the top 100 list</em><br/><em class="ma">    """</em><br/><br/>    <strong class="kw hj">def</strong> __init__(self):<br/>        super().__init__()<br/>        self.top_100_installer = []<br/><br/>    <strong class="kw hj">def</strong> fit(self, X, y=<strong class="kw hj">None</strong>):<br/>        self.top_100_installer = X.installer.value_counts()[:100].index<br/><br/>        <strong class="kw hj">return</strong> self<br/><br/>    <strong class="kw hj">def</strong> transform(self, X, y=<strong class="kw hj">None</strong>):<br/>        <strong class="kw hj">for</strong> idx, row <strong class="kw hj">in</strong> X.iterrows():<br/>            <strong class="kw hj">if</strong> row['installer'] <strong class="kw hj">in</strong> self.top_100_installer:<br/>                val = 'major' <br/>            <strong class="kw hj">else</strong>:<br/>                val = 'minor'<br/>            X.loc[idx, 'installer'] = val<br/>        <strong class="kw hj">return</strong> X</span></pre><h2 id="9320" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">4.缩放数字特征</h2><ul class=""><li id="4a2b" class="mb mc hi ix b iy ls jc lt jg mq jk mr jo ms js mg mh mi mj bi translated">缩放经度和纬度在这里特别重要，因为它们在不同的尺度上。</li><li id="78cf" class="mb mc hi ix b iy mk jc ml jg mm jk mn jo mo js mg mh mi mj bi translated">在对各种缩放器进行试验后，发现与其他缩放类型(包括<code class="du lx ly lz kw b">StandardScaler</code>、<code class="du lx ly lz kw b">RobustScaler</code>和<code class="du lx ly lz kw b">PowerTransformer</code>)相比，<code class="du lx ly lz kw b">MinMaxScaler()</code>产生的结果更好。</li></ul><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="0cd9" class="la ju hi kw b fi lb lc l ld le"><em class="ma"># SELECT NUMERICAL FEATURES TO BE INCLUDED IN MODELING</em><br/>numerical_features = ['amount_tsh', 'gps_height', 'num_private',<br/>                      'construction_year', 'year_recorded', <br/>                      'age_recorded', 'population', <br/>                      'nearest_big_city_population', 'longitude',        <br/>                      'latitude', 'nearest_big_city_distance']</span><span id="f58f" class="la ju hi kw b fi mp lc l ld le">numerical_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])</span></pre><h2 id="b450" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">5.一种热编码分类特征</h2><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="91ed" class="la ju hi kw b fi lb lc l ld le"><em class="ma"># SELECT CATEGORICAL FEATURES TO BE INCLUDED IN MODELING</em><br/>categorical_features = ['funder', 'installer', 'basin', 'region',<br/>                        'public_meeting', 'scheme_management',<br/>                        'permit', 'extraction_type_class', <br/>                        'management_group', 'payment_type', <br/>                        'quality_group', 'quantity', <br/>                        'source_class', 'waterpoint_type_group', <br/>                        'nearest_big_city_name', 'month_recorded']</span><span id="2e23" class="la ju hi kw b fi mp lc l ld le">categorical_transformer = Pipeline(steps=[<br/>                   ('ohe', OneHotEncoder(handle_unknown='ignore'))<br/>                 ])</span></pre><h1 id="bfff" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">建设管道</h1><p id="5a45" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">一旦我定义了所有的自定义转换器、估算器和缩放器，我只需要将这些部分放入一个管道中，如下所示:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9ad7" class="la ju hi kw b fi lb lc l ld le"><em class="ma"># ADDING NEW FEATURES USING FeatureUnion</em><br/>union = FeatureUnion(transformer_list=[ <br/>            ('recorded',  DateTransformer()),                                             <br/>            ('nearest_big_city', FeatureGenerator())<br/>        ])<br/><br/><em class="ma"># TRANSFORM NUMERICAL &amp; CATEGORICAL FEATURES SEPARATELY USING ColumnTransformer</em><br/>col_tranformer = ColumnTransformer(transformers=[<br/>            ('num', numerical_transformer, numerical_features),<br/>            ('cat', categorical_transformer, categorical_features)<br/>         ],<br/>         remainder='drop')<br/><br/><em class="ma"># STACKING THEM TOGETHER IN A PIPELINE</em><br/>preprocessor = Pipeline(steps=[('fillna', NaNImputer()),<br/>                               ('lng_imp', LongitudeImputer()),<br/>                               ('funder', FunderBinner()),<br/>                               ('installer', InstallerBinner()),<br/>                               ('col_tf', col_tranformer)])</span></pre><h2 id="f75c" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">1.使用带有交叉验证的管道</h2><p id="cf7d" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">以下是如何在随机森林分类器的交叉验证中使用管道的示例:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="ac6a" class="la ju hi kw b fi lb lc l ld le"><em class="ma"># CREATE NEW FEATURES IN TRAINING SET X_train<br/></em>union.fit_transform(X_train)</span><span id="98d7" class="la ju hi kw b fi mp lc l ld le"><em class="ma"># STACKING preprocessor AND RandomForestClassifier() INTO A PIPELINE</em><br/>pipeline = Pipeline(steps=[<br/>              ('preprocessor', preprocessor),<br/>              ('rf', RandomForestClassifier(random_state=2021))<br/>           ])<br/><br/>scores_rf1 = cross_val_score(pipeline, <br/>                             X_train, y_train, <br/>                             scoring='accuracy')</span></pre><h2 id="e9fe" class="la ju hi bd jv lf lg lh jz li lj lk kd jg ll lm kh jk ln lo kl jo lp lq kp lr bi translated">2.通过SMOTE使用管道</h2><p id="5cb0" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">如果您想使用合成少数过采样技术(<strong class="ix hj"> SMOTE </strong>)，请注意<code class="du lx ly lz kw b">imblearn</code>有自己的管道，可以通过以下方式导入:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="307d" class="la ju hi kw b fi lb lc l ld le"><strong class="kw hj">from</strong> <strong class="kw hj">imblearn.pipeline</strong> <strong class="kw hj">import</strong> Pipeline <strong class="kw hj">as</strong> imbPipeline</span></pre><p id="c314" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我们只需要使用<code class="du lx ly lz kw b">imbPipeline</code>而不是<code class="du lx ly lz kw b">sklearn</code>的常规<code class="du lx ly lz kw b">Pipeline</code>重新创建管道:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="2f5a" class="la ju hi kw b fi lb lc l ld le"><em class="ma"># STACKING PREPROCESSOR TRANSFORMATIONS, SMOTE() AND RandomForestClassifier() </em><br/><em class="ma"># INTO AM IMBALANCE PIPELINE</em><br/>pipe_sm = imbPipeline([<br/>            ('fillna', NaNImputer()),<br/>            ('lng_imp', LongitudeImputer()),<br/>            ('funder', FunderBinner()),<br/>            ('installer', InstallerBinner()),<br/>            ('col_tf', col_tranformer),<br/>            ('sampler', SMOTE(random_state=2021, <br/>                              n_jobs=-1,<br/>                              sampling_strategy='minority')),<br/>            ('rf', RandomForestClassifier(random_state=2021))<br/>          ])</span></pre><p id="5681" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><code class="du lx ly lz kw b">pipe_sm</code>的使用方法与上述<code class="du lx ly lz kw b">preprocessor</code>管道相同:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="8fba" class="la ju hi kw b fi lb lc l ld le">scores_rf2 = cross_val_score(pipe_sm, <br/>                             X_train, y_train, <br/>                             scoring='accuracy')</span></pre><p id="9f30" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有了系统集成的管道，拟合和预测可以像以下一样简单:</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="ac31" class="la ju hi kw b fi lb lc l ld le"><em class="ma"># FIT MODEL ON THE TRAINING DATASET X_train and y_train</em><br/>rf2 = pipe_sm.fit(X_train, y_train)</span><span id="45f7" class="la ju hi kw b fi mp lc l ld le"><em class="ma"># CREATE NEW FEATURES IN VALIDATION SET X_val</em><br/>union.fit_transform(X_val)<br/><br/><em class="ma"># MAKE PREDICTIONS ON THE VALIDATION DATASET </em><br/>y_val_pred = rf2.predict(X_val)</span></pre><h1 id="7de5" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="d2c1" class="pw-post-body-paragraph iv iw hi ix b iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">这只是我如何在项目中为混合特征类型构建预处理管道的一个例子。请注意，这一步通常在彻底的探索性数据分析之后<strong class="ix hj">进行，这为我们提供了如何正确处理每个功能的必要知识。根据数据集以及业务问题，我们可以根据需要毫不费力地调整和修改管道。这种方法还有另一个好处，就是更容易重现。</strong></p></div></div>    
</body>
</html>