<html>
<head>
<title>Building a powerful Image Search Engine for your pictures using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习为您的图片构建强大的图像搜索引擎</h1>
<blockquote>原文：<a href="https://medium.com/codex/building-a-powerful-image-search-engine-for-your-pictures-using-deep-learning-16d06df10385?source=collection_archive---------8-----------------------#2021-07-22">https://medium.com/codex/building-a-powerful-image-search-engine-for-your-pictures-using-deep-learning-16d06df10385?source=collection_archive---------8-----------------------#2021-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="bebe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">几天前，我很想回头看看一张我记忆犹新但不知道在哪里能找到的老照片…自从这张照片被拍摄后，我换了两次手机，一次笔记本电脑，我很确定我当时已经通过Messenger把它发给了某个人，但是是谁呢？如果能够通过一个简单的描述性查询来搜索我所有的图片，并找到它，那该有多方便啊…</p><p id="790a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算机视觉的最新进展提高了图像嵌入(密集矢量表示)的相关性，通过最近的CLIP模型，对我的本地图片实现类似Google的图像搜索现在变得轻而易举。</p><p id="db5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">无需深究细节(更多信息请参考博文和论文:<a class="ae jd" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/clip/</a>)，CLIP是一个通过自然语言监督来学习图像特征的神经网络。基本上，它使用互联网上带有相关标题的公共图像，用类似BERT的语言模型嵌入文本，用视觉转换器嵌入图像。注意，所使用的技术可以应用于其他NLP和CV模型架构。使用多个图像/文本嵌入对，可以通过批量否定对比训练来微调视觉和文本嵌入模型，类似于在信息检索的NLP领域中可以完成的事情。基本上，目标是使图像嵌入对应于(点积)其相关联的文本嵌入，并且不同于其他图像的所有标题(1)。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/c8800e377406185734d129a9a18efaea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ywDwlx1sSCX4eiEc.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">剪辑训练和推理方案(【https://github.com/openai/CLIP】T2)</figcaption></figure><p id="44a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CLIP通常用于“零炮”分类；给定一张图片和标题列表，它推断出图片的最佳标题是什么。在上面的例子(2)中，“一张狗的照片”是图片的最佳说明，相比之下，“一张飞机的照片”，“一张鸟的照片”，“一张汽车的照片”…</p><p id="78d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我对图像搜索引擎的想法(在这里并不新奇)，是将它翻转过来，而不是根据图像对标题进行分类，而是根据文本查询对图像进行分类。该过程如下:</p><ul class=""><li id="b4d3" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">定位给定目录中的所有图像</li><li id="ef0e" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">使用预先训练的CLIP vision transformer计算每个图像的嵌入，并将它们与图像路径一起存储，以供将来参考。</li><li id="efe4" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">在运行时，使用剪辑文本转换器将用户查询转换为文本嵌入。</li><li id="2457" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">计算文本嵌入与所有存储的图像嵌入的点积，按照获得的分数对所有图像进行排序，并返回N个最高排序图像的路径。</li></ul><p id="cb83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个过程，以及一些额外的特性，在我的Github仓库中实现:<a class="ae jd" href="https://github.com/ManuelFay/ImageSearcher" rel="noopener ugc nofollow" target="_blank">https://github.com/ManuelFay/ImageSearcher</a>。</p><div class="ki kj ez fb kk kl"><a href="https://github.com/ManuelFay/ImageSearcher" rel="noopener  ugc nofollow" target="_blank"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">GitHub - ManuelFay/ImageSearcher:这个库旨在实现一个图像搜索引擎</h2><div class="ks l"><h3 class="bd b fi z dy kq ea eb kr ed ef dx translated">这个存储库实现了一个基于本地照片的图像搜索引擎，由CLIP模型提供支持。从最初的测试来看，它…</h3></div><div class="kt l"><p class="bd b fp z dy kq ea eb kr ed ef dx translated">github.com</p></div></div><div class="ku l"><div class="kv l kw kx ky ku kz jo kl"/></div></div></a></div><p id="4650" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在索引阶段，代码使用<code class="du la lb lc ld b">os</code>库查找给定目录和子目录中的所有图片，使用<code class="du la lb lc ld b">transformers</code>和<code class="du la lb lc ld b">pickle</code>库嵌入和存储矢量化表示。在运行时，加载经过酸洗的嵌入内容，与嵌入的查询进行匹配，然后返回排名第二的图像。提供Flask / Gunicorn API以能够有效地使用具有外部接口的搜索引擎。还提供了一个用Vue.js构建的简单的类似Google图片搜索的web界面。</p><h1 id="c80c" class="le lf hi bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">例子</h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mc"><img src="../Images/e9f3ef02721c5bccfac77fbb9507096c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eyQiXSWTD0-m2fXQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">“一只可爱小猫的照片”。在这里，在我的电脑上出现两次的图像会重复出现。</figcaption></figure><p id="7c5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了获得大量的图片，我从脸书下载了我的信使档案，获得了我在过去几年中发送和接收的大约10，000张图片。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mc"><img src="../Images/71c4ddd818af0cbc89b827694ed1c67e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*08gjm_esbZLNDclw.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">“一张穿着运动衫、戴着帽子的男人在山里的照片”:所有最上面的选项不一定与查询的完全一样，但搜索总体上非常高效。</figcaption></figure><p id="d548" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">搜索引擎允许进行非常描述性的查询。排名靠前的图像排在第一位。请注意，这些图片都来自我的大约10，000张本地图片，因此选择有限。</p><p id="574b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">元查询也是可能的。这里我们请求无人机拍摄的照片:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mc"><img src="../Images/a50eda1b901d385bca1289a2a8cb0319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J8Tz5SbyO-byitIA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">“无人机拍摄”:前6张照片中的5张确实是由无人机拍摄的，而剩下的一张很容易在无人机飞过时拍摄。</figcaption></figure><p id="3164" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个快速的下午项目，但我对剪辑模型的精确度印象深刻。要自己测试，使用来自<a class="ae jd" href="https://github.com/ManuelFay/ImageSearcher" rel="noopener ugc nofollow" target="_blank">https://github.com/ManuelFay/ImageSearcher</a>的代码。欢迎贡献改进和额外的功能！</p></div></div>    
</body>
</html>