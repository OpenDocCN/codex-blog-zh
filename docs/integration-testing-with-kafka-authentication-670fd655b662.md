# 与 Kafka 和认证的集成测试

> 原文：<https://medium.com/codex/integration-testing-with-kafka-authentication-670fd655b662?source=collection_archive---------8----------------------->

![](img/b9ec1d59fef273bfd5624aebe6f3005a.png)

阿诺·塞纳尔在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄的照片

# 介绍

这篇文章是为了分享我在 Kafka 上编写操作集成测试时遇到的麻烦，希望它能帮助那些可能需要走相同路线的人。

您可能在阅读第一段时会想:“你真傻，这太简单了，只需启动一个包含 Kafka 的容器，然后就可以结束工作了”，您可能是对的，除非…您决定在组合中添加身份验证！

我所说的“添加身份验证”是指创建集成测试，以验证您的代码能够正确执行预期的操作**和**验证它也能够正确连接和验证配置了身份验证的集群，就像“每个”生产集群一样。

# 所以，让我们开始吧

让我马上告诉你，从现在开始你将看到的每个代码片段都是用 Kotlin 编写的…我希望你不介意。如果你懂 Java，理解代码应该没什么问题。

## 基础知识

好吧，让我们开始研究真正的测试。如您所知，测试应该相互独立，这意味着一个测试的通过或失败不应该影响任何其他测试的结果(如果您不知道，现在您知道了)。为了实现这一点，你基本上有两条路线:

1.  启动 Kafka 集群，但是无论您在每个测试中做什么，都必须在测试完成后撤销。这意味着你要么在每个测试中都有一个“清理功能”,要么你的测试功能会比测试范围所需要的要大。也请记住，你仍然可以在一些测试后忘记撤销某些东西，并影响其他人的结果。祝你好运 debbuging，当他们开始随机失败，因为运行顺序随机改变(它应该)。
2.  在每次测试之前启动一个具有相同配置的 Kafka 集群，然后销毁它。也就是说，在每次测试之前，你都有一个干净的画布，有效地将它与其他测试隔离开来。

我希望你喜欢我的高度偏颇的观点，以迫使你明白，在我看来，第二种选择是更好的。

如果不清楚的话，第二种方法有一个明显的优点，也有一个非常明显的缺点:“优点”是我确信测试是独立的，我不需要额外的代码。“缺点”是在每两次测试之间启动容器的时间，随着测试数量的增加，这基本上会成为一个更大的问题。

那么，你是如何对卡夫卡的作品进行“发射-使用-杀死-重复”的呢？使用 JUnit5 注释和 TestContainers 非常简单。

我告诉过你这很简单:在每次测试之前，启动一个 Kafka 容器，并创建一个 adminClient 实例(目前有一个非常基本的配置),指向刚刚启动的容器。每次测试后关闭它们！

# 认证和授权

TL；大卫:最后的答案就在接近结尾的结论段落之前。

## 认证是我们应该测试的一部分吗？

在我看来，是！直截了当地说:**冒着代码在 Kafka 集群、数据库等上正确地做你想做的事情的风险，你会得到什么好处？却连资源都拿不到？**所以，底线是:在集成测试中，你应该测试你的应用程序做了什么，而且，正如这类测试的名字所暗示的，它如何与它应该连接的系统集成。

**如果您的应用程序运行的真实场景涉及身份验证，请在您的 ITs 中测试身份验证！**

此外，如果您碰巧需要执行需要授权和认证的操作，您需要为您的 ITs 配置它，否则您无法真正测试您的应用程序。在 Kafka 设置中，一个与 ACL 相关的示例是:要在 Kafka 上创建、更改或删除 ACL，您必须在群集上配置身份验证和授权，因此基本上“身份验证是我们应该测试的一部分吗？”这是一个棘手的问题，因为您需要它来测试 ACL 操作！😅

## 文档和谷歌搜索的复杂过程

![](img/b6a59f02d847eec5860b6f08e49e1bb6.png)

照片由[汉斯·雷尼尔斯](https://unsplash.com/@hansreniers?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

当我开始尝试配置我的容器来执行身份验证和授权时，我遇到了第一个障碍:**我希望这很容易**，就像调用 KafkaContainer 上的一些函数来配置它或什么的，**但是我错了！**

TestContainers 并没有真正指定他们的类是否支持这些东西，也没有在他们的[网站](https://www.testcontainers.org/modules/kafka/)上给你任何关于如何以任何其他方式做到这一点的提示，这让我立即感到担心并思考“这完全应该在这里，我不相信没有人需要它！”。这个想法很快被“也许他们只是希望我们用文档来解决我们决定在容器中使用的任何图像”所吸引，这让我进入了 Confluent 的文档页面。

**confuent 很棒**，我相信他们是 Apache Kafka 服务的参考，他们有很多东西也围绕 Kafka 工作，他们公开提供 docker 图像供您使用。我也和他们有过职业接触，他们都很棒。现在，也就是说，他们的[文档看起来非常完整](https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_plain.html#kafka-sasl-auth-plain)，**这让我相信用他们的图像和简单的简单认证配置一个 Kafka 容器会非常容易解决…事实并非如此。**

我将长话短说，谈谈我在遵循文档和配置方面的经验:**基本上，我在他们的网站上记录了所有东西，但仍然缺少一些东西，因为我无法让它工作。**从那时起，谷歌搜索错误信息和类似问题的线索的努力就毫无结果了！什么都没用！我有过类似的经历，当我试图启动一个配置不是默认配置的 KSQL 集群时，让它工作起来也是一团糟。

**我不会过多地指责融合，他们在支持和融合云服务上赚钱，所以对我来说，他们的文档以“这几乎是一切，但最后的润色你必须有点聪明才能免费得到它们”的方式完成是有道理的。我不知道是不是这样…这只是我对情况的解读，但我是个白痴。**

现在，让我们进入你实际来这里阅读的内容…

## 我是怎么做到的

所以我让它工作的第一步是**让 Zookeeper 退出**因为[自从 Apache Kafka 2.8.0 之后，Zookeeper 就不再需要了！](https://www.confluent.io/blog/kafka-2-8-0-features-and-improvements-with-early-access-to-kip-500/)

通过这样做，配置中的许多复杂性立即消失了，所以我只选择了已经在使用 Kafka 2.8.0 的 docker 映像。这算作弊吗？我想知道…不用太在意答案，因为客户端配置是一样的，对我来说已经足够好了。😂

另外，我做的另一件事是**去掉外部 jaas 配置文件**，包括客户端和服务器端:你可以通过你的配置直接提供 jaas 配置作为一个字符串或者指向外部文件。

这些文件看起来更容易手动构建，但是你必须考虑识别约束之类的东西。我只是认为这是整个事情的又一个失败点,并删除了外部文件。我更喜欢创建辅助函数来构建字符串，并在服务器和客户端的配置中使用它们。

最后，**关于实际配置，在服务器端，它是通过传递给运行 kafka 单节点集群的容器的环境变量来完成的，我不打算粉饰它:为了找到要使用的配置，它主要是一个查阅文档和全面试错的过程，直到我找到一个工作配置。在客户端，它只是添加了 jaas 配置条目。**

这并不漂亮，这不是一个外科手术般精确的过程，但最终我让它工作了，这是任何需要集成测试工作基础的人的结果，Apache Kafka 使用身份验证和授权:

# 结论

我写这篇文章的目的是以一种有趣的阅读方式和一种讲故事的方式来分享我的痛苦，但也与社区分享一种用于创建与 Kafka 和 Authentication 的集成测试的工作配置，因为这似乎不是通常做的事情，我根本不明白为什么。

我希望这是以某种奇怪的方式娱乐，但最重要的是，我希望这是有帮助的。