<html>
<head>
<title>Credit risk assessment using support vector machine (SVM)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于支持向量机(SVM)的信用风险评估</h1>
<blockquote>原文：<a href="https://medium.com/codex/credit-risk-assessment-using-support-vector-machine-svm-88d9ffab94c8?source=collection_archive---------7-----------------------#2021-07-14">https://medium.com/codex/credit-risk-assessment-using-support-vector-machine-svm-88d9ffab94c8?source=collection_archive---------7-----------------------#2021-07-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6865" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM是一种广泛用于分类和回归问题的监督机器学习算法。其受欢迎的主要原因是其稳健性(低方差)、处理高维数据的能力(与线性回归相比，SVM适用于样本数少于预测数的情况)，以及处理非线性数据模式的能力。</p><p id="b54a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单地说，SVM包括四个理论基础:</p><ol class=""><li id="7d64" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">分离超平面。在二维空间中，它是一条直线，将数据点分成两个独立的区域。</li><li id="8932" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">最大边缘分离超平面。这相当于找到一条线，使决策边界与其最近的数据点(支持向量)之间的距离最大化，也称为余量。</li><li id="1fce" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">软利润。实际上，我们遇到的大多数数据集都不能被分离超平面所分离。在这种情况下，SVM允许一些数据实例位于边缘的错误一侧，甚至通过在公式中引入松弛变量和成本C等参数来分离超平面。参数C是超参数，我们可以使用它通过k重交叉验证(CV)来微调SVM模型。</li><li id="ec01" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">内核函数。SVM通过特征映射将数据点投射到更高维的空间。这种计算很容易通过核函数来解决。我强烈推荐这篇Quora帖子来了解更多关于内核功能的细节。有几个可用的核，但我将侧重于线性核和径向基函数(RBF)核。</li></ol><p id="c611" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，SVM被用来区分信用不良和信用良好。根据<a class="ae jr" href="https://www.investopedia.com/terms/b/bank-credit.asp" rel="noopener ugc nofollow" target="_blank"> investopedia </a>的说法，银行信贷是个人或企业可以从银行借到的资金总额。数据是从<a class="ae jr" href="https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>下载的。根据与数据相关联的<a class="ae jr" href="http://www1.beuth-hochschule.de/FB_II/reports/Report-2019-004.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，总共有20个预测因子和一个响应变量(良好与不良信用风险)。除此之外，作者还建议将错误分类坏风险的成本分配为错误分类好风险成本的五倍。因此，误分类成本将被用作网格搜索中的目标函数，以找到最佳的超参数设置。</p><p id="e161" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在温和地介绍了SVM和数据本身之后，让我们开始编码。</p><h1 id="944a" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">数据采集和分割</h1><p id="2e5a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">有一个名为‘read _ SouthGermanCredit’的R脚本文件。与下载的数据一起出现的“r”。运行R中的脚本文件，生成的“dat”数据帧是将用于分析和建模的处理数据。我将“dat”变量保存为。RData '文件，所以我只需要在需要的时候加载RData文件。</p><p id="7806" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">加载所有需要的包。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="beea" class="le jt hi la b fi lf lg l lh li">library(rsample) # stratified sampling<br/>library(cdata) # data wrangling<br/>library(ggplot2) # beautiful plot<br/>library(GGally) # grouped scatter plot matrix<br/>library(magrittr) # pipe<br/>library(dplyr) # data wrangling<br/>library(caret) # data preprocessing and transform<br/>library(e1071) # svm<br/>library(WVPlots) # double density plot and ROC curve<br/>library(knitr) # tidy table<br/>library(sigr) # calculate AUC</span></pre><p id="9576" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">显示数据的内部结构和统计摘要。然后，通过分层抽样对数据进行拆分。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="c1a8" class="le jt hi la b fi lf lg l lh li">load(“credit.RData”)<br/>str(dat)<br/>summary(dat)<br/>response=’credit_risk’</span><span id="beb2" class="le jt hi la b fi lj lg l lh li">set.seed(10)<br/>split=initial_split(dat,prop=0.8,strata = response)<br/>train=training(split)<br/>test=testing(split)</span></pre><p id="ec9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从str()输出中，我们知道有14个名义预测值(没有自然排序)，3个序数变量(有自然排序)和3个连续预测值。</p><h1 id="cc0f" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">数据可视化</h1><p id="b1ae" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">由于我们的数据包括分类预测值和连续预测值，我们需要使用不同的图形输出来可视化它们相对于响应变量的分布。</p><h2 id="85ab" class="le jt hi bd ju lk ll lm jy ln lo lp kc iq lq lr kg iu ls lt kk iy lu lv ko lw bi translated">连续预测器</h2><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="4de5" class="le jt hi la b fi lf lg l lh li">idx_con=c(“duration”,”amount”,”age”)<br/># Grouped boxplot. Turn train data from wide to long format<br/>train_con=cbind(train[,idx_con],credit_risk=train[,response])<br/>train_con_long=unpivot_to_blocks(train_con,nameForNewKeyColumn = “variables”,<br/> nameForNewValueColumn = “values”,<br/> columnsToTakeFrom = idx_con)</span><span id="81ab" class="le jt hi la b fi lj lg l lh li">ggplot(data=train_con_long, aes(x=credit_risk,y=values)) +<br/> geom_boxplot(color=”blue”,fill=”blue”,alpha=0.2,notch=TRUE,<br/> outlier.color=”red”,outlier.fill = “red”,outlier.size = 2) +<br/> facet_wrap(~variables,ncol=3,scales = “free”)</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/db8c3beda048f5fd5e751ee2babb916d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hRrtJGX4cxujLOKgN1K00Q.png"/></div></div></figure><p id="b0c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的方框图给我们带来了一些深刻的见解:不良信贷一般来自年轻的贷方。持续时间长往往是不良信贷。我们可以得出这些推论，因为“年龄”和“持续时间”面板中的箱线图的凹口不重叠，因此两组(坏信用和好信用)的中位数显著不同。但是，需要注意的是，存在异常值(标记为红圈)。因此，上述关系并不确定。</p><p id="5025" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于我们有多个连续的预测值，相关矩阵图构建如下。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="3491" class="le jt hi la b fi lf lg l lh li">ggpairs(train_con,columns = 1:3, ggplot2::aes(colour=credit_risk))</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/ce9a83ceb756dedeaba1e143d58e2870.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4GGf1-TzZAoPIpdOJDg-yg.png"/></div></div></figure><p id="b068" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">金额和期限变量正相关，这是有意义的，因为需要更多的时间来偿还更高金额的贷款。如密度图和散点图所示，类别没有很好地分开。</p><h2 id="14f0" class="le jt hi bd ju lk ll lm jy ln lo lp kc iq lq lr kg iu ls lt kk iy lu lv ko lw bi translated">分类预测</h2><p id="51cd" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">列联表是更好地了解分类变量在类别标签中分布情况的好方法。下面的代码片段显示了如何在r中构造列联表。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="2a10" class="le jt hi la b fi lf lg l lh li"># contigency table (count)<br/>table(train$housing,train$credit_risk)</span></pre><p id="40be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以将列联表形象化，如下所示。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="48a6" class="le jt hi la b fi lf lg l lh li"># Visualization of two categorical variables: method 1<br/>ggplot(data=train) +<br/> geom_count(aes(x=housing,y=credit_risk))</span><span id="d83e" class="le jt hi la b fi lj lg l lh li"># method 2<br/>train %&gt;%<br/> count(credit_history,credit_risk) %&gt;%<br/> ggplot(aes(x=credit_history,y=credit_risk)) +<br/> geom_tile(aes(fill=n)) +<br/> theme(axis.text.x = element_text(angle = 45,hjust=1))</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/c2187f7f63c06182c09699a625b67efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zD9K-GRsaovcXnJyWR7zA.png"/></div></div></figure><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/5772b2360c26dfafa32deb98288065e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3_oHiDzli3pzXhWL-l_7w.png"/></div></div></figure><p id="6f4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如何确定分类预测因子和反应变量之间的关系？独立性的卡方检验是这种假设检验的稳健统计量。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="4480" class="le jt hi la b fi lf lg l lh li">train_cat=train[,!(colnames(train) %in% idx_con)]</span><span id="e523" class="le jt hi la b fi lj lg l lh li">t=c()<br/>idx=c()<br/>for (i in (1:(ncol(train_cat)-1))) {<br/> t[i]=chisq.test(train_cat[,i],train$credit_risk)$p.value<br/> # u[i]=fisher.test(train[,i],train$credit_risk)$p.value<br/> if (!is.list(tryCatch( { result &lt;- chisq.test(train[,i],train$credit_risk) }<br/> , warning = function(w) { print(“TRUE”) }))) {<br/> idx=c(idx,i)<br/> }<br/>}</span><span id="3fce" class="le jt hi la b fi lj lg l lh li">idx_sig=which(t&lt;=0.05)</span><span id="ad48" class="le jt hi la b fi lj lg l lh li">idx_int=!(idx_sig %in% idx)<br/>colnames(train_cat)[idx_sig[idx_int]]</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div class="er es mg"><img src="../Images/3bf01aac568ff7c375f6d52d0a91a3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*Df_duEURYsL8ftgPS82E2g.jpeg"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">不独立于反应变量的预测因子:信用风险。</figcaption></figure><p id="9c98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果列联表中某个单元的预期频率小于5，卡方检验可能会产生不准确的结果。</p><h1 id="44b0" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">特征工程</h1><p id="7cb0" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">SVM的一个缺点是它不能处理分类特征。因此，必须对分类预测值进行预处理或转换成数值。一键编码应用于名义预测值，而标签编码应用于顺序预测值。连续变量通过最小-最大归一化被标准化为[0，1]。至此，我们应该意识到数据泄漏。为了防止这个问题，数据准备应该只适合于训练数据。下面显示了上述训练数据和拒绝数据转换的代码片段。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="ad34" class="le jt hi la b fi lf lg l lh li"># Perform one hot encoding for categorical (nominal) predictors.<br/>library(caret)<br/>var_cat=c("status","credit_history","purpose","savings","employment_duration",<br/>          "personal_status_sex","other_debtors","property","other_installment_plans",<br/>          "housing","job","people_liable","telephone","foreign_worker")</span><span id="cab7" class="le jt hi la b fi lj lg l lh li">train_cat=train[,colnames(train) %in% var_cat]<br/>dummy=dummyVars("~.",data=train_cat)<br/>newdata=data.frame(predict(dummy,newdata=train_cat))</span><span id="113a" class="le jt hi la b fi lj lg l lh li"># label encoding for ordinal variables<br/># chooses the related variables<br/>var_ord=c("installment_rate","present_residence","number_credits")<br/>train_cont=train[,colnames(train) %in% var_ord]<br/>train_cont=transform(train_cont,installment_rate=as.numeric(installment_rate)-1,<br/>                     present_residence=as.numeric(present_residence)-1,<br/>                     number_credits=as.numeric(number_credits)-1)</span><span id="06a6" class="le jt hi la b fi lj lg l lh li"># Min-max normalization of continuos predictors<br/>var_cont=c("amount","age","duration")<br/>dat_cont=train[,colnames(train) %in% var_cont]<br/>process=preProcess(dat_cont,method = c("range"))<br/>scaled_dat_cont=predict(process,dat_cont)</span><span id="9d16" class="le jt hi la b fi lj lg l lh li"># concatenate all the predictors with response variable by columns<br/>train_new=cbind(newdata,train_cont,<br/>                scaled_dat_cont,credit_risk=train$credit_risk)</span><span id="08af" class="le jt hi la b fi lj lg l lh li"># test data<br/># One-hot encoding<br/>test_cat=test[,colnames(test) %in% var_cat]<br/>newdata=data.frame(predict(dummy,newdata=test_cat))</span><span id="a1e8" class="le jt hi la b fi lj lg l lh li"># Label encoding<br/>test_cont=test[,colnames(test) %in% var_ord]<br/>test_cont=transform(test_cont,installment_rate=as.numeric(installment_rate)-1,<br/>                    present_residence=as.numeric(present_residence)-1,<br/>                    number_credits=as.numeric(number_credits)-1)<br/># Min-max normalization<br/>dat_cont=test[,colnames(test) %in% var_cont]<br/>scaled_dat_cont=predict(process,dat_cont)</span><span id="6f45" class="le jt hi la b fi lj lg l lh li"># concatenate by columns<br/>test_new=cbind(newdata,test_cont,<br/>               scaled_dat_cont,credit_risk=test$credit_risk)</span></pre><h1 id="abb2" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">SVM模型的训练与评估</h1><h2 id="a9d0" class="le jt hi bd ju lk ll lm jy ln lo lp kc iq lq lr kg iu ls lt kk iy lu lv ko lw bi translated">线性SVM</h2><p id="658a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">正则化参数C是决定SVM模型性能的关键。C的高值意味着分离超平面两侧的小余量，因此不利于可能导致更复杂的决策边界的错误分类。这可能会导致过度拟合问题。</p><p id="5b9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过网格搜索法可以找到最佳C参数。如上所述，两个类别的错误分类成本是不同的。因此，网格搜索的目标函数被设置为误分类成本，而不是分类误差的默认设置。对于成本敏感的分类问题，准确性度量可能会产生误导。线性SVM的权重(系数)(它们的符号和绝对幅度)有助于探索特征的重要性和对最终预测输出的贡献。更多详情请见本<a class="ae jr" href="https://stats.stackexchange.com/questions/39243/how-does-one-interpret-svm-feature-weights" rel="noopener ugc nofollow" target="_blank">换股帖</a>。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="d4e5" class="le jt hi la b fi lf lg l lh li"># Hyper-parameters tuning cost function<br/>cost_matrix=matrix(c(0,1,5,0),ncol=2)<br/>err=function(truth,pred){<br/>  t=table(truth=truth,pred=pred)<br/>  tot_cost=sum(t*cost_matrix)<br/>  tot_cost<br/>}</span><span id="3c9e" class="le jt hi la b fi lj lg l lh li">range_exp=seq(-10,10,by=2)<br/>set.seed(200)  # for reproducibility<br/># linear kernel SVM. No scaling is needed as it had been performed beforehand.<br/># class weight is set to be inversely proportional to the number of samples in <br/># each class<br/>svm_tune=tune(svm,credit_risk~.,data = train_new,kernel='linear', scale=FALSE,<br/>              probability=TRUE, class.weights='inverse',<br/>              ranges = list(cost=c(2^range_exp)),<br/>              tunecontrol = tune.control(cross=5,error.fun = err))<br/>summary(svm_tune)<br/>min_cost=svm_tune$performances$cost[which.min(svm_tune$performances$error)]</span><span id="2c98" class="le jt hi la b fi lj lg l lh li"># Visualization <br/>svm_tune$performances %&gt;%<br/>  ggplot(aes(x=cost,y=error)) +<br/>  geom_line() +<br/>  scale_x_continuous(name = "cost, C",trans = "log2") + <br/>  ylab("misclassification cost") +<br/>  geom_vline(xintercept = min_cost,<br/>             color="red",linetype=2)</span><span id="5d90" class="le jt hi la b fi lj lg l lh li"># Extract the best model in term of misclassification cost<br/>svm_lin=svm_tune$best.model</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/30e618762dd32f5995e8144886bfa0e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNEotsMZIKw31zLqeTtROw.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">最佳C值是16。</figcaption></figure><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="988d" class="le jt hi la b fi lf lg l lh li">coef_lin=data.frame(names=names(coef(svm_lin))[-1],coef=coef(svm_lin)[-1])<br/>coef_lin_10=coef_lin[order(-abs(coef_lin$coef))[1:10],]<br/>rownames(coef_lin_10)=NULL<br/>kable(coef_lin_10)</span><span id="68dc" class="le jt hi la b fi lj lg l lh li"># Visualization of coefficients estimates<br/>ggplot(data=coef_lin_10,aes(x=names,y=coef)) +<br/>  geom_pointrange(aes(ymin=0,ymax=coef)) +<br/>  coord_flip() +theme_classic() + ylab("coefficient estimates")</span><span id="e4e0" class="le jt hi la b fi lj lg l lh li"># first column shows the output labels of svm, second column is the # corresponding decision values<br/>data.frame(fitted=svm_lin$fitted[1:10],dv=svm_lin$decision.values[1:10])</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div class="er es ml"><img src="../Images/b8fa452e663ac39ee5f9f4de924fa193.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*y9XiRTSwg5x41pk3Zroj_Q.jpeg"/></div></figure><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/6de6ad0188bdc5694fcaead810b655d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjFB44BAo24oLT8OJmlIIA.png"/></div></div></figure><p id="3a6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上表告诉我们，正决策值指的是不良信用，反之亦然。因此，从上面的图表中我们可以看出，超过200德国马克(德国货币，应该指出，这一数据是在1973年至1975年收集的)的稳定工资和良好的信用记录有助于良好的信用，因为它们是负面的。另一方面，没有支票账户和持续时间长有助于不良信贷。</p><h2 id="ec78" class="le jt hi bd ju lk ll lm jy ln lo lp kc iq lq lr kg iu ls lt kk iy lu lv ko lw bi translated">SVM皇家银行</h2><p id="c175" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">径向基核函数可以数学表示如下:</p><figure class="kv kw kx ky fd ly er es paragraph-image"><div class="er es mm"><img src="../Images/96366a992d7e6696232794c6739c9165.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*k0mI5DzvlyUwEVZJFnUHxw.jpeg"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">径向基核函数</figcaption></figure><p id="cf28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上式所示的γ，γ定义了单个训练样本的影响范围。因此，C和γ是需要优化的超参数。我首先从粗网格搜索开始，在找到“更好”的区域后，按照这篇<a class="ae jr" href="https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中的建议进行细网格搜索。代码及其相应的输出可以在<a class="ae jr" href="https://rpubs.com/JQ_programmer_92/790849" rel="noopener ugc nofollow" target="_blank"> RPubs </a>中找到。</p><h2 id="eeb5" class="le jt hi bd ju lk ll lm jy ln lo lp kc iq lq lr kg iu ls lt kk iy lu lv ko lw bi translated">SVM模特表演评估</h2><p id="aba2" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">由于这是一个二分法分类问题，可以绘制双密度图和受试者工作特征(ROC)曲线。计算性能指标，如准确度、误分类成本、精确度、召回率和f1-measure，以比较线性SVM和RBF SVM。相关代码和性能指标如下所示。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="1b9d" class="le jt hi la b fi lf lg l lh li">pred_svm_lin=predict(svm_lin,newdata=test_new,decision.values = TRUE)<br/>pred_svm_rbf=predict(svm_rbf,newdata = test_new,decision.values = TRUE)<br/>dat_plot=data.frame(outcome=test_new$credit_risk,dv_svm_linear=attr(pred_svm_lin,”decision.values”)[1:nrow(test_new)],<br/> dv_svm_rbf=attr(pred_svm_rbf,”decision.values”)[1:nrow(test_new)])</span><span id="7c89" class="le jt hi la b fi lj lg l lh li"># double densitiy plot and paired ROC curves<br/>DoubleDensityPlot(dat_plot,xvar=”dv_svm_linear”,truthVar = “outcome”,<br/> title=”Distribution of linear svm scores (test data)”) +<br/> geom_vline(xintercept = 0, color=”red”, linetype=2)</span><span id="46ff" class="le jt hi la b fi lj lg l lh li">DoubleDensityPlot(dat_plot,xvar=”dv_svm_rbf”,truthVar = “outcome”,<br/> title=”Distribution of RBF svm scores (test data)”) +<br/> geom_vline(xintercept = 0, color=”red”, linetype=2)</span><span id="8483" class="le jt hi la b fi lj lg l lh li">ROCPlotPair(dat_plot,xvar1=”dv_svm_linear”,xvar2 = “dv_svm_rbf”,truthVar = “outcome”,<br/> truthTarget = “good”, title=”ROC plots for svm models (test data)”)</span></pre><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/f9a68c1b143dfc736b484e89f063b298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ndkxRcxkGVRrDMIx_lSFtw.png"/></div></div></figure><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/de98ef897a432787698550f8146a0d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VQYRRqpncZ6kQRAZ6KU4VQ.png"/></div></div></figure><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/781c7b4b9b300c6384c9f240e98a309a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GdhVjJKloHPzp-uBWGunNg.png"/></div></div></figure><figure class="kv kw kx ky fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mn"><img src="../Images/16f0080e797cbd775cb15db5ec381c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ID3fwgEEC-esC72LYyg7iA.jpeg"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">用测试数据评估支持向量机模型的性能。</figcaption></figure><p id="44db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个问题，回忆(敏感度)将是一个非常重要的性能指标，因为它告诉我们分类器在识别未来未知数据的潜在不良信用方面的能力。线性和径向基函数SVM模型表现出大致相似的性能。完整的代码可以在Github 的<a class="ae jr" href="https://rpubs.com/JQ_programmer_92/790849" rel="noopener ugc nofollow" target="_blank"> RPubs </a>和<a class="ae jr" href="https://github.com/Jacky-lim-data-analyst/programmer.git" rel="noopener ugc nofollow" target="_blank">信用数据目录中找到。</a></p><h1 id="fcb3" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">参考</h1><p id="e4c8" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">格勒普明大学(2019)。南德国信贷数据:修正一个广泛使用的数据集。报告4/2019，柏林应用科学大学第二系数学、物理和化学报告。</p></div></div>    
</body>
</html>