<html>
<head>
<title>Sentiment Analysis with Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于迁移学习的情感分析</h1>
<blockquote>原文：<a href="https://medium.com/codex/sentiment-analysis-with-tensorflow-hub-678c30ac79a2?source=collection_archive---------2-----------------------#2021-06-17">https://medium.com/codex/sentiment-analysis-with-tensorflow-hub-678c30ac79a2?source=collection_archive---------2-----------------------#2021-06-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="2b07" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">关于如何使用IMDB数据集进行迁移学习的简单指南。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/7c4a5843d0e0dd0ca081b1e665d46a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tnJ85U10vgcSV_RH"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://unsplash.com/@evertonvila?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">埃弗顿维拉</a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="2abf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">模特训练是一个艰难的过程。从零开始训练一个模型，必须要有大量的数据和计算能力。例如，运行了数千小时的GPU来训练2017年开发的<a class="ae jn" href="https://ai.googleblog.com/2017/11/automl-for-large-scale-image.html" rel="noopener ugc nofollow" target="_blank"> NASNet </a>模型。</p><p id="e5e0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">幸运的是，您可以使用预先训练的模型进行分析，如文本或图像分类。这些预先训练好的模型在TensorFlow和PyTorch等库中也有。您可以轻松地将这些预训练模型应用到您的数据集。</p><p id="8f3b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将这些模型直接应用于数据集可能不会获得良好的结果。因为这些模型是根据某些数据训练的。假设您想用ResNet模型对狗和猫的图片进行分类。ResNet经过训练，可以对数千张图像进行分类。但是你只想对狗和猫的图像进行分类。为此，您需要定制这个模型的最后几层。在这篇文章中，我将向你展示如何用一个预先训练好的模型进行情感分析。</p><p id="c926" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在开始之前，请不要忘记订阅我们的youtube频道，在那里我创建了关于人工智能、数据科学、机器学习和深度学习的内容。</p><p id="bbde" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开始吧！</p><h1 id="f87d" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">什么是TensorFlow Hub？</h1><p id="69de" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">TensorFlow Hub是一个预先训练好的机器学习模型的存储库。只需几行代码就可以在TensorFlow Hub中使用类似BERT的模型。借助TensorFlow Hub，您可以执行图像分类、文本嵌入、音频和视频识别等分析。</p><h1 id="9427" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">情感分析</h1><p id="ccc3" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">随着社交媒体和技术的发展，大多数人分享他们的想法和思想。这些共享的数据对于社会科学和市场营销等领域非常重要。分析一个文本是正面的还是负面的叫做情感分析。情感分析是自然语言处理的一个子领域，也是当今的热门领域之一。我将使用IMDB数据集来演示TensorFlow Hub的情感分析。让我们仔细看看IMDB数据集</p><h1 id="32cd" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">IMDB数据集</h1><p id="f10a" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated"><a class="ae jn" href="https://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">IMDB数据集</a>由5万条电影评论组成，其中2.5万条为教程，2.5万条为测试。这些评论一半被标为正面，另一半被标为负面。通过TensorFlow数据集(TFDS)库，您可以加载这些数据集。让我们安装数据集和tfds模块。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="2873" class="lm kl hi li b fi ln lo l lp lq">pip install tensorflow-datasets #for the stable version<br/>pip install tfds-nightly #Contains the latest version of datasets</span></pre><p id="c949" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">安装完这个库之后，让我们导入TensorFlow和tensorflow_datasets。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="aa87" class="lm kl hi li b fi ln lo l lp lq">import tensorflow as tf<br/>import tensorflow_datasets as tfds</span></pre><h1 id="1401" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">下载IMDB数据集</h1><p id="e03c" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">现在，让我们使用tfds.load方法加载IMDB数据集。在加载数据集时，让我们也将它分为训练、验证和测试。注意，用训练数据拟合模型，用验证数据调整超参数，用测试数据评估模型。</p><p id="cd4f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我想将训练数据集分成60%的训练和40%的验证。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="0dd3" class="lm kl hi li b fi ln lo l lp lq">train_data, validation_data, test_data = tfds.load(<br/>    name="imdb_reviews",                         #1<br/>    split=('train[:60%]', 'train[60%:]', 'test'),#2<br/>    as_supervised=True                           #3<br/>)</span></pre><p id="7db4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们检查一下这些代码。</p><p id="d246" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(1)我在name参数中设置了数据集的名称。</p><p id="bbbe" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(2)我指定了如何将数据集拆分为split参数。</p><p id="f1b3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(3)通过将as_supervised参数设置为True，我已经将数据集的结构设置为输入和标签。</p><p id="9f1c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开始探索数据集。</p><h1 id="7f1e" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">浏览数据集</h1><p id="1341" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">理解数据集是数据分析的重要阶段之一。IMDB数据集中的每个示例都由一个电影评论和该电影评论的标签组成。标签由0或1组成。0表示评论是负面的，1表示评论是正面的。</p><p id="e1f9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们打印前10个例子。首先，我要把例子中的注释和标签分开。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="8d57" class="lm kl hi li b fi ln lo l lp lq">train_examples_batch, train_labels_batch =<br/>next(iter(train_data.batch(10)))</span></pre><p id="e00e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我用分批法选择了前10个样本。让我们看看前10条评论。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="ee9a" class="lm kl hi li b fi ln lo l lp lq">train_examples_batch</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lr"><img src="../Images/44d5bab280faed2eb7db36c5aa6f0217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ZmFQ9PtzQoKQUdNCI1eeA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">训练数据集中的前10条评论</figcaption></figure><p id="c4f4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们打印前10个标签。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="a8be" class="lm kl hi li b fi ln lo l lp lq">train_labels_batch</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ls"><img src="../Images/2e316abc8315312b8f262a5f34038fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eYmak4VE0MN_0sbtBP6OSw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">训练数据集中的前10个标签</figcaption></figure><h1 id="39e5" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">建立模型</h1><p id="7cfd" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">让我建立一个神经网络模型。深度神经网络(DNN)模型已经变得非常流行，尤其是在最近几年。使用基于DNN的模型可以获得高精度。</p><p id="cb7f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">神经网络的最大缺点是调整模型的超参数。如果你不对超参数进行微调，你就不会得到好的模型。在构建神经网络时，您需要指定超参数，例如文本将如何表示，模型中使用了多少层，以及每层中有多少个神经元。</p><p id="e8b2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们的输入数据由句子组成。表示这些文本的一种方法是将句子翻译成嵌入向量。因此，从文本中学习单词在向量空间中的位置。学习单词的向量空间中的位置称为嵌入。请注意，向量空间中更接近的单词具有相似的含义。</p><p id="e756" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">文本分类的第一层必须是预先训练好的文本嵌入。有了这一层，文本预处理就完成了。因此，文本预处理过程(这是最累人的过程之一)很容易完成。</p><p id="cf97" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">TFHub上有很多预先训练好的<a class="ae jn" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank">文本嵌入</a>。这些文本嵌入是基于前馈神经网络语言模型(NNLM)。您可以根据您的工作使用这些嵌入之一。在这个分析中，我将使用<a class="ae jn" href="https://tfhub.dev/google/nnlm-en-dim50/2" rel="noopener ugc nofollow" target="_blank"> nnlm-en-dim50/2 </a>。该模型使用基于在7D英语google新闻语料库中训练的文本嵌入的标记，并且包括50个嵌入维度。</p><p id="39be" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">首先，我将把预先训练好的嵌入层赋给嵌入变量。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="091c" class="lm kl hi li b fi ln lo l lp lq">embedding = “<a class="ae jn" href="https://tfhub.dev/google/nnlm-en-dim50/2" rel="noopener ugc nofollow" target="_blank">https://tfhub.dev/google/nnlm-en-dim50/2</a>"</span></pre><p id="f667" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们使用TensorFlow Hub模型创建一个Keras层。首先我要导入tensorflow_hub。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="5ddc" class="lm kl hi li b fi ln lo l lp lq">import tensorflow_hub as hub</span></pre><p id="dcc7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们创建一个Keras层。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="89de" class="lm kl hi li b fi ln lo l lp lq">hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)</span></pre><p id="e745" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因为数据类型是text，所以我在dtypes参数中设置了tf.string。我还在可训练参数中设置了True，因为我希望这些层是可训练的。让我们看看使用hub_layer图层的训练数据集中前三个样本的输出。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="4517" class="lm kl hi li b fi ln lo l lp lq">hub_layer(train_examples_batch[:3])</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lt"><img src="../Images/a73ed4e6736dc0ff9fbdc8103a692e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*1lcM_k6SBI8Rubi0uMLHiw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">训练数据集的前三个示例</figcaption></figure><p id="7f3c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，我们可以建立整个模型。我将使用顺序技术来建立模型。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="98c3" class="lm kl hi li b fi ln lo l lp lq">model = tf.keras.Sequential()</span></pre><p id="ccac" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我将使用add方法添加每个图层。首先，让我们添加我刚刚创建的hub_layer嵌入层。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="8686" class="lm kl hi li b fi ln lo l lp lq">model.add(hub_layer)</span></pre><p id="cacd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有了这一层，句子就被拆分成了记号。意义上彼此接近的标记被放在一起。接下来，让我们添加一个密集层，并在这一层使用relu激活功能。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="33dd" class="lm kl hi li b fi ln lo l lp lq">model.add(tf.keras.layers.Dense(16, activation='relu'))</span></pre><p id="addd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于我们的输出有两类，正和负，让我们添加一个神经元密集层</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="1664" class="lm kl hi li b fi ln lo l lp lq">model.add(tf.keras.layers.Dense(1))</span></pre><p id="2a48" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们编写的整个代码如下所示。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="2bcd" class="lm kl hi li b fi ln lo l lp lq">model = tf.keras.Sequential()<br/>model.add(hub_layer)<br/>model.add(tf.keras.layers.Dense(16, activation=’relu’))<br/>model.add(tf.keras.layers.Dense(1))</span></pre><p id="bc71" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们建立了我们的模型。您可以使用summary方法来查看模型的摘要。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="8866" class="lm kl hi li b fi ln lo l lp lq">model.summary()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lu"><img src="../Images/44e58dafa8b754fb4c798d5ce5f62f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*YtkWfGvYeoAt4NeAgj4IWQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">模型摘要</figcaption></figure><p id="48d9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">您可以看到每层中使用的参数数量。</p><h2 id="f7fe" class="lm kl hi bd km lv lw lx kq ly lz ma ku jx mb mc kw kb md me ky kf mf mg la mh bi translated">损失函数和优化器</h2><p id="53b2" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">现在我要编译模型了。您可以使用compile方法来编译模型。在编译模型时，您需要指定损失函数和优化器。由于我们的问题是一个分类问题，我们可以使用二元交叉熵作为损失函数。让我们使用“adam”作为优化器，并设置“准确性”指标来查看模型在每个最后时期的性能。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="2b1d" class="lm kl hi li b fi ln lo l lp lq">model.compile(optimizer=’adam’, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[‘accuracy’])</span></pre><p id="65b7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">所以我们编译了这个模型，现在这个模型可以进行训练了。</p><h1 id="44fc" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">训练模型</h1><p id="1dc0" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">您可以使用fit方法来训练模型。我们开始吧。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="deb2" class="lm kl hi li b fi ln lo l lp lq">history = model.fit(<br/>    train_data.shuffle(10000).batch(512),       #1<br/>    epochs=10,                                  #2<br/>    validation_data=validation_data.batch(512), #3<br/>    verbose=1                                   #4<br/>)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/d237de5e30a4d4fd4b9758d4bedbfac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2UYYKlyBos3SfRuijGBCDw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mj"><img src="../Images/bc6c53c3c799ed45bd6fb3c67b80bb14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jIXS8yDVdqLWzFSo5x1YOg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">训练和验证损失和准确度值</figcaption></figure><p id="5a95" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们一步一步地检查这些代码。</p><p id="6eca" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(1)我设置了shuffle(10000)方法，每10000个样本对训练数据进行一次洗牌。在训练模型时，我想以512人为一组进行取样。</p><p id="cc2c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(2)我将纪元编号设置为10。时期决定了所有数据将通过神经网络的次数。</p><p id="9cf8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(3)我在validation_data参数中写了验证数据集。在用训练数据建立模型的同时，用验证数据调整模型的超参数。</p><p id="b534" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">(4)我设置verbose=1参数来查看每个时期的进度条和信息行。</p><p id="3fcc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们所预期的，模型的训练和验证准确性随着时期数的增加而增加。另一方面，训练和验证损失值正在减少。如您所见，模型对训练数据的准确性高于验证数据的准确性。说明这个模型可能存在过拟合问题。存在过拟合问题的模型存在泛化问题，难以很好地预测新数据。你可以使用L1、L2或辍学正规化技术来解决模型的记忆问题。</p><h1 id="bb1f" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">评估模型</h1><p id="455b" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">到目前为止，我们首先构建了模型，然后训练了模型。那么，模型的表现如何呢？测试数据集用于查看模型的性能。让我们用evaluate方法在测试数据上找到模型的精度值。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="8aa4" class="lm kl hi li b fi ln lo l lp lq">results = model.evaluate(test_data.batch(512), verbose=2)</span></pre><p id="e3ed" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，使用zip方法，让我们在模型的测试数据集上打印损失和准确性值。</p><pre class="iy iz ja jb fd lh li lj lk aw ll bi"><span id="a703" class="lm kl hi li b fi ln lo l lp lq">for name, value in zip(model.metrics_names, results):<br/>    print("%s: %.3f" %(name, value))</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/a4dd57855859734410854aab8aea21a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QvkfR_wAYFWfxyYG2GFhDQ.png"/></div></div></figure><p id="0c6e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">该模型的准确率约为86%。通过正则化技术，您可以将模型的精确度提高到95%。</p><h1 id="6163" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">结论</h1><p id="f0aa" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">TensorFlow Hub是预训练模型的存储库。您只需编辑几行代码就可以在您的分析中使用这些模型。使用这些模型可以节省时间和处理能力。</p><p id="68a2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">就是这样。感谢您的阅读。我希望你喜欢它。别忘了在YouTube上关注我们👍</p><p id="f5a1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你可以在这里找到笔记本<a class="ae jn" href="https://github.com/TirendazAcademy/DEEP-LEARNING-WITH-TENSORFLOW/blob/main/04-Sentiment-Analysis-with-TensorFlow-Hub.ipynb" rel="noopener ugc nofollow" target="_blank"/>。你可能会对下面的文章感兴趣。</p><div class="ml mm ez fb mn mo"><a href="https://levelup.gitconnected.com/7-differences-between-deep-learning-and-machine-learning-b5f2ff0ae00a" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">深度学习和机器学习的7个区别</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">深度学习与机器学习——有什么区别？</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">levelup.gitconnected.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc jh mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a rel="noopener follow" target="_blank" href="/mlearning-ai/how-to-use-data-pipelines-with-python-a9b662fadec2"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">Tensorflow数据管道初学者指南</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">如何使用Tensorflow为文本、图像和numpy数组数据集构建数据管道？</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">medium.com</p></div></div><div class="mx l"><div class="nd l mz na nb mx nc jh mo"/></div></div></a></div><p id="c070" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果这篇文章有帮助，请点击拍手👏按钮几下，以示支持👇</p></div></div>    
</body>
</html>