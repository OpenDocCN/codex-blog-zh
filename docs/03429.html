<html>
<head>
<title>Introduction to the Support Vector Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量机简介</h1>
<blockquote>原文：<a href="https://medium.com/codex/introduction-to-the-support-vector-machine-cd4a5857246e?source=collection_archive---------9-----------------------#2021-09-02">https://medium.com/codex/introduction-to-the-support-vector-machine-cd4a5857246e?source=collection_archive---------9-----------------------#2021-09-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="763f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">从它如何分类到它如何执行多类分类</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/050a72a00ec25065586264d8d619feaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5zVfBkbJhAcwXB0J"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">兰斯·阿斯佩在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="4964" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">久而久之，我们开始处理不同类型的数据。以前因为计算能力有限，只考虑简单的数据。随着计算能力的增强，数据的范围也在扩大。现在，我们可以评估文本、图像和视频数据。这些数据的一个共同点是它们具有大量的特征，而传统方法在这些数据上通常表现不佳。所以在这种情况下，可以使用支持向量机。</p><h1 id="e58b" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">以线性边界开始</strong></h1><p id="6836" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">想象10个点如下图所示分布。你如何用一条线性边界来分类这些点？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lh"><img src="../Images/24b74e07aa8c4f3100e0e62746729037.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*VCakqs3CxbbzmaJqfJiOIg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">10分的分配</figcaption></figure><p id="6ee1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">两个类中间的一条线可以正确的对分进行分类。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/867c84dd585ea00b4ade82d51a5d4769.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*w0boUK4EJVkBIxspAVl7zQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">划分两个阶级的线</figcaption></figure><p id="6d16" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这条线是由以下等式定义的2维空间的超平面的例子</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lj"><img src="../Images/63582ae53e2d0b464582b4b2fc65dc95.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*6VpFkJ9r1wNE6iwzTVEJhQ.png"/></div></figure><blockquote class="lk ll lm"><p id="1eae" class="jo jp ln jq b jr js ij jt ju jv im jw lo jy jz ka lp kc kd ke lq kg kh ki kj hb bi translated">B <!-- -->在我们继续之前:一个<strong class="jq hj">超平面</strong>是一个p维空间中具有p-1维的子空间。因此，在二维空间中，超平面是一条线。在三维空间中，超平面是一个平面。</p></blockquote><p id="5ac4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">回到上面的例子，您可以通过将一个数据点插入超平面来对点进行分类。如果结果值大于0，则该点位于超平面的上部。另一方面，如果该值小于0，则该点位于下部。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lr"><img src="../Images/214937aae1169a7b67d1dc60fc3b43ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*WBuhHTNcw4mtISBcXEdWuQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">用超平面的值对点进行分类</figcaption></figure><p id="7fb7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然而，上面显示的超平面并不是唯一可以分隔这10个点的线。正如你在下面看到的，可能有无限多的超平面分割这10个点。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ls"><img src="../Images/cc004e9dc21dcfae84b7098f0b9af043.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*F-_VoInc-MkxhBpFpc4Jew.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">可能的超平面的例子</figcaption></figure><p id="bc5a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，我们需要选择最好的一个。换句话说，它可以正确地对训练和测试观察进行分类。</p><h1 id="7ac8" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">什么被认为是最好的，为什么</strong></h1><p id="d77a" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">一种常见的方法是选择最大边缘超平面。顾名思义，它是一个具有最大边缘的超平面，边缘是训练观察和超平面之间的垂直距离。在下图中，边距用虚线表示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lr"><img src="../Images/2e8bff0b09283098f4c1ad59490943da.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*Q4dgywDlygqQtC0AtPiRQQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">边距用虚线表示</figcaption></figure><p id="cdc7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">但是我们为什么要用最大余量来选择超平面呢？这是因为如果一个点远离超平面，我们可以对我们的预测更有信心。因此，将超平面放置在离训练观察尽可能远的地方，是比将超平面放置在训练观察附近更自然的选择。使用最大间隔超平面的分类器称为最大间隔分类器。</p><h1 id="e142" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">什么定义超平面的形状</strong></h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lt"><img src="../Images/5861b1a302ff76ef1ae0a5f4925e8c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*s3iQKZnhrb9_TL0Y6_SNpw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">最大边缘线上的3个支持向量</figcaption></figure><p id="8e10" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从上面的图中，3个点直接位于最大边缘线上。这些点被称为支持向量，它们的名字来源于这样一个事实，即最大边缘超平面的形状只取决于这些点。因此，如果我们移动其中一个支持向量，超平面的方向将会改变，如下所示。然而，在超平面的边缘之外移动或添加点不会改变它的方向。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lu"><img src="../Images/4e71b3e3ef3b51444050523ba1c07a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/1*nFHSC8gxbZLkVUzPn2h5cA.gif"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">仅仅一个支持向量如何改变超平面的演示</figcaption></figure><h1 id="46a7" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">最大间隔分类器的问题</strong></h1><p id="d512" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">最大间隔分类器的一个问题来自它的硬间隔。与上面的例子不同，如果在边缘内添加一个点，那么不可避免地要移动最大边缘超平面，以便它能够正确地对所有的观察结果进行分类。例如，如果将下面的点添加到上面的10个数据点，最大边缘超平面将如下所示移动。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/24941f2f0ed357855931c8b351428144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aob7BR8d8WaL3S1HqeEHTw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在边缘内增加一个点如何改变超平面</figcaption></figure><p id="64ef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是一个非常巨大的变化。这是因为最大间隔分类器对于异常值来说是不鲁棒的，并且这种行为可能导致过度拟合。</p><p id="7f70" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最大间隔分类器的另一个限制是，找到一个能够正确分类每个观察值的超平面并不总是可能的。例如，当两个不同类别的点重叠时，不可能找到线性边界。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lw"><img src="../Images/a28deac0d5a927f140126443eefb0238.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*RFaIXO0EF5mE7zTIete9_w.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">当类别重叠时</figcaption></figure><p id="7e19" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了解决这些问题，我们可以使用支持向量分类器。</p><h1 id="d340" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">允许一些错误分类</strong></h1><p id="5e08" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">与最大间隔分类器不同，支持向量分类器实现了软间隔。正如你可以从它的名字推断的那样，软边允许观察在边的错误的一边，甚至是超平面的错误的一边。这些观察成为支持向量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lx"><img src="../Images/b925e911e99dbed6aa80083fe7bf8222.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*x_9wRLnMcbylHH4sFOnkGg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">软边距允许在边距内进行一些观察</figcaption></figure><p id="19c0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，它可能无法完美地分离两个类别，但它对于异常值是稳健的，并且能够正确地对大多数观察值进行分类。问题是软差值允许多少错误分类的案例。</p><p id="d2e2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果只允许几个点，那么最终的差距将会很小。相比之下，如果允许大量的点数，那么最终的差额将会很大。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/8bcdf309233323cac7e135e301996bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Upv_fcidL2U72wUBF-hZyA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作为允许不同数量的错误分类的软边距，边距如何变化</figcaption></figure><p id="e105" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">每一种都有利弊。具有几个支持向量的窄差不太可能减少方差，并且偏差仍然很低。因此，仍然会有过拟合的问题。另一方面，具有许多支持向量的宽裕度将减少方差，但是由于可能穿过超平面的若干观察，可能增加偏差。因此，可能会出现欠拟合，而不是过拟合。</p><p id="bc96" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如您所看到的，选择您的容忍程度与偏差-方差权衡有关，这可以通过r中e1071包的成本参数进行调整。通常，成本值是通过交叉验证选择的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lz"><img src="../Images/f8e5b6d02a44a1c4a2bdfaeb09ec5b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*mtIA3FYIg6fkZXhUtwhbhw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用e1071包装中的调节()执行交叉验证</figcaption></figure><h1 id="d6e8" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">支持向量分类器的局限性</strong></h1><p id="ae77" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">然而，支持向量分类器仍然是一种线性方法。因此，当一个分布不是线性的，它不可避免地表现不佳。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ma"><img src="../Images/e781f896c1b384be4bdcdc8f020b3a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*rvSq6LRVM0mcLmDT-ypEug.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">显示线性方法不适用于非线性分布</figcaption></figure><p id="25b7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，我们引入了支持向量机。</p><h1 id="fbcf" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">对于非线性边界—支持向量机</strong></h1><p id="02d5" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">为了增加非线性，支持向量机用预测器的多项式函数来扩大特征空间。意思是，不是X1，X2 …，Xp，扩大的特征空间包括X1，X1，X2，X2，…，Xp，Xp。但是这是如何带来非线性的呢？</p><p id="94f3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在扩大的特征空间中，由于新的特征，线性不可分的数据点变得可分。通常，在扩大的特征空间中使用的判定边界是线性的。但是当我们将决策边界带到原始特征空间时，边界变成非线性的。也许，更好的方法是直观地了解这是如何工作的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mb"><img src="../Images/a43216f9fa55ef8837fb97ed400c3c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*CylT_EK-eKBfWjgqWJ4vxQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">两类非线性分布</figcaption></figure><p id="f019" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">假设我们有如下的点分布。显然，线性决策边界在这种分布中表现不佳。在这种情况下，我们可以尝试通过添加由两个预测值组成的另一个维度来扩大特征空间。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mc"><img src="../Images/bc03bfc6fb8220e0a85fb0a8d8952bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*JmLyf3wMK6p4LSLSaDuYJw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在扩大的特征空间中变得可线性分离</figcaption></figure><p id="636f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在有了3个预测值，就有可能线性分割这两个类别。而当我们把这个带回原来的特征空间，平面就变成了一个圆形的边界。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es md"><img src="../Images/6da9085db51c4c618d80675aa119d2b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*wpRyD6duNoD6zhq5kFikAw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">扩大的特征空间中的线性边界在原始特征空间中变成非线性的</figcaption></figure><p id="ec5a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然而，盲目地扩大特征空间会导致大量的特征最终变得难以计算。因此，支持向量机不是将预测器转换为多项式函数，而是使用测量观察值之间相似性的核来达到相同的效果，而无需显式地使用更高维度。</p><p id="ae1b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">内核背后的数学解释不在本帖讨论范围之内，但是如果你有兴趣，<a class="ae jn" href="https://www.quora.com/What-are-kernels-in-machine-learning-and-SVM-and-why-do-we-need-them/answer/Lili-Jiang?srid=oOgT" rel="noopener ugc nofollow" target="_blank">你可以关注这个链接</a>。</p><h1 id="77c9" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">不同类型的内核</strong></h1><p id="88f6" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">因为核与决策边界直接相关，所以核的选择取决于数据点如何分布以及数据集看起来如何。在e1071软件包的svm函数中，有3种常用的选择:线性、多项式和径向。</p><p id="4c3c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如它们的名字所告诉你的，它们中的每一个都产生一个线性的、多项式的和圆形的判定边界。其中，线性核通常在有大量特征或计算时间至关重要时有用，因为它比其他核快得多。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es me"><img src="../Images/f919ddec01d0f3f6a228449bfc5a5e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*5pvxcm-Ud9CCCns4rlxvHQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">线性核的例子</figcaption></figure><p id="c283" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">当使用多项式核时，其次数可以通过次数参数进行调整，次数越高，模型越灵活。</p><div class="iy iz ja jb fd ab cb"><figure class="mf jc mg mh mi mj mk paragraph-image"><img src="../Images/5ebbdedaa30e2724b6b6a7ca5cb1f2c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*1smHHnw8gzoyW9pAM6T87w.png"/></figure><figure class="mf jc ml mh mi mj mk paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/c1988db218d762e2cfe546e5221e4cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*tuoWDZziw1pqHQYiauKXrg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx mm di mn mo translated">具有更高程度的模型具有更高的灵活性</figcaption></figure></div><p id="911c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">另一方面，径向核的摆动可以通过gamma参数进行调整，gamma值越高，摆动越多。</p><div class="iy iz ja jb fd ab cb"><figure class="mf jc mp mh mi mj mk paragraph-image"><img src="../Images/cb89fe24873a81b2f590223f1982041b.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*AyRKDUSUJWbcCUOGjBTOAA.png"/></figure><figure class="mf jc mq mh mi mj mk paragraph-image"><img src="../Images/eea12d292208e036a29927c7cab8d9dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*5Lb_5DrQ8ECFn3UWJNix1w.png"/><figcaption class="jj jk et er es jl jm bd b be z dx mr di ms mo translated">具有较高gamma值的模型会有更多的摆动</figcaption></figure></div><h1 id="ef52" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">划分两个以上的类别</strong></h1><p id="03bb" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">因为支持向量机是支持向量分类器的扩展，所以支持向量机不适合多类分类。但是，有几个扩展可以处理这些问题。</p><p id="d3ec" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">第一种方法叫做一对一分类。顾名思义，这种方法每次评估一对类。</p><blockquote class="mt"><p id="53bd" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">1.构造K(K-1)/2个支持向量机</p><p id="03aa" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">2.使用K(K-1)/2个支持向量机对观测值进行分类</p><p id="d8cb" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">3.统计观察被分配到每个班级的次数</p><p id="504e" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">4.为观察选择最常分配的类别</p></blockquote><figure class="ne nf ng nh ni jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/3457cdd46d9bcec2e00fca65318227bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ss9656yuo5FQ-rthvcXLuQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">一对一的视觉效果</figcaption></figure><p id="c539" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">例如，如果有3个类别a、b和c，那么这些类别就有3种组合:ab、ac和bc。因此，一对一分类构造了3个支持向量机。假设ab和ac选a，bc选c。由于有2 a和1 c，一对一分类会将观察结果分类为a类。</p><p id="a99b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">一对全体<br/> </strong>也顾名思义，这种分类是将一个阶层与其他所有阶层进行比较。因此，这种方法不是将一个观察值分为两类，而是告诉它是否属于某一类。</p><blockquote class="mt"><p id="8234" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">1.构造K支持向量机</p><p id="ede5" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">2.使用K支持向量机对观察值进行分类</p><p id="5275" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">3.选择一个概率分数最高的类</p><p id="3bd9" class="mu mv hi bd mw mx my mz na nb nc kj dx translated">(<a class="ae jn" href="https://jermwatt.github.io/machine_learning_refined/notes/7_Linear_multiclass_classification/7_2_OvA.html" rel="noopener ugc nofollow" target="_blank">更详细的解释</a>)</p></blockquote><p id="b6ba" class="pw-post-body-paragraph jo jp hi jq b jr nj ij jt ju nk im jw jx nl jz ka kb nm kd ke kf nn kh ki kj hb bi translated">相比一对一，优势是显而易见的。它需要更少的SVM，所以速度更快。然而，它的工作方式不可避免地带来了一个问题。例如，假设一个数据集中的10个类中的每一个都有100个样本。然后，每个SVM将在100到900个样本之间执行二元分类。这种不平衡的数据集会产生误导性的结果。由于这个原因，当给定多类变量时，e1071包中的svm()使用一对一方法。</p></div><div class="ab cl no np gp nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="hb hc hd he hf"><h1 id="3429" class="kk kl hi bd km kn nv kp kq kr nw kt ku io nx ip kw ir ny is ky iu nz iv la lb bi translated">参考</h1><p id="2be1" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">[1]阿尔邦，C. (2017年12月20日)。<em class="ln">使用RBF核时的SVC参数</em>。克里斯·阿尔邦。【https://chrisalbon.com/code/machine_learning/support_】T2<br/>vector _ machines/SVC _ parameters _ using _ RBF _ kernel/。</p><p id="9cb0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[2] Boehmke，B. (2020年2月1日)。<em class="ln">用r动手机器学习</em>。第十四章支持向量机。<a class="ae jn" href="https://bradleyboehmke.github.io/HOML/svm.html." rel="noopener ugc nofollow" target="_blank">https://bradleyboehmke.github.io/</a>T9<a class="ae jn" href="https://bradleyboehmke.github.io/HOML/svm.html." rel="noopener ugc nofollow" target="_blank">HOML/SVM . html .</a></p><p id="6d81" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[3]乔汉，未标明日期。<em class="ln">支持向量机的友好介绍</em>。KDnuggets。<a class="ae jn" href="https://www.kdnuggets.com/2019/09/friendly-introduction-support-vector-machines.html." rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2019/09/friendly-introduction-support-vector-machines . html</a></p><p id="b5a0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[4]詹姆斯·g .(2021)。<em class="ln">统计学习导论:r中的应用</em>。斯普林格。</p><p id="8642" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[5]奥列扎克，M. (2020年8月29日)。Svm内核:它们实际上做什么？中等。<a class="ae jn" href="https://towardsdatascience.com/svm-kernels-what-do-they-actually-do-56ce36f4f7b8." rel="noopener" target="_blank">https://towards data science . com/SVM-kernels-what-do-they-actually-do-56ce 36 f 4 f 7 b 8。</a></p></div></div>    
</body>
</html>