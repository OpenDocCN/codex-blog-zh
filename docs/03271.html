<html>
<head>
<title>Twitter Sentiment Analysis on Taliban Takeover of Afghanistan</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">塔利班接管阿富汗的推特情绪分析</h1>
<blockquote>原文：<a href="https://medium.com/codex/twitter-sentiment-analysis-on-taliban-takeover-of-afghanistan-62788e398734?source=collection_archive---------9-----------------------#2021-08-25">https://medium.com/codex/twitter-sentiment-analysis-on-taliban-takeover-of-afghanistan-62788e398734?source=collection_archive---------9-----------------------#2021-08-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/aa9c2ce273d8194f28996eba97e2a48a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8HtCfW6y8VMEiVyI"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">安德烈·克利姆克在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="617f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">今年4月，拜登总统下令美国军队在9月11日前全部撤出。到8月15日，塔利班已经接管了首都喀布尔。从拜登宣布他打算撤出美军的那一刻起，这就是一个政治上有争议的问题。随着塔利班迅速控制了这个国家，围绕它的争议越来越大。</p><p id="fda8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">出于对公众对拜登决定及其后果的看法的兴趣，我决定对与此问题相关的twitter数据进行快速自然语言处理(NLP)分析。我想看看所使用的语言有多情绪化，所以我选择Vader对一组推文进行情绪分析。我还想看看最常见单词的频率分布，看看是否有任何明显的单词或模式出现。</p><p id="8efa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我在我的Twitter开发者帐户上创建了一个新的应用程序，并打开了一个新的Jupyter笔记本。我将密钥和令牌保密，并创建了一个Tweepy对象。Tweepy是一个开源的python包，使用户能够访问Twitter API。这让我能够收集推文进行分析。更多关于Tweepy的信息可以在<a class="ae iu" href="https://docs.tweepy.org/en/latest/" rel="noopener ugc nofollow" target="_blank">的文档中找到。</a></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="03a4" class="kc kd hi jy b fi ke kf l kg kh">import credentials<br/>import pandas as pd<br/>import os</span><span id="78d1" class="kc kd hi jy b fi ki kf l kg kh">api_key = credentials.api_key<br/>api_secret_key = credentials.api_secret_key<br/>bearer_token = credentials.bearer_token<br/>access_token = credentials.access_token<br/>access_token_secret = credentials.access_token_secret</span><span id="fd8e" class="kc kd hi jy b fi ki kf l kg kh">import tweepy</span><span id="ae88" class="kc kd hi jy b fi ki kf l kg kh">auth = tweepy.OAuthHandler(api_key, api_secret_key)<br/>auth.set_access_token(access_token, access_token_secret)</span><span id="58f9" class="kc kd hi jy b fi ki kf l kg kh">api = tweepy.API(auth)</span></pre><p id="9bf8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我的Tweepy对象建立起来，我就用它来访问Tweepy。不幸的是Tweepy不让我无限制地访问它们——我相信限制是3200个。我使用tweepy.search()函数查询包含单词“Afghanistan”的tweets，将数据转换为JSON对象，并将其规范化为dataframe。之后，我缩小了想要保留的列数。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="11c5" class="kc kd hi jy b fi ke kf l kg kh">tweepy_object = api.search(q='afghanistan', lang='en')<br/>json_tweets = [tweet._json for tweet in tweepy_object]<br/>data = pd.json_normalize(json_tweets)</span><span id="ae6b" class="kc kd hi jy b fi ki kf l kg kh">columns = ['text', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'place', 'geo', 'coordinates' ]<br/>df = data[columns].copy()</span></pre><p id="4172" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在进行情感分析之前，我想看一眼我的一些数据。以下是我储存的五条转发量最大的推文。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="2e8a" class="kc kd hi jy b fi ke kf l kg kh">top_tweets = df.sort_values(by='retweet_count', ascending=False)['text'].to_list()<br/>top_tweets[:5]</span><span id="e8ee" class="kc kd hi jy b fi ki kf l kg kh">['RT @abhijitmajumder: With evacuation of the last 700 Hindus/Sikhs left in #Afghanistan in a 38-million population, an entire civilisation w…',<br/> 'RT @TheOnion: ‘Let’s Take It To Our Afghanistan Experts,’ Says Anchor Throwing To Panel Of Dick Cheneys <a class="ae iu" href="https://t.co/auVG3df5fV" rel="noopener ugc nofollow" target="_blank">https://t.co/auVG3df5fV</a> <a class="ae iu" href="https://t.c%E2%80%A6',/" rel="noopener ugc nofollow" target="_blank">https://t.c…',</a><br/> 'RT @AbhishBanerj: An Indian liberal trapped in Afghanistan appealed to PM Modi for help\n\nIndian govt rescued him.\n\nAs soon as he arrived in…',<br/> 'RT @BreitbartNews: Free Afghanistan Activist to Joe Biden: "I Regret My Vote for You" <a class="ae iu" href="https://t.co/4mnUsD8Shs'," rel="noopener ugc nofollow" target="_blank">https://t.co/4mnUsD8Shs',</a><br/> 'RT @Lowkey0nline: This is essential viewing. Unaccountable CIA backed militias, accompanied by US military in Afghanistan carrying out murd…']</span></pre><p id="3848" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">推文有点乱，所以我用正则表达式(regex)去除了一些混乱。作为一名学生，在过去的两年里，我成功地避免了regex语句，但是今天，我的运气赶上了我。我需要删除非字母数字字符，使文本更易读，更容易进行情感分析。如果你像我一样需要复习正则表达式，我发现这个<a class="ae iu" href="https://appdividend.com/2020/06/10/python-regex-replace-how-to-replace-string-in-python/" rel="noopener ugc nofollow" target="_blank">链接</a>对我的目的很有用。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="df70" class="kc kd hi jy b fi ke kf l kg kh">import regex as re<br/>tweets = df['text'].to_list()<br/>tweets = [re.sub("[^a-zA-Z0-9]", " ", tweet) for tweet in tweets]</span><span id="afdd" class="kc kd hi jy b fi ki kf l kg kh">df['text'] = tweets</span></pre><p id="1f9f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我再看一遍同样的推文，我会发现它们可读性稍微好一点。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8c71" class="kc kd hi jy b fi ke kf l kg kh">['RT @abhijitmajumder: With evacuation of the last 700 Hindus/Sikhs left in #Afghanistan in a 38-million population, an entire civilisation w…',<br/> 'RT @TheOnion: ‘Let’s Take It To Our Afghanistan Experts,’ Says Anchor Throwing To Panel Of Dick Cheneys <a class="ae iu" href="https://t.co/auVG3df5fV" rel="noopener ugc nofollow" target="_blank">https://t.co/auVG3df5fV</a> <a class="ae iu" href="https://t.c%E2%80%A6',/" rel="noopener ugc nofollow" target="_blank">https://t.c…',</a><br/> 'RT @AbhishBanerj: An Indian liberal trapped in Afghanistan appealed to PM Modi for help\n\nIndian govt rescued him.\n\nAs soon as he arrived in…',<br/> 'RT @BreitbartNews: Free Afghanistan Activist to Joe Biden: "I Regret My Vote for You" <a class="ae iu" href="https://t.co/4mnUsD8Shs'," rel="noopener ugc nofollow" target="_blank">https://t.co/4mnUsD8Shs',</a><br/> 'RT @Lowkey0nline: This is essential viewing. Unaccountable CIA backed militias, accompanied by US military in Afghanistan carrying out murd…']</span></pre><p id="99d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我选择使用Vader进行情感分析，很大程度上是因为它是为处理社交媒体数据而设计的。如果你是维达新手，我认为这篇文章是一个很好的介绍。polarity_score()函数返回传递给它的文本情感的负值、中性值、正值和复合值。为了便于访问，我获得了每条tweet的复合值，并将其作为一个新列保存在我的dataframe中。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5354" class="kc kd hi jy b fi ke kf l kg kh">from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer<br/>analyzer = SentimentIntensityAnalyzer()<br/>df['sentiment'] = [analyzer.polarity_scores(tweet)['compound'] for tweet in df['text']]</span></pre><p id="4fe2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">只是为了好玩，让我们看看我们的数据中一些最负面的推文。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="2aa3" class="kc kd hi jy b fi ke kf l kg kh">neg_tweets = df.sort_values(by='sentiment')['text'].to_list()<br/>neg_tweets[:5]</span><span id="b7a3" class="kc kd hi jy b fi ki kf l kg kh">['RT  GeorgeMonbiot  The media s lust for blood helped march us into the  disastrous wars in Afghanistan and Iraq  It wants us to forget that ',<br/> 'RT  MailOnline  US drone pilot leaks footage of his kills in Afghanistan questioning expansion of the program https   t co jX68BNwjgj',<br/> 'RT  TheOnion   Let s Take It To Our Afghanistan Experts   Says Anchor Throwing To Panel Of Dick Cheneys https   t co auVG3df5fV https   t c ',<br/> 'RT  billroggio  This is a big part of the problem  ISKP was never the major threat in Afghanistan  First threat has always been the Taliban ',<br/> 'The latest US Civil War Daily   https   t co nVLpuHLEbA Thanks to  LinnsStampNews  BurnTheTombs  galoistheory1  afghanistan  civilwar']</span></pre><p id="723b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">呀。嗜血、飞行员泄露杀戮镜头——很容易理解为什么这些被给予较低的情感分数。</p><p id="29ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了从整体上感受推文的情绪，我查看了平均分数、最低分数和最高分数。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3efd" class="kc kd hi jy b fi ke kf l kg kh">import numpy as np</span><span id="afac" class="kc kd hi jy b fi ki kf l kg kh">mean_sent = np.mean(df['sentiment'])<br/>mean_sent</span><span id="942c" class="kc kd hi jy b fi ki kf l kg kh">-0.10875000000000001</span><span id="d058" class="kc kd hi jy b fi ki kf l kg kh">print('min: ', df['sentiment'].min())<br/>print('max: ', df['sentiment'].max())</span><span id="0adf" class="kc kd hi jy b fi ki kf l kg kh">min:  -0.8555<br/>max:  0.4995</span></pre><p id="fecb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如你所见，平均分略有下降。老实说，我感到惊讶的是，考虑到主题——像“战争”、“恐怖主义”等词，它并没有降低。应该会降低分数。维达给文本的分数从-1到1，我们的最低值肯定接近下限。</p><p id="5f64" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是我对情感分析的全部想法，但我还想看看频率分布。我觉得看看是否有单词在数据中反复出现会很有趣。为此，我将我收集的tweets转换成一个列表，并开始预处理。我没有做太多，我只是删除了无用的单词(没有什么意义的单词，比如‘a’，‘the’等)，并通过一个叫做词干化的过程将单词还原到它们的词根。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8ec0" class="kc kd hi jy b fi ke kf l kg kh">import nltk<br/>nltk.download('stopwords')<br/>from nltk.corpus import stopwords</span><span id="ee0b" class="kc kd hi jy b fi ki kf l kg kh">stop = stopwords.words('english')<br/>stop.append('https')<br/>stop.append('rt')<br/>stop.append('co')<br/>words = ' '.join(df['text']).lower().split()<br/>words = [word for word in words if word not in stop and word != 'afghanistan']</span><span id="8b79" class="kc kd hi jy b fi ki kf l kg kh">from nltk.stem import PorterStemmer</span><span id="d58e" class="kc kd hi jy b fi ki kf l kg kh">stemmer = PorterStemmer()<br/>words = [stemmer.stem(word) for word in words]</span></pre><p id="92ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">之后，我使用NLTK的FreqDist()找到了最常见的单词，并绘制了结果。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="02da" class="kc kd hi jy b fi ke kf l kg kh">freqd = nltk.FreqDist(words)<br/>most_common = freqd.most_common(20)</span><span id="a17b" class="kc kd hi jy b fi ki kf l kg kh">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>most_common = pd.Series(dict(most_common))<br/>fig, ax = plt.subplots(figsize=(20, 20))<br/>most_common.plot = sns.barplot(x=most_common.index, y=most_common.values, ax=ax)<br/>ax.set(xlabel='20 Most Common Words in Tweets Concerning Afghanistan As of August 24, 2021', ylabel='Count')<br/>plt.savefig('Afghanistan Tweets Freq Dist.png')<br/>plt.show()</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kj"><img src="../Images/a7c22f86c3a6111290172ac206a79c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIH00A2DowN7lajpqxSpJA.png"/></div></div></figure><p id="eec1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">令我惊讶的是，我没有发现更多相同的单词重复出现。在“我们”之后，下一个最常见的单词最多只出现两次。列出的单词大概是你所期望的:“疏散”、“塔利班”、“战争”等等。有趣的是,“从不”和“忘记”都榜上有名。我没有检查n-grams，这是一种寻找一起出现的单词的方法，但看起来它们很可能在推特上以“永不忘记”的形式出现，这是指9/11事件。这种分析的扩展可以检查n元语法，以寻找与主题相关的常见单词对。</p><p id="a33d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">总而言之，这是一个非常粗略的分析。我只收集了某个时刻的几千条推文。阿富汗局势一直在迅速发展；这个数据没有反映出这一点。我使用的数据是来自一个社交媒体网络用户的有限时间段的小样本。这一调查结果并不意味着对正在发生的事情有更广泛的公众意见。</p><p id="2491" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">话虽如此，看看这些数据还是很有趣的。这些推文并不像我预期的那样负面，尽管情绪得分倾向于负值。我还期望从单词的频率分布中获得更多一点的洞察力。相反，似乎没有任何强有力的新兴主题。除了“我们”，没有任何有意义的词重复出现，尽管更频繁出现的词与主题相关。</p><p id="f371" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我非常喜欢做这个快速的小项目，希望你也是！如果你读到这里，感谢你花时间阅读到最后。</p></div></div>    
</body>
</html>