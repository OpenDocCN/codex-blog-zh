# Java 实现:用并行训练开发和测试神经网络的遗传算法。

> 原文：<https://medium.com/codex/a-java-implementation-genetic-algorithm-to-develop-and-test-neural-networks-with-parallel-training-7adb302d4250?source=collection_archive---------15----------------------->

这是一个能够在一篇文章中涵盖的大话题。因此，我必须假设熟悉神经网络、非常基本的遗传算法和作为面向对象语言的 Java，同时我打算更密切地关注实现。

该项目背后的想法是开发几个随机神经网络，在尽可能短的时间内并行训练它们，评估它们的适应性，并再次进入下一代。该项目收集了每一代的获胜者，通过“可训练性”因素进行评分，并在项目的远端展示他们。从这一点来看，很容易孤立任何赢家，并继续训练他们，直到理想的收敛。到目前为止，它已经被证明比手工运行和测试网络更有益。

为了演示我称为“瞬态”的结构的用法，我可能倾向于首先将其作为一个具有许多功能的小系统来介绍，如果不是作为我自己的神经网络的其他实现的有力竞争者的话。该系统被构建为并行分割网络实例，并在所有或任何可用网络上计算 I/O 和训练。这意味着大量的功能；你会问一家电视台一件事吗？一网多事？关于一件事的很多网络？许多…所以我构建了大多数访问模式，以并行和线性的方式，用于查询和训练。

索引很重要！！->我在这个实现中主要使用流，不能保证每个输入实例的每个网络的完成顺序。由于这个特殊原因，我对每个矩阵输出进行索引，以匹配生成决策的网络的索引。同样，收到的答案流很可能不会按照生成它们的网络的相应顺序进行计算。请使用你的索引。

这里的主要问题是我们如何为每个网络排列训练数据。有没有可能引导平行网络向前通过，然后进行平行的向后通过？我选择放弃这种方法，而使用简单的 fit()函数。通过同时提供查询和应答，每个并行网络可以在持续线程上托管的同时连续进行测试和训练，而不是请求将网络转移到另一个工作线程进行反向传播。那么，在用答案开始反向传播之前，如何确保网络观察到这个例子呢？通过倾向于某种程度上被忽略的编程范例，其中所列格式的对象的解析都是按照索引的顺序初始化的，即从左到右。通过打包对 Index(ed)Matrix 对象数组的调用，我确保了在同一线程上独立计算每个字段的顺序，一个在另一个之前。例如

```
return new IM[]{(input)->return proc1.start(input), (target)->return proc2.start(target)};
```

首先导致函数 proc1 的处理，这将产生网络的决策矩阵。接下来将依次处理函数 proc2，校正网络，并返回“影响”矩阵。这些列出的基本命令将用逗号分隔，将几个命令隐藏在一行中。一个例子是这两个循环的等价性:

```
//Traverses the 2D-plane in two loopsfor(int y = 0; y < 5; y ++) {
 for(int x = 0; x < 5; x ++) {
 System.out.println((“x,y”)+x + “,” + y);
 }
 }//Traverses 2D-plane in one loopfor(int x = 0, y = 0; y < 5; x ++, y += (x==5?1:0), x %= 5) {
 System.out.println((“x,y”)+x + “,” + y);
 }
```

在上面的单循环中，我们看到命令发生在每个循环的末尾。这些将从左到右处理。我们看到，我们从 x 递增 1 开始。那么我们可选地将 y 增加 1，当且仅当 x == 5。最后，我们将 x 调制 5 倍。这个方法是我如何确保网络在目标分布上训练之前看到样本的。当我们潜入时，分别在下面的 234 和 245 寻找“lFit”和“pFit”。

![](img/a0a2d1c3a9686f41b1c7e66b0bfa825c.png)![](img/a090f3186c569cfce13373ac60ce8e37.png)![](img/1c42feb99d559b58c1e6e27ec7975f6c.png)![](img/2531df78225d741b8fe674f90d544985.png)![](img/519a29becf488b7273a765a2593e8fd2.png)![](img/11fef7906fc427db5eb0bc1bfcbbe012.png)![](img/80464ba61839c6e4ec3bf56f9cce5585.png)![](img/77bcf9d1b759ff8a21dd39c1e41005a9.png)![](img/60e296e356f9b4cb07ee4fe7e0918a32.png)![](img/78053f1aad86ec6547e22ac8b1b12ad9.png)

概括一下:我们简单地设计了一个神经网络，一次运行和训练一个小批量。网络的输出将是一个流的流，其中每个内部流是每个网络对一个项目的决策。该最终流将具有与馈送到网络的小批量数量一样多的条目，并且每个内部流将具有与网络一样多的对该查询的回答。在这种情况下，小批量由矩阵中的一系列输入向量表示。此外，我们还提供了一些同时利用几个网络的功能(build()函数在给定一些特征的情况下生成这些网络)。这使我们有能力进行我所谓的“猎枪训练”，我们开发 BAGGING_CONST 数量的神经网络，并根据相同的数据训练它们。我想在这里强调，这种方法可以应用于任何神经网络的替代，这就是为什么我不打算在这篇文章中讨论网络本身的内部。一旦完成一些训练，这种结构也有三种方法对网络进行分类。首先，可以根据他们最近的表现对他们进行排序，因此，如果向他们提供一整批训练数据，他们就可以衡量他们的表现，并据此进行排序。我提供的另一种排序方法是基于一生的表现，但是将这种方法用于健康标记会产生问题。网络在它的一生中经历了多少挣扎？出于几个原因，我不会使用生命周期性能来定义网络的性能。这种方法的一个问题是，网络可能是从损失图中的一个方便点开始的，并且在接近最小值时做了很少的工作。此外，典型地，高寿命损耗和最后样本的低损耗表示非常可训练的网络，虽然它起飞慢(因此高寿命误差)，但仍然使它显著地接近最小值(低最后目标误差)。为此，我提供了基于“可训练性”的网络排序功能，这是我们的第三种排序方法。每个网络的可训练性分数通常为[-1，+1]，分数越低表示可训练性越高。通常，成功的或潜在成功的网络将显示出大约或低于-1 的可训练性。我用来计算这个的公式可以在 trainability()方法的第 403 行找到。该项目的下一步可能包括查询网络中 deltass 的严重性，以真正衡量每个 delta 的拟合程度，从而将更活跃的网络放在列表的前面。在那之前，我使用可训练性。

从网络本身出发，我将介绍我所谓的“农民”农民是几代网络的管理者。它训练每一堆网络一段时间，然后选择两个获胜者，通过轻微的突变功能将他们的遗传密码传递给下一代。在这个过程中，这位农民也在变异，并有可能与其他参与进化的网络的基因组杂交，以创造下一代。请记住，这不是这种方法的主要目标，训练网络完成。相反，它有助于创建几个独特的网络，并与上一代的获胜者进行测试，从而自动化我们的“猎枪训练”同样值得注意的是，即使是世代中的获胜者也只记录了他们的特征，并在下一次运行中重新构建和重新随机化。这确保了在几轮之间存活下来的任何网络实际上都是可在数据集上训练的，而不仅仅是比其他网络看到更多训练实例的网络。让我们看一下代码:

![](img/ef088361135b53e832b90ef36931dbf4.png)![](img/20c46a23f6a13b14ca94103c37e89a31.png)![](img/2f98bea6f462d25557c343037a645a3d.png)![](img/6d78a06949ff47f10053c675f97a100c.png)![](img/f4d7f0c6932f5c838391de2e40510cfa.png)

这个项目有很多东西我没有在这里介绍，所以我现在简要地谈一谈其中的一些。例如，DNA 类只包含一个数字数组，同时提供有用的方法，如 mateWith()和 copyPasta()。mateWith()方法获取另一条 DNA 链，并与双亲生成两个子代。这保持了种群的稳定，不像更多的生物启发方法。copyPasta()方法复制 DNA 链，同时提供轻微的突变。调用 mateWith()时也在引擎盖下使用。该项目的另一个重要方面是我从 DNA 构建的 Trait 对象，并用于绘制网络蓝图。每个特征由一个 TraitFactory 构建，并基于简单的规则来读取 DNA 的数据阵列。这些方法可能大相径庭，因此，我将它们留给您来解释。我在这篇文章中主要关注的是提供一种潜在的方法，对 Java 中的任何可替换的神经网络进行自动“猎枪训练”。可悲的是，目前的情况可能要求你现在[创建自己的神经网络](https://rwhildreth09.medium.com/bio-logical-java-implementation-of-a-neural-network-e9080f8f6b67)。狩猎愉快。:)

感谢您的阅读。