<html>
<head>
<title>Metrics to Measuring Calibration in Deep-Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中测量校准的度量</h1>
<blockquote>原文：<a href="https://medium.com/codex/metrics-to-measuring-calibration-in-deep-learning-36b0b11fe816?source=collection_archive---------1-----------------------#2021-08-03">https://medium.com/codex/metrics-to-measuring-calibration-in-deep-learning-36b0b11fe816?source=collection_archive---------1-----------------------#2021-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/608df4176239c28ee5676680c0fc2fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Lyrp6TIj4Tek7mwK"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">莉安娜·米卡在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="6e28" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在<a class="ae iu" rel="noopener" href="/codex/predicting-the-true-probability-in-neural-networks-confidence-calibration-fa6c6d712ff">之前的一篇文章</a>中，我们回顾了深度神经网络中的置信度校准问题。非正式地说，置信度校准意味着如果一个模型以90%的概率预测一个类，该类应该在90%的时间内出现。我们回顾了测量和改进校准的方法。我们还讨论了为什么深度学习通常表现出较差的校准性能。</p><p id="320c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">校准问题通常使用可靠性图来可视化，校准误差用预期校准误差来评估。最近的研究发现，这一措施是有问题的，原因有4个，并提出了衡量校准误差的替代指标。</p><p id="faea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">本帖基于论文</em> <a class="ae iu" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Uncertainty%20and%20Robustness%20in%20Deep%20Visual%20Learning/Nixon_Measuring_Calibration_in_Deep_Learning_CVPRW_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="jt">深度学习中的测量校准</em> </a></p><h2 id="5511" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">预期校准误差(ECE)</h2><p id="6bd3" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">由于校准无法直接计算，我们使用ECE等替代指标来评估网络校准。我们首先将概率区间[0，1]分成多个<em class="jt">箱</em>。ECE被计算为跨箱的准确度/预测误差的加权平均值，并根据每个箱中样本的相对数量进行加权。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/53c466afc2cbc466c18eb1ed9f0c45bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/0*xMpv8azeM4vR8g-B.png"/></div></figure><p id="c7e5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ECE通常用作标量度量来评估实验中的校准。但是本文发现，ECE作为校准的一种度量是有根本缺陷的，并且一些成功优化ECE的校准方法没有得到适当的评估。欧洲经委会的问题包括</p><p id="639d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">不计算所有预测的校准</strong> : ECE设计用于二元分类，当扩展到多类分类时，仅使用预测类的概率来测量校准。该度量固有地忽略了模型如何预测其他K-1个概率。ECC成为更差的校准度量，因为超出预测的类别预测更重要。</p><p id="ca34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">固定校准范围</strong>:ECE指标根据每个箱中样本的相对数量进行加权。因为网络预测通常非常可信，所以右侧的几个条柱对ECE的贡献最大。ECE仅关注于确保校准更有把握的样本。</p><p id="3551" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">偏差-方差权衡</strong>:箱数是一个超参数，涉及校准测量偏差和方差的权衡。较大数量的箱将改善将范围细分为低偏差测量，但是由于较少的样本被分配到每个箱中，它们将具有较高的方差。因为某些仓比其他仓更稀疏，所以这个问题与之前的固定校准范围问题相结合。</p><p id="a58b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">静态宁滨方案中的病态</strong>:显然，网络似乎可以“黑掉”ECE指标。当过度自信和欠自信预测出现在同一个仓中时，可能出现接近0的校准误差。然而，考虑到深度学习中的校准问题通常是过度自信，这似乎有点极端，也许不切实际。</p><blockquote class="kz la lb"><p id="280a" class="iv iw jt ix b iy iz ja jb jc jd je jf lc jh ji jj ld jl jm jn le jp jq jr js hb bi translated">例如，假设数据集是45%阳性的，我们可以简单地为阴性实例输出(0.41，0.43)范围内的预测，为阳性实例输出(0.47，0.49)范围内的预测，以创建一组具有1.0 AUC，0 ECE但未校准的预测。</p></blockquote><p id="7b65" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了解决ECE度量的问题，本文提出了对ECE的修改。</p><h2 id="651e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">阶级制约性</h2><p id="d895" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">我们可以分别计算每个类别的误差，然后对其进行平均，以计算最终的校准误差。这允许我们独立于模型在类别频率中的不平衡来评估类别之间的校准误差。这证明了错误，特别是当我们有一个类不平衡(一个类比另一个类太多)或者当模型预测有偏差时。</p><h2 id="3320" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">最大概率</h2><p id="2223" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">类条件性通过考虑多类输出的每个概率而不是仅一个概率来扩展ECE。它计算所有类别以及所有条块的加权平均值。这旨在解决<em class="jt">不能跨所有预测计算校准的问题。</em>它还将类别权重倾斜固定到一个最有把握的输出。等式很简单(K: # classes)。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/b43f9912196845ecdfdbfce4741871c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*htRdh1ZlEOoyDz2w9DZPOg.png"/></div></figure><h2 id="1576" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">适应性</h2><p id="e7e3" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">自适应校准范围修改箱间隔，因此每个箱包含相同数量的样本。自适应性是通过从预测精度的排序数组(N: # data，R:范围数组)中对大小为[N/R]的批次进行采样来实现的。这种自适应方案解决了<em class="jt">偏差-方差权衡问题。</em></p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/78b93871a236e6aeff8bfbf8160b60e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*f5PqyywZql_PozKkdXQEhA.png"/></div></figure><h2 id="ea9c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">标准</h2><p id="0415" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">比较准确度和置信度的标准可以被测量为L1标准|acc-conf|或L2标准sqrt((acc-conf))。众所周知，与L1常模相比，L2常模对异常值更敏感。这种选择似乎有助于校准指标的有效性。</p><h2 id="0578" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">阈值处理</h2><p id="7421" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">通过使用softmax，输出变得极小(&gt; 0，但非常小)，并且可以清除校准分数。尤其是在应用SCE时，大多数模型预测应该有一个微小的值。这类似于<em class="jt">固定校准范围</em>问题，其中置信度是偏斜的。我们可以通过只考虑阈值ε以上的预测来解决这个问题。虽然这种对小类概率的忽略可能类似于只关注最大概率，但选择小ε保证了重要的次级预测不会被拒绝。</p><h2 id="6206" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">实验(显示ECE中的缺陷)</h2><p id="f598" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">直方图宁滨和普拉特缩放等校准方法在之前的<a class="ae iu" rel="noopener" href="/codex/predicting-the-true-probability-in-neural-networks-confidence-calibration-fa6c6d712ff">文章</a>中有所描述。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/eef4cf5bca49aad7496254356530d677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPj4MZ_P0tZbYcXIICdaZg.png"/></div></div></figure><p id="d381" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为直方图宁滨实际上优化了ECE的概念，所以该方法似乎更倾向于ECE度量。上表显示直方图宁滨在ECE指标中表现更好。ECE校准误差是class条件变量的三分之一到五分之一。根据下图中绘制的每个类别的校准误差，误差在各个类别之间是不一致的。所有这些都表明ECE给了直方图宁滨不公平的优势。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es li"><img src="../Images/c2343cef117880eb30b408d902ad60ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*j9oZSkLbjCb4SownpAmNJg.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/ab537373037ea9b7bd070aff3b3dad0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1i5uG_EG326EVPhnmJZRg.png"/></div></div></figure><p id="8179" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上表比较了对ECE指标上的温度标度参数的学习目标的多次修改的效果。在“属性”目标上优化用于温度缩放的温度参数，并测量ECE。ECE似乎受到小属性的影响，而不是评估一般校准性能。例如，ECE建议优化L2范数而不是L1范数可以将Imagenet上的校准误差减半。</p><p id="f6e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ECE对箱的数量非常敏感。在实验中，测量了不同宁滨超参数的相同校准度量的等级。自适应校准度量在平均秩相关方面显著优于经典的均匀分仓度量，表明自适应宁滨方案在分仓数量方面更稳健。诸如最大问题、类条件性、阈值和L2范数之类的其他度量恶化了平均等级相关性。令人失望。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/f2fe4a6c58b7c8edd64114e9dd52c5c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GRcg_bkR86NHEo-hWWUB7w.png"/></div></div></figure><p id="0987" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上表描述了8种校准技术在32个指标上的排名。一般来说，在校准指标的排序中发现了不一致性。虽然没有明显更好或更差的技术在所有指标上都表现良好，但我们可以发现每种技术的一些有利指标。改变校准误差度量将导致关于哪种方法实现最佳校准的不同结论。很容易对后处理校准方法做出错误的结论。</p><h2 id="b5a5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">结论</h2><p id="d55a" class="pw-post-body-paragraph iv iw hi ix b iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">本文研究了用于评估校准的度量的不确定性和局限性。它使用ECE指标识别问题并对问题进行分类。我们还审查了对ECE指标的修改，以解决所指出的局限性。最后，我们讨论了用于评估校准性能的度量标准的怪异现象。</p><p id="fb2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">测量校准和评估校准的未来指标必须解决本文提出的挑战。为了在校准方面取得实际进展，我们首先需要明确定义校准。这篇论文表明，这并不像我们想象的那么容易。</p><p id="3eab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我认为深度学习的校准非常怪异，而且研究不足。这是学习算法中的一个重大缺陷，同时它是不一致的，推理也不清楚。</p></div></div>    
</body>
</html>