<html>
<head>
<title>Get them before they churn…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在他们流失之前抓住他们…</h1>
<blockquote>原文：<a href="https://medium.com/codex/get-them-before-they-churn-561ec6e98307?source=collection_archive---------14-----------------------#2021-07-07">https://medium.com/codex/get-them-before-they-churn-561ec6e98307?source=collection_archive---------14-----------------------#2021-07-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d203" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在客户真正离开你之前，如何使用数据科学来了解他们将要做什么。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/ad5a5fb0242fff8e9878367cd6d7a122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*orjV_3jcBdwFehBv.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><a class="ae jn" href="https://www.evergent.com/blog/5-strategies-to-reduce-churn-in-ott-services/" rel="noopener ugc nofollow" target="_blank"> Evergent </a>的图像属性</figcaption></figure><p id="7709" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在商业语境中,“客户流失”一词指的是某项服务的用户在使用一段时间后，出于这样或那样的原因，决定离开<a class="ae jn" href="https://www.investopedia.com/terms/c/churnrate.asp" rel="noopener ugc nofollow" target="_blank"/>的行为。</p><p id="d29c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这当然是该服务的<em class="kk">提供商</em>想要避免的事情，因此通常会投入相当大的努力来定义和实施策略，以在用户真正采取最后一步并离开之前检测出他们很可能会流失的用户。反过来，这可以成为专门营销或保留策略、特别优惠、推荐等的输入。</p><p id="6f76" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在下文中，我将记录这些步骤，并展示我正是为了这个目标进行的一项研究的结果，使用数据科学技术并利用<a class="ae jn" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>。这是我在从<a class="ae jn" href="https://www.udacity.com/" rel="noopener ugc nofollow" target="_blank"> Udacity </a>攻读<a class="ae jn" href="https://www.udacity.com/course/data-scientist-nanodegree--nd025" rel="noopener ugc nofollow" target="_blank">数据科学</a>纳米学位过程中完成的最后(顶点)项目。完整代码可在<a class="ae jn" href="https://github.com/russom/DSND-Capstone" rel="noopener ugc nofollow" target="_blank"> Git repo中获得。</a></p><h1 id="17bb" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">介绍“Sparkify”</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ld"><img src="../Images/e1464d8f3b166a3077972ebbfeeaa440.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*KAAvwwtyBsww6Bzem0fZNg.jpeg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">rawpixel.com创建的背景向量—<a class="ae jn" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank">www.freepik.com</a></figcaption></figure><p id="0f47" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">分析的数据由Udacity直接提供，旨在代表在一个名为“Sparkify”的虚构音乐流媒体服务的运营过程中收集的日志。它实际上有两种不同的“大小”:一种是有限的数据集(大约128 MB，超过280000行)，用于在本地机器上进行初步分析，另一种是完整的数据集(大约12 GB，超过2600行)，用于在集群上运行Spark进行分析。</p><p id="2d2c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">数据集的架构显示以下字段:</p><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="ace2" class="lj km hi lf b fi lk ll l lm ln">root<br/> |-- artist: string (nullable = true)<br/> |-- auth: string (nullable = true)<br/> |-- firstName: string (nullable = true)<br/> |-- gender: string (nullable = true)<br/> |-- itemInSession: long (nullable = true)<br/> |-- lastName: string (nullable = true)<br/> |-- length: double (nullable = true)<br/> |-- level: string (nullable = true)<br/> |-- location: string (nullable = true)<br/> |-- method: string (nullable = true)<br/> |-- page: string (nullable = true)<br/> |-- registration: long (nullable = true)<br/> |-- sessionId: long (nullable = true)<br/> |-- song: string (nullable = true)<br/> |-- status: long (nullable = true)<br/> |-- ts: long (nullable = true)<br/> |-- userAgent: string (nullable = true)<br/> |-- userId: string (nullable = true)</span></pre><p id="7f7a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是数据集的一行实际看起来的样子:</p><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="c948" class="lj km hi lf b fi lk ll l lm ln">Row(artist='Popol Vuh', auth='Logged In', firstName='Shlok', gender='M', itemInSession=278, lastName='Johnson', length=524.32934, level='paid', location='Dallas-Fort Worth-Arlington, TX', method='PUT', page='NextSong', registration=1533734541000, sessionId=22683, song='Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent='"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36"', userId='1749042')</span></pre><p id="6387" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了处理完整的数据集，我利用了AWS <a class="ae jn" href="https://aws.amazon.com/emr/" rel="noopener ugc nofollow" target="_blank"> EMR </a>服务。这样，我就可以运行一个由<strong class="jq hj"> 4个</strong>节点(1个主节点，3个工作节点)组成的集群，由<a class="ae jn" href="https://aws.amazon.com/blogs/aws/m5-the-next-generation-of-general-purpose-ec2-instances/" rel="noopener ugc nofollow" target="_blank"> m5.xlarge </a> EC2虚拟机组成，运行:</p><ul class=""><li id="618c" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">EMR 5.33</li><li id="affe" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">火花2.4.7</li><li id="03c1" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">李维0.7.0</li><li id="c0ad" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">蜂巢2.3.7</li><li id="a2b2" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">Jupyter企业网关2.1.0</li></ul><h1 id="30b1" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">战略和方法</h1><p id="3f7f" class="pw-post-body-paragraph jo jp hi jq b jr mc ij jt ju md im jw jx me jz ka kb mf kd ke kf mg kh ki kj hb bi translated">我试图解决这个问题的方法是建立一个分类器，根据提供的数据预测用户是否会流失。我使用了<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-classification-regression.html" rel="noopener ugc nofollow" target="_blank"> Spark </a>提供的工具，在一部分数据上训练分类器，在剩余部分上测试。</p><p id="6f3c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在真正引入分类器之前，我经历了一个广泛的数据探索阶段，这使我能够识别出一个重要特征的子集，这些特征可以有效地识别出离开的用户。</p><p id="2c5e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在那之后，我可以真正进入建模阶段。我分两步走:</p><ul class=""><li id="3bea" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">我最初训练并比较了Spark中可用的一些分类器的结果，使用了它们的默认参数，以便识别那些在分析数据集上具有更好行为的分类器；</li><li id="0dbd" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">之后，我继续进行优化阶段，在这个阶段，我可以为一些参数提供一个选项网格，并验证是否/如何改变它们可以产生更好的结果。</li></ul><h1 id="e262" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">清理和探索</h1><p id="b9a1" class="pw-post-body-paragraph jo jp hi jq b jr mc ij jt ju md im jw jx me jz ka kb mf kd ke kf mg kh ki kj hb bi translated">首先，我对数据进行了一些清理，删除了最终出现在<code class="du mh mi mj lf b">sessionId</code>、<code class="du mh mi mj lf b">userId</code>或<code class="du mh mi mj lf b">gender</code> / <code class="du mh mi mj lf b">location</code>等字段中的任何<code class="du mh mi mj lf b">NaN</code>行:这些可能是日志记录系统中的错误或缺陷造成的结果。之后，我还删除了任何剩余的空<code class="du mh mi mj lf b">userId</code>字段的行:这很可能与用户与系统的第一次交互有关。总的来说，这个过程将数据集中的行数减少了约3%。</p><p id="dae6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一旦清理了数据，我就可以分析用户查看<code class="du mh mi mj lf b">page</code>字段值的行为，这显示了他们访问的页面。例如，根据本专栏中可用的信息类型，我们可以识别实际的客户流失(查看用户何时访问<code class="du mh mi mj lf b">Cancellation Confirmation</code>页面)或服务的升级/降级(从免费到付费，反之亦然)，还可以识别用户竖起大拇指或添加好友，或看到滚动广告等事件。<br/>我们还可以参考<code class="du mh mi mj lf b">registration</code>和<code class="du mh mi mj lf b">ts</code>列，重建用户使用系统的时间。</p><p id="d050" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">之后，我可以继续将留下的用户和离开的用户分开，并在一些特定特征上比较两组用户，例如他们在服务上花费的时间:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/7a2b440580d573a2b4422f2b04a5f085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyThHtCswMeoiJGGlV1NtQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图1 —用户在服务上花费的时间</figcaption></figure><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="307b" class="lj km hi lf b fi lk ll l lm ln">------------------------------------------------<br/>Time spent statistics for users that cancelled:<br/>Mean =  69.69 ; Std. Dev. =  40.74<br/>------------------------------------------------<br/>Time spent statistics for users that stay:<br/>Mean =  86.45 ; Std. Dev. =  39.59<br/>------------------------------------------------</span></pre><p id="2d42" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">或者他们每天听的歌曲数量:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/d571465ba9f883c37c65973ca753d5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wo70hVu-0PjLTohh-rUo_Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图2-每天收听的歌曲</figcaption></figure><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="d329" class="lj km hi lf b fi lk ll l lm ln">---------------------------------------------------<br/>Songs per day statistics for users that cancelled:<br/>Mean =  33.40 ; Std. Dev. =  26.71<br/>---------------------------------------------------<br/>Songs per day statistics for users that stay:<br/>Mean =  20.21 ; Std. Dev. =  19.17<br/>---------------------------------------------------</span></pre><p id="8b5c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">他们每天“拒绝”的次数:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/cb579cc5e3e534930cb981b52e1d582c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UZ29WATZABz8p2YxcV0pcA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图3-每天给出的拇指向下</figcaption></figure><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="6423" class="lj km hi lf b fi lk ll l lm ln">--------------------------------------------------------------<br/>Thumbs down given per day statistics for users that cancelled:<br/>Mean =  0.48 ; Std. Dev. =  0.43<br/>--------------------------------------------------------------<br/>Thumbs down per day statistics for users that stay:<br/>Mean =  0.27 ; Std. Dev. =  0.29<br/>--------------------------------------------------------------</span></pre><p id="9533" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">或者他们每天添加的朋友数量:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/9f09d763ecd5fa2ec37d6fdd638634dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VU2OdJzRh8BwS5BbJAkYxQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图4 —每天添加的朋友</figcaption></figure><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="ef04" class="lj km hi lf b fi lk ll l lm ln">---------------------------------------------------------<br/>Added friend per day statistics for users that cancelled:<br/>Mean =  0.68 ; Std. Dev. =  0.61<br/>---------------------------------------------------------<br/>Added friend per day statistics for users that stay:<br/>Mean =  0.41 ; Std. Dev. =  0.44<br/>---------------------------------------------------------</span></pre><p id="0897" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><a class="ae jn" href="https://github.com/russom/DSND-Capstone" rel="noopener ugc nofollow" target="_blank">回购</a>中的<a class="ae jn" href="https://github.com/russom/DSND-Capstone/tree/main/notebooks" rel="noopener ugc nofollow" target="_blank">笔记本</a>和特定<a class="ae jn" href="https://github.com/russom/DSND-Capstone/blob/main/Capstone_writeup.md" rel="noopener ugc nofollow" target="_blank">记录</a>最好详细记录所有这些。</p><p id="9991" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我也试着从其他角度看数据:</p><ul class=""><li id="e62a" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">我从离开/留下的用户数据集中提取了一个子集，包含每个用户最近一周的数据。这个想法是为了寻找用户在离开时的不同行为模式。然而，这并没有显示出用户在搅动前的最后一周的行为与之前的行为有任何显著差异，所以我决定考虑他们的全部历史。</li><li id="40c6" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">我研究了非行为特征，比如用户的性别或位置。然而，这里也没有出现明显的模式:离开的人和留下的人在性别上一样平衡，在这两种情况下，代表性最强的州几乎相同。</li></ul><h1 id="e520" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">定义正确的特征</h1><p id="6086" class="pw-post-body-paragraph jo jp hi jq b jr mc ij jt ju md im jw jx me jz ka kb mf kd ke kf mg kh ki kj hb bi translated">在所有的清理和探索之后，我决定将建模阶段使用的训练特性考虑在内:</p><ul class=""><li id="70ea" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">每天滚动广告的数量</li><li id="2f82" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">添加的好友数量/天</li><li id="54ca" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">每天被拒绝的次数</li><li id="0898" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">每天收听的歌曲数量</li><li id="eea5" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">花费在服务上的时间</li></ul><p id="2e0d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">标签将是实际的搅动事件，特征将由<code class="du mh mi mj lf b">userId</code>分组。结果数据集格式的一个示例是:</p><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="687f" class="lj km hi lf b fi lk ll l lm ln">Row(id='100010', rolledAdvDay=1.1818181818181819, addedFriendDay=0.09090909090909091, thumbsDwnDay=0.022727272727272728, songsDay=6.113636363636363, permanence=56.0, label=0)</span></pre><h1 id="e036" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">适合模型</h1><p id="1c32" class="pw-post-body-paragraph jo jp hi jq b jr mc ij jt ju md im jw jx me jz ka kb mf kd ke kf mg kh ki kj hb bi translated">一旦准备好了特性，我就可以开始实际的建模了。我决定开始比较<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-classification-regression.html" rel="noopener ugc nofollow" target="_blank"> Spark </a>中可用的几个分类器，考虑所有这些分类器的参考参数(也就是说，我在这里没有运行任何网格优化)。我选择了:</p><ul class=""><li id="8d78" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">一个<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>分类器；</li><li id="805f" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">一个<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier" rel="noopener ugc nofollow" target="_blank">梯度提升树</a>分类器；</li><li id="3ad6" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">一个<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier" rel="noopener ugc nofollow" target="_blank">随机森林</a>分类器；</li><li id="17fc" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">一个<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine" rel="noopener ugc nofollow" target="_blank">线性支持向量</a>分类器。</li></ul><p id="927c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">就阶段而言:</p><ul class=""><li id="acb4" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">第一件事是将数据集分成训练和测试部分(注意:在这里固定种子可以确保实验的可重复性):</li></ul><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="1132" class="lj km hi lf b fi lk ll l lm ln"># 80/20 % split<br/>  train, test = df_user_logs_mod.randomSplit([0.8, 0.2], seed=42)</span></pre><ul class=""><li id="51e2" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">然后我定义了一个<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-features#vectorassembler" rel="noopener ugc nofollow" target="_blank"> VectorAssembler </a>来将所有感兴趣的特性组合到一个向量中:</li></ul><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="81ca" class="lj km hi lf b fi lk ll l lm ln"># Define VectorAssembler<br/>  assembler = VectorAssembler(inputCols=["rolledAdvDay",\<br/>                                       "addedFriendDay",\<br/>                                       "thumbsDwnDay",\<br/>                                       "songsDay",\<br/>                                       "permanence"], \<br/>                            outputCol="inputFeatures")</span></pre><ul class=""><li id="5493" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">然后我使用<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-features#minmaxscaler" rel="noopener ugc nofollow" target="_blank">最小-最大缩放器</a>缩放数据。我选择这个是因为各种特性的分布(如数据探索部分所见)非常不均匀，远不像正态分布。</li></ul><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="1a70" class="lj km hi lf b fi lk ll l lm ln"># Define Scaler<br/>  scaler = MinMaxScaler(inputCol="inputFeatures", outputCol="features")</span></pre><ul class=""><li id="15bc" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">之后，我可以引入4个<a class="ae jn" href="https://spark.apache.org/docs/latest/ml-pipeline.html" rel="noopener ugc nofollow" target="_blank">管道</a>，每个分类器一个:</li></ul><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="0c43" class="lj km hi lf b fi lk ll l lm ln"># Classifiers/Pipelines<br/><br/>  # Logistic Regression <br/>  lr = LogisticRegression()<br/>  pipeline_lr = Pipeline(stages = [assembler, scaler, lr])<br/><br/>  # Gradient-Boosted Tree classifier<br/>  gbt = GBTClassifier()<br/>  pipeline_gbt = Pipeline(stages = [assembler, scaler, gbt])<br/><br/>  # Random Forest classifier<br/>  # Note: setting the seed will ensure repeatability of the results<br/>  rf = RandomForestClassifier(seed = 42)<br/>  pipeline_rf = Pipeline(stages = [assembler, scaler, rf])<br/><br/>  # Linear Support Vector Machine classifier<br/>  lsvc = LinearSVC()<br/>  pipeline_svc = Pipeline(stages = [assembler, scaler, lsvc])</span></pre><ul class=""><li id="deeb" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">最后，我选择了一个使用<strong class="jq hj"> f1-score </strong>指标的验证器，考虑到<a class="ae jn" href="https://stats.stackexchange.com/questions/210700/how-to-choose-between-roc-auc-and-f1-score" rel="noopener ugc nofollow" target="_blank">数据的不平衡</a>(留下的用户比离开的用户多得多):</li></ul><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="2d79" class="lj km hi lf b fi lk ll l lm ln"># Evaluator - will be common for all the grids<br/>  evaluator = MulticlassClassificationEvaluator(metricName="f1")</span></pre><p id="403e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">之后，我继续拟合和评估四个分类器。在所有情况下，我使用了一个<a class="ae jn" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html" rel="noopener ugc nofollow" target="_blank">交叉验证器</a>，<strong class="jq hj">用</strong> <code class="du mh mi mj lf b"><strong class="jq hj">k = 3</strong></code>折叠数据集，以验证训练分类器相对于训练数据的健壮性。例如，对于逻辑回归模型，我有:</p><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="9627" class="lj km hi lf b fi lk ll l lm ln"># Empty parameter grid<br/>paramgrid_lr = ParamGridBuilder()\<br/>    .build()<br/><br/># Crossvalidator <br/>crossval_lr = CrossValidator(estimator = pipeline_lr, \<br/>                             estimatorParamMaps = paramgrid_lr, \<br/>                             evaluator = evaluator, \<br/>                             numFolds = 3, \<br/>                             seed = 4242)</span></pre><p id="efde" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">查看结果，我认为最有趣的事情之一是有限数据集和完整数据集之间的结果差异。</p><h2 id="9b80" class="lj km hi bd kn mo mp mq kr mr ms mt kv jx mu mv kx kb mw mx kz kf my mz lb na bi translated"><strong class="ak"> <em class="nb">有限数据集</em> </strong></h2><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="b051" class="lj km hi lf b fi lk ll l lm ln">F1-score, Logistic Regression classifier:  0.8828</span><span id="c250" class="lj km hi lf b fi nc ll l lm ln">F1-score, Gradient-Boosted Tree classifier:  0.8190</span><span id="ceda" class="lj km hi lf b fi nc ll l lm ln">F1-score, Random Forest classifier:  0.8095</span><span id="88a8" class="lj km hi lf b fi nc ll l lm ln">F1-score, Linear Support Vector Machine classifier:  0.8302</span></pre><h2 id="5e42" class="lj km hi bd kn mo mp mq kr mr ms mt kv jx mu mv kx kb mw mx kz kf my mz lb na bi translated"><strong class="ak"> <em class="nb">完整数据集</em> </strong></h2><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="c3d4" class="lj km hi lf b fi lk ll l lm ln">F1-score, Logistic Regression classifier:  0.8344</span><span id="d1cd" class="lj km hi lf b fi nc ll l lm ln">F1-score, Gradient-Boosted Tree classifier:  0.8858</span><span id="2713" class="lj km hi lf b fi nc ll l lm ln">F1-score, Random Forest classifier:  0.8798</span><span id="6dd6" class="lj km hi lf b fi nc ll l lm ln">F1-score, Linear Support Vector Machine classifier:  0.8236</span></pre><h1 id="4040" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">优化和验证</h1><p id="c1c7" class="pw-post-body-paragraph jo jp hi jq b jr mc ij jt ju md im jw jx me jz ka kb mf kd ke kf mg kh ki kj hb bi translated">一旦给分类器配备了默认参数，我就开始对<strong class="jq hj">梯度增强树</strong>和<strong class="jq hj">随机森林</strong>的情况进行优化。为了在可能对改变有影响的参数和计算负载之间寻找折衷，我定义了以下网格(注意:每个参数的第一个值是默认值):</p><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="d27f" class="lj km hi lf b fi lk ll l lm ln"># Gradient Boosted Tree <br/>  # Parameter grid<br/>  paramgrid_gbt_o = ParamGridBuilder()\<br/>      .addGrid(gbt.stepSize, [0.1, 0.25, 0.5])\<br/>     .addGrid(gbt.maxIter, [20, 40, 60])\<br/>     .build()</span><span id="0175" class="lj km hi lf b fi nc ll l lm ln"># Random Forest<br/>  # Parameter grid<br/>  paramgrid_rf_o = ParamGridBuilder()\<br/>      .addGrid(rf.impurity, ['entropy', 'gini'])\<br/>     .addGrid(rf.maxDepth, [5, 10])\<br/>     .addGrid(rf.numTrees, [20, 40])\<br/>     .build()</span></pre><p id="67fb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">分数有所提高:</p><h2 id="27b1" class="lj km hi bd kn mo mp mq kr mr ms mt kv jx mu mv kx kb mw mx kz kf my mz lb na bi translated"><em class="nb">有限的数据集</em></h2><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="048a" class="lj km hi lf b fi lk ll l lm ln">F1-score, Gradient-Boosted Tree classifier:  0.8401</span><span id="49bc" class="lj km hi lf b fi nc ll l lm ln">F1-score, Random Forest classifier:  0.8302</span></pre><h2 id="1b14" class="lj km hi bd kn mo mp mq kr mr ms mt kv jx mu mv kx kb mw mx kz kf my mz lb na bi translated"><em class="nb">完整数据集</em></h2><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="5fb8" class="lj km hi lf b fi lk ll l lm ln">F1-score, Gradient-Boosted Tree classifier:  0.8858</span><span id="0650" class="lj km hi lf b fi nc ll l lm ln">F1-score, Random Forest classifier:  0.8850</span></pre><p id="a6e4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">评估参数相对于默认值改变了多少是很有趣的。<br/>查看完整的数据集案例(即具有更好分数的案例)，可以验证梯度增强的树分类器，即使仍然是最好的一个，实际上仍然保留了默认参数(详情请参见<a class="ae jn" href="https://github.com/russom/DSND-Capstone" rel="noopener ugc nofollow" target="_blank"> repo </a>中的<a class="ae jn" href="https://github.com/russom/DSND-Capstone/blob/main/notebooks/Sparkify-project-EMR.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>),而对于随机森林案例，我们有:</p><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="5b18" class="lj km hi lf b fi lk ll l lm ln">name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'<br/>name='maxDepth', doc='Maximum depth of the tree. (Nonnegative) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10<br/>name='numTrees', doc='Number of trees to train (at least 1)'): 40</span></pre><p id="83c0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，我们可以看到影响参数似乎是<code class="du mh mi mj lf b">maxDepth</code>和<code class="du mh mi mj lf b">numTrees</code>，它们移动到所提供的最大值。当然，这种评估总是一种权衡:进一步增加任何一项都可以提高分数，但肯定会增加计算量。</p><p id="ec5a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有了为最佳模型确定的最佳参数组合，我们还可以比较f1分数对于<code class="du mh mi mj lf b">CrossValidator</code>定义的每个折叠如何/是否变化。如前所述，度量的稳定性将是分类器相对于训练数据的鲁棒性的指示。</p><p id="4d1f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这里，我们也可以看到数据集之间的差异:</p><h2 id="9935" class="lj km hi bd kn mo mp mq kr mr ms mt kv jx mu mv kx kb mw mx kz kf my mz lb na bi translated">有限数据集</h2><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="9a43" class="lj km hi lf b fi lk ll l lm ln">Fold:  0 ; F1-score, Gradient-Boosted Tree classifier:  0.8613<br/>Fold:  1 ; F1-score, Gradient-Boosted Tree classifier:  0.7891<br/>Fold:  2 ; F1-score, Gradient-Boosted Tree classifier:  0.7523</span><span id="0551" class="lj km hi lf b fi nc ll l lm ln">Fold:  0 ; F1-score, Random Forest classifier:  0.8571<br/>Fold:  1 ; F1-score, Random Forest classifier:  0.7523<br/>Fold:  2 ; F1-score, Random Forest classifier:  0.7944</span></pre><h2 id="2a3d" class="lj km hi bd kn mo mp mq kr mr ms mt kv jx mu mv kx kb mw mx kz kf my mz lb na bi translated">完整数据集</h2><pre class="iy iz ja jb fd le lf lg lh aw li bi"><span id="81fc" class="lj km hi lf b fi lk ll l lm ln">Fold:  0 ; F1-score, Gradient-Boosted Tree classifier:  0.8854<br/>Fold:  1 ; F1-score, Gradient-Boosted Tree classifier:  0.8847<br/>Fold:  2 ; F1-score, Gradient-Boosted Tree classifier:  0.8834</span><span id="c823" class="lj km hi lf b fi nc ll l lm ln">Fold:  0 ; F1-score, Random Forest classifier:  0.8771<br/>Fold:  1 ; F1-score, Random Forest classifier:  0.8798<br/>Fold:  2 ; F1-score, Random Forest classifier:  0.8823</span></pre><p id="51ad" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">显而易见，更丰富的数据集如何提供更好的训练，从而为两个分类器带来非常稳定的度量。</p><h1 id="afc2" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">结果和结论</h1><p id="1e0e" class="pw-post-body-paragraph jo jp hi jq b jr mc ij jt ju md im jw jx me jz ka kb mf kd ke kf mg kh ki kj hb bi translated">在这个项目中，我展示了训练一个分类器的可能性，该分类器基于可用的信息来预测“Sparkify”服务的用户是否会以由<strong class="jq hj"> f1-score &gt; 0.8 </strong>测量的性能水平“搅动”。</p><p id="ca1f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">具体来说，我可以比较和对比几个分类器，既可以针对有限的数据集(~128 MB，超过280000行)，也可以针对完整的数据集(~12 GB，超过2600万行)。<br/>参考指标是f1得分，考虑到数据中的不平衡，有更多的用户留下来离开，最好的得分分类器是<strong class="jq hj">梯度提升树</strong>，它可以针对完整的数据集实现大约0.886的最终<strong class="jq hj"> f1得分</strong>。<br/>这种分类器不仅优于其他分类器(包括随机森林分类器，即使是轻微的)，而且还提供了稳健的结果，当用k倍交叉验证器评估时，其度量没有太大变化。<br/>此外，我在分类器上运行了一个网格优化过程，没有对默认参数产生任何变化。然而，应该注意的是，网格被定义为探索空间的大小和计算负担之间的折衷，因此它并不打算是详尽的。</p><p id="d0bf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在体验过程中，我发现了一些特别有趣的事情:</p><ul class=""><li id="15f2" class="lo lp hi jq b jr js ju jv jx lq kb lr kf ls kj lt lu lv lw bi translated">首先，一般说数据科学的大部分时间都花在做数据探索和特性工程上是绝对正确的。我可以说，我在这个项目上至少花了75%的时间在这两个阶段，可能还会更多。</li><li id="9804" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">实际的建模阶段强调了完整数据集与有限数据集之间的差异和附加值。事实上，虽然在对有限数据进行拟合时，一些分类器(逻辑回归和SVC)比其他分类器得分更高，但当对完整数据集进行评估时，位置发生了变化。在这种情况下，像梯度增强树和随机森林这样的集成技术在相对和绝对意义上都取得了更好的成绩，正如人们可能已经预料到的那样。</li><li id="9f69" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">通过网格优化阶段可以进一步改进结果，例如，改变随机森林分类器相对于完整数据集的结果，从0.8798的f1分数变为0.8850的分数。一般来说，探索分类器的参数空间以获得更好的分数肯定是进一步改进的可能选择。</li><li id="b922" class="lo lp hi jq b jr lx ju ly jx lz kb ma kf mb kj lt lu lv lw bi translated">当运行k倍交叉验证分析时，数据集之间的差异甚至起了更大的作用:在这种情况下，有限的数据集明显显示出不太稳定的度量，因此分类器对于数据不是特别稳健。</li></ul></div></div>    
</body>
</html>