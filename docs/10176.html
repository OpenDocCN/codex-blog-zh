<html>
<head>
<title>Skew No More: Creative Ways to Optimize Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不再偏斜:优化Apache Spark的创造性方法</h1>
<blockquote>原文：<a href="https://medium.com/codex/skew-no-more-creative-ways-to-optimize-apache-spark-b39860cc7ac2?source=collection_archive---------5-----------------------#2022-12-10">https://medium.com/codex/skew-no-more-creative-ways-to-optimize-apache-spark-b39860cc7ac2?source=collection_archive---------5-----------------------#2022-12-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/39bfca3c4837d081a323f5f848bfe6d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s3NoaDYk8fHuSoS_WZngDg@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由杰克逊在Unsplash煨</figcaption></figure><p id="1e02" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">不对称是分布式系统中的一个常见问题，它会对Apache Spark应用程序的性能和效率产生重大影响。当少数任务或执行者接收到不成比例的数据量或工作量，导致他们比其他任务花费更长的时间来完成时，就会发生偏斜。这可能导致瓶颈、不均衡的资源利用率和次优的性能。</p><p id="c0b0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">有几种方法可以优化Apache Spark中的skew，最佳方法取决于应用程序和数据的具体细节。处理不对称的一些常见策略包括:</p><p id="a415" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对数据进行分区:处理不对称最有效的方法之一是对数据进行分区，在任务和执行者之间平均分配工作负载。在Apache Spark中，可以使用哈希分区、范围分区和自定义分区等方法对数据进行分区。例如，以下代码使用partitionBy方法根据特定列中的值对DataFrame进行分区:</p><pre class="js jt ju jv fd jw jx jy bn jz ka bi"><span id="da9f" class="kb kc hi jx b be kd ke l kf kg">val df = spark.read.csv(“/path/to/data.csv”)<br/><br/>val dfWithPartitions = df.repartition(8, $”columnName”)</span></pre><p id="468a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用联合和重新分区:联合和重新分区方法可用于减少或增加数据帧中的分区数量。这些方法对于处理不对称非常有用，因为它们有助于在任务和执行器之间均匀地分布数据。例如，以下代码使用repartition方法将数据帧中的分区数量增加到16:</p><pre class="js jt ju jv fd jw jx jy bn jz ka bi"><span id="7143" class="kb kc hi jx b be kd ke l kf kg">val df = spark.read.csv(“/path/to/data.csv”)<br/><br/>val dfWithMorePartitions = df.repartition(16)</span></pre><p id="27f0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用专门的算法:有些算法和操作比其他算法和操作对倾斜更敏感。例如，reduce-by-key操作中的reduce操作可能对skew特别敏感，因为它组合了所有分区的结果。在这些情况下，使用专门设计的算法来更有效地处理偏斜会很有帮助。例如，sortByKey方法可用于按键对数据进行排序，这有助于减少不对称对reduce操作的影响。以下代码显示了使用sortByKey方法按特定列中的值对DataFrame进行排序的示例:</p><pre class="js jt ju jv fd jw jx jy bn jz ka bi"><span id="fd96" class="kb kc hi jx b be kd ke l kf kg">val df = spark.read.csv(“/path/to/data.csv”)<br/><br/>val dfSortedByKey = df.sortByKey($”columnName”)</span></pre><p id="1040" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用缓存和广播:缓存和广播对于处理不对称非常有用，因为它们有助于减少在任务和执行器之间被混洗和传输的数据量。缓存可用于将数据存储在内存中，因此任务可以快速访问这些数据。广播可用于向每个执行者发送数据的副本，因此不必通过网络进行混洗和传输。例如，以下代码显示了如何使用缓存和广播方法来优化Spark应用程序:</p><pre class="js jt ju jv fd jw jx jy bn jz ka bi"><span id="9300" class="kb kc hi jx b be kd ke l kf kg">val df = spark.read.csv(“/path/to/data.csv”)<br/><br/>val dfCached = df.cache()<br/><br/>val broadcastVar = spark.sparkContext.broadcast(dfCached)</span></pre><p id="930f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">总之，数据倾斜是Apache Spark中的一个常见问题，它会影响分布式应用程序的性能。为了优化Apache Spark中的不对称，可以使用诸如重新分区、定制分区、数据采样和数据压缩等技术。您还可以使用shuffle服务、缓存和持久性等工具和策略来提高数据洗牌和分区的效率和性能。通过应用这些技术和工具，您可以有效地解决Apache Spark中的数据不对称问题，并提高应用程序的性能。</p><blockquote class="kh ki kj"><p id="55f4" class="iu iv kk iw b ix iy iz ja jb jc jd je kl jg jh ji km jk jl jm kn jo jp jq jr hb bi translated">请关注我，了解关于数据工程和数据科学的最新消息:<a class="ko kp ge" href="https://medium.com/u/1578151e227b?source=post_page-----b39860cc7ac2--------------------------------" rel="noopener" target="_blank"> Paul Scalli </a></p></blockquote></div></div>    
</body>
</html>