<html>
<head>
<title>Recognizing Handwritten Digits with Scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Scikit-learn识别手写数字</h1>
<blockquote>原文：<a href="https://medium.com/codex/recognizing-handwritten-digits-with-scikit-learn-90ca6e2471ed?source=collection_archive---------1-----------------------#2021-02-23">https://medium.com/codex/recognizing-handwritten-digits-with-scikit-learn-90ca6e2471ed?source=collection_archive---------1-----------------------#2021-02-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/36c300284b7ba9d744b9f93f66c33a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkqc68a6b7_TLALs5fmI6A.png"/></div></div></figure><p id="b07f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">识别手写文本是一个问题，可以追溯到需要识别手写文档中的单个字符的第一台自动机器。例如，想想邮局信件上的邮政编码以及识别这五个数字所需的自动化。为了自动有效地分拣邮件，对这些代码的准确识别是必要的。可能想到的其他应用包括OCR(光学字符识别)软件。OCR软件必须读取手写文本或印刷书籍的页面，用于每个字符都有明确定义的普通电子文档</p><blockquote class="jo jp jq"><p id="5c89" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">假设:</strong></p></blockquote><p id="6164" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Scikit-learn库的Digits数据集提供了许多数据集，可用于测试数据分析和结果预测的许多问题。一些科学家声称它95%的时候都能准确预测数字。进行数据分析来接受或拒绝这个假设。</p><blockquote class="jo jp jq"><p id="23af" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">先决条件:</strong></p></blockquote><p id="bf92" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Sklearn</p><p id="a683" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Matplotlib</p><p id="743c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">机器学习基础</p><blockquote class="jo jp jq"><p id="1580" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">数据集:</strong></p></blockquote><p id="82fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个项目中，我们使用sklearn库中已经准备好的手写数字数据集。我们可以使用下面的代码导入数据集。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="881a" class="ke kf hi ka b fi kg kh l ki kj">from sklearn import datasets<br/>digits = datasets.load_digits()</span></pre><p id="f9b7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Digits数据集是一个字典，包含数据、目标、图像、特征名称、数据集描述、目标名称等。</p><p id="e4a4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们主要关注数据和目标。我们在不同的变量上提取两者。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="f504" class="ke kf hi ka b fi kg kh l ki kj">main_data = digits['data']<br/>targets = digits['target']</span></pre><p id="14b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们可以看到我们的数据。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="6a0b" class="ke kf hi ka b fi kg kh l ki kj">def view_digit(index):<br/>    plt.imshow(digits.images[index] , cmap = plt.cm.gray_r , interpolation = 'nearest')<br/>    plt.title('Orignal it is: '+ str(digits.target[index]))<br/>    plt.show()</span><span id="dd7e" class="ke kf hi ka b fi kk kh l ki kj">view_digit(17)</span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es kl"><img src="../Images/31b4786c027becebe1cc2c605b7230f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*v_-cBNcW3YwCedZGcJevAQ.png"/></div><figcaption class="km kn et er es ko kp bd b be z dx translated">手写数字数据集</figcaption></figure><blockquote class="jo jp jq"><p id="1040" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">模型规划:</strong></p></blockquote><p id="1fd4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了了解不同的模型如何处理不同的数据量，我们使用了3种模型:支持向量分类器、决策树分类器和随机森林分类器。</p><ol class=""><li id="fa84" class="kq kr hi is b it iu ix iy jb ks jf kt jj ku jn kv kw kx ky bi translated"><strong class="is hj">支持向量分类器:</strong></li></ol><p id="7020" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">支持向量机算法的目标是在N维空间(N-特征的数量)中找到一个超平面，该超平面清楚地分类数据点。<a class="ae kz" href="https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47" rel="noopener" target="_blank">更多… </a></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/243c5b425d60a9f535c1cd1bcf374111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xtGPAYCEIhMK4Vt93cAWKw.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">学分:-<a class="ae kz" href="https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47" rel="noopener" target="_blank">https://towards data science . com/support-vector-machine-introduction-to-machine-learning-algorithms-934 a 444 FCA 47</a></figcaption></figure><p id="4db2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jr">代码:</em> </strong></p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="bcd5" class="ke kf hi ka b fi kg kh l ki kj"># import the SVC<br/>from sklearn import svm<br/>svc = svm.SVC(gamma=0.001 , C = 100.) <br/># gamma and C are hyperparameters</span><span id="8aa0" class="ke kf hi ka b fi kk kh l ki kj"># Training data = 1790 , Validation data = 6<br/>svc.fit(main_data[:1790] , targets[:1790])</span><span id="a567" class="ke kf hi ka b fi kk kh l ki kj"># predict on test data<br/>predictions = svc.predict(main_data[1791:])</span><span id="88cc" class="ke kf hi ka b fi kk kh l ki kj"># check the result <br/>predictions , targets[1791:] </span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/8c84b467f5cf3dcec364ba698d87dd1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YjKlOhNqgskXgrWxpmaGCQ.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">SVC输出</figcaption></figure><p id="e856" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们可以看到的，我们使用非常多的数据进行训练，使用非常少的数据进行训练，支持向量分类器在数据方面做得非常好，我们在测试数据上获得了100 %的准确性。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/43a25e10066c05b67fe1438e085ed3b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*_n6CTdW6bxclrDioMecETg.jpeg"/></div></figure><p id="02f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。决策树分类器:</strong></p><p id="809a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">决策树分类器是一种简单而广泛使用的分类技术。它应用一种简单的思想来解决分类问题。决策树分类器提出了一系列关于测试记录属性的精心制作的问题。每次它收到一个回答，都会询问后续问题，直到得出关于记录的类标签的结论。</p><p id="5ec8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kz" href="http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/lguo/decisionTree.html" rel="noopener ugc nofollow" target="_blank">关于决策树的更多详细信息… </a></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/2fbdf87b8482035721b3a0b6a09c2d10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SB64Wb6caDW3Ovp7aijrIQ.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">演职员表:-<a class="ae kz" href="http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/lguo/decisionTree.html" rel="noopener ugc nofollow" target="_blank">http://mines . human oriented . com/classes/2010/fall/csci 568/portfolio _ exports/lguo/decision tree . html</a></figcaption></figure><p id="2b7a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jr">代号:</em> </strong></p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="beac" class="ke kf hi ka b fi kg kh l ki kj"># import the Classifier<br/>from sklearn.tree import DecisionTreeClassifier</span><span id="f098" class="ke kf hi ka b fi kk kh l ki kj"># Instanciate Model<br/># we can also use criterion = 'entropy' both lead us to nearly same <br/># result</span><span id="6dac" class="ke kf hi ka b fi kk kh l ki kj">dt = DecisionTreeClassifier(criterion = 'gini') </span><span id="fc6e" class="ke kf hi ka b fi kk kh l ki kj"># fit the data on model<br/># Training Set = 1600 , Validation Set = 197<br/>dt.fit(main_data[:1600] , targets[:1600])</span><span id="0fe0" class="ke kf hi ka b fi kk kh l ki kj"># prediction on test data<br/>predictions2 = dt.predict(main_data[1601:])</span><span id="6d25" class="ke kf hi ka b fi kk kh l ki kj"># We use classification materics as accuracy_score<br/># import accuracy_score<br/>from sklearn.metrics import accuracy_score</span><span id="f038" class="ke kf hi ka b fi kk kh l ki kj">accuracy_score(targets[1601:] , predictions2)</span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/1818427b3ba59b5544bd6e22fb5cd428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DsM3cDQfbpVYTFtnSf4yiw.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">决策树分类器的准确性</figcaption></figure><p id="5659" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，这一次，我们使用不同大小的训练数据和验证数据。正如我们所看到的，决策树分类器在数据上表现不佳。我们可以通过微调DTC的超参数来提高精度。</p><p id="d715" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">决策树分类器的超参数</a></p><p id="7d8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。随机森林分类器:</strong></p><p id="36fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随机森林是一种监督学习算法。它既可以用于分类，也可以用于回归。也是最灵活易用的算法。森林是由树木组成的。据说树越多，森林就越健壮。随机森林在随机选择的数据样本上创建决策树，从每棵树中获得一个预测，并通过投票的方式选择最佳解决方案。它也为特性的重要性提供了一个很好的指示器。</p><p id="930a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kz" href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python" rel="noopener ugc nofollow" target="_blank">更多关于随机森林… </a></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/153a03e0a84d2bea75c19ca82bf47398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37ZjVjDaXd7pFP1icprhqQ.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">演职员表:-<a class="ae kz" href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python" rel="noopener ugc nofollow" target="_blank">https://www . data camp . com/community/tutorials/random-forests-classifier-python</a></figcaption></figure><p id="f096" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jr">代码:</em> </strong></p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="6426" class="ke kf hi ka b fi kg kh l ki kj">from sklearn.ensemble import RandomForestClassifier</span><span id="b848" class="ke kf hi ka b fi kk kh l ki kj"># n_estimators hyperparameters( default 100 )<br/>rc = RandomForestClassifier(n_estimators = 150)</span><span id="0098" class="ke kf hi ka b fi kk kh l ki kj"># Training Data = 1500 , Validation data = 297<br/>rc.fit(main_data[:1500] , targets[:1500])</span><span id="5bad" class="ke kf hi ka b fi kk kh l ki kj">predictions3 = rc.predict(main_data[1501:])</span><span id="c1a5" class="ke kf hi ka b fi kk kh l ki kj">accuracy_score(targets[1501:] , predictions3)</span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/991d75fb4594572750255cf886c0336f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*LAZSh_NnNgQ77Eqy_HExBw.jpeg"/></div><figcaption class="km kn et er es ko kp bd b be z dx translated">准确度分数随机森林</figcaption></figure><p id="9e37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们所看到的，与决策树和支持向量相比，随机森林在使用较少数据的情况下表现出色。我们用随机森林分类器得到了92 %的准确率。</p><blockquote class="jo jp jq"><p id="a955" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">结论:</strong></p></blockquote><p id="233d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据我们的假设，我们可以说，通过使用不同的机器学习模型或使用更多的数据来调整超参数，我们可以在手写数据集上实现近95%的准确率。但要确保我们也有大量的测试数据，否则模型会过拟合。</p><blockquote class="jo jp jq"><p id="4127" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">代码:</strong></p></blockquote><div class="lh li ez fb lj lk"><a href="https://github.com/manthan89-py/Recognizing-Handwritten-Digits-with-scikit-learn" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hj fi z dy lp ea eb lq ed ef hh bi translated">man than 89-py/识别-手写数字-带scikit-learn</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">用Scikit Learn预测手写数字。有助于…</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">github.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly io lk"/></div></div></a></div><blockquote class="jo jp jq"><p id="e450" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">联系我:</strong></p></blockquote><p id="6361" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">T3】Github:T5】</strong></p><div class="lh li ez fb lj lk"><a href="https://github.com/manthan89-py" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hj fi z dy lp ea eb lq ed ef hh bi translated">manthan89-py -概述</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">对AI、深度学习、机器学习、计算机视觉、区块链、Flutter感兴趣😇。做一些竞争性的…</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">github.com</p></div></div><div class="lt l"><div class="lz l lv lw lx lt ly io lk"/></div></div></a></div><p id="ff8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jr">博客:</em> </strong></p><div class="lh li ez fb lj lk"><a href="https://manthan-bhikadiya.medium.com/" rel="noopener follow" target="_blank"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hj fi z dy lp ea eb lq ed ef hh bi translated">曼丹·比卡第亚·🖋-中等</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">机器学习、深度学习、人工智能是未来。我们几乎在每个领域都使用这些技术…</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">manthan-bhikadiya.medium.com</p></div></div><div class="lt l"><div class="ma l lv lw lx lt ly io lk"/></div></div></a></div><p id="9a72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jr">领英:</em> </strong></p><div class="lh li ez fb lj lk"><a href="https://www.linkedin.com/in/manthanbhikadiya" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hj fi z dy lp ea eb lq ed ef hh bi translated">印度古吉拉特邦苏拉特曼丹·比卡第亚-查罗特科技大学|…</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">查看Manthan Bhikadiya在世界上最大的职业社区LinkedIn上的个人资料。Manthan有一份工作列在…</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">www.linkedin.com</p></div></div></div></a></div><blockquote class="jo jp jq"><p id="73fd" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">最终注释:</strong></p></blockquote><p id="a4dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">感谢阅读！如果你喜欢这篇文章，请点击</strong>👏尽可能多次按下按钮。这将意味着很多，并鼓励我继续分享我的知识。</p></div></div>    
</body>
</html>