<html>
<head>
<title>An intuitive journey to Object Detection through Human Vision, Computer Vision and CNN’s</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过人类视觉、计算机视觉和CNN的直观的目标探测之旅</h1>
<blockquote>原文：<a href="https://medium.com/codex/an-intuitive-journey-to-object-detection-through-human-vision-computer-vision-and-cnns-58d15ac6578c?source=collection_archive---------9-----------------------#2021-08-15">https://medium.com/codex/an-intuitive-journey-to-object-detection-through-human-vision-computer-vision-and-cnns-58d15ac6578c?source=collection_archive---------9-----------------------#2021-08-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="3f4e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">为什么是计算机视觉(CV)？</strong></h1><p id="b4cf" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">下一次，当你在拍你那张漂亮的自拍照时，或者当你坐在你崭新的特斯拉车里时，或者当你被跳着<a class="ae kb" href="https://www.youtube.com/watch?v=fn3KWM1kuAw" rel="noopener ugc nofollow" target="_blank">舞的机器人惊呆时，你爱我吗？</a>’，CV是它的核心。这些应用进一步扩展到面部检测和识别，比训练有素的医生更好地从扫描和X射线中识别乳腺癌、皮肤癌和新冠肺炎。</p><h1 id="e2b4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">人类视觉</strong></h1><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/f30ea848a78635907d21e1473cc7da4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Q0kW0nC-A5PEcsLSYigDeA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">礼貌:<a class="ae kb" href="https://www.pexels.com/" rel="noopener ugc nofollow" target="_blank">https://www.pexels.com/</a></figcaption></figure><p id="f4ef" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">快速浏览一下这张照片，你看到了什么？可能是一群来自大学的朋友，在一个新的国家，在火车站或汽车站，试图弄清楚他们下一个目的地的时间表。我们的大脑用不到一秒钟的时间为我们提供如此多的信息，这些信息在这里是不明确的。</p><p id="6601" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">这怎么可能呢？由于数百万年的进化，我们所有人都有幸拥有地球上最复杂的系统之一，即拥有800亿神经元的人脑。在我们大脑不断处理和整合的5种感觉中，超过一半的处理能力只用于一种感觉，即视觉。</p><h1 id="4562" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">人类如何看？</strong></h1><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kt"><img src="../Images/31239f47cb7bef1206d1eb9d68a32099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*4thlzeFRbKWFmzE3mKyN9w.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated"><a class="ae kb" href="http://www.blogs.paulesbarakaldo.com/lh4/files/2018/02/1.-Presentacion-3%C2%BA.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="66bb" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">一切都与光有关。光从一个物体上反射，如果这个物体在你的视野中，它就会进入眼睛(1，2，3)</p><p id="0a0f" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">当光线照射到视网膜(眼睛后部的一层感光组织)时，称为感光细胞的特殊细胞将光线转化为电信号(4，5)。这些电信号从视网膜通过<strong class="jf hj">视神经</strong> <strong class="jf hj">神经</strong>传到大脑。然后大脑将这些信号转化成你看到的图像</p><h1 id="c430" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">分等级的人类视觉</strong></h1><p id="2965" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">两位神经生理学家David Hubel和Torsten Wiesel在1959年发表了人类/动物视觉领域最有影响力的论文之一，该论文也启发了计算机视觉。他们发表的题为“<a class="ae kb" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1363130/" rel="noopener ugc nofollow" target="_blank"> <em class="ku">猫纹状皮层单个神经元的感受野</em> </a> <em class="ku">”的论文，重点研究了猫大脑中的视觉神经元如何对各种形状做出反应。</em></p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kv"><img src="../Images/7c3f6b9ad4e0b9617356476d6c5e46ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*3XAIu2yF-SfBvhnLXY2YgA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">来源:<a class="ae kb" href="https://goodpsychology.wordpress.com/2013/03/13/235/" rel="noopener ugc nofollow" target="_blank">https://goodpsychology.wordpress.com/2013/03/13/235/</a></figcaption></figure><p id="914b" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">他们将电极放入麻醉猫大脑的初级视觉皮层区域，在给动物展示各种图像的同时，观察或至少试图观察该区域的神经元活动。研究人员通过他们的实验确定，<strong class="jf hj">在初级视觉皮层中有简单和复杂的神经元</strong>和<strong class="jf hj">视觉处理总是从简单的结构开始，如定向边缘。</strong></p><p id="17db" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">1982年，英国神经学家大卫·马尔(David Marr)发表了另一篇颇具影响力的论文——《<a class="ae kb" href="https://mechanism.ucsd.edu/teaching/f18/David_Marr_Vision_A_Computational_Investigation_into_the_Human_Representation_and_Processing_of_Visual_Information.chapter1.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ku">视觉:对视觉信息</em> </a> <em class="ku">的人类表征和处理的计算研究》。<br/> </em>基于Hubel和Wiesel的想法(他们发现视觉处理<strong class="jf hj">总是从简单的结构开始，比如定向边。</strong>)，大卫给了我们下一个重要的洞见:<strong class="jf hj">他确立了视觉是分等级的</strong>。他认为，视觉系统的主要功能是创建环境的3D表示，以便我们可以与之互动。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kw"><img src="../Images/399399aa1ddd03f18921362f2eebe2c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*7kaCnC1g-JAzmRrhwuD2sQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">女装:<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/</a></figcaption></figure><p id="fde4" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><em class="ku">他引入了一个视觉框架，其中包含检测边缘、曲线、拐角等的低级算法。，用作对视觉数据的高级理解的垫脚石。</em></p><p id="2a25" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">David Marr的代表性愿景框架包括:</p><ul class=""><li id="bc21" class="kx ky hi jf b jg ko jk kp jo kz js la jw lb ka lc ld le lf bi translated">图像的原始草图，包括边缘、线条、边界等。，都有代表(这显然是受了Hubel和Wiesel的研究启发)。</li><li id="ed27" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">一种2 D草图表示，其中表面、关于深度的信息和图像上的不连续性被拼凑在一起。</li><li id="60c4" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">根据表面和体积图元分层组织的3D模型。</li></ul><p id="87ed" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">将这一理论映射到实际的大脑中，你看到的初级视觉皮层在大脑后部的绿色区域中表示为v1，它是进行图像处理的第一层，从边缘检测开始。随后的层聚集来自V1的信息，并执行逐渐复杂的任务，以实现视觉的最终目标。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ll"><img src="../Images/a86d9d22c02545540faa9fbc29ca2f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*G4jQ_0lfdhCljk1FET3VbA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">来源:<a class="ae kb" href="https://figshare.com/articles/dataset/Ventral_visual_stream/106794" rel="noopener ugc nofollow" target="_blank">https://fig share . com/articles/dataset/腹侧_visual_stream/106794 </a></figcaption></figure><h1 id="86bf" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">计算机视觉</strong></h1><p id="8f4a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">让我们换个话题，转到今天的主题“计算机视觉”，我们的重点是计算机识别图像中物体的能力，这就是通常所说的“分类问题”，即给定的图像是猫还是狗？</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lm"><img src="../Images/a0e8701691a9545b1b9e0350f61d246b.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*06cfOc0g0BCK3usSC55QTQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated"><a class="ae kb" href="https://worldcatcomedy.com/omg-so-cute-cats-%E2%99%A5-best-funny-cat-videos-2021-74/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="498a" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">虽然这个问题看起来是一个基本的图像分类练习，但它是计算机视觉中复杂任务的最基本的构建块之一，如下所示。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/4c87491904dac73d9d0d99402c2c131b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*aZwq7yN_XqtaQaZJY_AcbA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">http://cs231n.stanford.edu/<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><h1 id="03f3" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">电脑怎么看？</strong></h1><p id="4c91" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">人类视物体为物体反射的光，而计算机视图像为数字。</p><p id="681e" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">下面是存储亚伯拉罕·林肯图像的灰度图像缓冲区的简单说明。每个像素的亮度由一个8位数字表示，其范围从0(黑色)到255(白色)</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/2e544fe5624180b2950673981dccb00c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*MaVXz1BtffYKDUgOuG7ftw.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">礼貌用语:<a class="ae kb" href="http://introtodeeplearning.com/" rel="noopener ugc nofollow" target="_blank">http://introtodeeplearning.com/</a>(麻省理工学院)</figcaption></figure><p id="4923" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">这应该给了你一个很好的想法，关于我们如何解决图像分类的问题。如果你有一个与猫图像(猫A)等价的数字，那么对于一个呈现的新图像(图像A)，如果我们将其数字表示与猫A进行比较，如果发现数字相似，那么图像A也应该有一只猫，对吗？</p><p id="b166" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">这正是早期CV算法的工作原理，该算法被命名为“<a class="ae kb" href="https://yearsofnolight.medium.com/intro-to-image-classification-with-knn-987bc112f0c2" rel="noopener">K-最近邻</a>”算法。在名为<a class="ae kb" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10数据集</a>的标准化图像分类测试数据集上，这被发现有38.6%的有效性。该数据集由60，000幅32像素高和32像素宽的微小图像组成。每幅图像被标记为10类中的一类(例如<em class="ku">“飞机、汽车、鸟等”</em>)。这60，000幅图像被分成50，000幅图像的训练集和10，000幅图像的测试集。</p><p id="15be" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">在下面左侧的图片中，您可以看到10个随机示例图片，分别来自10个类别:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ln"><img src="../Images/b33fca957b7d651575961a25e61163b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*ess7IwZG4HwP9_Cr_hnsYQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">女装:<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/</a></figcaption></figure><p id="94ce" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">下图第一列显示了几幅测试图像，每幅图像旁边是根据像素差异确定的训练集中前10个最近的相邻图像。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ln"><img src="../Images/112e58a3cbf5f88072cf37247c46c241.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*7thxOlHaa2XP7OrsWyteCQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">女装:<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/</a></figcaption></figure><p id="03cc" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">但是，这里确实有问题。第一个图像是一艘船，但是第一个与之匹配的图像是一只鸟。此外，第三个图像是一只青蛙，但首先与一只猫匹配！！！<br/> <br/>是的，这就是这个算法的主要缺陷。在第一种情况下，算法可能会混淆，因为船的轮廓看起来像匹配图像中的鸟，而在第二种情况下，颜色和姿势是匹配的。这些进一步凸显了计算机视觉<strong class="jf hj">中的一个关键挑战，即相似的物体受到各种设置的影响。</strong></p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/72abb9f20817f4f1cedd09a6aad25461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*FWD0yg9ioBSCxckGtJHW2w.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">http://cs231n.stanford.edu/<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="29f5" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">为了解决这个</strong>，我们必须找到一种方法<strong class="jf hj">从图像中提取人脸的特征</strong>，如鼻子、嘴唇、眼睛、耳朵等，然后通过组合这些特征，我们可以将物体识别为人类，而不管它在什么环境中，我们看到这与人脑/人类视觉的工作方式非常相似。这就是我们今天讨论的主题进入“卷积神经网络(CNN)”的原因。</p><h1 id="ae99" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">卷积神经网络</strong></h1><p id="c040" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在一个非常高的层面上，CNN关注两个关键领域</p><p id="c3e7" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">1)从图像中提取低级特征(线、边缘等)。<br/> 2)从这些低级特征建立高级特征(鼻子、嘴唇、眼睛、耳朵等)。</p><p id="44d2" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">1)</strong>T15】提取低层特征</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lo"><img src="../Images/6696be14fd8e2a392c954e1f0a4755dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*Y0tvNnH7sXHw2zP7TrCKgA.gif"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">来源:https://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/<a class="ae kb" href="https://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="f8bb" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">一个<strong class="jf hj">滤镜</strong>(红色轮廓)滑过输入图像(<strong class="jf hj">卷积运算</strong>)产生一组特征(<strong class="jf hj">特征图</strong>)。另一个滤镜(绿色轮廓)，在同一张图片上滑动，给出不同的特征图，如图所示。值得注意的是，卷积运算捕获原始图像中的局部相关性/低级特征。还要注意这两个不同的过滤器是如何从相同的原始图像生成不同的特征图的。请记住，上面的图像和两个过滤器只是数字矩阵，我们已经讨论过了。</p><p id="a1cc" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">更多数学细节，请参考这篇伟大的文章<a class="ae kb" href="https://mlnotebook.github.io/post/CNN1/" rel="noopener ugc nofollow" target="_blank">https://mlnotebook.github.io/post/CNN1/</a></p><p id="a16f" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">这可能是一个介绍实际卷积神经网络(CNN)的好时机</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lp"><img src="../Images/d7321c8ba393732cb582bd834b23188f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*QjynAeqTSvr8XSA0YD335g.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated"><strong class="bd ih">图1.1 — </strong> <a class="ae kb" href="https://developers.google.com/machine-learning/practica/image-classification/images/cnn_architecture.svg" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="0cbc" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">CNN是多个“卷积模块”堆叠在一起，最终的分类层决定了图像的实际内容，例如猫或狗。<br/> <strong class="jf hj"> Conv。模块#1 </strong>可以被认为是提取低级特征的模块。</p><p id="3e5f" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">2)</strong>T5】从这些低级特征中建立高级特征(鼻子、嘴唇、眼睛、耳朵等)。<br/> 低级特征被组合在一起以构建中级特征，然后在后面的层中构建高级特征，类似于人的视觉层次。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/da72f343c4f6432d00511d586ae1c37f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*FSXsismepR8ZR1oZNICHXw.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">女装:<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/</a></figcaption></figure><p id="79ba" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">这里显而易见的问题是，CNN如何知道要应用的模板(滤波器),因为这可能因不同类型的图像而异，以及CNN如何提出如此精确地表示输入图像的中/低级特征？这就是机器学习的学习部分发挥作用的地方。正如你可能已经猜到的那样，这不会在CNN一看到图像就自动发生。<br/><br/>CNN经历了一个训练(监督学习)过程，在这个过程中，它会看到一堆不同的猫图像，然后一次一个地浏览它们。在过程开始之前，模板是空白的石板，当它通过CNN，<br/> <strong class="jf hj"> Conv的不同层处理第一个图像时。第一单元→Conv。模块# 2→分类(如图1.1) <br/> </strong>几乎没有低/中/高级特征识别发生，CNN将其预测为猫图像的置信度将非常低。</p><p id="6fe8" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然而，通过这些层反馈回来的是，<br/> <strong class="jf hj">分类→Conv。第二单元→Conv。模块#1(如图1.1) <br/> </strong>关于“预测”与“实际”图像相比有多好。这种反馈会跨层调整，让CNN变得更聪明一点。对所有图像重复该过程，并且该批图像被处理多次，每次都增强了学习。</p><p id="4a14" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">把这看作是教一个孩子苹果的样子。我们第一次给她看苹果的图像时，她可能会称之为球。但是当我们纠正她时，她可能会捕捉到图像中的一个特征，假设它是圆的。下一次我们给她看同样的图像，她可能会称之为桔子，接近但不完全在那里。然后，我们将它强化为一个苹果，这样她可能会得到一个额外的特征，即它是红色的。随着时间的推移，重复同样的过程有助于她识别苹果最相关的特征，而这些知识也将永远嵌入她的脑海。</p><p id="b74a" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">看看<a class="ae kb" href="https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html" rel="noopener ugc nofollow" target="_blank">由<a class="ae kb" href="http://scs.ryerson.ca/~aharley/" rel="noopener ugc nofollow" target="_blank">亚当·哈利</a>在MNIST手写数字数据库上训练的卷积神经网络</a>的惊人可视化效果。</p><p id="8d2e" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">如果你对CNN的深度报道感兴趣，请参考<a class="ae kb" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="842e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">物体检测</strong></h1><p id="3255" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在我们对图像分类有了很好的直觉，让我们将概念扩展到一个高级问题<strong class="jf hj">对象检测。<br/> <br/> </strong>物体检测是一种计算机视觉技术，用于识别和定位图像或视频中的物体。具体来说，对象检测在这些检测到的对象周围绘制边界框，这允许我们定位所述对象在给定场景中的位置(或者它们如何移动)。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lq"><img src="../Images/ddec79c9d994cd45495b2b77c286c60b.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*dZtzs2kZVdNLFjKktTcdsA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">女装:<a class="ae kb" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/</a></figcaption></figure><p id="1f14" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">基于我们目前所看到的，如果有一种方法可以让我们<strong class="jf hj">识别图像中每个对象的边界</strong>，那么我们可以裁剪该部分，并使用图像分类算法来识别该部分中的对象。</p><p id="5b88" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">在非常高的水平上，考虑两种方法<strong class="jf hj">来识别图像中的对象边界</strong>。</p><p id="4729" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj"> 1。滑动窗口检测器</strong> —不同尺寸和长宽比的窗口从上到下和从左到右在图像上滑动。我们根据滑动窗口从图片中剪切出小块。由于许多分类器仅拍摄固定大小的图像，因此这些片是扭曲的。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/f17d57638443705b044f07cb03478329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*w7laXmAGvVeQWfNucm50qA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated"><a class="ae kb" href="https://jonathan-hui.medium.com/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9" rel="noopener">来源</a></figcaption></figure><p id="f41f" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj"> 2。选择性搜索</strong> —与“滑动窗口检测器”中的强力方法不同，我们使用区域提议方法来创建<strong class="jf hj">感兴趣区域(ROIs) </strong>进行对象检测。在<strong class="jf hj">选择性搜索</strong> ( <strong class="jf hj"> SS </strong>)中，我们从每个单独的像素开始作为自己的组。接下来，我们计算每个组的纹理，并组合两个最接近的组。但是为了避免一个地区吞并其他地区，我们倾向于先分组。我们继续合并区域，直到所有的东西都被合并。在下面的第一行中，我们展示了我们如何扩大区域，第二行中的蓝色矩形显示了我们在合并过程中产生的所有可能的ROI。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es lr"><img src="../Images/ea729a42d56601513b48e3f56d9c5a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*Xm3FsvtI6JhZL85RbO-1qw.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">资料来源:范德桑德等人，ICCV，2011年</figcaption></figure><p id="6b78" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">主要有两种类型的对象检测算法</p><p id="ba80" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj"> 1。基于区域的对象检测器(更快的R-CNN，R-FCN，FPN)</strong>——首先它们识别图像中的对象，然后对它们进行分类。相对较慢但更准确。<br/>2<strong class="jf hj">。单发物体探测器(SSD，YOLO)</strong>——识别物体并并行分类。速度更快，但相对不太准确。</p><p id="4513" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">如果你有兴趣了解物体检测算法的细节，请查看这篇文章。</p><h1 id="b674" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">动手</strong></h1><p id="8a1d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">脸书的Detectron2 是一种快速简单的方式来开始你的物体探测之旅。如果您想将对象检测应用到您的自定义数据集，请查看这篇文章。</p><h1 id="8107" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">应用</strong></h1><h2 id="556e" class="ls ig hi bd ih lt lu lv il lw lx ly ip jo lz ma it js mb mc ix jw md me jb mf bi translated"><strong class="ak">自动驾驶</strong></h2><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es mg"><img src="../Images/1425a98f7c2860fb101325e62a81a329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x54087HspQmrfM1_j4PHuQ.jpeg"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx translated">资料来源:联合国人类住区规划署</figcaption></figure><p id="9bd9" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">医学影像</strong></p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ml"><img src="../Images/270a4515e4f1b52690ada55d7428c3d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*WTdlVty5y-209wtrUjqOQg.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated"><a class="ae kb" href="https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-5/issue-03/036501/DeepLesion--automated-mining-of-large-scale-lesion-annotations-and/10.1117/1.JMI.5.3.036501.full?SSO=1" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ih">深度病变:利用深度学习自动挖掘大规模病变标注和通用病变检测</strong> </a></figcaption></figure><p id="0d5e" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">机器人学</strong></p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es kc"><img src="../Images/911b0ac6d1ed8ab3b434518382503b26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*IGNUkzVs5Q_oVQ5WqRAOFQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx translated">在我们身后打扫卫生的机器人</figcaption></figure><h1 id="3ec2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">近期趋势</strong></h1><p id="1aec" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj"> 3D物体检测:</strong>3D物体的检测有其自身的要求。例如，这些对象不遵循任何特定的方向，这带来了相当大的挑战。近年来取得了一定的进步，但要持续实现高绩效，仍有许多工作要做。<br/> <br/> <strong class="jf hj">实时、高速检测:</strong>物体检测是资源密集型的，无论是人工干预还是模型处理(计算)。因此，实时高速检测，尤其是移动设备的实时高速检测，是一个重要的发展领域。</p><p id="dc45" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">小物体检测:</strong>大多数检测器都难以检测小物体。小物体探测的不准确性比那些与中或大物体相关的不准确性要高得多</p><p id="f69c" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">基于视频的对象检测:</strong>现代对象检测主要是为图像设计的，而不是明确为视频设计的。因此，在检测发生之前，视频需要被分成单独的帧。这造成了低效率，如检测延迟、将视频转换成帧的开销以及没有考虑帧级关系。解决这些问题是当前和未来发展的一个关键领域。</p><h1 id="b084" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">深潜参考</strong></h1><p id="fd23" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj"> MIT 6。S191:深度学习简介</strong>——<a class="ae kb" href="https://github.com/jim-j-james/introtodeeplearning" rel="noopener ugc nofollow" target="_blank">https://github.com/jim-j-james/introtodeeplearning</a><br/><br/><strong class="jf hj">斯坦福CS231n:用于视觉识别的卷积神经网络</strong>——<a class="ae kb" href="https://github.com/jim-j-james/cs231n" rel="noopener ugc nofollow" target="_blank">https://github.com/jim-j-james/cs231n</a></p><p id="69ed" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated"><strong class="jf hj">帕德海，IIT·马德拉斯</strong>——<a class="ae kb" href="https://github.com/jim-j-james/PadhAI_Deep_Learning" rel="noopener ugc nofollow" target="_blank">https://github.com/jim-j-james/PadhAI_Deep_Learning</a></p><ul class=""><li id="365f" class="kx ky hi jf b jg ko jk kp jo kz js la jw lb ka lc ld le lf bi translated"><strong class="jf hj"> *这些观点是我个人的观点，不代表我的雇主的观点** </strong></li></ul></div></div>    
</body>
</html>