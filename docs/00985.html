<html>
<head>
<title>7 Steps to Build Automatic Number Plate Recognition in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现自动车牌识别的7个步骤</h1>
<blockquote>原文：<a href="https://medium.com/codex/7-steps-to-build-automatic-number-plate-recognition-in-python-53e34c9ae583?source=collection_archive---------2-----------------------#2021-03-29">https://medium.com/codex/7-steps-to-build-automatic-number-plate-recognition-in-python-53e34c9ae583?source=collection_archive---------2-----------------------#2021-03-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/7ad9d6d33e849185ef75a972a6df725a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xp4lLXDUx0T4IUa9"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">托马斯·米洛特在<a class="ae hv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="0600" class="hw hx hy bd b fp hz ia ib ic id ie dx if translated" aria-label="kicker paragraph"><a class="ae ge" href="http://medium.com/codex" rel="noopener">抄本</a></h2><div class=""/><figure class="ev ex jf jg jh hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es je"><img src="../Images/95044967f2323bb5bbadc8d9b11f92ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZyOc2VQaM4qJ0UzC8iY0gw.png"/></div></div></figure><p id="abc8" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jk ii">图像处理和目标检测</strong>是数据科学的一个领域，在当今世界的各行各业都有广泛的应用。许多行业都在寻找具备这些技能的数据科学家。</p><p id="4bc6" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">本文介绍了如何从头开发一个车牌对象检测模型。我们甚至用Flask开发了一个API。然而，在本文中，我们解释了如何从头开始训练一个<strong class="jk ii">定制对象检测模型</strong>。</p><p id="4e8a" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">为了建立车牌识别系统，我们需要数据。为此，我们需要收集出现<strong class="jk ii">车牌</strong>的车辆图像。<a class="ae hv" href="https://drive.google.com/drive/folders/1VRqnQnlYYdTMl1icgW0L_rUEmU-E-NHZ?usp=sharing" rel="noopener ugc nofollow" target="_blank">这是我用来构建这个项目的样本数据。你也可以从我的google drive下载。</a></p><h1 id="cf47" class="kg kh hy bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">项目架构:</h1><p id="0037" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">现在，让我们来看一下我们构建的车牌识别和OCR的项目架构。</p><figure class="lj lk ll lm fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es je"><img src="../Images/eaef74eb01fc6b12036c4c86e0afe0e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsxDyw0N5shI4q0_PyXxlQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图1:车牌识别项目架构</figcaption></figure><p id="e238" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在上述架构中，有六个模块。标签、训练、保存模型、OCR和管道以及RESTful API。但是本文仅限于前三个模块。过程如下。首先，我们将收集图像。然后我们必须使用<a class="ae hv" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">图像标注工具</a>对图像进行标记，用于车牌或号码牌的对象检测，图像标注工具是在python GUI中开发的开源软件。然后在标记图像后，我们将进行数据预处理，在<strong class="jk ii"> TensorFlow </strong> 2中建立和训练深度学习对象检测模型(Inception Resnet V2)。一旦我们完成了对象检测模型训练过程，然后使用该模型我们将裁剪包含车牌的图像，该图像也被称为感兴趣区域(ROI)，并将ROI传递给Python中的光学字符识别API tessera CT(<strong class="jk ii">pytessera CT</strong>)。在本模块中，我们将从图像中提取文本。现在，我们将所有这些放在一起，建立一个管道深度学习模型。在最后一个模块中，我们将学习使用FLASK Python创建一个web应用程序项目。至此，我们终于准备好了我们的应用程序。</p><h2 id="185c" class="ln kh hy bd ki lo lp lq km lr ls lt kq jt lu lv ku jx lw lx ky kb ly lz lc ie bi translated">第一步:贴标签</h2><p id="695a" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">为了建立车牌识别系统，我们需要数据。为此，我们需要收集车牌出现的车辆图像。这是我用来构建这个项目的样本数据。你也可以从我的google drive下载。对于标签图像，我使用了<a class="ae hv" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">标签图像注释工具</a>。从GitHub下载labelImg并按照说明安装软件包。打开后，GUI as给出指令，点击<strong class="jk ii"> CreateRectBox </strong>，绘制如下图所示的矩形框，并将输出保存在<strong class="jk ii"> XML </strong>中。</p><pre class="lj lk ll lm fd ma mb mc md aw me bi"><span id="bb70" class="ln kh hy mb b fi mf mg l mh mi">pip install pyqt=5<br/>pip install lxml<br/>pyrcc5 -o libs/resources.py resources.qrc<br/>python labelImg.py<br/>python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]</span></pre><figure class="lj lk ll lm fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mj"><img src="../Images/7600fba8440e1b1b7c6e7cdf2e014fc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XVVOz85jdug1HGjiDRejRw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图2:使用图像注释进行标记</figcaption></figure><p id="a63f" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">这是一个手动过程，您需要对所有的图像都这样做。标注时要小心，因为标注过程会直接影响模型的准确性。<a class="ae hv" href="https://www.udemy.com/course/deep-learning-web-app-project-number-plate-detection-ocr/?referralCode=BCC3EDB9787790441A19" rel="noopener ugc nofollow" target="_blank">点击这里观看视频教程</a></p><h2 id="a0ef" class="ln kh hy bd ki lo lp lq km lr ls lt kq jt lu lv ku jx lw lx ky kb ly lz lc ie bi translated">步骤2:解析XML中的信息</h2><p id="5227" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">一旦你完成了标记过程，现在我们需要做一些数据预处理。</p><figure class="lj lk ll lm fd hk er es paragraph-image"><div class="er es mk"><img src="../Images/f447ba4085a15802d3b581c9c4da4d0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*1gEG_LQrtONphfgMP1XCoA.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图3 XML格式的图像注释工具的输出</figcaption></figure><p id="9b0a" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">由于标签的输出是XML，为了将它用于训练过程，我们需要数组格式的数据。为此，我们将从标签中提取有用的信息，即矩形框或<strong class="jk ii">包围框</strong>的对角点，分别为<em class="ml"> xmin，ymin，xmax，ymax </em>，如图<strong class="jk ii">图3 </strong>所示。这在XML中是可用的。因此，我们需要提取信息并以任何方便的格式保存它，这里我将把绑定信息转换成CSV，稍后，我将使用<strong class="jk ii"> Pandas </strong>把它转换成一个数组。现在让我们看看如何使用Python来解析信息。</p><p id="711c" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jk ii">解析XML数据并将其转换成CSV格式</strong></p><p id="f48a" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">这里我使用<strong class="jk ii"> xml.etree </strong> python库解析来自xml的数据，并导入pandas和glob。使用glob让我们首先获得在标记过程中产生的所有XML文件。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="bec1" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在上面的代码中，我们分别获取每个文件并解析成xml.etree，找到第2到7行中的对象-&gt; bndbox。然后我们提取xmin，xmax，ymin，ymax，并将这些值保存在字典中，即第8到17行。然后，我们将它转换成熊猫数据帧，并保存到CSV文件，如下所示。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><figure class="lj lk ll lm fd hk er es paragraph-image"><div class="er es mo"><img src="../Images/16174cb00a2afd356ffd5328a1bf3eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*QqqHCSVSwOQH_0yhbVCjrQ.png"/></div></figure><p id="77ad" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">通过上面的代码，我们成功地提取了每幅图像的对角线位置，并将数据从非结构化格式转换为结构化格式。</p><p id="8b50" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在还提取XML的相应图像文件名。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><h2 id="4e69" class="ln kh hy bd ki lo lp lq km lr ls lt kq jt lu lv ku jx lw lx ky kb ly lz lc ie bi translated">步骤4:验证数据</h2><p id="8af3" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">到目前为止，我们都是手动操作，因此验证我们获得的信息是否有效非常重要。为此，只需验证给定图像的边界框是否正确出现。这里我考虑图像N1.jpeg和相应的对角线位置可以在<strong class="jk ii"> df中找到。</strong></p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><figure class="lj lk ll lm fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mp"><img src="../Images/d82a8048299a9dfcad1df5b338960c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WnKKxQdUF6TJ6k6rV2h4RQ.png"/></div></div></figure><h2 id="f138" class="ln kh hy bd ki lo lp lq km lr ls lt kq jt lu lv ku jx lw lx ky kb ly lz lc ie bi translated">第五步:数据处理:</h2><p id="e9c0" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">这是一个非常重要的步骤，在这个过程中，我们将使用<strong class="jk ii"> OpenCV </strong>将每张图像转换为一个数组，并将图像大小调整为224 x 224，这是预训练<strong class="jk ii">迁移学习模型的标准兼容大小。</strong></p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="deb8" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">之后，我们将通过除以最大数来标准化图像，因为我们知道8位图像的最大数是</p><figure class="lj lk ll lm fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/e0bf344bb1a815c19e8a3e70d74564f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:198/0*cip1n22lSK-pT0d-"/></div></figure><p id="12aa" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">我们将我们的图像分割成255.0的原因。用最大值分割一个数组的方式叫做<strong class="jk ii">归一化</strong> (Min-Max Scaler)。</p><p id="f4d2" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">我们也需要标准化我们的标签。因为对于深度学习模型，输出范围应该在0到1之间。为了归一化标签，我们需要用图像的宽度和高度来划分对角点。最后是python列表中的值。下一步，我们将使用Numpy将列表转换成数组。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="a1aa" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在使用<strong class="jk ii"> sklearn </strong>将数据分成训练集和测试集。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><h2 id="c8a5" class="ln kh hy bd ki lo lp lq km lr ls lt kq jt lu lv ku jx lw lx ky kb ly lz lc ie bi translated">步骤6:建立和培训迁移学习</h2><p id="c7ce" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">现在我们准备训练一个用于对象检测的深度学习模型。这里，我们将使用带有预训练权重的<strong class="jk ii"> InceptionResNetV2 </strong>模型，并根据我们的数据对其进行训练。让我们从从<strong class="jk ii"> TensorFlow 2.3.0 </strong>导入必要的库开始</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="d5bd" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">我们正在建立的模型是对象检测模型，并且从模型4期望的输出数量是对角点。因此，我们将向迁移学习模型添加一个嵌入的神经网络层，如第5行到第9行所示。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="24ec" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在编译模型并训练模型</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="87ac" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">这就是我们训练模型的目的。这个过程通常需要3到4个小时，取决于计算机的速度。在这里，我向你展示了模型在TensorBoard中的丢失。</p><figure class="lj lk ll lm fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mr"><img src="../Images/400ca579324df3d55a974dfa50c40425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c3_7FZsg48PMVqG-HHqcIQ.png"/></div></div></figure><p id="e5a1" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">似乎模型在100个纪元后收敛了。</p><blockquote class="ms mt mu"><p id="89a9" class="ji jj ml jk b jl jm jn jo jp jq jr js mv ju jv jw mw jy jz ka mx kc kd ke kf hb bi translated">注意:为了更好地减少损失，我们需要用至少10000幅图像的大量数据来训练模型</p></blockquote><h2 id="14c9" class="ln kh hy bd ki lo lp lq km lr ls lt kq jt lu lv ku jx lw lx ky kb ly lz lc ie bi translated">步骤7:进行包围盒预测</h2><p id="e7b1" class="pw-post-body-paragraph ji jj hy jk b jl le jn jo jp lf jr js jt lg jv jw jx lh jz ka kb li kd ke kf hb bi translated">这是物体检测的最后一步。在这一步，我们将把所有这些放在一起，并得到给定图像的预测。</p><figure class="lj lk ll lm fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><figure class="lj lk ll lm fd hk er es paragraph-image"><div class="er es my"><img src="../Images/bce80392bcc1c12fbda12c518b0b70d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*Anj6w9rLro52EAqZn1rVyg.png"/></div></figure><p id="db20" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">就是这样！！！。这就是我们如何从零开始开发车牌检测。</p></div><div class="ab cl mz na gp nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="hb hc hd he hf"><p id="9e30" class="pw-post-body-paragraph ji jj hy jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">本文只解释了项目架构的50%。下一个过程包括从车牌中提取文本并在Flask中开发RestfulAPI。这是项目的输出</p><figure class="lj lk ll lm fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ng"><img src="../Images/7d05d2e51c024e981734fd48fe8487e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VnDLRhRABHUMDKJyDmk6ZA.gif"/></div></div></figure><blockquote class="ms mt mu"><p id="dd89" class="ji jj ml jk b jl jm jn jo jp jq jr js mv ju jv jw mw jy jz ka mx kc kd ke kf hb bi translated"><a class="ae hv" href="https://www.udemy.com/course/deep-learning-web-app-project-number-plate-detection-ocr/?referralCode=BCC3EDB9787790441A19" rel="noopener ugc nofollow" target="_blank">点击此处，3小时视频项目讲解，从零开始搭建号牌Web App。</a></p></blockquote></div></div>    
</body>
</html>