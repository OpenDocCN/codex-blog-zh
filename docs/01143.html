<html>
<head>
<title>Code a Polynomial Regression model from scratch using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python从头开始编写多项式回归模型</h1>
<blockquote>原文：<a href="https://medium.com/codex/code-a-polynomial-regression-model-from-scratch-using-python-6f02d708177?source=collection_archive---------1-----------------------#2021-04-07">https://medium.com/codex/code-a-polynomial-regression-model-from-scratch-using-python-6f02d708177?source=collection_archive---------1-----------------------#2021-04-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/d543c902f8bd5ae953ea752ba2e69f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3SER7rAzUqJROK-O"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">潘卡杰·帕特尔在<a class="ae hv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><div class=""/><div class=""><h2 id="1eb7" class="pw-subtitle-paragraph iv hx hy bd b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm dx translated">了解多项式回归背后的基本数学，以及如何使用Python从头开始实现它。</h2></div><p id="27fb" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在机器学习和统计分析中，回归模型是一种可以与已知数据点相关联的模型，以便估计某个函数<em class="kj"> F </em>并逼近关于数据点<em class="kj"> X. </em>的<em class="kj"> Y </em>的值</p><p id="ae15" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在本文中，我们将快速回顾回归背后的数学，然后我们将学习如何使用Python和Numpy编写多项式回归模型。最后，我们将看到如何防止我们的模型过度拟合，尽管使用了高学历。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="d6d4" class="kr ks hy bd kt ku kv kw kx ky kz la lb je lc jf ld jh le ji lf jk lg jl lh li bi translated">数学的快速概述</h1><p id="5525" class="pw-post-body-paragraph jn jo hy jp b jq lj iz js jt lk jc jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">为了估计某个<em class="kj"> X </em>的值<em class="kj"> Y </em>，我们需要运行这个等式:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es lo"><img src="../Images/a85ed3d282150f066f4c3f1b3c52ec2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/1*6ALapiP_IblNPoUb7eJI3g.gif"/></div></figure><p id="d0e8" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这可以简化为:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es lt"><img src="../Images/c8c5bed89142df6289a734f41e8c9144.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/1*jQQGKcJd0U-A-JS-lO9YPg.gif"/></div></figure><p id="2781" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">其中<em class="kj"> D </em>是多项式的次数。</p><p id="4011" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在的问题是，我们如何找到这些重量？简而言之，我们可以用我们的数据<strong class="jp hz"> <em class="kj"> X </em> </strong>形成的设计矩阵来估计矢量<em class="kj"> w </em>，使用以下等式:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es lu"><img src="../Images/6b1893d8278c0e076412ad96e28f86b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/1*qOyfqQFEdP8JgCZdCBhP1Q.gif"/></div></figure><p id="ef48" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">其中<em class="kj">φ</em>是设计矩阵<strong class="jp hz">YT29】是每个目标<em class="kj"> y </em>形成的向量。<br/>尺寸<em class="kj"> N </em> x <em class="kj"> D </em>的设计矩阵是这样建立的，每个<em class="kj"> x </em>都是我们训练集中的一个数据点:</strong></p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es lv"><img src="../Images/978d4fcaa722cfc579b6778d2fe15303.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/1*Ih9xyUX9Uu7Wl9IwMQLo5w.gif"/></div></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="3864" class="kr ks hy bd kt ku kv kw kx ky kz la lb je lc jf ld jh le ji lf jk lg jl lh li bi translated">回归模型类</h1><p id="f9ce" class="pw-post-body-paragraph jn jo hy jp b jq lj iz js jt lk jc jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">我们现在要对这个类进行编码。请记住，它不是最优化的模型实现，但我相信它很容易理解。首先，初始化函数:</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="60b5" class="mb ks hy lx b fi mc md l me mf">def __init__(self, d=5): <br/>    self.d = d</span></pre><p id="41e6" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这里变量<em class="kj"> d </em>是我们多项式的次数。注意，如果<em class="kj"> d </em>等于1，那么我们将有一个线性回归。<br/>现在进入拟合功能:</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="7663" class="mb ks hy lx b fi mc md l me mf">def fit(self, X, y):<br/>    A = []<br/>    C = []<br/>    for i in range(self.d):<br/>        A_row = []<br/>        for j in range(self.d):<br/>            A_row.append(numpy.sum([x**(i+j) for x in X]))<br/>        A.append(A_row)<br/>        C.append(numpy.sum(numpy.multiply([x**i for x in X], y)))<br/>    w = numpy.linalg.inv(A) * numpy.transpose(C)<br/>    self.w = w</span></pre><p id="a3d9" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们在这里使用两个矩阵计算上一节中给出的等式，例如:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es mg"><img src="../Images/6600c5b869869d14a6f90035a2b7e6d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/1*vBi3tNr-7GTKj5dfKKFemg.gif"/></div></figure><p id="4a02" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">使用我们刚刚找到的权重，我们现在可以估计一些数据点的值<em class="kj">Y</em>X:</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="ea89" class="mb ks hy lx b fi mc md l me mf">def predict(self, X): <br/>    pred = [] <br/>    for x in X:<br/>    pred.append(numpy.sum([w_j * x**j for j, w_j in<br/>                enumerate(self.w)])) <br/>    return pred</span></pre><p id="8b6e" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们的回归模型完成了，让我们看看它的表现如何。<br/>首先，我们需要创建一些数据:</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="e95b" class="mb ks hy lx b fi mc md l me mf">numpy.random.seed(0)</span><span id="b9c2" class="mb ks hy lx b fi mh md l me mf">X = numpy.arange(0, 10, 0.1)<br/>X = X + numpy.random.normal(0, 0.2, X.shape)<br/>y = numpy.sin(X)<br/>y = y + numpy.random.normal(0, 0.3, y.shape)</span><span id="9b02" class="mb ks hy lx b fi mh md l me mf">plt.scatter(X, y)<br/>plt.show()</span></pre><p id="6c79" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这段代码只创建了一个正弦波，我在其中添加了一些噪声:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es mi"><img src="../Images/ae384d7d60b1c6025b8da84f9acd9265.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*ZQlR3vbXXQ7xJzS-c41aUA.png"/></div></figure><p id="340c" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们现在实例化模型，并使用拟合函数找到权重:</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="349c" class="mb ks hy lx b fi mc md l me mf">model = regressionModel(d=5)<br/>model.fit(X, y)</span></pre><p id="42a9" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后，我们可以在分散的数据上绘制回归线，看看它是否吻合。</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="8c6a" class="mb ks hy lx b fi mc md l me mf">plt.scatter(X, y)<br/>x_min = min(X)<br/>x_max = max(X)<br/>xx = numpy.arange(x_min, x_max, 0.05)<br/>plt.plot(xx, model.predict(xx), c="red")<br/>plt.show()</span></pre><p id="062e" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我画了3个例子，这样你就能看出高低学位的区别:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mj"><img src="../Images/e1dc7ef2df237dc8fdaeb933ff4c3c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UGGrpEVsc5uy-XJBYPSAjA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">d=1、d=5和d=12的多项式回归</figcaption></figure><p id="c33c" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请注意，当<em class="kj"> d </em> =1时，这只是一个线性回归，当<em class="kj"> d </em> =12时，模型过度拟合，而<em class="kj"> d </em> =5则很好地代表了我们的数据。因此，选择合适的学位非常重要。</p><p id="96a8" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果你仍然需要使用高学位，你需要防止这种过度拟合，这可以通过正则化来实现。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="2c89" class="kr ks hy bd kt ku kv kw kx ky kz la lb je lc jf ld jh le ji lf jk lg jl lh li bi translated">具有L2正则化的回归模型类</h1><p id="0963" class="pw-post-body-paragraph jn jo hy jp b jq lj iz js jt lk jc jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">L2正则化，或权重衰减，如果一些权重的影响较小，会对它们增加惩罚。换句话说，没有数据支持的权重将向零衰减。</p><p id="201d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于多项式回归，可以通过在我们的矩阵<strong class="jp hz"> <em class="kj"> A </em> </strong> <em class="kj"> </em>中添加一个值为λ的对角矩阵来进行这种正则化(关于<strong class="jp hz"> <em class="kj"> A </em> </strong>的定义见上文)。这样，我们的权重向量可以计算如下:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es mk"><img src="../Images/019f4768a4b476d41c2bace01d31aefc.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/1*mYpZz9NTZvdBrlZbj8aRGw.gif"/></div></figure><p id="afd8" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后，采用L2正则化的回归模型类变为:</p><pre class="lp lq lr ls fd lw lx ly lz aw ma bi"><span id="b337" class="mb ks hy lx b fi mc md l me mf">class regressionModel: <br/>    def __init__(self, d=5, lbda=0.5): <br/>        self.d = d<br/>        self.lbda = lbda </span><span id="6d95" class="mb ks hy lx b fi mh md l me mf">    def fit(self, X, y): <br/>        A = [] <br/>        C = [] <br/>        for i in range(self.d): <br/>            A_row = [] <br/>            for j in range(self.d): <br/>                lbda = 0 if i != j else self.lbda <br/>                A_row.append(numpy.sum([x**(i+j) + <br/>                             lbda for x in X]))<br/>            A.append(A_row) <br/>            C.append(numpy.sum(<br/>                     numpy.multiply([x**i for x in X], y))) <br/>        w = numpy.linalg.inv(A) * numpy.transpose(C) <br/>        self.w = w </span><span id="830e" class="mb ks hy lx b fi mh md l me mf">    def predict(self, X): <br/>        pred = [] <br/>        for x in X: <br/>            pred.append(numpy.sum(<br/>                 [w_j * x**j for j, w_j in enumerate(self.w)]))<br/>        return pred</span></pre><p id="ea3d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">使用与之前相同的代码来生成数据并拟合我们的模型，这是当<em class="kj"> d </em> =12且λ= 0.5时的回归曲线:</p><figure class="lp lq lr ls fd hk er es paragraph-image"><div class="er es ml"><img src="../Images/af9f0dc56a072a16669c5879c2b1969b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*OzxbeBZNbs6FuWnQpA32qA.png"/></div></figure><p id="08e5" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">看起来好多了，不是吗？</p><p id="62e4" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">选择度数和λ值的良好组合通常需要反复试验。幸运的是，大多数机器学习库，如Scikit-Learn，都有K倍验证算法的实现来帮助您找到这些值。</p><p id="27bf" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">你可以在这里进一步阅读K-Fold验证:<a class="ae hv" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . model _ selection。KFold.html</a></p></div></div>    
</body>
</html>