<html>
<head>
<title>When robots make biased fake content on social media</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当机器人在社交媒体上制作有偏见的虚假内容时</h1>
<blockquote>原文：<a href="https://medium.com/codex/when-robots-make-biased-fake-content-on-social-media-8530eff4e6c4?source=collection_archive---------40-----------------------#2022-06-17">https://medium.com/codex/when-robots-make-biased-fake-content-on-social-media-8530eff4e6c4?source=collection_archive---------40-----------------------#2022-06-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="140e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">人工智能和fakenews</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/17f02b5737b85ae0249fd1ab9ac3a6c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkTUkWrcsDQkeVCvIBWv_A.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">脸书、Twitter、LinkedIn:在每一个社交网络中，自动化系统都可能产生和传播虚假信息。|图片(细节):colourbox.com</figcaption></figure><p id="4ada" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">世界各地的组织都在大规模实施人工智能系统。然而，这些自动系统并不总是用于好的方面，它们也不总是做出最好的决定。在这篇文章中，我将强调三种类型的有偏见的机器人，以三个案例为例:消除社交机器人，有偏见的人工智能工具和合成档案。</p><p id="7fbe" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><em class="kj">作者布莱恩·l·到期</em></p><h1 id="5cdb" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">需要注意的三种类型</h1><p id="f08a" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">在本文中，人工智能实际上被定义为自动软件机器人，它们基于先进的算法，由人类编程，并由人类为了特定的目的在大型但特定的数据集上进行训练。人工智能可能会产生虚假和有偏见的内容，通常不可能确定其来源。人类可能认识到这一点，并有目的地使用它，而不知道或声明它是假的，我们称之为<em class="kj">假信息</em>，因为它故意误导或操纵。</p><p id="4f54" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">例如，2016年英国退出欧盟公投期间，社交媒体上流传的<a class="ae lh" href="https://www.deutschlandfunk.de/soziale-medien-und-das-brexit-referendum-propaganda-luegen-100.html" rel="noopener ugc nofollow" target="_blank">种族主义错误信息</a>就显示了这种影响:在所谓的黑暗广告中，一群人针对脸书，虚假声明欧盟将给予7600万土耳其人免签证入境。除此之外，这个群体中的人因为害怕更多的移民和失去主权而团结在一起——他们被算法过滤掉了。这些活动旨在吸引潜在的英国退出欧盟支持者投票。它们威胁到民主决策的原则。</p><p id="bf46" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然而，虚假的人工智能生成的内容也可能“只是”被传播，而没有任何恶意，仍然会导致偏见或<em class="kj">错误信息</em>。在这篇文章中，我们看三种结合了三个关键特征的现象:a)人工智能内容生成b)在某种形式上是假的，c)也(重新)产生偏见。<em class="kj">内容</em>在这里定义为提供给广大受众的信息。<em class="kj">假的</em>意味着信息是误导性的，要么是错误的，而<em class="kj">偏见</em>被广义地定义为支持或反对某事的不成比例的权重，这通常是无意的和无意识的。</p><p id="9d1c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在下文中，我将简要描述三种类型的软件机器人，包括1)虚假信息/错误信息之间的区别，2)内容、虚假和偏见的结合，以及3)在不同社交媒体平台上的发生。显然，还有其他类型和呈现类型的方式。例如，有一个方面没有被涵盖，那就是日益严重的假货。</p><h1 id="8b17" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">1.反病毒社交机器人:当虚假的机器人档案传播虚假信息</h1><p id="4909" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">第一种有偏见的机器人大量出现在脸书和推特这样的大平台上。在这里，我们看到了人工智能机器人的简介，起初似乎是人类在关键话题上传播有偏见的虚假信息，特别是在政治方面。通过更仔细地检查这些简介，人们会发现它们通常有数字名称，在网络上相当新，没有或只有很少的追随者，并且它们的帖子有非常狭隘或有偏见的主题。有许多机器人军队污染政治进程的例子，这也被称为社交媒体的武器化。最近的例子与新冠肺炎有关，在那里，人们看到机器人制作虚假内容，导致人们不信任政府(见例子1)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es li"><img src="../Images/fda55eae29cb63b416e2fd3cacea586c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NW4p1dqRUGNA_jEjspLuNw.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">【https://apnews.com/bc2f19097a4c4fffaa00de6770b8a60d? T2】UTM _ campaign = social flow&amp;UTM _ medium = AP&amp;UTM _ source = Twitter</figcaption></figure><p id="5e49" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">例1: </strong>一个由机器人“Mel65842178”创建的虚假社交媒体账号。一种自动生成的机器人，将评论植入社交媒体源，其更深层次的意图是消除或改变公众的观点。在这种情况下，梅尔传播假新闻，仅仅是因为机器人不可能有女儿，所描述的事件也不可能发生。它还转发了一条带有强烈偏见和仇恨的评论。</p><h1 id="460d" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">2.有偏见的人工智能工具:当人工智能创造的内容导致错误信息时</h1><p id="a71f" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">第二种有偏见的机器人是作为特定平台内的工具存在的AI算法。它们旨在帮助提高工作效率，例如，通过建议单词或句子完成或图像建议，作为平台上的用户体验。基本上，人工智能工具不仅基于预测，还基于说明性分析，能够使用户在工具中嵌入下一步行动时立即采取行动。在此过程中，他们可能会产生无意识的偏见，因为例如，他们是由特定的开发人员群体(例如，白人男性)开发的，并根据有偏见的数据进行训练。先前的例子计算警察算法(<em class="kj">预测警务</em>)，这可能导致警察不公平地将目标对准少数族裔人口比例高的社区，而不管这些地区的真实犯罪率如何。最近的一个例子是Twitter的人工智能裁剪工具——如果你发布长而瘦的照片，裁剪工具会集中在它认为是推文中最好的部分。它裁剪图像的方式是优先选择白皮肤的人，而不是黑皮肤的人(见例2)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lj"><img src="../Images/4f470e9e59632dd8cbc76c7c0afe7ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9j_6guItaArxbpC1.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片(截图):推特</figcaption></figure><p id="c25c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">例子2:</strong>Twitter裁剪工具更喜欢以白人面孔为中心，而不是黑人面孔。原图输入的是左图11个黑皮肤的人和1个白皮肤的人。裁剪工具选择聚焦于一个白人。应该提到的是，Twitter很快处理了这个问题。</p><h1 id="1685" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">3.合成侧写。当伪造的个人资料导致虚假信息</h1><p id="565a" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">第三种类型的机器人是合成的“人类”，即，如果它们是物理机器人，将被称为类人机器人。作为软件机器人，它们比“消灭社交机器人”更有说服力，后者成群出现，没有背景故事。合成的个人资料在Instagram上作为影响者而出名，其中<em class="kj"> #lilmiquela </em>就是一个典型的例子。有一个完整的虚拟人行业，由人工智能生成人脸和内容。看ThisPersonDoesNotExist.com的假面。他们可以被用来制作有偏见的内容和传播虚假信息。一个重要的例子是LinkedIn上的简介“凯蒂·琼斯”能够与美国政界的高层人物建立联系。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lj"><img src="../Images/ee363ae60fe8702a6033de76b173fc84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*W5pYKym2DD4yG-qu.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片(截图):推特</figcaption></figure><p id="b8ab" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">例3:LinkedIn的个人资料“凯蒂·琼斯”不存在。这是假的，人工智能合成的脸。美联社对个人资料图片进行了分析，并表示这是专业社交网站上典型的间谍活动。</p><h1 id="e54d" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">揭穿假新闻</h1><p id="f0b2" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">社交媒体上有许多类型的虚假个人资料和人工智能生成的内容。在这篇文章中，我已经涵盖了三种类型:1)反病毒社交机器人，2)有偏见的人工智能工具，以及3)合成简档。显然，当被标记为来自机器人时，机器人可以为传播真实信息提供很大帮助，并可能在更广泛的层面上用于打击偏见，例如西挪威研究所所做的，该研究所试图在人工智能的帮助下揭穿假新闻和仇恨言论。最终，不可能有一个完全无偏见的人类，所以基本上也不可能建立一个无偏见的人工智能系统。但我们肯定可以做得比现在好得多。</p></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h2 id="688b" class="lr kl hi bd km ls lt lu kq lv lw lx ku jw ly lz kw ka ma mb ky ke mc md la me bi translated"><strong class="ak">相关链接</strong></h2><ul class=""><li id="40de" class="mf mg hi jp b jq lc jt ld jw mh ka mi ke mj ki mk ml mm mn bi translated"><a class="ae lh" href="https://www.deutschlandfunk.de/soziale-medien-und-das-brexit-referendum-propaganda-luegen-100.html" rel="noopener ugc nofollow" target="_blank">英国退出欧盟公投期间的社交媒体</a></li><li id="186f" class="mf mg hi jp b jq mo jt mp jw mq ka mr ke ms ki mk ml mm mn bi translated"><a class="ae lh" href="https://stories.uq.edu.au/contact-magazine/2020/stop-covid-19-bots/index.html" rel="noopener ugc nofollow" target="_blank">社交机器人Mel65842178 </a></li><li id="74e7" class="mf mg hi jp b jq mo jt mp jw mq ka mr ke ms ki mk ml mm mn bi translated"><a class="ae lh" href="https://www.theguardian.com/uk-news/2019/sep/16/predictive-policing-poses-discrimination-risk-thinktank-warns" rel="noopener ugc nofollow" target="_blank"> PredPol的算法带来了歧视风险</a></li><li id="0073" class="mf mg hi jp b jq mo jt mp jw mq ka mr ke ms ki mk ml mm mn bi translated"><a class="ae lh" href="https://www.boredpanda.com/twitter-image-centering-algorithm-racist/?utm_source=google&amp;utm_medium=organic&amp;utm_campaign=organic" rel="noopener ugc nofollow" target="_blank">Twitter裁剪工具中的偏见</a></li><li id="26d5" class="mf mg hi jp b jq mo jt mp jw mq ka mr ke ms ki mk ml mm mn bi translated"><a class="ae lh" href="https://apnews.com/article/ap-top-news-artificial-intelligence-social-platforms-think-tanks-politics-bc2f19097a4c4fffaa00de6770b8a60d" rel="noopener ugc nofollow" target="_blank">伪造凯蒂·琼斯的LinkedIn个人资料</a></li></ul><h2 id="6fb2" class="lr kl hi bd km ls lt lu kq lv lw lx ku jw ly lz kw ka ma mb ky ke mc md la me bi translated">作者</h2><p id="f2b6" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">Brian L. Due是丹麦哥本哈根大学北欧研究和语言学系的副教授。他正在对人类与新技术的互动进行社会研究，并对感知人工智能和人类多感官特别感兴趣。</p><p id="42f1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">版权所有:正文:<a class="ae lh" href="https://www.goethe.de/de/index.html?wt_ca=22cc" rel="noopener ugc nofollow" target="_blank">歌德学院，布莱恩l .到期</a>。这个文本是德国3.0版的知识共享协议。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/2007a2c058db4d29e2b69a3991ec89c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:160/format:webp/0*pu6U9rEd79sEO6nR.png"/></div></figure><p id="5726" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">2022年2月</p></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><p id="1d3a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><em class="kj">原载于</em><a class="ae lh" href="https://www.goethe.de/prj/one/en/aco/art/22740616.html" rel="noopener ugc nofollow" target="_blank"><em class="kj">https://www . Goethe . de</em></a><em class="kj">。</em></p></div></div>    
</body>
</html>