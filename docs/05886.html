<html>
<head>
<title>Paper Explained — SeMask: Semantically Masked Transformers for Semantic Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释— SeMask:用于语义分割的语义屏蔽转换器</h1>
<blockquote>原文：<a href="https://medium.com/codex/paper-explained-semask-semantically-masked-transformers-for-semantic-segmentation-966c19a1512?source=collection_archive---------6-----------------------#2022-04-01">https://medium.com/codex/paper-explained-semask-semantically-masked-transformers-for-semantic-segmentation-966c19a1512?source=collection_archive---------6-----------------------#2022-04-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c937" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">一种新的语义分割SOTA</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/94a791f94d38389bd8455ef14d46da27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k3tLOn3ph9fk7P_pFbWLoQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">语义分割</figcaption></figure><h1 id="bc14" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">“语义是你所需要的一切”(semicit。:D)</h1><p id="471a" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">每次我们处理图像转换器网络时，我们最终做的是完全相同的事情:微调编码器部分的预训练主干。这是传统的方法，而不仅仅是用于语义分割任务。</p><p id="e9ba" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">然而，不考虑<strong class="kh hj">图像的语义信息来解决这个任务可能不是最佳方法</strong>，尤其是如果我们正在讨论语义分割的话。</p><p id="8627" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">本文的作者通过提出一种新的简单有效的框架来解决上述问题，该框架可以在<strong class="kh hj">语义注意力操作</strong>的帮助下，将图像的语义信息合并到预先训练的基于层次变换器的主干中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lg"><img src="../Images/374aa91cb18d157aace99e8b34afd2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-THiRDN8oHk7zdz5LDb9Q.png"/></div></div></figure><p id="ff69" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">总之，本文的贡献有三个方面:</p><ul class=""><li id="bf59" class="lh li hi kh b ki lb kl lc ko lj ks lk kw ll la lm ln lo lp bi translated">引入<strong class="kh hj"> SeMask模块</strong>，研究了将语义上下文添加到预训练的变压器主干中以用于语义分割任务的效果；</li><li id="17db" class="lh li hi kh b ki lq kl lr ko ls ks lt kw lu la lm ln lo lp bi translated">他们引入了一个<strong class="kh hj">语义解码器</strong>，用于聚合来自编码器不同阶段的语义先验；</li><li id="e37c" class="lh li hi kh b ki lq kl lr ko ls ks lt kw lu la lm ln lo lp bi translated">提供了对SeMask块对ADE20K和Cityscapes数据集的影响的深入分析。特别是，作者在ADE20K 上实现了<strong class="kh hj">新的最先进性能，并在Cityscapes上的<em class="lv"> mIoU </em>指标上提高了3%以上。</strong></li></ul><h1 id="b1ae" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">架构概述</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/da480c167611749c812c1467d3ccadc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjNIYaAAhjRkX0ZZNO_PTg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">上图显示了SeMask Swin语义FPN框架。</figcaption></figure><p id="0661" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">作者通过将SeMask集成到Swin-Transformer中提供了经验证据。</p><blockquote class="lx ly lz"><p id="ac6a" class="kf kg lv kh b ki lb ij kk kl lc im kn ma ld kq kr mb le ku kv mc lf ky kz la hb bi translated">我们在Swin变换器层之后添加了具有Ns个SeMask块的语义层，以捕获编码器网络中的语义上下文。使用简单的上采样+求和操作聚集来自每个阶段的语义层的语义图，并通过加权CE损失来监控语义上下文。</p></blockquote><p id="6758" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">上图显示了整体架构，即<strong class="kh hj"> SeMask Swin语义FPN框架</strong>。</p><p id="55e5" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">编码阶段包括层次特征建模的四个不同阶段。对于等级表示，他们通过为下一个阶段合并图层将每个阶段的要素地图缩小2倍，其中<em class="lv"> i </em>是阶段编号(见下图)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es md"><img src="../Images/675f07ea472c982a9f58f966f73a73dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n-KLNjbgoA675OZaWb-O8Q.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/72cb7dc17a14c7890734c43b12a74cfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJQ9KR6GD2-3giPzuxi7uA.png"/></div></div></figure><h1 id="7f67" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">SeMask编码器</h1><p id="58de" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">编码器中的每个阶段都由两层组成:转换器层和语义层。</p><p id="1e20" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">在将尺寸为H x W x 3的RGB输入图像输入到转换器之前，它首先被分裂成尺寸为4x4x3的不重叠的小块，这给出了48的特征维数。</p><p id="de6f" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated"><strong class="kh hj">编码阶段的第一阶段</strong>是线性嵌入层，其将补丁令牌的维度从48改变为<em class="lv"> C </em>(对于Swin-T变体，在第一阶段，<em class="lv"> C </em> =96)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mf"><img src="../Images/c6d41df049eb76dfed4a1200d58432da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VemYZXKzw0BH2ECdz3DSCQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">一个H=W=64，C=4的例子</figcaption></figure><p id="9ac1" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated"><em class="lv"> X </em>转化为<em class="lv"> Q，K </em>和<em class="lv"> V </em>分别是维度为<em class="lv"> N x C </em>的查询、键和值矩阵<em class="lv">。</em>相对位置嵌入(RPE)包括在尺寸<em class="lv">N×N</em>中，其中<em class="lv">N = M×M，</em>其中<em class="lv"> N </em>是小块的数量，<em class="lv"> M </em>是窗口大小<em class="lv">。</em></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mg"><img src="../Images/f2e1bddc7ec907d3de08390059aa6d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*WHgspNGhL3VsJfPGxUv8MA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">变形层内部的注意力等式</figcaption></figure><h2 id="8a9c" class="mh jo hi bd jp mi mj mk jt ml mm mn jx ko mo mp jz ks mq mr kb kw ms mt kd mu bi translated">变压器层</h2><p id="50f3" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">Transformer层由<em class="lv">Na</em>T28】Swin关注块堆叠在一起组成，从图像中提取图像级上下文信息。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mv"><img src="../Images/ff8bb6b34489977666339b6c7196b0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0sY-xGZXQ11Zr3R0VyzZMQ.png"/></div></div></figure><h2 id="e6d5" class="mh jo hi bd jp mi mj mk jt ml mm mn jx ko mo mp jz ks mq mr kb kw ms mt kd mu bi translated">语义层</h2><p id="0672" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">语义层<strong class="kh hj"> </strong>在编码步骤的每个阶段都跟在变换器层之后。</p><blockquote class="lx ly lz"><p id="684d" class="kf kg lv kh b ki lb ij kk kl lc im kn ma ld kq kr mb le ku kv mc lf ky kz la hb bi translated">语义层负责<strong class="kh hj">对语义上下文</strong>建模，该语义上下文用作计算分割分数的先验，以基于图像中存在的语义本质的指导来更新特征图。</p><p id="23b8" class="kf kg lv kh b ki lb ij kk kl lc im kn ma ld kq kr mb le ku kv mc lf ky kz la hb bi translated"><strong class="kh hj"> SeMask注意模块</strong>负责捕获编码器中的语义上下文。它根据分割分数更新来自变换器层的特征，提供指导并给出语义优先图，以便在训练期间有效监督语义建模。</p></blockquote><p id="b2f1" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">来自先前变换器层的特征Y被分成三个矩阵:语义查询(Sq)、语义关键字(Sk)和特征值(Yv)。Sq和Sk的维数是N×K，其中K是类的个数，Yv的维数仍然是N×C，其中C是嵌入维数。从Sq返回语义图S，并且使用Sk和Sq为SeMask注意力等式计算分割分数:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mw"><img src="../Images/86e0f675c0c0dade74e7b6c613f29fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYLoLbZzjGI5qyBp6D4pnA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">语义层内部的注意力等式</figcaption></figure><p id="5920" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">在分割分数和特征值之间的矩阵乘法之后，矩阵通过线性层并与<strong class="kh hj">可学习常数λ </strong>相乘，该常数用作处理来自权重初始化的噪声的特征的调谐因子。经过残差连接后，得到富含语义信息<em class="lv">Y’</em>的修改特征，统称为<strong class="kh hj">Se</strong>T42ed特征。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mx"><img src="../Images/755bce1f81bc9d66e1a4ac13d64c7ad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Ahhr3us7gLFimC1fgfJkg.png"/></div></div></figure><h1 id="e293" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">解码器</h1><p id="f0d2" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">作者使用两个解码器分别从编码器的不同阶段聚集特征图和语义先验图:</p><ul class=""><li id="665b" class="lh li hi kh b ki lb kl lc ko lj ks lk kw ll la lm ln lo lp bi translated"><strong class="kh hj">语义FPN解码器</strong>，其通过一系列卷积、上采样和求和操作融合来自不同阶段的特征图；</li><li id="8847" class="lh li hi kh b ki lq kl lr ko ls ks lt kw lu la lm ln lo lp bi translated">一个<strong class="kh hj">轻量级语义解码器</strong>，仅用于训练，用于语义优先图的地面真实监督</li></ul><p id="3241" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">作为最后一步，两个解码器的输出被放大x4，以匹配最终预测的原始图像的分辨率。</p><h1 id="67a8" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">损失函数</h1><p id="badf" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">为了训练该模型，总损失已经被计算为下图所示的两个每像素交叉熵损失的<strong class="kh hj">加权和:第一个是基于语义FPN解码器的主预测计算的，第二个是基于来自所提出的轻量级解码器的语义先验预测计算的。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/d24e0ebcbc70824f237925f44cea4203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i2vAHpv7NHFQTHeHBiuU1w.png"/></div></div></figure><h1 id="1652" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">浅析SeMask</h1><blockquote class="lx ly lz"><p id="0ae5" class="kf kg lv kh b ki lb ij kk kl lc im kn ma ld kq kr mb le ku kv mc lf ky kz la hb bi translated">为了证实我们的假设，即在语义关注操作的帮助下在编码器中添加语义上下文有助于提高特征的语义质量，我们在Cityscapes val数据集上分析了SeMask-T FPN模型的中间特征的像素级关注质量，如下图所示</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/d78309e67d0e8f256256467bd9757892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n9RsVueDan2qBcFFuolQvw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/a1580c55b68b804d9505f8444ec13146.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*6eJrkQtUPTvAn-A2qe_moA.png"/></div></figure><blockquote class="lx ly lz"><p id="1856" class="kf kg lv kh b ki lb ij kk kl lc im kn ma ld kq kr mb le ku kv mc lf ky kz la hb bi translated">我们计算对应于目标像素(红色十字符号)的逐像素注意图，并且我们观察到，与前SeMask特征相比，后SeMask特征对于具有更好边界的相同语义类别区域具有更多相似特征。这反映了语义先验图有助于增加属于相同语义类别的像素之间的相似性，并改善语义分割性能。</p></blockquote><h1 id="ee45" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">结果</h1><h2 id="bcbc" class="mh jo hi bd jp mi mj mk jt ml mm mn jx ko mo mp jz ks mq mr kb kw ms mt kd mu bi translated">ADE20K数据集</h2><p id="0c28" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">下面是作者取得的结果，他们在<strong class="kh hj"> ADE20K数据集</strong>上获得了<strong class="kh hj">新的最先进的性能</strong>。</p><blockquote class="lx ly lz"><p id="1236" class="kf kg lv kh b ki lb ij kk kl lc im kn ma ld kq kr mb le ku kv mc lf ky kz la hb bi translated">使用SeMask Swin-L作为主要预测的编码器，Mask2Former-FaPN作为我们的解码器，我们在单尺度和多尺度mIoU度量上分别获得了56.97%和58.22%的分数。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nb"><img src="../Images/234a8ace7a4a67e08abd018cc8396e44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bl3sTv16BievuP7gj90JJQ.png"/></div></div></figure><h2 id="9564" class="mh jo hi bd jp mi mj mk jt ml mm mn jx ko mo mp jz ks mq mr kb kw ms mt kd mu bi translated">城市景观数据集</h2><p id="1719" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">在语义分割的另一个参考数据集Cityscapes上，Semask Swin-L与其他最先进的方法相比具有竞争力，SeMask Swin-L Mask2Former达到84.98% mIoU。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/44273c3e7e125bdd074e3a01675b7b73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E61Iqznbl6UnIQ-wDRZh1w.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/68e3e38b85f22ff0ac838d6ce4eab621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-BdOfayKE-7DpzoXud71w.png"/></div></div></figure><h1 id="7f23" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">结论</h1><p id="c398" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">本文提出了加入语义先验来指导编码器的特征建模，对语义分割有很好的影响，提高了分割精度和整体性能。</p><p id="f4d6" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">作者提出了SeMask块，它使用语义注意操作来捕获语义上下文，从而增强特征图的语义表示。</p><p id="a24d" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">真正有趣的特性是<strong class="kh hj">这个模块可以插入任何现有的层次视觉转换器</strong>！</p><p id="494e" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">如果你想了解更多关于这部作品的信息，我把所有的参考资料都留在了下面。</p><p id="9b8b" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated"><a class="ae ne" href="https://arxiv.org/abs/2112.12782" rel="noopener ugc nofollow" target="_blank">论文链接</a></p><p id="ce47" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated"><a class="ae ne" href="https://github.com/Picsart-AI-Research/SeMask-Segmentation" rel="noopener ugc nofollow" target="_blank"> GitHub页面链接</a></p></div><div class="ab cl nf ng gp nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="hb hc hd he hf"><blockquote class="nm"><p id="45c5" class="nn no hi bd np nq nr ns nt nu nv la dx translated">我希望你喜欢这篇文章！</p></blockquote><p id="4611" class="pw-post-body-paragraph kf kg hi kh b ki nw ij kk kl nx im kn ko ny kq kr ks nz ku kv kw oa ky kz la hb bi translated">如果你能开始在Medium或<a class="ae ne" href="https://www.linkedin.com/in/lorenzo-baiocco-lb/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我，在社交媒体上分享这篇文章，并使用下面的鼓掌按钮来支持我，我将不胜感激，当然，如果你喜欢的话！:D</p><p id="7aab" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated">最后，如果您还不是中等会员，您可以使用我的推荐链接成为中等会员:</p><p id="9e22" class="pw-post-body-paragraph kf kg hi kh b ki lb ij kk kl lc im kn ko ld kq kr ks le ku kv kw lf ky kz la hb bi translated"><a class="ae ne" rel="noopener" href="/subscribe/@lorebaiocco">https://medium.com/subscribe/@lorebaiocco</a></p></div></div>    
</body>
</html>