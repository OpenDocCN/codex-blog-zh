<html>
<head>
<title>Diabetes prediction system with KNN algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于KNN算法的糖尿病预测系统</h1>
<blockquote>原文：<a href="https://medium.com/codex/diabetes-predication-system-with-knn-algorithm-e040999229f7?source=collection_archive---------1-----------------------#2021-03-20">https://medium.com/codex/diabetes-predication-system-with-knn-algorithm-e040999229f7?source=collection_archive---------1-----------------------#2021-03-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d73f22eae26bf655a2b81494ca655aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MN9wiApZREB60UfxfYUoCg.png"/></div></div></figure><p id="b3cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我想处理这个迷你项目，就好像我有一个问题要解决一样，该项目将通过采用K-最近邻(KNN)预测模型来解决，因此显然这是一个分类模型挑战。在这种情况下，我选择了一个与医疗保健相关的数据集，该数据集与国家糖尿病和消化研究所的糖尿病数据库相关联，我将尝试测试该数据，看一个人是否患有糖尿病。该数据集是从Kaggle获得的，ka ggle是一个基于真实数据和事件提供各种不同数据集的网站。因此，事不宜迟，让我们开始解读数据集，并使用KNN和交叉验证模型创建一个预测模型。</p><p id="fa5d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数据集描述:</strong></p><p id="5a8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我已经从Kaggle获得了受试数据集，然而该数据集最初是由国家糖尿病、消化和肾脏疾病研究所提供的。数据集由预测变量和结果组成，其中描述了一个人是否是糖尿病患者。数据集代表来自不同患者的研究列表，其导致糖尿病或非糖尿病的分类。对于本课程，我将使用这些数据，并采用Knn算法来测试一些给定的患者数据，看看他们是否属于糖尿病或非糖尿病类别。该数据集中与糖尿病和非糖尿病患者相关的研究列表总数为768，我们将处理、废弃和清理这些数据，以在我们的KNN预测模型中使用它们。<br/>在我们开始使用Knn算法研究我们的预测模型之前，我们需要了解一下什么是KNN算法。</p><p id="1e8d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> KNN算法</strong>是一种处理相似性的监督机器学习算法。KNN代表K-最近邻。这基本上是一种分类算法，它将根据定义的最近邻数量来预测目标变量的类别。它将计算要分类的实例与训练数据集的每个实例之间的距离，然后根据k个最近实例的大多数类对实例进行分类。</p><p id="57ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">Knn算法中数据点之间的距离</strong></p><p id="6309" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这个项目，默认情况下，库将考虑欧几里德距离来测量数据集中两个数据点或向量之间的距离。</p><p id="576b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[1]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="3367" class="jx jy hi jt b fi jz ka l kb kc">import os<br/>from IPython.display import Image<br/>print("**Euclidean Distance Formula**")<br/>Image(filename="../input/euclidean-distance/euclidean distance.JPG", width= 500, height=200)</span><span id="3702" class="jx jy hi jt b fi kd ka l kb kc">**Euclidean Distance Formula**</span></pre><p id="bd3f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Out[1]:</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es ke"><img src="../Images/c8562428e60e47d337f969483b239e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/0*KEMqLpTLundUz8TS.jpg"/></div></figure><p id="d652" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阅读和探索数据集</strong></p><p id="c9db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面，我们首先使用pandas语法<strong class="is hj"> csv_read() </strong>打开主题数据集，该语法读取数据集并将其转换为结构化的表格数据供我们读取。</p><p id="aa6b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[2]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="fdf2" class="jx jy hi jt b fi jz ka l kb kc"><em class="kf"># First let's start with calling all the dependencies for this project </em><br/>import numpy as np <br/>import pandas as pd<br/>import math<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns <br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn import metrics<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.model_selection import KFold<br/>%matplotlib inline<br/></span><span id="9090" class="jx jy hi jt b fi kd ka l kb kc">location = '../input/diabetes/diabetes.csv'<br/>f = pd.read_csv(location)<br/>data = pd.DataFrame(f)<br/>data.head()</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kg"><img src="../Images/f15729bcb611b17941f59bd934b5f7fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*qIE0kqw8bs_JgdwF-kvu0Q.png"/></div></figure><p id="91e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">操作和清理我们的数据集</strong></p><p id="db44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本节中，我们将尝试清除数据集的所有零和缺失值(如NaN ),并用指定列的平均值替换它们。我已决定使用特定数量的色谱柱进行清洗，这些色谱柱如下文所述<strong class="is hj">[‘葡萄糖’，‘血压’，‘皮肤厚度’，‘胰岛素’，‘身体质量指数’，‘谱系’]</strong>，因为它们是最重要的数据，具有明显的影响，可确定患者是否患有糖尿病。</p><p id="5cff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[3]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="9e1f" class="jx jy hi jt b fi jz ka l kb kc"><em class="kf">#cleaning the dataset  from missing values or zeros</em><br/><em class="kf">#zeros or missing values will be replaced by the mean of that particular column</em><br/><em class="kf"># this practice is the best practie to have a readable and consistent data values</em><br/>cols_clean = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI','Pedigree']</span><span id="8ffd" class="jx jy hi jt b fi kd ka l kb kc"><em class="kf"># with this function , i dealt with missing values and NaN values </em><br/>for i <strong class="jt hj">in</strong> cols_clean:<br/>    data[i] = data[i].replace(0,np.NaN)<br/>    cols_mean = int(data[i].mean(skipna=True))<br/>    data[i] = data[i].replace(np.NaN, cols_mean)<br/>data1 = data<br/>data1.head().style.highlight_max(color="lightblue").highlight_min(color="red")</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/f036a79aa0efcccbf8a83b6a59b9dbb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*Y_c4X8virB0CeZ-aInswkw.png"/></div></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="2bdb" class="jx jy hi jt b fi jz ka l kb kc">In [4]:<em class="kf"><br/># Let's take a quick statistcal view of the data provided</em><br/>print(data1.describe())</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/618c144e3ef3265e527f6f49b973772b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*LNvswiy_UPMlpDPWoawyeA.png"/></div></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="563d" class="jx jy hi jt b fi jz ka l kb kc"><strong class="jt hj">Plotting the dataset</strong></span><span id="6899" class="jx jy hi jt b fi kd ka l kb kc">The diabetes updated dataset is ready for a basic plotting, in order to see how would our data looks like, also plotting at this stage will help me decide which column I will choose to run a K-nearest neighbour (KNN) experiment. For plotting I’ve used <strong class="jt hj">pairplot()</strong> function with the help of Seaborn library , that will give me a range of graph plotting for each group of data presented in the dataset .</span><span id="e12f" class="jx jy hi jt b fi kd ka l kb kc">In [5]:</span><span id="36ba" class="jx jy hi jt b fi kd ka l kb kc">graph = ['Glucose','Insulin','BMI','Age','Outcome']<br/>sns.set()<br/>print(sns.pairplot(data1[graph],hue='Outcome', diag_kind='kde'))</span><span id="13fe" class="jx jy hi jt b fi kd ka l kb kc">&lt;seaborn.axisgrid.PairGrid object at 0x7ff431934610&gt;</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kj"><img src="../Images/e5ab9306680f05d210356b1981eb5e8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*988U6rHqJwGOpLU2Pc546g.png"/></div></figure><p id="8d80" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">很明显，我们正在处理一个丰富的多维数据集，其中许多数据点属于所呈现的变量。为了使我们的生活更容易和简单，我们将只选择几个变量来测试我们的模型。</p><p id="a324" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[6]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="2e13" class="jx jy hi jt b fi jz ka l kb kc"><em class="kf"># for the purpose of simplicity and analysing the most relevent  data , we will select three features of the dataset</em><br/><em class="kf"># Glucose , Insulin and BMI</em><br/>q_cols = ['Glucose','Insulin','BMI','Outcome']</span><span id="7f43" class="jx jy hi jt b fi kd ka l kb kc"><em class="kf"># defining variables and features for the dataset for splitting </em><br/>df = data1[q_cols]<br/>print(df.head(2))</span><span id="3a90" class="jx jy hi jt b fi kd ka l kb kc">Glucose  Insulin   BMI  Outcome<br/>0    148.0    155.0  33.6        1<br/>1     85.0    155.0  26.6        0</span></pre><p id="4bb1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">将数据集分割成训练和测试数据集</strong></p><p id="7fa7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">机器学习建模或为机器学习算法准备数据的一个特别重要的部分是将我们的数据集分成训练和测试数据集。</p><p id="3005" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">主要是，数据集经历了一个分裂过程，以测试模型，测试过程将确定您的机器学习算法在预测每个测试集和训练集时的准确性，以及在现实世界中的形成方式。然后，我们获取提供的数据，并计算机器学习算法的准确率。理想情况下，你的机器学习算法的准确率越高，你的模型在预测呈现的样本数据时就越好。</p><p id="9f4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[7]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="2592" class="jx jy hi jt b fi jz ka l kb kc"><em class="kf"># let's split the data into training and testing datasets</em><br/>split = 0.75 <em class="kf"># 75% train and 25% test dataset</em><br/>total_len = len(df)<br/>split_df = int(total_len*split)<br/>train, test = df.iloc[:split_df,0:4],df.iloc[split_df:,0:4] <br/>train_x = train[['Glucose','Insulin','BMI']]<br/>train_y = train['Outcome']<br/>test_x = test[['Glucose','Insulin','BMI']]<br/>test_y = test['Outcome']</span></pre><p id="b714" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要运行一个快速语法来查看这些数据是否被正确分割</p><p id="ece1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[8]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="b24d" class="jx jy hi jt b fi jz ka l kb kc">a = len(train_x) <br/>b = len(test_x)<br/>print(' Training data =',a,'<strong class="jt hj">\n</strong>','Testing data =',b,'<strong class="jt hj">\n</strong>','Total data length = ',a+b)</span><span id="dcdd" class="jx jy hi jt b fi kd ka l kb kc">Training data = 576 <br/> Testing data = 192 <br/> Total data length =  768</span></pre><p id="3a0f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">处理样本测试数据和训练数据相似性的Knn算法。这种相似性由K值确定，这些值由最接近样本数据点的数据定义。在这种情况下，我们将使用两个距离度量来获得测试数据和训练数据集之间的最近距离。本练习中选择的距离度量是欧几里德距离，但是，我使用了一个内置的库来对模型运行这些操作，我使用的库是scikit-learn库。</p><p id="37d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> KNN功能</strong></p><p id="7a87" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我编写了一个函数来填充对拆分数据采用KNN算法的结果。该函数将运行KNN算法K次，并以线图的形式填充结果。</p><p id="a079" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[9]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="2a96" class="jx jy hi jt b fi jz ka l kb kc"><em class="kf"># let's test it using KNN  classifier with a loop to cover as much n-neightbors as possible </em><br/>def knn(x_train, y_train, x_test, y_test,n):<br/>    n_range = range(1, n)<br/>    results = []<br/>    for n <strong class="jt hj">in</strong> n_range:<br/>        knn = KNeighborsClassifier(n_neighbors=n)<br/>        knn.fit(x_train, y_train)<br/>        <em class="kf">#Predict the response for test dataset</em><br/>        predict_y = knn.predict(x_test)<br/>        accuracy = metrics.accuracy_score(y_test, predict_y)<br/>        <em class="kf">#matrix = confusion_matrix(y_test,predict_y)</em><br/>        <em class="kf">#seaborn_matrix = sns.heatmap(matrix, annot = True, cmap="Blues",cbar=True)</em><br/>        results.append(accuracy)<br/>    return results</span></pre><p id="331d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个练习中，我将测试并绘制K值从1到500的模型，看看我们在哪里有最好的整体K值</p><p id="4378" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在[10]中:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="86ec" class="jx jy hi jt b fi jz ka l kb kc">n= 500<br/>output = knn(train_x,train_y,test_x,test_y,n)<br/>n_range = range(1, n)<br/>plt.plot(n_range, output)</span></pre><p id="312c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Out[10]:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="ea7f" class="jx jy hi jt b fi jz ka l kb kc">[&lt;matplotlib.lines.Line2D at 0x7ff42c0bf450&gt;]</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kk"><img src="../Images/ac38a33627ccb4a46df92df0eb101c20.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*s1v-MD4HUXQnNGhC-f56gA.png"/></div></figure><p id="afe3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有机会试验从<strong class="is hj"> n=1到n=500 </strong>的不同K，从图中我可以得出结论，可以优化该模型的最佳K在<strong class="is hj"> 100到200 </strong>之间，提供77%的准确性。</p><p id="7120" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个数据集的理想k值应该是<strong class="is hj"> 120 </strong>左右。</p></div></div>    
</body>
</html>