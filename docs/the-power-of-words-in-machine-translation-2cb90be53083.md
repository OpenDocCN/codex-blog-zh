# 机器翻译中单词的力量

> 原文：<https://medium.com/codex/the-power-of-words-in-machine-translation-2cb90be53083?source=collection_archive---------11----------------------->

![](img/eaac2ce5b0221c74f883dbee9d2988fc.png)

照片:歌德学院。插图:EL BOUM

语言是交流、艺术、文化和社会结构的核心。然而，随着时间的推移，单个单词可以发挥不可思议的力量。

*作者阿拉娜·卡伦和普里扬卡·达斯古普塔*

语言不仅仅是文字，而是一种力量的载体。很多时候，它成为一种工具，让压迫性的系统发挥作用，并通过媒体微妙地揭示和维护社会等级制度。鲍里斯·约翰逊在英国退出欧盟问题上使用类似 T4 战争的语言被批评为在英国煽动暴力。而在荷兰，有人声称他们对新冠肺炎的封锁是“明智”的，认为他们“高人一等”。这只是语言和媒体框架导致国内和国际分歧的两个例子。

当谈到身份特征时，通过语言观察到类似的分裂和压迫性框架。为什么一个女人会被贴上“好斗、专横”或“母亲”的标签(T7)——因为同样的品质，她的男性同事可能会被称为雄心勃勃、善于管理，而且几乎从不认为“父亲”是一种主导身份？为什么用来描述白人公共射手的词汇大多比用来描述黑人或拉美裔的词汇更宽大？媒体和每个人使用的语言都有可能延续危险的刻板印象。

# **人为纠正**

必须解决历史上的不公正和今天使用的语言之间的联系，以防止偏见进一步深入社会。对于翻译来说也是如此，语境和内容一样重要。译者需要敏锐的眼光来注意所选词汇的社会和历史内涵。即使人工智能(AI)用于机器翻译，也会出现同样的问题。

机器翻译是一个有用的工具，而且每天都在变得越来越有用，但是当涉及到性别时，它经常出错。技术支持语言服务的国际提供商 RWS 的研究科学家 Danielle Saunders 说，机器翻译会犯这些错误，即使是在明确的情况下，原因有二；算法选择，例如当算法有动机产生具有更常见词汇的翻译时

数据选择，例如男性词汇在可用于训练的数据集中更常见。例如，如果人工智能根据欧洲议会的演讲进行训练(这种情况经常发生)，那么人工智能将在自己的翻译中反映演讲中的偏见，例如，重申选择男医生而不是女医生的工作角色偏见。男性语言习惯进一步扭曲了这一点。

作为一个相对空白的画布，有机会纠正人工智能中的这些初始偏见。也许最显而易见的方法是给训练材料增加更多的平衡:但这是昂贵的，因为它需要生成新的训练数据集，而增加一层复杂性将有产生更多偏见的风险。我们甚至还没有谈到替代的，非二进制代词，机器翻译经常会弄错性别。随着文化讨论的发展，非二元、替代或新代词的整合需要在其实践方面有所发展。桑德斯指出，增加这种复杂性的问题是“机器翻译学得快，忘得也快”，这是一种称为“灾难性遗忘”的现象，可能发生在人工智能必须学习新信息的时候。虽然接受灾难性遗忘的风险是一种选择，但用新材料进行再培训可能会有失去机器翻译质量的风险。一个可行的选择是将性别视为拼写检查——为用户提供选择——这种选择可以包含非二进制代词，例如德语的 Xier-代词。

# **“重建真理”**

交叉正义中心的创始人兼主任 Emilia Roig 说，有必要“重建真相”，以真实的方式摆脱压迫性的制度。在解构单词以及我们觉得不舒服的上下文时，译者可以帮助找到正确的单词。例如，在葡萄牙语中,“被奴役”这个词现在比原来的“奴隶”更受欢迎——表示某人所处的地位。我们选择的词语可以揭示我们社会的苦恼；它们还可以帮助建立更好的结构，引导我们的对话，并为我们提供创建公平对话的工具。在翻译、人和机器以及日常生活中，我们必须问自己:什么是正确的词汇，它们有什么力量？
当我们考虑到我们今天使用的语言在 20 年、50 年、100 年后将不会与我们现在使用的语言相同时，就增加了最后一层复杂性。语言不是我们可以规定的，而是不断进化的。语言的这种不断变化的性质必须反映在人工智能设计中，以允许在未来几年快速而容易地适应语言。

## 作者

Alana Cullen 和 Priyanka Dasgupta 的这篇文章是在一个关于人工智能、偏见和机器翻译的研讨会的背景下撰写的(23。-24.4.2021).

*原载于*[*https://www . Goethe . de*](https://www.goethe.de/prj/one/en/aco/art/22267118.html)*。*