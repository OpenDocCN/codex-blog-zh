<html>
<head>
<title>ImVoteNet: Paper Overview and Code Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ImVoteNet:论文概述和代码分析</h1>
<blockquote>原文：<a href="https://medium.com/codex/imvotenet-paper-review-and-code-analysis-bf103117b32e?source=collection_archive---------5-----------------------#2021-07-08">https://medium.com/codex/imvotenet-paper-review-and-code-analysis-bf103117b32e?source=collection_archive---------5-----------------------#2021-07-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="f63f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">利用图像投票促进点云中的3D对象检测</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/00007e51b99f0e16867d62268c35a05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYO-C0yYtAzgCY3bH2yLCA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">融合图像中的2D投票和点云中的3D投票。学分:<a class="ae jn" href="https://camo.githubusercontent.com/b06ebcac5afb2566b8f0f559a7a710ea9613166861041458946a3dcbf2c2d2c2/687474703a2f2f78696e6c6569632e78797a2f696d616765732f696d766f74652e706e67" rel="noopener ugc nofollow" target="_blank"> facebookresearch </a></figcaption></figure><blockquote class="jo jp jq"><p id="9a93" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">请注意，这篇文章的目的是记录并有意义地与任何有兴趣了解这种艺术级架构的人分享我的学习。</p></blockquote><p id="14c8" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">实现最先进的算法似乎是一项相对简单的任务。从某个存储库中复制粘贴几行，瞧！即使我们考虑恼人的编译错误和不兼容的版本错误，实现别人的代码也是不值得称赞的。然而，如果在花了一周的时间试图解决令人沮丧的错误后，你终于训练好了你的模型，但仍然不能在一组随机的图像和点云上使用它，那该怎么办呢！要理解为什么ImVoteNet演示不能马上进行，恐怕您必须继续阅读。如果这似乎有点太繁琐，你可以直接跳到我的GitHub帐户<a class="ae jn" href="https://github.com/Sakshee5/imvotenet" rel="noopener ugc nofollow" target="_blank"> <em class="jt">这里</em> </a>马上尝试一下3D物体检测演示。</p><p id="0c7b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">说了这么多，让我们来看看这篇论文是关于什么的。</p><h1 id="9300" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">介绍</h1><p id="5049" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">术语'<a class="ae jn" href="https://arxiv.org/abs/2001.10692" rel="noopener ugc nofollow" target="_blank"> ImVoteNet </a>'不过是单词' Image '和' VoteNet '的混合。这里的图像指的是简单的RGB图像，而<a class="ae jn" href="https://arxiv.org/abs/1904.09664" rel="noopener ugc nofollow" target="_blank"> VoteNet </a>是作者的另一种3D对象检测架构，该网络建立在该架构上。VoteNet论文发表于2019年，展示了仅使用点云输入的最先进性能。</p><p id="0fac" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">然而，点云数据具有固有的局限性。它们很稀疏，缺少颜色信息，并且经常受到传感器噪声的影响。另一方面，图像分辨率高，纹理丰富。此外，图像可以覆盖主动深度传感器的“盲区”，这通常是由于反射表面而出现的。因此，作者得出结论，2D信息可以补充点云提供的3D几何图形，这反过来是这种架构背后的动机。</p><p id="bd29" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">本文介绍了一种用于融合2D和3D数据的健壮技术<strong class="ju hj">,通过5.7 mAP提高了最先进的结果。这里的“地图”指的是来自具有挑战性的<a class="ae jn" href="https://rgbd.cs.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> SUN RGB-D数据集</a>的10类物体的平均精度，该模型已经在该数据集上进行了训练。</strong></p><h1 id="b8cd" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">ImVoteNet建筑</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lo"><img src="../Images/7931ad05f9626e7c9ddb6bdc0a49fc80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xAK31cJSGXxz3KkdjnudmQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">3D对象检测流水线</figcaption></figure><p id="5fbb" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">为便于理解，我们将上述结构分为3个部分:</p><ol class=""><li id="0170" class="lp lq hi ju b jv jw jy jz ko lr kp ls kq lt kn lu lv lw lx bi translated">使用<a class="ae jn" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">更快的RCNN </a>主干从2D检测中提取图像投票(左上半部分)</li><li id="b3fd" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn lu lv lw lx bi translated">深度霍夫投票用<a class="ae jn" href="https://arxiv.org/abs/1706.02413?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> PointNet++ </a>主干(左下半部分)</li><li id="4133" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn lu lv lw lx bi translated">功能融合和多塔训练(右半部分)</li></ol><blockquote class="jo jp jq"><p id="c431" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">乍一看，该架构可能有点误导，因为它显示它输入RGB图像和相应的点云模型来输出3D检测。实际上，该模型从RGB图像中提取几何、语义和纹理线索，这些线索又作为输入馈送给网络。因此，我们可以说该架构的左上方属于数据处理管道，而不是培训管道。</p></blockquote><p id="f364" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">为了彻底理解，让我们分别处理这些部分:</p><h1 id="93ca" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">1.提取图像投票</h1><p id="f4f2" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">ImVoteNet的官方存储库直接提供来自预训练的更快RCNN模型的2D检测。<strong class="ju hj">通过使用这些下载的检测文本文件中提供的信息，以几何、语义和纹理线索</strong>的形式生成2D图像投票。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es md"><img src="../Images/25bf040aeee49b3da95c8abae305995f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*a4X5I3xdGPAw48DUHyelIA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">用于2D物体检测的预训练快速RCNN主干</figcaption></figure><p id="1bfb" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">在深入什么是“图像投票”或“线索”之前，首先让我们简单了解一下什么是更快的RCNN输出，因为它用于提取所述线索。</p><p id="9b8b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">根据ImVoteNet的官方知识库:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/7d45fac6ba33e1fc8f9c96a3de59600d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPQAY4aPBehSSIRGHG-3VA.png"/></div></div></figure><p id="1e83" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">我们可以看到，来自预训练的更快RCNN模型的2D检测被直接提供用于下载。预训练模型本身不可下载。给定文件的下载和解压缩会产生一个与数据集中的每个图像相对应的. txt文件。</p><p id="12a5" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">每个。txt文件包含100行，对应于每幅图像检测到的100个对象。下面是示例文本文件的前几行:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mf"><img src="../Images/fc13ee79a07771ee8d42480995801be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tyI-3JvHtvAdHclD5keHEg.png"/></div></div></figure><p id="ba35" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">让我们快速分解一下这些值是什么:</p><ul class=""><li id="c437" class="lp lq hi ju b jv jw jy jz ko lr kp ls kq lt kn mg lv lw lx bi translated">对于每一行，首先我们有来自模型被训练的10个类的<strong class="ju hj">类标签</strong>。这10类是床、桌子、沙发、椅子、马桶、书桌、梳妆台、床头柜、书架和浴缸。</li><li id="f359" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn mg lv lw lx bi translated">接下来的3个值是冗余常数。</li><li id="3265" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn mg lv lw lx bi translated">接下来的4个值按照Xmin、Ymin、Xmax和Ymax的顺序定义了<strong class="ju hj">边界框</strong>，其中最小值定义了边界框的左上角，最大值定义了边界框的右下角。请注意，这些值不是标准化的。(图像尺寸:730像素宽x 530像素高)</li><li id="1daa" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn mg lv lw lx bi translated">最后一个值是<strong class="ju hj">对象性得分</strong>，它是一个介于0到1之间的浮点值。它简单地定义了检测器对于它声称已经检测到的对象的置信度。</li></ul><p id="c862" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">下面是一个代码片段，它加载一个给定的文本文件，并根据我们提取所讨论的线索的要求对其进行处理。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mh mi l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">加载和处理从快速RCNN提取的2D包围盒信息</figcaption></figure><h2 id="07f9" class="mj ks hi bd kt mk ml mm kx mn mo mp lb ko mq mr ld kp ms mt lf kq mu mv lh mw bi translated">几何、语义和纹理线索的提取</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mx"><img src="../Images/5b0b21b090b600badd9d64f3df4029a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*R6RUGXcBRPN3aYVFGZFLqQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">提取线索</figcaption></figure><h2 id="268a" class="mj ks hi bd kt mk ml mm kx mn mo mp lb ko mq mr ld kp ms mt lf kq mu mv lh mw bi translated">几何线索</h2><p id="70e0" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">首先，什么是形象投票？</p><p id="d61b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">引用作者的话，“图像投票，就其几何部分而言，只是一个连接图像像素和该像素所属的2D对象边界框中心的向量。”</p><blockquote class="jo jp jq"><p id="20df" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">仅允许属于过滤的2D检测框内的图像像素投票。此外，多个框内的像素被给予多次投票，而不属于任何边界框的像素用零填充。查看下面相同的代码实现。</p></blockquote><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mh mi l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">提取几何线索</figcaption></figure><h2 id="8cc1" class="mj ks hi bd kt mk ml mm kx mn mo mp lb ko mq mr ld kp ms mt lf kq mu mv lh mw bi translated">几何线索:将图像投票提升到3D</h2><p id="8d4f" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">图像平面中的2D物体中心可以表示为3D空间中的光线，该光线借助于固有相机矩阵连接3D物体中心和相机光学中心。下图显示了这一点。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es my"><img src="../Images/8c6e840cd9d9a932ef7f65884e269688.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*F5FcbL1PVg3aQZVF5au31g.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">伪3D投票生成背后的直觉</figcaption></figure><p id="3c8b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">设，<br/> P = (x1，y1，z1) —点云中物体表面的点</p><p id="aef8" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">C = (x2，y2，z2)-3D对象的中心点</p><p id="2fe3" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">p = (u1，v1) —点P在2D图像上的投影</p><p id="e99d" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">c = (u2，v2) —点C在2D图像上的投影</p><p id="4cdb" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">我们可以观察到，2D投票将3D对象中心的搜索空间缩小到一条线(线OC ),其中只有z值在变化。</p><p id="46be" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">此外，我们可以将PC向量，即从点P到投票中心的真实3D投票表示为</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/e3b9329b559bced5f87145d73f61305d.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/0*zSblX6mJTxKlZSZU.png"/></div></figure><p id="3e21" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">和pc，即假设焦距f为的2D投票向量</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/86dd6757867463a7671c0d46863f976d.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*pDKh8bMLqSI4DdDr.png"/></div></figure><p id="0f08" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">使用Y维的相似关系作为v1/f = y1/z1和v2/f = y2/z2</p><p id="1d27" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">因此，我们计算伪3D投票向量PC '其中C '在射线OC上，如下所示</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nb"><img src="../Images/7ffcf9c98e37c896947cd631d7904dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/0*Pr6cclJzABR0bqRL.png"/></div></figure><p id="f1ed" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">假设点P的表面深度和中心深度是相同的，这是合理的，考虑到物体不是非常靠近照相机的事实。</p><p id="40a8" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">因为我们假设z1=z2，所以上面提到的深度关系表示误差(在求导之后沿着x轴)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/44814085ca4a4f2d2a207d109d012c90.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/0*AoYRjZa-31EpvvB9.png"/></div></figure><p id="d2b5" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">根据PC '和OP，我们可以得到真正的几何提示</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nd"><img src="../Images/de93a2f1ce89ba3cb9909190cb9b3faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/0*lOfGI5V5nLNDLOj-.png"/></div></figure><p id="514d" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">在执行一个规范后，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ne"><img src="../Images/8a300aa8fcc5110b8cf7bf4b6db21789.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/0*80QmobKb7-d6G8ut.png"/></div></figure><p id="9451" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">我们来讨论一下上式中的三个维度。首先，表面点P需要2D图像传递给它的几何信息，在这种情况下，搜索空间被压缩到1D(射线OC’)。所计算的是2D图像被投影到3D的位置。最后一个维度是到3D表面点的光线方向信息，以补偿由于深度近似(z1 = z2)引起的误差。</p><p id="e419" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">目前，我们有一个直观的图像投票是什么，由2D边界框的空间坐标表示。然而，每张图片的投票还会增加其语义和纹理线索。我们来看看这些是怎么定义的。</p><p id="8dd6" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated"><strong class="ju hj">语义提示</strong></p><p id="2eed" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">与稀疏点云相比，RGB图像可以更好地传达图像内容的语义。这种来自2D图像的输入将有利于区分具有类似几何形状的类别，如桌子与书桌或床头柜与梳妆台。语义线索背后的思想是用一个简单的独热类向量来表示图像中检测到的每个边界框，该向量具有该类的置信度得分。</p><p id="ca65" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">对应于特定边界框的该独热编码矢量被传递给投影在该2D框内的所有3D点。如果一个3D点落入多个2D盒中，它将被复制，而那些没有落入任何盒中的点将被填充全零特征向量。总而言之，我们将提取10维语义线索向量(与10个SUN RGB-D类相关联)。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mh mi l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">从2D检测中提取语义线索</figcaption></figure><p id="daee" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated"><strong class="ju hj">纹理提示</strong></p><p id="ca80" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">简单地说，纹理线索是图像的原始RGB像素值。它们的重要性在于，与点云不同，2D RGB图像非常密集地捕捉高分辨率信号，进而显示良好的纹理内容。首先，三个通道图像像素首先被归一化为[-1，1]，然后被转换为一维。注意，我们将提取一个三维纹理线索向量。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mh mi l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">提取纹理线索</figcaption></figure><p id="8351" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">注意，除了这些线索之外，还提供相机参数(<strong class="ju hj">内在(calib_K) </strong>和<strong class="ju hj">外在(calib_Rtilt) </strong>矩阵)和常数值(<strong class="ju hj">比例</strong>)作为输入，以帮助将这些提取的特征提升到3D。在进入下一节之前，让我们简要讨论一下这些输入的作用。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nf"><img src="../Images/154368b8a5b8dcc099735908e231a500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BAnsNwCDpyUODsaK6h_WjA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">利用相机外部性的图像投票提升</figcaption></figure><p id="f04b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">在SUN RGB-D数据集中定义了五个坐标系。其中两个是垂直深度坐标(Z是向上的轴，Y是向前的，X是向右的)和相机坐标，如上所示。竖直坐标被Rtilt倾斜，使得Z是重力方向。点云输入(接下来讨论)在直立坐标中表示，因此3D伪投票也需要转换到相同的坐标。这是因为网络不能估计沿着z摄像机方向的深度位移，因为从摄像机到直立坐标的旋转角度对于网络是未知的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/d79abd3d9db7d179beab8ee3dca4b419.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*1sc6Np3fEPrmz50egar4EA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">模型输入。截图来自<a class="ae jn" href="https://github.com/Sakshee5/imvotenet/blob/master/demo.py" rel="noopener ugc nofollow" target="_blank"> demo.py </a></figcaption></figure><h1 id="0256" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">2.深度霍夫投票</h1><blockquote class="jo jp jq"><p id="cc01" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">一定要看看<a class="ae jn" href="https://www.youtube.com/watch?v=XRBc_xkZREg" rel="noopener ugc nofollow" target="_blank">霍夫变换</a>来获得投票在数学意义上如何工作的基本直觉。</p></blockquote><p id="e904" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">这部分架构基于VoteNet，这是一个前馈网络，输入3D点云并输出3D对象检测的对象建议。让我们粗略地看一下VoteNet管道。</p><p id="139e" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">输入是N×3点云，即由具有3个坐标属性的N个点组成的点云。首先，点云通过作为特征提取器的PointNet++主干网络。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nh"><img src="../Images/5df756fc163cfcf58da8547ca6e9805f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rU0yVgPHj6l2R9hMnmA9Jw.png"/></div></div></figure><p id="40dd" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">特征提取器采样M个种子点，同时还用C维特征向量扩充每个点。因此，每个点与3+C(坐标+深度)特征的属性相关联。</p><blockquote class="jo jp jq"><p id="95fa" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">总而言之，每一个投票既是3D空间中的一个点，其欧几里德坐标(3-dim)被监督为接近对象中心，也是为最终检测任务(C-dim)学习的特征向量。</p></blockquote><p id="242f" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">这些特征然后通过多层感知器(MLP)产生投票。这正是ImVoteNet架构的构建基础。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ni"><img src="../Images/864d907f8c896cb626bedc66fc2ea49b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YYK_oLL9gbmeA8pk.png"/></div></div></figure><p id="e04f" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated"><em class="jt">注意，K个种子等价于M个种子，F维向量只不过是来自VoteNet管道的C维向量。</em></p><p id="f3cf" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">然而，对于VoteNet，投票直接由另一个点云网络处理，以生成对象提议和分类分数，而对于ImVoteNet，它们与提升的2D投票融合，以经历多塔训练。ImVoteNet选择了多模型方法，这将在下一节讨论。</p><h2 id="f815" class="mj ks hi bd kt mk ml mm kx mn mo mp lb ko mq mr ld kp ms mt lf kq mu mv lh mw bi translated">总结一下；</h2><p id="657d" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">下面是我在上面讨论的两个部分的代码实现中观察到的一些见解:</p><ul class=""><li id="f6c5" class="lp lq hi ju b jv jw jy jz ko lr kp ls kq lt kn mg lv lw lx bi translated">输入点云由20k(=N)个随机采样点组成。点云也通过从动态深度图像中随机子采样点来扩充。使用增强技术，如翻转、沿上轴均匀旋转[-30，30]度、均匀缩放[-85，1.15]。</li><li id="6e9e" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn mg lv lw lx bi translated">20k点云输入被PointNet++主干转换成1024(=M)个种子。每个种子与其3个空间坐标和256(=F)维特征向量相关联。</li><li id="0ca8" class="lp lq hi ju b jv ly jy lz ko ma kp mb kq mc kn mg lv lw lx bi translated">总而言之，2D图像投票生成管道，每个复制的种子点的特征通过以下图像投票特征的连接而增强:5维提升几何线索(2个用于投票，3个用于光线角度)、10维(每类)语义线索和3维纹理线索。因此，融合的种子点与其3个空间坐标和274(= F’)维特征向量相关联。</li></ul><h1 id="fc3c" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">3.特征融合和多塔训练</h1><p id="87e5" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">因此，现在我们有了来自点云主干网络的K x(3+F’)dim提升2D投票和K x (3 + F) dim 3D点特征。这些特征被进一步串联用于训练。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nj"><img src="../Images/4ee1f44f00d6ecbd41c42e073deda7ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/0*9lIBkykPR9t8qTs8.png"/></div></figure><p id="7121" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">如上图所示，我们有三个训练塔:形象塔，联合塔，点塔。相应的输入仅为图像特征、关节特征和点云特征。每个塔都有相同的探测3D物体的目标任务，但它们都有自己的3D投票和盒子提议网络参数以及自己的损失。拥有三个独立训练塔的原因是为了避免级联设计。例如，如果3D物体提议仅仅基于2D物体检测输出，那么在2D错过的物体在3D中也会被错过。</p><p id="99d4" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">尽管如此，对于这样一个多塔楼的网络结构，由于不同的学习速率，两种模态可能最终被第三种模态所支配。这可以用<a class="ae jn" href="https://arxiv.org/abs/1905.12681" rel="noopener ugc nofollow" target="_blank">渐变混合</a>来避免，这本身是另一个新颖的想法，不幸的是超出了本文的范围。</p><p id="c720" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">因此，最终的训练损失是三个检测损失的加权和:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nk"><img src="../Images/e7f3b2fe7d6e7ca7e23b9886ee92da1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/0*UIvDJVcTUJwnm9Af.png"/></div></figure><p id="7ac0" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated">注意，在推理时，只有联合塔用于最小化计算开销。</p><h1 id="afe2" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">结论</h1><p id="4644" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">本文通过将ImVoteNet体系结构分成三个部分来讨论它，以便对本文后面的3D对象检测管道有一个全面的了解。它还受到与以正确格式生成模型输入相关的代码片段的支持。</p><blockquote class="jo jp jq"><p id="9bdb" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">注意:文章中提供的代码来自我的<a class="ae jn" href="https://github.com/Sakshee5/imvotenet" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中的demo.py脚本。然而，该脚本确实使用了来自官方ImVoteNet存储库的代码片段。文章中的图片是来自官方文件/存储库的截图。两者都在下面被提及。</p></blockquote><h1 id="62a2" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">参考</h1><p id="965d" class="pw-post-body-paragraph jr js hi ju b jv lj ij jx jy lk im ka ko ll kd ke kp lm kh ki kq ln kl km kn hb bi translated">【https://arxiv.org/abs/2001.10692 T4】</p><p id="1e1f" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated"><a class="ae jn" href="https://github.com/facebookresearch/imvotenet" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/imvotenet</a></p><p id="2a88" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka ko kc kd ke kp kg kh ki kq kk kl km kn hb bi translated"><a class="ae jn" href="https://www.programmersought.com/article/80886180098/" rel="noopener ugc nofollow" target="_blank">https://www.programmersought.com/article/80886180098/</a></p></div></div>    
</body>
</html>