<html>
<head>
<title>Web Scraping Using BeautifulSoup + Pushing Data to MySQL Database</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用BeautifulSoup +将数据推送到MySQL数据库的网络抓取</h1>
<blockquote>原文：<a href="https://medium.com/codex/web-scraping-using-beautifulsoup-pushing-data-to-mysql-database-9de6af06e7b8?source=collection_archive---------1-----------------------#2021-09-12">https://medium.com/codex/web-scraping-using-beautifulsoup-pushing-data-to-mysql-database-9de6af06e7b8?source=collection_archive---------1-----------------------#2021-09-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a168" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">通过定期从网站收集和记录数据来创建自己的数据集。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/a32f54e1cd3e2d036e13f3adeaf301af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Qt9ap-rO9kWcuXSx"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">由<a class="ae jn" href="https://unsplash.com/@alfonsmc10?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿尔方斯·莫拉莱斯</a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="f7f8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在本文中，我们将学习如何使用BeautifulSoup从web的HTML内容中抓取数据，beautiful soup是一个流行的用于web抓取的Python包。然后，我们将学习如何将数据推入MySQL数据库中的一个表中。</p><h2 id="5664" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">用BeautifulSoup抓取HTML数据</h2><p id="3698" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">BeautifulSoup是一个用于解析HTML和XML文档的Python包。通过网络浏览器访问的每个网站都由HTML文档组成，通过查看页面可以看到这些文档。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lk"><img src="../Images/b287d998c0196f774c1c6ff636def9af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9u3eUKlDvxdfvmEKJZxIQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">Book Depository的新发布页面和HTML。—图片由作者提供。</figcaption></figure><p id="aecc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">比方说，你是个书呆子。你想通过书库的新书来更新自己，并且你想定期更新你的列表。你可以时不时地在Book Depository的网站上查看新的发行页面(通过访问<a class="ae jn" href="https://www.bookdepository.com/top-new-releases" rel="noopener ugc nofollow" target="_blank">https://www.bookdepository.com/top-new-releases</a>)，但你认为如果你能收集数据并以表格形式保存，处理这些信息会容易得多。</p><p id="a46c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在检查了该网站的元素后，您发现该页面中的所有book元素都存储在div标签下，并带有<code class="du ll lm ln lo b">"book-item"</code>类。从每个book-item元素中，您可以获得各种信息，如ISBN、标题、作者姓名、出版日期、图书格式和价格。你想记录所有信息，加上一个额外的信息，即刮削日期。所以，现在你有一个粗略的计划，为您的网页抓取之旅:(1)首先，从HTML抓取信息，并将其转换为表格格式，和(2)保存表格到外部位置。为了简单起见，我们将使用requests包发送HTTP请求以获得HTML响应，使用BeautifulSoup解析HTML，使用pandas将信息转换为DataFrame，最后使用sqlalchemy包将所有数据推送到MySQL数据库。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lp"><img src="../Images/9418b1cd69a857173c32d4467b75c9df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kiYOne5pyiaH__aS1j5b0w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图书仓库新发布页面中图书项目的HTML标签-图片由作者提供。</figcaption></figure><p id="62ab" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用Python包管理器安装BeautifulSoup。如果您使用pip，请使用<code class="du ll lm ln lo b">pip install beautifulsoup4</code>进行安装。然后，导入几个包，并开始通过HTTP请求请求HTML。</p><pre class="iy iz ja jb fd lq lo lr ls aw lt bi"><span id="ed66" class="kk kl hi lo b fi lu lv l lw lx">import requests<br/>import pandas as pd<br/>import datetime<br/>from bs4 import BeautifulSoup<br/>from sqlalchemy import create_engine</span><span id="2abc" class="kk kl hi lo b fi ly lv l lw lx">URL = '<a class="ae jn" href="https://www.bookdepository.com/top-new-releases" rel="noopener ugc nofollow" target="_blank">https://www.bookdepository.com/top-new-releases</a>'<br/>page = requests.get(URL)<br/>soup = BeautiulSoup(page.content, "html.parser")<br/>books = soup.find_all("div", class_ = "book-item")</span></pre><p id="d2ed" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在上面的代码片段中，get请求被发送到URL。存储在<code class="du ll lm ln lo b">page</code>变量中的响应，该变量后来通过使用BeautifulSoup对象转换成一个解析的数据对象。然后，我们用<code class="du ll lm ln lo b">book-item</code>类获取所有HTML元素，并将其存储在<code class="du ll lm ln lo b">books</code>列表中。<code class="du ll lm ln lo b">books</code>变量由数百个book元素组成，每个元素如下所示:</p><pre class="iy iz ja jb fd lq lo lr ls aw lt bi"><span id="6c40" class="kk kl hi lo b fi lu lv l lw lx">print(books[0])</span><span id="3910" class="kk kl hi lo b fi ly lv l lw lx">===============</span><span id="7998" class="kk kl hi lo b fi ly lv l lw lx">&lt;div class="book-item" itemscope="" itemtype="<a class="ae jn" href="http://schema.org/Book" rel="noopener ugc nofollow" target="_blank">http://schema.org/Book</a>"&gt;<br/>&lt;div class="item-img"&gt;<br/>&lt;a href="/Mirror-Light-Hilary-Mantel/9780007481002" itemprop="url"&gt;<br/>&lt;img alt="The Mirror and the Light" class="lazy" data-lazy="<a class="ae jn" href="https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/mid/9780/0074/9780007481002.jpg" rel="noopener ugc nofollow" target="_blank">https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/mid/9780/0074/9780007481002.jpg</a>"/&gt;<br/>&lt;/a&gt;<br/>&lt;/div&gt;<br/>&lt;meta content="9780007481002" itemprop="isbn"/&gt;<br/>&lt;meta content="The Mirror and the Light" itemprop="name"/&gt;<br/>&lt;meta content="Hilary Mantel" itemprop="contributor"/&gt;<br/>&lt;div class="item-info"&gt;<br/>&lt;h3 class="title"&gt;<br/>&lt;a href="/Mirror-Light-Hilary-Mantel/9780007481002"&gt;<br/>                    The Mirror and the Light&lt;br/&gt;<br/>&lt;/a&gt;<br/>&lt;/h3&gt;<br/>&lt;p class="author"&gt;<br/>&lt;a href="/author/Hilary-Mantel" itemprop="author"&gt;Hilary Mantel&lt;/a&gt;<br/>&lt;/p&gt;<br/>&lt;div class="rating-wrap"&gt;<br/>&lt;a aria-label="Ratings for The Mirror and the Light" href="/Mirror-Light-Hilary-Mantel/9780007481002"&gt;<br/>&lt;div class="stars"&gt;<br/>&lt;span class="star full-star"&gt;&lt;/span&gt;<br/>&lt;span class="star full-star"&gt;&lt;/span&gt;<br/>&lt;span class="star full-star"&gt;&lt;/span&gt;<br/>&lt;span class="star full-star"&gt;&lt;/span&gt;<br/>&lt;span class="star half-star"&gt;&lt;/span&gt;<br/>&lt;/div&gt;<br/>&lt;/a&gt;<br/>&lt;/div&gt;<br/>&lt;p class="published" itemprop="datePublished"&gt;29 Apr 2021&lt;/p&gt;<br/>&lt;p class="format"&gt;Paperback&lt;/p&gt;<br/>&lt;div class="price-wrap"&gt;<br/>&lt;p class="price"&gt;<br/>                        Rp271.455&lt;/p&gt;<br/>&lt;/div&gt;<br/>&lt;/div&gt;<br/>&lt;div class="item-actions"&gt;<br/>&lt;div class="btn-wrap"&gt;<br/>&lt;a class="btn btn-sm btn-primary add-to-basket" data-currency="IDR" data-isbn="9780007481002" data-price="271455" data-ref="carousel" data-show-related="false" href="/basket/addisbn/isbn13/9780007481002" rel="nofollow"&gt;<br/>                        Add to basket&lt;/a&gt;<br/>&lt;/div&gt;<br/>&lt;/div&gt;<br/>&lt;/div&gt;</span></pre><p id="a41a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">根据元素的结构，我们可以决定从哪里获取我们需要的信息。例如，ISBN、价格和货币可以用<code class="du ll lm ln lo b">"btn btn-sm btn-primary add-to-basket"</code>类从标签<code class="du ll lm ln lo b">a</code>中提取。可以从itemprop的带有<code class="du ll lm ln lo b">"name"</code>属性的<code class="du ll lm ln lo b">meta</code>标签中抓取标题，其中作者姓名、图书格式和出版日期可以分别从带有<code class="du ll lm ln lo b">"author"</code>、<code class="du ll lm ln lo b">"format"</code>和<code class="du ll lm ln lo b">"published"</code>类的<code class="du ll lm ln lo b">p</code>标签中抓取。</p><p id="20cd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于第一个book元素，可以使用以下几行代码来抓取每条信息:</p><pre class="iy iz ja jb fd lq lo lr ls aw lt bi"><span id="006e" class="kk kl hi lo b fi lu lv l lw lx">book_title = books[0].find("meta", {"itemprop":"name"}).get("content")</span><span id="9b8a" class="kk kl hi lo b fi ly lv l lw lx">book_author = books[0].find("p", class_ = "author").find("a").text</span><span id="ad3b" class="kk kl hi lo b fi ly lv l lw lx">book_format = books[0].find("p", class_ = "format").text</span><span id="5023" class="kk kl hi lo b fi ly lv l lw lx">book_published = books[0].find("p", class_ = "published").text</span><span id="3b3a" class="kk kl hi lo b fi ly lv l lw lx">book_isbn = books[0].find("a", class_ = "btn btn-sm btn-primary add-to-basket").get("data-isbn")</span><span id="708b" class="kk kl hi lo b fi ly lv l lw lx">book_currency = books[0].find("a", class_ = "btn btn-sm btn-primary add-to-basket").get("data-currency")</span><span id="4e57" class="kk kl hi lo b fi ly lv l lw lx">book_price = books[0].find("a", class_ = "btn btn-sm btn-primary add-to-basket").get("data-price")</span></pre><p id="9b45" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">要从所有book元素中抓取信息，创建一个字典，其中每个键对应于每一列(例如标题、作者或isbn)，每个值包含相应列的值列表。然后，迭代到<code class="du ll lm ln lo b">books</code>变量，并通过使用与前面代码片段所示相同的方法抓取单个信息来追加每个列表。</p><pre class="iy iz ja jb fd lq lo lr ls aw lt bi"><span id="6cef" class="kk kl hi lo b fi lu lv l lw lx">books_dict = {'title':[], 'author':[], 'format':[], 'published':[], 'isbn':[], 'currency':[], 'price':[], 'date':[]}</span><span id="6da2" class="kk kl hi lo b fi ly lv l lw lx">for b in books:<br/>     books_dict['title'].append(b.find("meta", {"itemprop":"name"}).get("content"))<br/>     books_dict['author'].append(b.find("p", class_ = "author").find("a").text)<br/>     books_dict['format'].append(b.find("p", class_ = "format").text)<br/>     books_dict['published'].append(b.find("p", class_ = "published").text)<br/>     books_dict['isbn'].append(b.find("a", class_ = "btn btn-sm btn-primary add-to-basket").get("data-isbn"))<br/>     books_dict['currency'].append(b.find("a", class_ = "btn btn-sm btn-primary add-to-basket").get("data-currency"))<br/>     books_dict['price'].append(b.find("a", class_ = "btn btn-sm btn-primary add-to-basket").get("data-price"))<br/>     books_dict['date'].append(datetime.date.today())</span></pre><p id="b4b0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后，将字典转换成熊猫数据框架。</p><pre class="iy iz ja jb fd lq lo lr ls aw lt bi"><span id="983a" class="kk kl hi lo b fi lu lv l lw lx">df = pd.DataFrame.from_dict(books_dict)<br/>df.head(5)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lz"><img src="../Images/fed234ced7cb6e2b0b37444123e7c944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D-9ooZokU4M3tjBiIgehlA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">数据帧格式的抓取数据—按作者分类的图像</figcaption></figure><h2 id="a1d8" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">将数据帧推送到MySQL数据库</h2><p id="b669" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">假设您有一个MySQL数据库，有一个名为<code class="du ll lm ln lo b">"book-depo-new-releases"</code>的表。除了这个表，还有MySQL数据库的用户名和密码、主机和数据库名称。要将数据帧推送到MySQL，用sqlalchemy创建一个引擎，然后利用pandas方法直接推送数据。</p><pre class="iy iz ja jb fd lq lo lr ls aw lt bi"><span id="fd9c" class="kk kl hi lo b fi lu lv l lw lx">engine = create_engine('mysql+pymysql://'+{USERNAME}+':'+{PASSWORD}+'@'+{HOST}+'/'+{DATABASE})</span><span id="75c6" class="kk kl hi lo b fi ly lv l lw lx">df.to_sql(con=engine, name='book-depo-new-releases', if_exists='append', index=False)</span></pre><p id="5b7f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通过使用<code class="du ll lm ln lo b">append</code>选项，您不会覆盖该表中以前写入的行。此外，DataFrame的索引也不会写入MySQL表。</p></div></div>    
</body>
</html>