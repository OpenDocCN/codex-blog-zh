<html>
<head>
<title>Hyper-parameter Tuning with Custom GridSearchCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用定制GridSearchCV进行超参数调整</h1>
<blockquote>原文：<a href="https://medium.com/codex/hyper-parameter-tuning-with-custom-gridsearchcv-d5212f218cc0?source=collection_archive---------8-----------------------#2021-07-09">https://medium.com/codex/hyper-parameter-tuning-with-custom-gridsearchcv-d5212f218cc0?source=collection_archive---------8-----------------------#2021-07-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9fd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常在机器学习中，我们将数据集分为两部分，即训练(通常70%)和测试(通常30%)数据集。如果我们正在处理一个分类问题，其中我们将<strong class="ih hj"> X </strong>作为特征，将<strong class="ih hj"> Y </strong>作为标签，我们将数据拆分为<strong class="ih hj"> X_train </strong>、<strong class="ih hj"> X_test、</strong>和<strong class="ih hj"> Y_train </strong>、<strong class="ih hj"> Y_test </strong>。我们通常做的是，在训练数据集上训练和拟合模型，并在测试数据集上测试模型。我们通常通过将我们的模型根据测试数据预测的值与实际数据进行比较来发现准确性。这种方法的问题是，每当您的模型在现实世界中遇到新数据时，准确性就不再一样了。你可能会看到你的模型是如何悲惨地失败的。为了解决这些问题，研究人员提出了各种方法，其中一种方法是在拆分数据时使用交叉验证。</p><h1 id="4da7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">交叉验证</h1><p id="f04d" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">为了理解这一点，我们举一个KNN算法的例子。我们通常将数据分成三部分，而不是两部分，即训练数据(60%)、cv数据(20%)和测试数据(20%)。注意:并不总是60–20–20，有些人更喜欢70–10–20和其他一些人。现在，在K-NN中，我们使用训练数据来训练和拟合模型，基本上，我们正在为数据集中的每个点找到所有最近的邻居。CV数据用于寻找最佳K(K-NN中的K被称为超参数，选择正确的K至关重要。简而言之，K是在应用K-NN时要选择的最近邻的数量。CV数据用于查找多个K的精确度，精确度最高的K被认为是最佳K。例如，当K为5时，我们得到了模型的最高精确度，即95%。现在，如果我们使用最佳K和经过训练的模型，并在测试数据上对其进行测试，并说我们获得了大约93%的准确性，我们现在更确定我们的模型在现实世界中也会给出高准确性，因为我们的模型在训练期间以及在寻找最佳K的过程中没有看到测试数据。</p><p id="9193" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，还有一个问题需要解决。如果我们将数据分成60–20–20的比例，其中60%用于训练目的，我们肯定会丢失40%的信息，而使用60%的信息来训练我们的模型在现实世界中并不合适。为了解决这个问题，研究人员提出了许多修改方法，我们将在本文中学习一种。</p><h1 id="c05e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">GridSearchCV</h1><p id="8c32" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">将数据分成两部分，80%的数据将用作训练数据，而20%将用作测试数据。现在，训练数据集进一步分为四个部分，每个部分占20%，比如D1、D2、D3和D4区块。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/f2d0a8914fa97351ca34acd0045b5036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-aQaFTcWMDCdB9GhMFpIiQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图1:将数据分为训练和测试(用MS Excel制作)</figcaption></figure><p id="264d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将首次使用D1、D2和D3街区作为训练数据集来训练我们的模型，而D4将用作CV数据，K=1，以找到模型的准确性，即81%。对于K=1，将D1、D2、D4作为训练数据并将D3作为CV数据的第二组合将具有85%的准确度。K=1的第三个组合将给出85%的准确度，第四个组合将给出84%的准确度。一旦我们使用了所有的组合，我们现在取K=1时所有精度的平均值。这样，我们可以巧妙地使用80%的数据作为训练，而不会像我们在前面的案例中看到的那样丢失太多信息。注意:我们仍然没有使用D5或测试数据，因此，对于K=1，我们可以测试我们的模型，并可以预期测试精度对于现实世界的情况也是可持续的。人们可以对多个K，K=1，3，5…尝试这样的组合，并且可以找到给出最高精度的最佳K，在我们的例子中是K=5，精度为93%。因此，如果我们在测试数据上用K=5测试我们的模型，并说我们得到了相似的精度，我们现在更确定我们的模型在真实数据上也会给出相似的精度。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kw"><img src="../Images/7846a68670c40902403250e540360e52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iosRrbRTsHmA1LWmoGi3WQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图2:K与折叠次数的网格状组合(用MS Excel制作)</figcaption></figure><p id="46da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样一种通过制作网格(见上图)来寻找最佳超参数(K-NN中的K)的方法被称为GridSearchCV。让我们在不使用Sklearn的情况下，使用Python从头实现GridSearchCV。您也可以使用Sklearn库，它以自己的方式更加高效。</p><h1 id="c90a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">实现自定义GridSearchCV</h1><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="d8e8" class="lc je hi ky b fi ld le l lf lg">from sklearn.datasets import make_classification<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score<br/>import pandas as pd<br/>import numpy as np<br/>import random<br/>import matplotlib.pyplot as plt</span></pre><p id="fe4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用来自<code class="du lh li lj ky b">sklearn.datasets</code>的<code class="du lh li lj ky b">make_classification</code>，这将帮助我们创建具有各种参数的点的聚类(用于分类问题)，例如<code class="du lh li lj ky b">n_samples</code>用于样本数量，<code class="du lh li lj ky b">n_features</code>定义我们想要的特征数量，<code class="du lh li lj ky b">n_informative</code>定义您想要提供信息的特征，<code class="du lh li lj ky b">n_redundant</code>定义您想要冗余或无用的特征，<code class="du lh li lj ky b">random_state</code>如果设置为任何特定的数字，每次将返回相同的随机数据，这有助于您与任何人共享相同的随机选择的数据。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="4f53" class="lc je hi ky b fi ld le l lf lg">def GridSearchCV(x_train, y_train, classifier, parameter, folds):<br/>    trainscores = []<br/>    testscores = []</span></pre><p id="a92f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">定义一个带五个输入的函数<code class="du lh li lj ky b">x_train</code>、<code class="du lh li lj ky b">y_train</code>、<code class="du lh li lj ky b">classifier</code>在我们的例子中分类器是KNN、<code class="du lh li lj ky b">parameter</code>比如<strong class="ih hj"> n_neighbors </strong>、<code class="du lh li lj ky b">folds</code>我们的cv折叠数。最初，我们定义了两个空列表<code class="du lh li lj ky b">trainscores</code>和<code class="du lh li lj ky b">testscores</code>，它们存储了我们在用<strong class="ih hj"> n个折叠数</strong>对<strong class="ih hj"> n个K </strong>进行训练和测试时获得的所有精度。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="f81b" class="lc je hi ky b fi ld le l lf lg">for k in parameter['n_neighbors']:<br/>        training_fold_scores = []<br/>        cv_fold_scores = []</span></pre><p id="2096" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一个for循环将K的不同值作为一组列表存储在变量<strong class="ih hj">参数</strong>中。<code class="du lh li lj ky b">parameter={'n_neighbors':[1,3,5,7,9,11,13,15,17,19,21,23,25,27,29]}</code>我们将从1到30个奇数中迭代K，因为在KNN，如果K是偶数，如果我们得到偶数个邻居，则很难决定类别标签。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="aafc" class="lc je hi ky b fi ld le l lf lg">for j in range(0, cv_folds):<br/>    training_data = select_data_without_duplicates(x_train) <br/>    cv_data = list(set(list(range(1, len(x_train)))) - set(training_data))</span></pre><p id="5de7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个循环将为每个K选择k_folds的数量。因此，如果K=1，并且<code class="du lh li lj ky b">cv_folds=4</code>我们得到四次迭代，K1F0，K1F1，K1F2，K1F3，其中K1是K=1，F0到F4是F=0到3。由于我们取了从1到29的多个K，我们将从K1F0，K1F1，K1F2，K1F3，K2F0得到15*4=60个组合…至K29F3。正如我之前所说，我们将把数据分成两部分，即80%的数据是训练数据+简历数据，20%是测试数据。因此，在第二行中，已经有80%的训练+cv数据，我们将其中的60%数据拆分为训练数据，其余20%数据拆分为cv数据。第三行简单地表示剩余的数据给了cv_data。将我们的数据随机分成60%而不创建副本的函数如下:</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="0929" class="lc je hi ky b fi ld le l lf lg">def select_data_without_duplicates(x_train):<br/>    return random.sample(range(0, len(x_train)), int(0.6*len(x_train)))</span></pre><p id="cb1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述函数基本上采用<code class="du lh li lj ky b">x_train</code>数据，并返回60%的随机样本数据，范围从0到训练数据的长度，没有重复。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="32d8" class="lc je hi ky b fi ld le l lf lg">X_train = x_train[training_data]<br/>X_cv = x_train[cv_data]<br/>Y_train = y_train[training_data]<br/>Y_cv = y_train[cv_data]</span></pre><p id="7bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于我们已经将数据分为训练数据和cv数据，区分由训练数据和cv数据映射的<code class="du lh li lj ky b">X_train</code> <code class="du lh li lj ky b">X_cv</code> <code class="du lh li lj ky b">Y_train</code> <code class="du lh li lj ky b">Y_cv</code>非常重要。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="7788" class="lc je hi ky b fi ld le l lf lg">classifier.n_neighbors = k<br/>classifier.fit(X_train, Y_train)</span></pre><p id="77b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将n_neighbors指定为用户给定的k的数量，然后使用<code class="du lh li lj ky b">X_train</code>和<code class="du lh li lj ky b">Y_train</code>来拟合模型</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="88ea" class="lc je hi ky b fi ld le l lf lg">Y_cv_predict = classifier.predict(X_cv)<br/>cv_fold_scores.append(accuracy_score(Y_cv, Y_cv_predict))<br/>            <br/>Y_train_predict = classifier.predict(X_train)<br/>training_fold_scores.append(accuracy_score(Y_train, Y_train_predict))</span></pre><p id="f5cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦模型被训练，我们将预测<code class="du lh li lj ky b">X_cv</code>，并将它与给定的<code class="du lh li lj ky b">Y_cv</code>进行比较，以计算精确度。精确度将存储在我们已经创建的<code class="du lh li lj ky b">cv_fold_scores</code>列表中。同样，我们将预测<code class="du lh li lj ky b">X_train</code>，并将其与<code class="du lh li lj ky b">Y_train</code>进行比较，以计算精确度并将其存储在<code class="du lh li lj ky b">training_fold_scores</code>中。在我们的例子中，我们已经创建了<code class="du lh li lj ky b">cv_fold=4</code>,所以我们为每个k获得了四个精度。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="597d" class="lc je hi ky b fi ld le l lf lg">    trainscores.append(np.mean(np.array(training_fold_scores)))<br/>    testscores.append(np.mean(np.array(cv_fold_scores)))<br/>return trainscores,testscores</span></pre><p id="a2ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">取四个精度的平均值，并将平均值分别添加到<code class="du lh li lj ky b">trainscores</code>和<code class="du lh li lj ky b">testscores</code>列表中。请参见图2以直观理解。现在已经创建了函数，我们可以在数据集上测试我们的函数了。</p><p id="8846" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是该函数的完整代码。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h1 id="d63a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">测试我们的功能</h1><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="603f" class="lc je hi ky b fi ld le l lf lg">x, y = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=53)</span><span id="72b2" class="lc je hi ky b fi lm le l lf lg">#Spliting data into training and testing datasets<br/>X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=32)</span></pre><p id="5272" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们将创建一个包含10，000个样本的数据集，其中包含2个信息性特征和0个冗余特征(n_redundant应等于0，默认为2)。将数据拆分成X和Y训练测试后，训练数据为7500，测试数据为2500。如果我们将数据的特征和标签可视化，它将类似于下图:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ln"><img src="../Images/bc9554c92745974a32141883d2f69d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*gJFokvqcAPezaHTBQlktJQ.png"/></div></figure><p id="691b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将我们的函数应用于上述数据集之后，我们可以识别最佳K或最佳超参数。下面是<strong class="ih hj">超参数与精度的关系图。</strong></p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lo"><img src="../Images/4d35a4baedb0283a60348495785a05af.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*ISL341HQJVWMnb2PN1za3Q.png"/></div></figure><p id="1168" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于测试数据，您可以看到的最高K值约为15，准确率为87.5%。见下图。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lo"><img src="../Images/8c3fdc28247ed9bd4cdd465115a71593.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*3P9PWqjraYAEZPhnnGPxrA.png"/></div></figure><p id="f8ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关详细的分步代码，请参考my <a class="ae lp" href="https://github.com/noor12401/Machine-Learning/tree/main/Implementing%20Custom%20GridSearchCV" rel="noopener ugc nofollow" target="_blank"> GitHub </a>或<a class="ae lp" href="https://colab.research.google.com/drive/1LVt0p07240f21pJPv2stvTrF6JwfNOZy?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab </a></p></div></div>    
</body>
</html>