<html>
<head>
<title>How to train Multimodal Image-to-Image Translation using MISO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用MISO训练多模态图像到图像的翻译</h1>
<blockquote>原文：<a href="https://medium.com/codex/how-to-train-multimodal-image-to-image-translation-using-miso-a5f6b081e220?source=collection_archive---------17-----------------------#2021-08-19">https://medium.com/codex/how-to-train-multimodal-image-to-image-translation-using-miso-a5f6b081e220?source=collection_archive---------17-----------------------#2021-08-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/36ee8195819fbe5272efa18e79aeef9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*gs5q8Wwy7eaeiOWm31bvBg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">论文中的例子</figcaption></figure><p id="2f10" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像到图像的翻译是将一个特定领域的图像翻译到另一个领域，同时保留特定的语义内容。图像到图像的翻译主要有两个问题，即成对数据的学习和不成对数据的学习。在现实世界的问题中，收集成对的数据集可能会有问题，而基于不成对数据的学习算法(如流行的CycleGAN)已经获得了更多的兴趣。</p><p id="8a41" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像到图像翻译的另一个特性是问题固有的多模态性质。如上图所示，单个图像可以转换为多个同样真实的图像。关于<em class="jo">不成对多模态图像到图像转换的研究</em>例如本文旨在从不成对数据集中的单个图像生成不同的图像。</p><p id="fc4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇论文…</p><ul class=""><li id="b1be" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">根据来自目标域(MISO管道)的样式表示，使用来自源域的<em class="jo">内容表示</em>。</li><li id="6a6b" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">提出互信息损失作为损失函数。</li><li id="9f7e" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">将不成对的多模式图像到图像翻译的性能提高到令人惊讶的水平<em class="jo">。</em></li></ul><p id="ba9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kd" href="https://arxiv.org/pdf/1902.03938.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="jo">原始论文:MISO:用于多模态图像到图像翻译的具有随机风格表示的互信息损失</em> </a></p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="4828" class="kl km hi bd kn ko kp kq kr ks kt ku kv jb kw kx ky jf kz la lb jj lc ld le lf bi translated">以前的方法</h2><p id="4ca7" class="pw-post-body-paragraph iq ir hi is b it lg iv iw ix lh iz ja jb li jd je jf lj jh ji jj lk jl jm jn hb bi translated">我们将很快讨论以前关于不成对的多模态图像到图像翻译的工作的想法。这一节是根据MISO的论文写的。有关更多详细信息，请参考每篇论文。</p><p id="dfb5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多模态映射可以通过将一对(噪声，源图像)映射到目标图像来学习。BicycleGAN提出了一个在图像和<em class="jo">特征</em>之间进行翻译的两阶段训练，用于多模态成对翻译。准确地说，训练包括平移X → Z → X(图像-特征-图像，IFI)和Z → X → Z(特征-图像-特征，FIF)，每个阶段用不同的损失函数进行训练。</p><p id="cc91" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关于不成对的多模态图像到图像翻译的工作，例如穆尼特和DRIT，通过解开<em class="jo">风格</em>和<em class="jo">内容</em>扩展了两阶段训练。确切地说，领域不变的特征(内容)如背景、脸部角度，以及领域特定的特征(风格)如区分每个领域的长发和胡须。两种方法的IFI阶段都使用自重建损失，即源和重建图像之间的L1损失(类似于循环一致性损失？).</p><h2 id="2533" class="kl km hi bd kn ko kp kq kr ks kt ku kv jb kw kx ky jf kz la lb jj lc ld le lf bi translated">随机风格表示的互信息(MISO)</h2><p id="8c56" class="pw-post-body-paragraph iq ir hi is b it lg iv iw ix lh iz ja jb li jd je jf lj jh ji jj lk jl jm jn hb bi translated"><em class="jo">随机…？</em></p><p id="5a0c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">综上所述，我们的目标是学习一个从域A到B，或者从源域S到目标域T的一对多映射，严格来说，一对多映射是通过学习p(t|s，z)实现的，其中t <strong class="is hj"> ∈ </strong> T，s <strong class="is hj"> ∈ </strong> S，z∽<em class="jo">N</em>(0，I)。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/adbafedde214d9305b8b1ff76415b607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*B1WT2-TkPqivulxkBj6FbA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">两阶段训练MISO</figcaption></figure><p id="9053" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">流水线由用于每个域的两个<strong class="is hj">风格编码器</strong>和<strong class="is hj">鉴别器</strong>以及用于每个方向的两个<strong class="is hj">生成器</strong>和<strong class="is hj">条件编码器</strong>组成。在上图中，E_A和E_B代表样式编码器，E_BA和E_AB代表条件编码器，D_A和D_B代表鉴别器，G_AB和G_BA代表对应于其下标的域的生成器。</p><p id="5ff2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">z向量在概念上代表了图像的期望样式，因为它直接影响映射的多模态性。风格编码器(不是条件编码器)从域A或B接收图像，并预测相应的z向量。为了避免单一的确定性映射，编码器是断言潜在空间中的噪声的值。</p><p id="61af" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关键是<em class="jo">样式</em>是从源域A的图像中编码的，而<em class="jo">内容</em>是从目标域b中编码的。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/34d396f7d1150be1aabaf753a7db678d.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*zsqFGsVZVeE7O0opfWh9HQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">论文中的例子</figcaption></figure><h2 id="35fa" class="kl km hi bd kn ko kp kq kr ks kt ku kv jb kw kx ky jf kz la lb jj lc ld le lf bi translated">相互信息损失</h2><p id="a837" class="pw-post-body-paragraph iq ir hi is b it lg iv iw ix lh iz ja jb li jd je jf lj jh ji jj lk jl jm jn hb bi translated">接下来，作者指出在多模态翻译中广泛使用的自我重建损失可能会有问题。先前的工作表明，SR损失未能捕捉细节特征，因为该损失会促使平均像素值。MILO损耗被认为是SR损耗的一种替代。</p><p id="3bf0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多模态翻译旨在学习条件分布p(t|s，z)。作者将z视为后验概率为p(z|x)，x ∈ X的随机变量。这也给条件编码器提取的特征带来了随机性。从概念上讲，MILO的设计是为了在测量损耗时更好地利用这种随机性。</p><p id="693b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">MILO损失使特征z_a=E_A(z)和从该特征G_BA(b，z_a)生成的图像之间的<em class="jo">互信息</em>最大化。基于InfoGAN，互信息近似为下面的等式。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/910a82af59979bd9628a8495f56d1310.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*stDFdrO5v8Lkb-3Pa9NBrg.png"/></div></figure><p id="3579" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在基于MISO成分的各种统计特性近似分布之后，这被重写为下面的公式。下面表示为L_info的公式可以直接计算，其中_out和σ_out是编码器的输出。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/e2599dd1ffe18ac3e504068e893696e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*L7qBpvTO2-_S22CBXW03hA.png"/></div></figure><p id="e7ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欲知全部细节，请参阅原文。我承认，由于繁重的数学负担，我无法解释整个过程。</p><p id="3e11" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整的目标函数包括这种MISO损失、KL背离、周期一致性损失和对抗性损失的组合。这些损失与我们通常使用的经典方程相同，关于何时使用每个损失的详细信息在描述训练管道的图中描述。使用下面的等式来训练发生器，该等式计算每个损失的加权和。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/e51355c418a9f449528b05ace2577ac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*rQ6s30ovalgjvEcDanOLLw.png"/></div></figure><h2 id="e47e" class="kl km hi bd kn ko kp kq kr ks kt ku kv jb kw kx ky jf kz la lb jj lc ld le lf bi translated">实验</h2><p id="c2f7" class="pw-post-body-paragraph iq ir hi is b it lg iv iw ix lh iz ja jb li jd je jf lj jh ji jj lk jl jm jn hb bi translated">该方法在4个不成对的图像到图像翻译数据集上进行评估:雄性↔雌性，艺术↔照片，夏季↔冬季，和猫↔狗。MISO能够在许多指标上超越其他不成对的多模态翻译模型。</p><p id="8a3c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与其他多模态和非多模态技术的分类精度相比，MISO在CelebA性别条件图像生成上实现了最佳性能。这表明MISO生成的图像成功地包含了特定领域的特征。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/893a6d7ebdd113096a2764c88babdfc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*SCyh2A14XQhriyyfaN-AVw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">在CelebA属性上训练的分类器可以成功地识别生成图像的预期性别。(F和M表示女性和男性。)</figcaption></figure><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/729c10e924b972637cb3a3281c2d32ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*Sd_sG_hhWm0nA_lLnes_ww.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">平移时的LPIPS距离(I:输入，O:输出)</figcaption></figure><p id="7af0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与其他不成对的翻译方法相比，MISO是用户研究和感知度量(LPIPS)方面最可取的方法。↔O之间较低的lpip意味着内容被保留，而O↔O之间较高的lpip意味着输出更加多样化。例如，NycleGAN似乎正在生成逼真但不多样的图像。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/3bd97939dc884d35a23dc65942665bec.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*Y9APcPaxR2I0xqqXVGo2Fg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">用户研究结果</figcaption></figure><p id="9351" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们实际比较示例时，结果有些明显。在下图中，MISO生成了无与伦比的多样化和高质量的图像。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lx"><img src="../Images/07678582fa77e72253367e4c94c4d604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4y51Tl9z-iTIiAXzf_trQ.png"/></div></div></figure><p id="e2ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在原始论文中提供了关于潜在空间的更多定性分析和生成图像的例子。</p><h2 id="1315" class="kl km hi bd kn ko kp kq kr ks kt ku kv jb kw kx ky jf kz la lb jj lc ld le lf bi translated">摘要</h2><ul class=""><li id="cbf8" class="jp jq hi is b it lg ix lh jb mc jf md jj me jn ju jv jw jx bi translated">本文提出了一种用于不成对的多模态图像到图像翻译的改进流水线，并且提高了各种设置下的感知质量。</li><li id="5a25" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">本文提出了一种MILO信息损失方法，该方法通过将z视为随机变量来代替有问题的自重构损失。</li></ul><p id="d247" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我了解到图像到图像的翻译是一个固有的多模态问题。本文中提出的MISO框架很有趣，因为它模拟了样式和内容的抽象概念。</p></div></div>    
</body>
</html>