<html>
<head>
<title>How to read compressed files from an Amazon S3 bucket using AWS Glue without decompressing them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在不解压的情况下使用AWS Glue从亚马逊S3桶中读取压缩文件</h1>
<blockquote>原文：<a href="https://medium.com/codex/how-to-read-compressed-file-in-an-amazon-s3-bucket-by-using-aws-glue-without-decompressing-it-b6515db863df?source=collection_archive---------1-----------------------#2021-05-10">https://medium.com/codex/how-to-read-compressed-file-in-an-amazon-s3-bucket-by-using-aws-glue-without-decompressing-it-b6515db863df?source=collection_archive---------1-----------------------#2021-05-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e55b1009aab3d614a096cafb1e1a91be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_Kqz-3eoSX4lhftj1nh8A.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu"> AWS胶水</strong></figcaption></figure><h1 id="fe7f" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">AWS胶水介绍</strong></h1><p id="f325" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated"><a class="ae kq" href="https://docs.aws.amazon.com/glue/latest/dg/what-is-glue.html" rel="noopener ugc nofollow" target="_blank"> <em class="kr"> AWS Glue </em> </a>是一个完全托管的提取、转换和加载(<strong class="ju hj"> ETL </strong>)服务，使客户能够轻松准备和加载他们的数据进行分析。</p><p id="dcf3" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">您可以在AWS管理控制台中通过几次点击来创建和运行ETL作业。您只需将AWS Glue指向存储在AWS上的数据，AWS Glue就会发现您的数据并将相关的元数据(例如表定义和模式)存储在AWS Glue数据目录中。AWS Glue支持spark (Pyspark和Scala)语言以及<strong class="ju hj"> python shell </strong>。</p><p id="2bcd" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">一旦编目，您的数据就可以立即被搜索、查询和用于ETL。AWS Glue生成代码来执行数据转换和数据加载过程。</p><h1 id="89d8" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">问题</strong></h1><p id="5228" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">从某些来源，我们接收数据压缩格式直接进入我们的S3桶。挑战是在不解压缩文件的情况下读取这些压缩数据的内容。</p><p id="871c" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">所有在S3的压缩文件，无论是zip还是gzip，我们都必须在一个脚本中处理两种不同的文件格式。</p><p id="008f" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">别担心，我们已经有了上述问题的解决方案，我们已经使用python <a class="ae kq" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html" rel="noopener ugc nofollow" target="_blank"> <em class="kr"> boto3 </em> </a>库，以及<a class="ae kq" href="https://docs.python.org/3/library/zipfile.html" rel="noopener ugc nofollow" target="_blank"> <em class="kr"> zip </em> </a>和<a class="ae kq" href="https://docs.python.org/3/library/gzip.html#gzip.open" rel="noopener ugc nofollow" target="_blank"> <em class="kr"> gzip </em> </a>模块来获得解决方案！</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><h1 id="adc5" class="iv iw hi bd iu ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr bi translated"><strong class="ak">进场</strong></h1><p id="855d" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">第一步是识别文件(或S3中的对象)是zip还是gzip，我们将使用文件的路径(使用Boto3 S3 <a class="ae kq" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/resources.html" rel="noopener ugc nofollow" target="_blank">资源</a>对象)</p><p id="8c3b" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">这可以通过使用python的<a class="ae kq" href="https://python-reference.readthedocs.io/en/latest/docs/str/endswith.html" rel="noopener ugc nofollow" target="_blank"><em class="kr">ends with</em></a><em class="kr"/>函数来实现。同样在提供的path的帮助下，您可以将它分成Bucket name和Key Name，这也可以在以后使用</p><p id="8c3f" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">基于压缩对象的标识，在脚本中将调用zip和gzip(或任何其他)各自的块(这里，我使用了If/Else)</p><p id="5c74" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">一旦确定了文件格式，我们现在必须<strong class="ju hj">读取zip文件的内容</strong>。这可以通过将它读入一个<strong class="ju hj">字节数</strong>缓冲区对象来完成，然后我们需要迭代zip文件中的每个对象，我们使用<a class="ae kq" href="https://docs.python.org/3.6/library/zipfile.html#zipfile.ZipFile.namelist" rel="noopener ugc nofollow" target="_blank"> <em class="kr">名称列表</em> </a>方法并最终写入S3，我们可以使用<a class="ae kq" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_file" rel="noopener ugc nofollow" target="_blank"><em class="kr">meta . client . upload _ file obj</em></a>方法或<a class="ae kq" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.put_object" rel="noopener ugc nofollow" target="_blank"><em class="kr">client . put _ object</em></a></p><p id="710f" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">同样为了读取gzip文件的内容，我尝试了<a class="ae kq" href="https://docs.python.org/3/library/gzip.html#gzip.GzipFile" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hj"> <em class="kr"> Gzip构造函数</em> </strong> </a> <strong class="ju hj"> <em class="kr">。<br/> </em> </strong>它将使用python的read函数读取S3对象的内容，然后在put_object Boto3命令的帮助下，将这些内容作为文本文件转储到各自的目的地</p><p id="3467" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">我已经使用了<a class="ae kq" href="https://docs.aws.amazon.com/glue/latest/dg/add-job-python.html" rel="noopener ugc nofollow" target="_blank"><strong class="ju hj"><em class="kr">AWS Glue—python shell</em></strong></a>来执行以下代码，我们甚至可以使用AWS Lambda来执行相同的代码，但是AWS Lambda的唯一问题是执行时间限制，最长为15分钟。所以如果你的文件太大，可能会有问题。</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><h1 id="7474" class="iv iw hi bd iu ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr bi translated">代码</h1><ol class=""><li id="d844" class="lj lk hi ju b jv jw jz ka kd ll kh lm kl ln kp lo lp lq lr bi translated">从S3路径返回存储桶和键名的函数:</li></ol><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="0999" class="mb iw hi lx b fi mc md l me mf">def split_s3_path(s3_path):<br/> path_parts=s3_path.replace(“s3://”,””).split(“/”)<br/> bucket=path_parts.pop(0)<br/> key=”/”.join(path_parts)<br/> return bucket, key</span></pre><p id="bee3" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">这将以字符串格式返回提供的路径的存储桶名和键名</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><p id="8bfb" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">2.识别Zip文件的内容并将其提取到另一个位置</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="75ac" class="mb iw hi lx b fi mc md l me mf">if path.endswith('.zip'):<br/> zip_obj = s3_resource.Object(bucket_name=bucket ,key=key_name)<br/> buffer = BytesIO(zip_obj.get()[“Body”].read())<br/> z = zipfile.ZipFile(buffer)</span><span id="4c57" class="mb iw hi lx b fi mg md l me mf">for filename in z.namelist():<br/> file_info = z.getinfo(filename)<br/> s3_resource.meta.client.upload_fileobj(<br/> z.open(filename),<br/> Bucket=bucket,<br/> Key=output_location + filename,<br/> Config=config<br/> )</span></pre><p id="107c" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">或者，也可以使用is_zipfile()函数来代替path.endswith()。</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><p id="1958" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">3.最后，我们还需要检查Gzip对象</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="b3db" class="mb iw hi lx b fi mc md l me mf">elif path.endswith(‘.gz’):<br/> obj = s3.Object(bucket_name=bucket ,key=key_name)<br/> with gzip.GzipFile(fileobj=obj.get()[“Body”]) as gzipfile:<br/> content = gzipfile.read()<br/> client.put_object(Body=content, Bucket=bucket, Key=’newfolder/new_filename.txt’)</span></pre><p id="1032" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">有了它，我们可以很容易地阅读S3的zip和gzip文件。</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><h1 id="86a4" class="iv iw hi bd iu ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr bi translated">结论</h1><p id="3fe0" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">因此，正如我们已经看到的，借助python模块，我们可以轻松地读取任何压缩文件(zip/Gzip ),并且可以在AWS Glue中执行它，而不用担心任何时间限制。此外，我们可以轻松地创建压缩文件中内容的文本文件，而无需对其进行解压缩。</p><p id="d185" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">你甚至可以添加块来读取bz2，tar和许多其他压缩文件格式，只需使用endswith函数。</p><p id="ab18" class="pw-post-body-paragraph js jt hi ju b jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl kw kn ko kp hb bi translated">我希望这对开发人员和数据工程师有所帮助。请让我知道你对此的想法和/或任何可能的优化</p></div></div>    
</body>
</html>