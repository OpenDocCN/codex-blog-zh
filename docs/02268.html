<html>
<head>
<title>Lighting Estimation for Mobile AR (Part I)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">移动增强现实中的光照估计(上)</h1>
<blockquote>原文：<a href="https://medium.com/codex/lighting-estimation-for-mobile-ar-part-i-8c548affc7e5?source=collection_archive---------4-----------------------#2021-07-10">https://medium.com/codex/lighting-estimation-for-mobile-ar-part-i-8c548affc7e5?source=collection_archive---------4-----------------------#2021-07-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="c232" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">概观</h1><p id="fe91" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这篇文章中，我将简要比较最近的两篇研究论文，<a class="ae kb" href="https://dl.acm.org/doi/abs/10.1145/3458864.3467886?sid=SCITRUS" rel="noopener ugc nofollow" target="_blank"> <em class="kc">【熙和】</em> </a>和<a class="ae kb" href="https://dl.acm.org/doi/10.1145/3307334.3326098" rel="noopener ugc nofollow" target="_blank"> <em class="kc"> GLEAM </em> </a>，它们在移动设备上提供<strong class="jf hj">实时光照估计</strong>。简而言之，光照估计是指从环境场景中获取光照信息。对于增强现实，场景是物理环境(例如，您的客厅)，因此可以在时间和空间上有自然的光照条件变化。</p><p id="04d3" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated"><strong class="jf hj"> <em class="kc">动态场景光照</em> </strong>是物理环境光照估计具有挑战性的一个关键原因。由于照明条件可能从一帧到下一帧变化，这种快速变化需要快速估计(例如，30 fps)；此外，照明条件可能从房间的一个角落到另一个角落变化(例如，由于光源位置)，这使得导出感兴趣位置的照明估计很重要。</p><p id="2d61" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">现有的商业AR平台包括ARCore和ARKit已经开始提供光照估计API，如<a class="ae kb" href="https://developer.apple.com/documentation/arkit/arlightestimate" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj"><em class="kc">ARLightEstimate</em></strong></a><strong class="jf hj"><em class="kc">。</em> </strong>然而，现有的支持仍处于早期阶段，仅提供整个场景的环境光信息。换句话说，现有的商业AR平台包括ARCore和ARKit仍然缺乏对精确光照估计的支持，因此经常导致<strong class="jf hj">不真实的渲染</strong>效果。下面是两张图，演示了使用ARKit vs. GLEAM/Xihe提供的光照信息的渲染效果。GLEAM和Xihe都产生了视觉上更连贯的虚拟对象。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/d526e6d9c9ac6d329329df743ee69cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ajOtUds1bq2lM5H0ojvWfw.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">截图自GLEAM论文原文:AR场景渲染对比。</figcaption></figure><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ky"><img src="../Images/1d81b3ec3910347f893e3dc57c0ec17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wz5DD2rmH_NyZsli5opQEw.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">截图自西河论文原文:AR场景渲染对比。</figcaption></figure><h1 id="0d9d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">GLEAM(MobiSys 2019)</h1><p id="6f59" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">简而言之，GLEAM使用<strong class="jf hj">物理光探测器</strong>捕捉环境照明信息，然后将这些信息提供给图形渲染器，以照亮物理世界中的虚拟物体。</p><h2 id="57cb" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">最初的</h2><p id="b753" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">什么是物理光探头？它通常是一个反射球，放置在特定的物理位置，用于感应光线。下图显示了一个铬球形式的光探头示例。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ln"><img src="../Images/7d1aebf031d6e1cc115ea56452b58db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*Vy91b1YPPSSZQOrQSaKG8Q.png"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">原始GLEAM论文截图:物理光探针示例</figcaption></figure><p id="707c" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">什么是立方体贴图？立方体贴图是环境贴图的常见表示形式之一。环境贴图通过将入射光线方向映射到光线强度来帮助我们建模照明。下图显示了GLEAM捕获的立方体贴图示例。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lo"><img src="../Images/eb3dbf8a0961334e4f47a743a72fc36b.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*ijRZ2KMsimtvnrCxII4yow.png"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">来自原始GLEAM论文的截图:立方体贴图的例子。</figcaption></figure><h2 id="2742" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">微光:引擎盖下</h2><p id="cfdf" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">GLEAM概念上由以下两个关键步骤组成。</p><p id="6663" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">第一步:生成辐射样本。首先，将在场景中放置一个微光探头(一个物理光探头和一个AR定位标记)。然后，AR用户将捕捉微光探头的图像，通过将每个像素与反射光线相关联来生成辐射样本。捕获的辐射样本将作为构建环境地图的基础。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lp"><img src="../Images/5c76f9bafe02c0c88ede50438f548a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*bBh-7hDk9czVATUOVbI16g.png"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">来自原始GLEAM文件的截图</figcaption></figure><p id="af82" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated"><strong class="jf hj">第二步:从多个辐射样本合成一个立方体贴图。</strong>由于辐射样本本质上是稀疏的，例如<strong class="jf hj"> </strong>受到光探测器或FOV数量的限制，GLEAM使用<em class="kc">一种改进的反距离加权(IDW)插值算法</em>和<em class="kc">一种最近邻算法</em>来为每个立方体贴图纹理元素赋值。纹理元素值分配是一个两阶段的过程。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lp"><img src="../Images/a8029a35de9bcee85e5094520fe15034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*qBt9CXk411FxGC1mRvsT0Q.png"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">来自原始GLEAM文件的截图</figcaption></figure><p id="0752" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">具体而言，每个纹理元素<strong class="jf hj"> u(x) </strong>将首先<em class="kc">使用以下等式由来自合格辐射样本的相应值填充</em>。这里，<strong class="jf hj"> wi(x) </strong>表示分配给辐射样本I的权重，<strong class="jf hj"> d(x，xi) </strong>描述辐射样本I和纹理元素x之间的距离。GLEAM使用基于可靠性的权重函数和L1距离函数。理论上，可以选择其他权重和距离函数。对于每个纹理元素，合格的辐射样本必须满足半径检查。在第二阶段，任何空的纹理元素将使用它们的相邻纹理元素值来填充。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lq"><img src="../Images/87a1d3d43b34bfa2cd006b90c04509c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*76Sya1EWU7PuEttmy6p-JQ.png"/></div></figure><h2 id="4581" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">包裹</h2><p id="a6f7" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">GLEAM为移动AR中的光照估计提供了一个端到端的框架。正如论文所述，“GLEAM建立在图形社区丰富的光照估计历史之上。”事实上，基于物理光探针的方法在移动AR之外被广泛使用；但看到这一想法实现并证明对移动AR的有效性仍然令人高兴。</p><p id="36cf" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">如果您对基于物理探针的照明估计感兴趣，作者已经指出了一些限制。例如，如何在坚持实时目标的同时，从辐射样本中实现更好的立方体贴图插值质量？网络对GLEAM的性能有什么影响，尤其是在多视口配置下？</p></div><div class="ab cl lr ls gp lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="hb hc hd he hf"><h1 id="1b58" class="if ig hi bd ih ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc bi translated">西河(MobiSys'21)</h1><p id="bffb" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">简而言之，Xihe利用<strong class="jf hj"> 3D视觉</strong>数据(RGB-D)在渲染位置生成点云，然后将其传递给轻量级神经网络，以预测用<strong class="jf hj"> <em class="kc">球谐(SH)系数</em> </strong>表示的光照。</p><p id="32af" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated"><em class="kc">(你可能也会对MobiSys’21上展示的其他移动AR相关论文感兴趣。查看</em> <a class="ae kb" href="https://belindanju.medium.com/why-mobile-ar-excites-me-582b79abf3f0" rel="noopener"> <em class="kc">我之前的帖子</em> </a> <em class="kc">。)</em></p><h2 id="ce76" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">最初的</h2><p id="dbfd" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">什么是SH和SH系数？SH是定义在球面上的函数，由Ramamoorthi等人引入，用于创建逼真的渲染。SH系数可用作漫射辐照度图的紧凑照明表示。</p><p id="90f5" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">放置位置，估计位置，观察位置有什么区别？<em class="kc">观察位置</em>定义为摄像机(和移动用户)所在的位置；<em class="kc">放置位置</em>是指被渲染虚拟物体的几何中心，而<em class="kc">估计位置</em>对应光照表示。换句话说，较大的物体可以受益于具有一个以上的估计位置。</p><h2 id="5e2c" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">西河:引擎盖下</h2><p id="f9fe" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">第一个关键的新颖性是<strong class="jf hj"> <em class="kc">一种新的点云采样技术</em> </strong>既快速又保持精度。这种新的采样技术被称为单位球点云采样，它通过将原始点云投影到单位球上来有效地压缩原始点云。下图举例说明了将三个点(p1，p2，p3)投影到单位球上，并产生两个彩色锚点(a1，a2)。本质上，这种采样技术利用球体几何信息，根据观察方向对点进行采样，以尽可能保持观察覆盖范围。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es md"><img src="../Images/af937dc9ea9ceadf6ed1059d6c2620ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QePwpDfhU2t4SciYav2gZQ.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">截图自西河论文原文</figcaption></figure><p id="d42a" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">抛开理论不谈，在移动设备上(甚至在iPad Pro等高端设备上)支持这种采样技术可能具有挑战性，这在很大程度上是由于点的数量和最近邻算法。西河如何满足实时目标？西河设计了<strong class="jf hj"> <em class="kc">一个定制的GPU流水线</em> </strong>用于管理捕获的点云样本和<strong class="jf hj"> <em class="kc">一个密集采样的2D加速网格</em> </strong>用于权衡存储和计算。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es me"><img src="../Images/8cf7ee9396baad33e4d3ee6125a4a7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4MDxAQLQeLBSXy39z5bp0g.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">截图自西河论文原文</figcaption></figure><p id="0d2e" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">第二个关键的新颖性是<strong class="jf hj"> <em class="kc">一个名为XiheNet </em> </strong>的合作设计的神经网络，它采用向下采样的点云并生成照明信息，以SH系数的形式呈现。由于缺乏一些运营商对移动设备的支持，XiheNet将被托管在运行Ubuntu发行版的边缘设备上。为了最小化网络对基于边缘的推理性能的影响，Xihe使用以下方案来编码缩减采样的点云。不是使用float32来编码(R，G，B，X，Y，Z)，而是使用较低精度的数据格式和锚索引来编码每个点。此外，在将编码版本从设备发送到边缘之前，Xihe在剥离步骤中移除所有未初始化的锚。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mf"><img src="../Images/a8eab83b0024b460532b5c872ebe1b0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HkK7ZU_ZseYnFpqCGax54w.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">原西河幻灯片截图</figcaption></figure><p id="6439" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">最后一个新颖之处是<strong class="jf hj"> <em class="kc">一种自适应触发策略</em> </strong>，它基于连续帧之间基于单位球体的点云差异跳过向边缘发送光照估计请求。通过使用这种自适应策略，Xihe可以有效地响应动态环境，同时避免不必要的网络通信。该策略目前是使用球体池和经验得出的阈值和池窗口大小来实现的。</p><p id="b627" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">挑战之一在于如何评估自适应触发策略的有效性。为什么难？很大程度上是因为(1)我们无法获得照明地面真相，以及(2)照明条件难以控制。为了解决这一挑战，Xihe开发了一个AR会话记录器，允许<em class="kc">记录和重放！</em></p><h2 id="7d06" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">包裹</h2><p id="091b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Xihe提出了一个基于3D视觉的框架，实现实时光照估计。Xihe是完全<a class="ae kb" href="https://github.com/cake-lab/Xihe" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">开源的</strong> </a> <strong class="jf hj"> </strong>，由客户端和服务器API组成，如下所示。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mg"><img src="../Images/77d12d8820778f1e0695b31c6a79c43a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKRcihdYg4pI-q1iqDYyrw.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">截图自西河论文原文</figcaption></figure><p id="3779" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">此外，Xihe还提供了一个附带的iOS应用程序，具有便于调试的功能。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mh"><img src="../Images/01069037d054076c8b679a246b988b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*77BOFS_1QYOaEmKdPw-X-A.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">原西河幻灯片截图</figcaption></figure><p id="4605" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">在利用3D视觉来提供功能丰富的移动AR体验方面，有许多开放的挑战和机遇。我们目前正致力于改进西河，以更逼真地渲染不同形状和材料的3D对象！敬请期待！</p></div><div class="ab cl lr ls gp lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="hb hc hd he hf"><h1 id="7bc9" class="if ig hi bd ih ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc bi translated">编后记</h1><p id="29d0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">如果你对增强现实感兴趣，可以考虑在Twitter上关注我，获取商业和研究领域的最新消息。</p><h2 id="aab1" class="kz ig hi bd ih la lb lc il ld le lf ip jo lg lh it js li lj ix jw lk ll jb lm bi translated">参考</h2><p id="3a8b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">[1] Prakash，s .等人，2019年。GLEAM:一个用于移动设备上实时真实感增强现实的光照估计框架。第17届移动系统、应用和服务国际年会论文集(美国纽约州纽约市，2019年6月)，142–154页。</p><p id="5535" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo kf jq jr js kg ju jv jw kh jy jz ka hb bi translated">[2]赵，杨，郭，T. 2021 .Xihe:基于3D视觉的移动增强现实光照估计框架。<em class="kc">第19届移动系统、应用和服务国际年会会议录</em>(美国纽约州纽约市，2021年6月)，第28–40页。</p></div></div>    
</body>
</html>