<html>
<head>
<title>A short narrative on solving Spark Streaming file sink problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于解决Spark流文件接收器问题的简短叙述</h1>
<blockquote>原文：<a href="https://medium.com/codex/a-short-narrative-on-solving-spark-streaming-file-sink-problem-674f7367ae98?source=collection_archive---------18-----------------------#2021-08-05">https://medium.com/codex/a-short-narrative-on-solving-spark-streaming-file-sink-problem-674f7367ae98?source=collection_archive---------18-----------------------#2021-08-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/25f355dca44e800f6aef3697aae483e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIKqod2aGEjiRsytPR3OLQ.jpeg"/></div></div></figure></div><div class="ab cl iq ir gp is" role="separator"><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv"/></div><div class="hb hc hd he hf"><p id="e5f6" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在工作中，我的团队一直在为批处理和流数据摄取编写大量数据管道，并在企业数据湖S3中维护ETL数据，用于各种即席分析和罐装报告。对于一家拥有数百万用户的领先游戏公司来说，我们的游戏服务器在用户在线游戏时会持续生成大量游戏事件(~ 10k/秒)，这些日志需要保存在数据湖中，以用于各种使用情形，如产品运营、CX仪表盘、欺诈模型、游戏统计、异常检测、报告实体查找等。</p><p id="3a69" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">设置管道的一个快速方法是使用从卡夫卡消费者那里读取的Spark结构化流(因为我们已经在使用Spark ),并在S3上演。我们就是这样做的，在从kafka读取/解析数据时，我们在日期字段上创建一个分区，并在S3上保存为拼花格式。</p><figure class="jw jx jy jz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jv"><img src="../Images/7b4dc982cbef5e9920a987c6a6561fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dNYMKYyboZrfGWMYA8VQIQ.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">火花直流</figcaption></figure><figure class="jw jx jy jz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ke"><img src="../Images/80e0a5e72914560ea5ed1a01c7846258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ZSkIQeBI2PQg_WSBdsBtA.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">定义一个火花卡夫卡消费者</figcaption></figure><p id="91bb" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">虽然这是针对特定用例(以及少数其他用例)启动并运行的，但随着这些管道被推向生产，我们很快就遇到了问题。其中一个问题是spark结构化流将元数据信息保存在S3的一个文件夹中，并在HDFS保存一份相同的副本，以维护偏移和模式相关信息。此元数据文件夹是Spark SS在运行的流作业不断更新文件夹时维护状态的方式。如果正在运行的作业出现中断，会导致状态失衡，这意味着正在运行的作业出错并停止。</p><p id="0672" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">使用元数据检查点时需要注意的一些事项是:</p><p id="aa63" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><em class="kf">检查点无法经受Spark版本升级</em></p><p id="edb4" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在升级Spark版本时，您需要手动删除您的检查点。</p><p id="9b49" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><em class="kf">代码升级之间需要清除检查点</em></p><p id="350f" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">如果您的代码库发生变化，您的检查点就会失效。</p><p id="a8bd" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><em class="kf">如果作业运行之间的输出路径发生变化，检查点将无法继续运行</em></p><p id="8dcd" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">点击阅读关于流文件接收器问题<a class="ae kg" href="https://kb.databricks.com/streaming/file-sink-streaming.html?_ga=2.69328528.189140751.1620891486-2088291463.1616493133" rel="noopener ugc nofollow" target="_blank">的已知问题</a></p><figure class="jw jx jy jz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kh"><img src="../Images/e0bc1867e1415eaa374f11b2af840c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cct_kKj6GPdq2fqewRACKQ.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">该问题的典型错误日志</figcaption></figure><p id="e9a4" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">恢复作业最合理的方法是删除两个文件夹(S3和HDFS)并重新提交作业，但这样会破坏恰好一次的语义，因为数据是从kafka队列中重新读取的。这个问题有两个原因:</p><ol class=""><li id="e476" class="ki kj hi iz b ja jb je jf ji kk jm kl jq km ju kn ko kp kq bi translated">如果起始偏移标志设置为最早，则复制写入的数据</li><li id="ef6d" class="ki kj hi iz b ja kr je ks ji kt jm ku jq kv ju kn ko kp kq bi translated">如果“起始偏移量”标志设置为“最新”，则作业未运行时会有数据丢失。</li></ol><p id="0508" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">因此，为了有效地维护恰好一次的处理，我们要么需要备份元数据文件夹，要么使用DB来保存数据。对于我们的使用情形来说，在一个数据库上维护每天近10亿条记录似乎有些大材小用，因此我们尝试为元数据文件夹备份解决方案，但没有成功。</p><p id="85a6" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">状态管理(也称为检查点)在这里是至关重要的，因为如果不知道最后读取的是哪个偏移量，我们就无法确定记录之前是否已经被处理过。并且由于流式管道遭受偶然的中断(由于基础设施问题、源的变化、模式演变等。)默认机制经常崩溃，缺点是如上所述的重复或数据丢失。</p><p id="1e59" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">因为我们的主要要求是在保持整个管道容错的同时保持低延迟处理——这就是lambda架构设计派上用场的地方，我们将来自Kafka的数据同时馈送到批处理层(以特定间隔)和速度(流)层。然后，这些数据在服务层合并批处理和速度视图。</p><p id="6453" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">更多关于数据处理流水线中的lambda架构<a class="ae kg" href="http://lambda-architecture.net/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="a7e8" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这种设计的简单性使我们能够在speed layer中断的情况下返回到batch layer视图，并协调该小时的数据。</p><p id="5698" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">通过这种方法，我们能够确保整个数据管道是容错的，并可以扩展到复杂的流ETL用例，包括窗口和事件水印计算。</p><p id="351f" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">另外，我们将所有旧的流API (Spark Dstream)管道转移到了新的Spark API(结构化流),并将其内存占用减少了10倍。</p><figure class="jw jx jy jz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/abbab27deac395ae6341aa7e706f1625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iu5lOEehsrpn3D4e23Z7NQ.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">我们的spark流作业UI的快照</figcaption></figure></div></div>    
</body>
</html>