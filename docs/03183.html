<html>
<head>
<title>The Elements of Statistical Learning 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统计学习的要素2</h1>
<blockquote>原文：<a href="https://medium.com/codex/the-elements-of-statistical-learning-2-overview-of-supervised-learning-part-1-cfd16044e4f9?source=collection_archive---------12-----------------------#2021-08-21">https://medium.com/codex/the-elements-of-statistical-learning-2-overview-of-supervised-learning-part-1-cfd16044e4f9?source=collection_archive---------12-----------------------#2021-08-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="23fe" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">监督学习概述第1部分</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/24dbd2ddef87ce3e091f7b8da182be1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cDueCXeryCpGn1ZnmbPqtA.png"/></div></div></figure><p id="57e5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">变量类型和术语</strong></p><p id="5b1d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我知道大多数阅读这篇文章的人可能都熟悉其中的一些术语。但由于这是一篇学术论文，我需要再一次击败死马，制定基本规则。</p><p id="f8c8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">y代表定量输出，G代表定性输出，那么X呢？大家都知道“X”表示输入，有什么大不了的？嗯，在学术界，“X”代表一个标量或向量“<strong class="jl hj">X”</strong>(粗体)代表一个矩阵。虽然这种记法上的差异看似迂腐，但当我们在阅读一篇学术论文时，这种细微差别会澄清很多困惑。例如，如果“X”是一个向量，那么X下标j代表一个标量，而<strong class="jl hj"> X </strong> (bold)下标j代表一个向量，而不是一个标量！</p><p id="928c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">大写字母用于描述变量的一般方面，而观察值用小写字母书写，这是一种统计和离散数学惯例。与编程惯例相反，小写是一个实例，大写通常是实例的集合。</p><p id="3082" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">两个量词的故事</strong></p><p id="61c9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">将线性模型和最近邻归类为分类器类似于将枪和刀归类为武器。是的，它们都是武器，但是试图用枪的知识来理解刀会让我们问这样的问题，比如我们在哪里为刀装载ammos？线性模型和最近邻都在尝试分类，但是它们的均值是昼夜不同的。</p><p id="3c77" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">线性分类器</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kf"><img src="../Images/bccaaf7d4edbdb904f6dd91a7108553c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWW8s70ZYgIV0MnfQ5-3dw.png"/></div></div></figure><p id="33df" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">线性分类器由两部分组成:线性模型和最小二乘法。它们是专门从事不同任务的独立功能。线性模型进行预测，而最小二乘法衡量预测的好坏。如果你仔细观察上图，你甚至可以看到最小二乘法内部的一个微小的线性模型被实际值y subscribe i减去。</p><p id="fff4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">事实上，线性分类器有更多的辅助功能，比如更新线性模型参数的优化器，我将在后面的博客中介绍。虽然线性分类器产生相对稳定的预测，但其严格的模型假设会产生偏差结果。最近的邻居在相反的一端，是非常灵活的，这也有自己的问题。我将在后面的博客中回到刚性和柔性模型假设。</p><p id="7dc0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">最近邻居</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kg"><img src="../Images/911d8ebeb842bc12f8e8e07ad377557c.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*lX4l53KY-aAFh1cQjig6PQ.png"/></div></figure><p id="4aed" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">回想一下我之前提到的优化器，它不存在于最近邻中。好吧，那我们到底为什么要用”。适合“在sklearn？答案与面向对象编程有关。我就不细说了，你要记住的就是”。fit”将训练数据存储为一个对象变量，因此我们可以在以后使用它进行预测。如果你认为将最近邻归类为机器学习模型有点误导，我将不得不同意你的观点，因为没有学习到任何参数。但是话说回来，我们仍然使用“虚数”这个术语，尽管它在现实世界中有非常广泛的应用，那么这是为什么呢？</p><p id="b235" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">那么最近邻是如何进行预测的呢？首先，它计算输入和每个可能的训练数据实例之间的距离(这就是为什么你的计算机正在融化)。其次，它将距离从最短到最远进行排序。第三，它过滤k个最短距离，并对其标签求和(标签表示它属于哪个类别)。最后，它将该总和除以k。例如，如果我们的目标是用k = 6对黄色(1)和蓝色(0)进行分类，并且最接近的5个邻居是黄色(1)，则我们得到5/6，这给出了更接近1的值。另一方面，如果邻域内的所有5个实例都是蓝色(0)，那么我们将得到1/6，这更接近于0。代表不同类别的二进制数是任意的，但是统计惯例告诉我们将1分配给感兴趣的类别。</p><p id="bf01" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">该模型的灵活性可以超越我们拥有100%训练数据准确性的理由。100%的准确率有什么问题？嗯，很多，实际上是两个。假设我们在训练数据中有一个实例“John ”,他被错误地标记为肥胖，而他的体重只有150磅。让我们也想象我们用1个最近邻(100%准确)训练一个KNN。这个模型将体重150磅的人归类为肥胖，而不是149磅或151磅，因此放大了错误的标签。即使数据中没有错误标注“约翰”是一个异常值，他实际上是肥胖的，因为他是一个超级小的家伙，“这个模型在没有看不见的数据的情况下不会是准确的，所有其他因素都是一样的，包括身高。如你所见，两种情况都会给出不准确的预测。这种不稳定的现象称为高方差，将在后面的博客中讨论。</p><p id="2723" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">结论</strong></p><p id="0604" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这一部分讨论的是大家最熟悉的概念，但更为详细。我相信对ML模型内部工作原理感兴趣的程序员可以从阅读中受益。如果你想看到这两个模型的代码，而不是“导入sklearn”并祈祷好运，我在下面有一个到我的github库的链接。感谢您的阅读，下一篇博客将讨论统计决策理论和更多内容。敬请期待！</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><p id="7c1f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">[1]: <a class="ae ko" href="https://github.com/janaSunrise" rel="noopener ugc nofollow" target="_blank">孙丽佳娜</a>，<a class="ae ko" href="https://github.com/janaSunrise" rel="noopener ugc nofollow" target="_blank">孙丽佳娜</a>。(2021年6月12日)。<em class="kp">最近邻</em><a class="ae ko" href="https://github.com/Yuanleoluo/MLfromscratch/blob/master/mlfromscratch/knn.py" rel="noopener ugc nofollow" target="_blank">https://github . com/yuan leoluo/mlfromscrack/blob/master/mlfromscrack/KNN . py</a></p><p id="756d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">[2]: <a class="ae ko" href="https://github.com/janaSunrise" rel="noopener ugc nofollow" target="_blank"> Sunrit Jana </a>，<a class="ae ko" href="https://github.com/janaSunrise" rel="noopener ugc nofollow" target="_blank"> Sunrit Jana </a>。(2021年6月12日)。<em class="kp">线性分类器</em><a class="ae ko" href="https://github.com/Yuanleoluo/MLfromscratch/blob/master/mlfromscratch/linear_regression.py" rel="noopener ugc nofollow" target="_blank">https://github . com/yuan leoluo/mlfromstack/blob/master/mlfromstack/Linear _ regression . py</a></p></div></div>    
</body>
</html>