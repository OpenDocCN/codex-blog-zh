<html>
<head>
<title>Distraction Detection using Pose Estimation with OpenCV and TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于OpenCV和TensorFlow的姿态估计的注意力分散检测</h1>
<blockquote>原文：<a href="https://medium.com/codex/distraction-detection-using-pose-estimation-with-opencv-and-tensorflow-16f28e733da4?source=collection_archive---------5-----------------------#2021-04-27">https://medium.com/codex/distraction-detection-using-pose-estimation-with-opencv-and-tensorflow-16f28e733da4?source=collection_archive---------5-----------------------#2021-04-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1c1bfd372006aa9d4d3aa15238eb5b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Af4jjYv6XM6zhkgfVfEdqA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图一。</strong>库依赖关系</figcaption></figure><h1 id="cd1a" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">摘要</strong></h1><p id="7e39" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">最近，由于新冠肺炎·疫情，我们的社会被推入了以在家工作为中心的劳动力大军。社会已经从在工作场所工作、在教室学习、在图书馆苦干项目转变为在家的中央工作站上计算所有这些任务。它打破了工作与生活的平衡，我猜想大多数人在远程工作时都会受到各种干扰。这个假设启发我创建了一个应用程序，可以量化地测量一个人在远程工作时的专注与疏忽行为。通过使用Python的张量流库进行面部检测，并使用OpenCV进行面部旋转，开发了一个应用程序来测试某人是否正在使用他们的工作站。</p><h1 id="246f" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> TensorFlow面部检测</strong></h1><p id="9e83" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">TensorFlow是一个面向机器学习的端到端开源python库。也就是说，它包含创建和训练健壮的机器学习模型所必需的工具。这款软件从2015年末开始上市，负责开发数千个机器学习模型。我决定利用一个预先训练好的模型进行面部检测，而不是重新发明轮子和训练我自己的面部检测算法。尹在GitHub 上发布了这个模型，它可以检测68个面部标志，这些标志可以用来定义面部对象[2]。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/ef953febb54d26682966f13643aea985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pokRL1SblUbd93ak8ym0Sw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图二</strong>。基于CNN分类器的人脸检测实现</figcaption></figure><h1 id="4752" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> OpenCV姿态估计</strong></h1><p id="3861" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">这就是项目从提供的代码偏离到实验代码的地方。姿态估计问题归结为计算检测到的面部对象的相对旋转/方向。这是计算机视觉中一个臭名昭著的数学问题，被称为n点透视问题(PnP)。[1]“n”代表图像平面中已知和已识别点的数量。PnP问题很特殊，因为它为我们提供了一种在给定<strong class="ju hj">预定义的2D坐标</strong>、<strong class="ju hj">实时3D坐标</strong>和来自当前摄像机的<strong class="ju hj">内在摄像机参数</strong>的情况下求解外部摄像机属性的方法。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/8fd5644d45dd32c80721231fd60fd9d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zCthemY4h7FrKh6t.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图3 </strong>。透视n点问题方程</figcaption></figure><p id="29be" class="pw-post-body-paragraph js jt hi ju b jv kx jx jy jz ky kb kc kd kz kf kg kh la kj kk kl lb kn ko kp hb bi translated">因此，当将当前图像帧与先前定义的面部检测模型进行比较时，<strong class="ju hj">数学函数将能够求解矩阵<em class="lc"> R </em>和<em class="lc">T</em>T5】中定义的外部相机属性。对于这个项目，我将只关心旋转矩阵<em class="lc"> R </em>，它可以用openCV的solvePNP(…)函数来计算</strong></p><h1 id="a360" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">实施初期的不足之处</strong></h1><p id="9a2a" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">找到旋转矩阵后，我以为我的项目完成了，嘣，简单。我只是将solvePnP函数返回的弧度值转换成度数，并显示信息。然而，虽然旋转矩阵被解决了，并且似乎当前说明了我的脸的当前旋转。实际的滚转、俯仰和偏航值与摄像机非常不一致。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/8a445318fe3bb926675d8a357127eacb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9YpsU3DaZos29socV9hkw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图4 </strong>。展示摄像机矩阵和偏斜度的最小变化(红色表示X，绿色表示Y)</figcaption></figure><p id="2345" class="pw-post-body-paragraph js jt hi ju b jv kx jx jy jz ky kb kc kd kz kf kg kh la kj kk kl lb kn ko kp hb bi translated">例如，简单地直视相机会产生-155度的X旋转，而实际上应该是0或180度。有点不方便，但是我可以通过给旋转轴值增加权重来解决。添加权重后，我添加了计时器，并通过检查面部是否在Y轴(-15，15)度(头部倾斜)和X轴(-10，10)度(头部转动)的范围内旋转，来计算用户是否在关注摄像头。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/f1d8b9fe744e5a9df85aa82b68634d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*16BlqPUll_5G5nPMIzLDhg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图5 </strong>。用旋转矩阵测试分心与注意力</figcaption></figure><h1 id="0fda" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">更简单的方法</strong></h1><p id="2180" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">简单地说，从旋转矩阵看23.9%的误差并不令人印象深刻。这是一个受计算机视觉启发的项目，所以我想用计算机视觉的概念来解决这个问题。然而，我不禁注意到，在尹的鼻子上有三个面部标志的面部探测器标记。因此，我们可以利用这些点中的两个来做一条线！利用一些代数和几何知识，我们可以解出鼻线的斜率，然后通过反正切函数计算角度:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/4d470e648c777923a749438f8717c447.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*i1b9ZVmdM0NwKy9kNvv9NQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图6。</strong>显示给定鼻子坐标的面部理论三角形。</figcaption></figure><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/4ab914970d21edccbccc16528e1c05ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*MEt5VzTk_exxtPgqLP0Wow.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图7。</strong>用于求解arctan的数学</figcaption></figure><p id="a724" class="pw-post-body-paragraph js jt hi ju b jv kx jx jy jz ky kb kc kd kz kf kg kh la kj kk kl lb kn ko kp hb bi translated">这意味着当用户面对相机时，角度将会很小(或者90度，如果完全笔直的话),当用户从相机移开时，角度将会增加！让我们比较结果:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/61b2cad40622719258dad78682b2ad8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5pFlObEazrHiZO8kQwo2Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">图8。</strong>用正切角测试</figcaption></figure><h1 id="2618" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">结论</strong></h1><p id="614d" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">总而言之，通过姿势估计算法来预测分心是一个有趣的实验项目。它带我进入了张量流的兔子洞，面部标志，PnP问题(并真正理解它！)，以及一些几何函数。它也扩展了我解决问题的技能，因为我最初是与旋转矩阵脱轨的。。。不太准确。几何示例显然是两个函数中更准确的一个，但是如果用户向下看手机屏幕，这个示例就失败了。如果有更多的时间和耐心，或许可以开发出更好的姿态估计算法来检测用户何时分心。当我制造这个问题时，我意识到姿势估计通常不能确定用户是否正在分心。大部分时间会管用吗？是的，然而，这个问题可以很容易地用眼睛跟踪算法而不是姿势估计算法来解决。</p><p id="b755" class="pw-post-body-paragraph js jt hi ju b jv kx jx jy jz ky kb kc kd kz kf kg kh la kj kk kl lb kn ko kp hb bi translated"><strong class="ju hj">源代码:</strong><a class="ae kq" href="https://github.com/Jacob-Mellichamp/DistractionDector" rel="noopener ugc nofollow" target="_blank"><strong class="ju hj">【https://github.com/Jacob-Mellichamp/DistractionDector】</strong>T5】</a></p><h1 id="bf13" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">关于性能的快速说明</strong></h1><p id="5c17" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我还试验了fps时间，以便在算法运行时最小化CPU的使用。通过利用0.2 FPS(或每五秒一帧)的速度，2.25 Ghz i5英特尔处理器能够成功跟踪分心的事物，在整个跟踪过程中仅使用5%的CPU，而无需外部显卡！</p><h1 id="d568" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">参考</h1><blockquote class="lh li lj"><p id="b864" class="js jt lc ju b jv kx jx jy jz ky kb kc lk kz kf kg ll la kj kk lm lb kn ko kp hb bi translated">[1]萨蒂亚·马利克。2016.基于OpenCV和Dlib的头部姿态估计。2021年4月15日检索自<a class="ae kq" href="https://learnopencv.com/head-poseestimation-using-opencv-and-dlib/" rel="noopener ugc nofollow" target="_blank">https://learnopencv . com/head-pose estimation-using-opencv-and-dlib/</a></p><p id="3561" class="js jt lc ju b jv kx jx jy jz ky kb kc lk kz kf kg ll la kj kk lm lb kn ko kp hb bi translated">[2]英·威茨曼。[未注明]。头部姿态估计。从https://github.com/yinguobing/head-pose-estimation<a class="ae kq" href="https://github.com/yinguobing/head-pose-estimation" rel="noopener ugc nofollow" target="_blank">检索到2021年4月10日</a></p></blockquote></div></div>    
</body>
</html>