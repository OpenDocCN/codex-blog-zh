<html>
<head>
<title>Machine Learning: My Very First ML Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:我的第一个人工智能项目</h1>
<blockquote>原文：<a href="https://medium.com/codex/machine-learning-my-very-first-ml-project-c347e12ce465?source=collection_archive---------10-----------------------#2022-08-15">https://medium.com/codex/machine-learning-my-very-first-ml-project-c347e12ce465?source=collection_archive---------10-----------------------#2022-08-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/72973a1a37c2172b068861be71aed41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BFyIweJ1Bk_09Qyd"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">由<a class="ae iu" href="https://unsplash.com/@austindistel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Austin Distel </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="47d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">嗨伙计们！我的第一个机器学习项目来了。该项目基于<a class="ae iu" href="https://archive.ics.uci.edu/ml/datasets/spambase" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>上的<a class="ae iu" href="https://archive.ics.uci.edu/ml/datasets/spambase" rel="noopener ugc nofollow" target="_blank"> Spambase数据集</a>。这个项目的主要目标是<strong class="ix hj">将电子邮件分类为垃圾邮件或非垃圾邮件</strong>。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="6b59" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">数据</h1><p id="708e" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我们先来看看数据。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="6abf" class="lm kb hi li b fi ln lo l lp lq">import pandas as pd<br/>import numpy as np</span><span id="db44" class="lm kb hi li b fi lr lo l lp lq">names = pd.read_csv('spambase/spambase.names', skiprows=32, sep=':\\s+', engine='python', names=['attr', ''])<br/>names = names['attr']<br/>names = list(names)<br/>names.append('label')<br/>print(names)</span><span id="cf5b" class="lm kb hi li b fi lr lo l lp lq">['word_freq_make',<br/> 'word_freq_address',<br/> 'word_freq_all',<br/> 'word_freq_3d',<br/> 'word_freq_our',<br/> 'word_freq_over',<br/> 'word_freq_remove',<br/> 'word_freq_internet',<br/> 'word_freq_order',<br/> 'word_freq_mail',<br/> 'word_freq_receive',<br/> 'word_freq_will',<br/> 'word_freq_people',<br/> 'word_freq_report',<br/> 'word_freq_addresses',<br/> 'word_freq_free',<br/> 'word_freq_business',<br/> 'word_freq_email',<br/> 'word_freq_you',<br/> 'word_freq_credit',<br/> 'word_freq_your',<br/> 'word_freq_font',<br/> 'word_freq_000',<br/> 'word_freq_money',<br/> 'word_freq_hp',<br/> 'word_freq_hpl',<br/> 'word_freq_george',<br/> 'word_freq_650',<br/> 'word_freq_lab',<br/> 'word_freq_labs',<br/> 'word_freq_telnet',<br/> 'word_freq_857',<br/> 'word_freq_data',<br/> 'word_freq_415',<br/> 'word_freq_85',<br/> 'word_freq_technology',<br/> 'word_freq_1999',<br/> 'word_freq_parts',<br/> 'word_freq_pm',<br/> 'word_freq_direct',<br/> 'word_freq_cs',<br/> 'word_freq_meeting',<br/> 'word_freq_original',<br/> 'word_freq_project',<br/> 'word_freq_re',<br/> 'word_freq_edu',<br/> 'word_freq_table',<br/> 'word_freq_conference',<br/> 'char_freq_;',<br/> 'char_freq_(',<br/> 'char_freq_[',<br/> 'char_freq_!',<br/> 'char_freq_$',<br/> 'char_freq_#',<br/> 'capital_run_length_average',<br/> 'capital_run_length_longest',<br/> 'capital_run_length_total',<br/> 'label']</span></pre><p id="5902" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集有58列，包括word_freq的48个连续属性，char_freq的6个连续属性，capital_run_length_average，capital_run_length_longest，capital_run_length_total，以及目标标签(1 =垃圾邮件，0 =非垃圾邮件)。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="9251" class="lm kb hi li b fi ln lo l lp lq">df = pd.read_csv('spambase/spambase.data', names=names)<br/>df.head()</span></pre><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/33dbdb92c70ce503791c1fa6c19df857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yl6kYoxsS_BoZteK_XDJhg.png"/></div></div></figure><p id="3d1a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为数据集已经被清理，并且所有变量都是连续的，所以没有做进一步的处理。</p><p id="0b19" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，将数据分成两个子集，一个用于训练，一个用于测试。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="b04d" class="lm kb hi li b fi ln lo l lp lq">from sklearn.model_selection import train_test_split</span><span id="79e8" class="lm kb hi li b fi lr lo l lp lq">X = df.drop('label', axis=1)<br/>y = df['label']</span><span id="4477" class="lm kb hi li b fi lr lo l lp lq">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)</span></pre><h1 id="2392" class="ka kb hi bd kc kd lt kf kg kh lu kj kk kl lv kn ko kp lw kr ks kt lx kv kw kx bi translated">培养</h1><h2 id="2583" class="lm kb hi bd kc ly lz ma kg mb mc md kk jg me mf ko jk mg mh ks jo mi mj kw mk bi translated">用GridSearchCV进行逻辑回归</h2><p id="a5c2" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">首先，我们从简单的<code class="du ml mm mn li b">LogisticRegression</code>开始。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="b888" class="lm kb hi li b fi ln lo l lp lq">from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.metrics import classification_report</span><span id="cc34" class="lm kb hi li b fi lr lo l lp lq">lr = LogisticRegression(random_state=0, max_iter=10000)</span><span id="433b" class="lm kb hi li b fi lr lo l lp lq">param_grid = {<br/>    'C': [1, 3, 5], <br/>    'solver': ['lbfgs', 'newton-cg']<br/>}</span><span id="226a" class="lm kb hi li b fi lr lo l lp lq">model = GridSearchCV(lr, param_grid=param_grid, cv=5).fit(X_train, y_train)</span><span id="b75d" class="lm kb hi li b fi lr lo l lp lq">print(model.best_params_)</span><span id="e688" class="lm kb hi li b fi lr lo l lp lq">y_pred = model.best_estimator_.predict(X_test)<br/>print(classification_report(y_test, y_pred))</span></pre><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/8e875b366b0fb4aeb2e3a0398ec9fbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WZFK7zh2dSJRJESd5ndqJA.png"/></div></div></figure><p id="5258" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">0.9的精度已经相当不错了，但是让我们探索一下其他的模型吧！</p><h2 id="6903" class="lm kb hi bd kc ly lz ma kg mb mc md kk jg me mf ko jk mg mh ks jo mi mj kw mk bi translated">基于GridSearchCV的梯度推进分类器</h2><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="f7e0" class="lm kb hi li b fi ln lo l lp lq">from sklearn.ensemble import GradientBoostingClassifier</span><span id="2635" class="lm kb hi li b fi lr lo l lp lq">gbc = GradientBoostingClassifier(random_state=0)</span><span id="0422" class="lm kb hi li b fi lr lo l lp lq">param_grid = {<br/>    'n_estimators': [10, 50, 100], <br/>    'max_depth': [5, 10, 20, 50], <br/>    'max_features': ['sqrt', 'log2'], <br/>    'criterion': ['friedman_mse', 'squared_error']<br/>}</span><span id="dc78" class="lm kb hi li b fi lr lo l lp lq">model = GridSearchCV(gbc, param_grid=param_grid, cv=5).fit(X_train, y_train)</span><span id="c24f" class="lm kb hi li b fi lr lo l lp lq">print(model.best_params_)</span><span id="78f7" class="lm kb hi li b fi lr lo l lp lq">y_pred = model.best_estimator_.predict(X_test)<br/>print(classification_report(y_test, y_pred))</span></pre><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/8f72a81c4f93a6ff1affdc4b52066a44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6er8TXyikQTxaFfS8VMX0A.png"/></div></div></figure><h2 id="b213" class="lm kb hi bd kc ly lz ma kg mb mc md kk jg me mf ko jk mg mh ks jo mi mj kw mk bi translated">GridSearchCV随机森林分类器</h2><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="5538" class="lm kb hi li b fi ln lo l lp lq">from sklearn.ensemble import RandomForestClassifier</span><span id="e100" class="lm kb hi li b fi lr lo l lp lq">rfc = RandomForestClassifier(random_state=0)</span><span id="f47d" class="lm kb hi li b fi lr lo l lp lq">param_grid = {<br/>    'n_estimators': [10, 50, 100], <br/>    'max_depth': [5, 10, 20, 50], <br/>    'max_features': ['sqrt', 'log2'], <br/>    'criterion': ['gini', 'entropy']<br/>}<br/>model = GridSearchCV(rfc, param_grid=param_grid, cv=5, verbose=3).fit(X_train, y_train)</span><span id="aa35" class="lm kb hi li b fi lr lo l lp lq">print(model.best_params_)</span><span id="a875" class="lm kb hi li b fi lr lo l lp lq">y_pred = model.best_estimator_.predict(X_test)<br/>print(classification_report(y_test, y_pred))</span></pre><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/c361274340cb3618fd03b80449c04473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dtCjlC2AKg7Atn8uzKcclA.png"/></div></div></figure><h2 id="77a7" class="lm kb hi bd kc ly lz ma kg mb mc md kk jg me mf ko jk mg mh ks jo mi mj kw mk bi translated">基于GridSearchCV的支持向量分类</h2><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="8512" class="lm kb hi li b fi ln lo l lp lq">from sklearn.svm import SVC</span><span id="9df6" class="lm kb hi li b fi lr lo l lp lq">svc = SVC(random_state=0)</span><span id="21ee" class="lm kb hi li b fi lr lo l lp lq">param_grid = {<br/>    'C': [0.1, 1, 3], <br/>    'kernel': ['rbf', 'linear', 'poly'], <br/>    'degree': [1, 3, 5], <br/>}<br/>model = GridSearchCV(svc, param_grid=param_grid, cv=5, verbose=2).fit(X_train, y_train)</span><span id="3ba5" class="lm kb hi li b fi lr lo l lp lq">print(model.best_params_)</span><span id="d789" class="lm kb hi li b fi lr lo l lp lq">y_pred = model.best_estimator_.predict(X_test)<br/>print(classification_report(y_test, y_pred))</span></pre><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/9b98266d5f798958c090bda1dc17b765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L3cvAn1UjzM-fcKrLfUQyg.png"/></div></div></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="c183" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">反射</h1><p id="adfd" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">总的来说，我很高兴四个模型都有很高的准确性。然而，垃圾邮件分类应该是一个NLP项目，其中数据处理是必不可少的。如您所见，数据集已经清理，我没有清理任何数据。因此，所有的荣誉都属于数据集的创造者:马克·霍普金斯、埃里克·里伯、乔治·福尔曼和贾普·苏尔蒙特！</p><p id="be02" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://github.com/hckkiu/machine-learning/tree/main/spam" rel="noopener ugc nofollow" target="_blank">GitHub上的视图</a></p></div></div>    
</body>
</html>