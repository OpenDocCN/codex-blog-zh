<html>
<head>
<title>Scala Functional Programming with Spark Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark数据集上的Scala函数式编程</h1>
<blockquote>原文：<a href="https://medium.com/codex/scala-functional-programming-with-spark-datasets-e470f48fcc11?source=collection_archive---------3-----------------------#2021-03-22">https://medium.com/codex/scala-functional-programming-with-spark-datasets-e470f48fcc11?source=collection_archive---------3-----------------------#2021-03-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/04614f75d14be7cacf655c15ef9256ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4WvzGA399cLd65EfWBLvKw.png"/></div></div></figure><h2 id="9225" class="hr hs ht bd b fp hu hv hw hx hy hz dx ia translated" aria-label="kicker paragraph"><a class="ae ge" href="http://medium.com/codex" rel="noopener">法典</a></h2><div class=""/><p id="41b7" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">本教程将给出使用Scala和Spark转换数据的例子。本教程的重点是如何在读入数据之后，写出数据之前使用Spark数据集…在<code class="du jx jy jz ka b">Extract, Transform, Load</code> (ETL)中的<code class="du jx jy jz ka b">Transform</code>。</p><p id="6e12" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">在Spark上用Scala编写代码的一个好处是，Scala允许你用面向对象编程(OOP)或者函数式编程(FP)的风格来编写。当Java开发人员只知道如何用OOP风格编写代码时，这是很有用的。然而，Spark是一个分布式处理引擎，它受益于以FP风格编写代码。在我看来，如果你写的函数是纯的、无副作用的、小的，那么写单元测试也更容易。Scala/Spark开发人员的目标应该是朝着用函数式风格编写应用程序的方向前进。这意味着使用纯函数、不可变值、高阶函数和复合。</p><p id="ee23" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">如果这些想法对你来说是新的，花些时间去理解为什么它们在Spark世界中是重要的。一个很好的资源是<a class="ae kb" href="https://learning.oreilly.com/library/view/functional-programming-in/9781617290657/" rel="noopener ugc nofollow" target="_blank">函数式编程</a>，可以在O'Reilly books上找到。</p><h1 id="7e37" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">进口</h1><p id="7240" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">仅导入您将在应用程序中使用的内容。这些是我们将在本教程中使用的导入。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="91ba" class="ln kd ht ka b fi lo lp l lq lr">import org.apache.spark.sql.types.StructType<br/>import org.apache.spark.sql.{Encoder, Encoders, DataFrame, Dataset, Row, SparkSession}<br/>import org.apache.spark.sql.functions.{avg, sum}<br/>import java.sql.Date</span></pre><h1 id="1e56" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">创建您的对象</h1><p id="3fa5" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">我们正在创建一个<code class="du jx jy jz ka b">object</code>，在Scala中是<code class="du jx jy jz ka b">Singleton</code>设计模式。我们将用特征<code class="du jx jy jz ka b">App</code>来扩展它，使它可以运行。你也可以选择使用<code class="du jx jy jz ka b">def main</code>而不是<code class="du jx jy jz ka b">App</code>。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="945c" class="ln kd ht ka b fi lo lp l lq lr">object FunctionalSpark extends App {</span></pre><h1 id="a733" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">助手功能</h1><p id="b3f6" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">这是一个帮助器函数，用于将数据帧转换为数据集。您应该始终对数据进行强类型化。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="39e3" class="ln kd ht ka b fi lo lp l lq lr">def toDS[T &lt;: Product: Encoder](df: DataFrame): Dataset[T] = df.as[T]</span></pre><h1 id="32f0" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">创建数据集</h1><p id="a598" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">我们将创建两个数据集用于本教程。在您自己的项目中，您通常会使用自己的框架来读取数据，但是我们将手动创建一个数据集，以便这些代码可以在任何环境中运行。</p><p id="64ee" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">Case类用于对数据进行强类型化。当将它们应用到<code class="du jx jy jz ka b">DataFrames</code>时，这允许您在Spark中使用<code class="du jx jy jz ka b">Dataset</code> API。DataFrames相当于Dataset[Row]，它是非类型化数据集。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="1513" class="ln kd ht ka b fi lo lp l lq lr">final case class Person(<br/>    personId: Int,<br/>    firstName: String,<br/>    lastName: String)</span><span id="924a" class="ln kd ht ka b fi ls lp l lq lr">  final case class Sales(<br/>    date: Date,<br/>    personId: Int,<br/>    customerName: String,<br/>    amountDollars: Double)</span></pre><p id="9d56" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">这是我们将使用<code class="du jx jy jz ka b">Seq</code>类型创建的数据。我们将使用其中的两个，一个用于人员，另一个用于一组销售数据。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="d73d" class="ln kd ht ka b fi lo lp l lq lr">val personData: Seq[Row] = Seq(<br/>    Row(1, "Eric", "Tome"),<br/>    Row(2, "Jennifer", "C"),<br/>    Row(3, "Cara", "Rae")<br/>  )</span><span id="3c2c" class="ln kd ht ka b fi ls lp l lq lr">  val salesData: Seq[Row] = Seq(<br/>    Row(new Date(1577858400000L), 1, "Third Bank", 100.29),<br/>    Row(new Date(1585717200000L), 3, "Pet's Paradise", 1233451.33),<br/>    Row(new Date(1585717200000L), 2, "Small Shoes", 4543.35),<br/>    Row(new Date(1593579600000L), 1, "PaperCo", 84990.15),<br/>    Row(new Date(1601528400000L), 1, "Disco Balls'r'us", 504.00),<br/>    Row(new Date(1601528400000L), 2, "Big Shovels", 9.99)<br/>  )</span></pre><p id="4964" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">使用Spark，我们可以从Scala <code class="du jx jy jz ka b">Seq</code>对象中读取数据。下面的代码将从上面定义的case类中创建一个<code class="du jx jy jz ka b">StructType</code>对象。然后我们有一个带参数<code class="du jx jy jz ka b">data</code>和<code class="du jx jy jz ka b">schema</code>的函数<code class="du jx jy jz ka b">getDSFromSeq</code>。然后，我们使用Spark读取我们的<code class="du jx jy jz ka b">Seq</code>对象，同时对它们进行强类型化。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="b7ce" class="ln kd ht ka b fi lo lp l lq lr">private val personSchema: StructType = Encoders.product[Person].schema<br/>  private val salesSchema: StructType  = Encoders.product[Sales].schema</span><span id="aea2" class="ln kd ht ka b fi ls lp l lq lr">  def getDSFromSeq[T &lt;: Product: Encoder](data: Seq[Row], schema: StructType) =<br/>    spark<br/>      .createDataFrame(<br/>        spark.sparkContext.parallelize(data),<br/>        schema<br/>      ).as[T]</span><span id="ab1c" class="ln kd ht ka b fi ls lp l lq lr">  val personDS: Dataset[Person] = getDSFromSeq[Person](personData, personSchema)<br/>  val salesDS: Dataset[Sales] = getDSFromSeq[Sales](salesData, salesSchema)</span></pre><p id="cd12" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><code class="du jx jy jz ka b">show()</code>方法会将<code class="du jx jy jz ka b">Dataset</code>或<code class="du jx jy jz ka b">DataFrame</code>中的数据显示到控制台。这是结果:</p><p id="23f9" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb id">人员数据</strong></p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="45d2" class="ln kd ht ka b fi lo lp l lq lr">+--------+---------+-------------+<br/>|personId|firstName |     lastName|<br/>+--------+---------+-------------+<br/>|       1|     Eric|         Tome|<br/>|       2| Jennifer|            C|<br/>|       3|     Cara|          Rae|<br/>+--------+---------+-------------+</span></pre><p id="a20b" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb id">销售数据</strong></p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="7fb8" class="ln kd ht ka b fi lo lp l lq lr">+----------+--------+----------------+-------------+<br/>|      date|personId|    customerName|amountDollars|<br/>+----------+--------+----------------+-------------+<br/>|2020-01-01|       1|      Third Bank|       100.29|<br/>|2020-04-01|       3|  Pet's Paradise|   1233451.33|<br/>|2020-04-01|       2|     Small Shoes|      4543.35|<br/>|2020-07-01|       1|         PaperCo|     84990.15|<br/>|2020-10-01|       1|Disco Balls'r'us|        504.0|<br/>|2020-10-01|       2|     Big Shovels|         9.99|<br/>+----------+--------+----------------+-------------+</span></pre><h1 id="5df3" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">过滤</h1><p id="642b" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">有多种方法可以过滤您的数据，以下是一些例子:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="26f3" class="ln kd ht ka b fi lo lp l lq lr">personDS.filter(r =&gt; r.firstName.contains("Eric"))</span></pre><p id="869d" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="84a7" class="ln kd ht ka b fi lo lp l lq lr">+--------+--------+--------+<br/>|personId|firstName|lastName|<br/>+--------+--------+--------+<br/>|       1|    Eric|    Tome|<br/>+--------+--------+--------+</span></pre><p id="7fde" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">滤波器，其中<code class="du jx jy jz ka b">personId</code>等于<code class="du jx jy jz ka b">1</code>。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="f8d0" class="ln kd ht ka b fi lo lp l lq lr">salesDS.filter(r =&gt; r.personId.equals(1))</span></pre><p id="afed" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="82e5" class="ln kd ht ka b fi lo lp l lq lr">+----------+--------+----------------+-------------+<br/>|      date|personId|    customerName|amountDollars|<br/>+----------+--------+----------------+-------------+<br/>|2020-01-01|       1|      Third Bank|       100.29|<br/>|2020-07-01|       1|         PaperCo|     84990.15|<br/>|2020-10-01|       1|Disco Balls'r'us|        504.0|<br/>+----------+--------+----------------+-------------+</span></pre><p id="70e0" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">在<code class="du jx jy jz ka b">amountDollars</code>大于<code class="du jx jy jz ka b">100</code>的地方过滤。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="43df" class="ln kd ht ka b fi lo lp l lq lr">salesDS.filter(r =&gt; r.amountDollars &gt; 100)</span></pre><p id="7cec" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="67e2" class="ln kd ht ka b fi lo lp l lq lr">+----------+--------+----------------+-------------+<br/>|      date|personId|    customerName|amountDollars|<br/>+----------+--------+----------------+-------------+<br/>|2020-01-01|       1|      Third Bank|       100.29|<br/>|2020-04-01|       3|  Pet's Paradise|   1233451.33|<br/>|2020-04-01|       2|     Small Shoes|      4543.35|<br/>|2020-07-01|       1|         PaperCo|     84990.15|<br/>|2020-10-01|       1|Disco Balls'r'us|        504.0|<br/>+----------+--------+----------------+-------------+</span></pre><p id="e639" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">在<code class="du jx jy jz ka b">amountDollars</code>大于<code class="du jx jy jz ka b">600</code>的地方过滤。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="05a6" class="ln kd ht ka b fi lo lp l lq lr">salesDS.filter(r =&gt; r.amountDollars &gt; 600)</span></pre><p id="1490" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="9c62" class="ln kd ht ka b fi lo lp l lq lr">+----------+--------+--------------+-------------+<br/>|      date|personId|  customerName|amountDollars|<br/>+----------+--------+--------------+-------------+<br/>|2020-04-01|       3|Pet's Paradise|   1233451.33|<br/>|2020-04-01|       2|   Small Shoes|      4543.35|<br/>|2020-07-01|       1|       PaperCo|     84990.15|<br/>+----------+--------+--------------+-------------+</span></pre><p id="6316" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">过滤<code class="du jx jy jz ka b">amountDollars</code>在<code class="du jx jy jz ka b">600</code>和<code class="du jx jy jz ka b">5000</code>之间的地方。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="4157" class="ln kd ht ka b fi lo lp l lq lr">salesDS.filter(r =&gt; r.amountDollars &gt; 600 &amp;&amp; r.amountDollars &lt; 5000)</span></pre><p id="47fd" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="50b4" class="ln kd ht ka b fi lo lp l lq lr">+----------+--------+------------+-------------+<br/>|      date|personId|customerName|amountDollars|<br/>+----------+--------+------------+-------------+<br/>|2020-04-01|       2| Small Shoes|      4543.35|<br/>+----------+--------+------------+-------------+</span></pre><h1 id="ed29" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">重命名列</h1><p id="72be" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">您可以使用<code class="du jx jy jz ka b">withColumn</code>或<code class="du jx jy jz ka b">withColumnRenamed</code>在spark中创建新列或重命名列。假设我们想要重命名所有的列，就像它们出现在数据库中一样。我们可以为数据集中的每一列调用一个<code class="du jx jy jz ka b">withColumnRenamed</code>，就像这样:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="b381" class="ln kd ht ka b fi lo lp l lq lr">df.withColumnRenamed("col1", "newcol1")<br/>        .withColumnRenamed("col2", "newcol2")<br/>        .withColumnRenamed("col3", "newcol3")<br/>        .withColumnRenamed("col4", "newcol4")<br/>        ...<br/>        .withColumnRenamed("coln", "newcoln")</span></pre><p id="28f7" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">然而，当修改大量的列时，有更好的解决方案。</p><ol class=""><li id="9665" class="lt lu ht jb b jc jd jg jh jk lv jo lw js lx jw ly lz ma mb bi translated">创建一个case类，定义最终数据集的外观。</li><li id="08ea" class="lt lu ht jb b jc mc jg md jk me jo mf js mg jw ly lz ma mb bi translated">创建一个返回<code class="du jx jy jz ka b">Map[String, String]</code>的函数，其中第一个字符串是当前列名，第二个是新名称。</li><li id="1b50" class="lt lu ht jb b jc mc jg md jk me jo mf js mg jw ly lz ma mb bi translated">创建一个接受<code class="du jx jy jz ka b">Map</code>并折叠输入<code class="du jx jy jz ka b">Dataset</code>的函数。fold中的函数是<code class="du jx jy jz ka b">withColumnRenamed</code>，它从<code class="du jx jy jz ka b">Map</code>中获取当前列名和新名称的值。一个新的<code class="du jx jy jz ka b">Dataset</code>被返回给你最后的case类。</li></ol><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="e7ac" class="ln kd ht ka b fi lo lp l lq lr">final case class SalesChangeColumnNames(<br/>    SALES_DATE: Date,<br/>    PERSON_ID: Int,<br/>    CUSTOMER_NAME: String,<br/>    SALES_IN_DOLLARS: Double)</span><span id="1cb2" class="ln kd ht ka b fi ls lp l lq lr">  def saleColumns: Map[String, String] =<br/>    Map(<br/>      "date"          -&gt; "SALES_DATE",<br/>      "personId"      -&gt; "PERSON_ID",<br/>      "customerName"  -&gt; "CUSTOMER_NAME",<br/>      "amountDollars" -&gt; "SALES_IN_DOLLARS"<br/>    )</span><span id="aef2" class="ln kd ht ka b fi ls lp l lq lr">  def renameColumns(ds: Dataset[Sales], m: Map[String, String]): Dataset[SalesChangeColumnNames] =<br/>    toDS {<br/>      m.foldLeft(ds.toDF())((acc, colnames) =&gt; acc.withColumnRenamed(colnames._1, colnames._2))<br/>    }</span><span id="4f6d" class="ln kd ht ka b fi ls lp l lq lr">  renameColumns(salesDS, saleColumns)</span></pre><p id="d412" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="000b" class="ln kd ht ka b fi lo lp l lq lr">+----------+---------+----------------+----------------+<br/>|SALES_DATE|PERSON_ID|   CUSTOMER_NAME|SALES_IN_DOLLARS|<br/>+----------+---------+----------------+----------------+<br/>|2020-01-01|        1|      Third Bank|          100.29|<br/>|2020-04-01|        3|  Pet's Paradise|      1233451.33|<br/>|2020-04-01|        2|     Small Shoes|         4543.35|<br/>|2020-07-01|        1|         PaperCo|        84990.15|<br/>|2020-10-01|        1|Disco Balls'r'us|           504.0|<br/>|2020-10-01|        2|     Big Shovels|            9.99|<br/>+----------+---------+----------------+----------------+</span></pre><h1 id="26cd" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">连接</h1><p id="071f" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">在Spark中连接数据很简单，但是当连接两个不同的数据集时，您需要创建一个新的case类并输入连接的输出。Spark支持多种连接类型，左连接、右连接、全连接、反连接以及SQL标准中的所有外部连接。在这种情况下，我们在<code class="du jx jy jz ka b">personId</code>上连接，并使用一个<code class="du jx jy jz ka b">left</code>连接。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="7086" class="ln kd ht ka b fi lo lp l lq lr">final case class JoinedData(<br/>    personId: Int,<br/>    firstName: String,<br/>    lastName: String,<br/>    date: Date,<br/>    customerName: String,<br/>    amountDollars: Double)</span><span id="8e6e" class="ln kd ht ka b fi ls lp l lq lr">  val joinedData: Dataset[JoinedData] =<br/>    toDS(personDS.join(salesDS, Seq("personId"), "left"))</span></pre><p id="b3b3" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="4661" class="ln kd ht ka b fi lo lp l lq lr">+--------+---------+-----+----------+----------------+-------------+<br/>|personId|firstName|lastN|      date|    customerName|amountDollars|<br/>+--------+---------+-----+----------+----------------+-------------+<br/>|       1|     Eric| Tome|2020-01-01|      Third Bank|       100.29|<br/>|       1|     Eric| Tome|2020-07-01|         PaperCo|     84990.15|<br/>|       1|     Eric| Tome|2020-10-01|Disco Balls'r'us|        504.0|<br/>|       3|     Cara|  Rae|2020-04-01|  Pet's Paradise|   1233451.33|<br/>|       2| Jennifer|    C|2020-04-01|     Small Shoes|      4543.35|<br/>|       2| Jennifer|    C|2020-10-01|     Big Shovels|         9.99|<br/>+--------+---------+-----+----------+----------------+-------------+</span></pre><h1 id="3382" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">使用地图</h1><p id="f77c" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">地图是Scala语言中一个强大的特性。我们在这里使用它们将数据从一种类型的对象转换成另一种类型的对象。map函数将使用用户定义的函数(<code class="du jx jy jz ka b">dollarToEuro</code>、<code class="du jx jy jz ka b">initials</code>)和原始字符串类型的函数(<code class="du jx jy jz ka b">toUpperCase</code>、<code class="du jx jy jz ka b">toLowerCase</code>、<code class="du jx jy jz ka b">trim</code>)遍历数据集中的每条记录，将该记录映射到一个新的对象。我们再次创建一个case类，用于创建我们映射到的对象。还可以使用地图更改列顺序，您可以在这里看到我们将日期移动到列列表的顶部。我们地图的输出产生了一个类型为<code class="du jx jy jz ka b">JoinedDataWithEuro</code>的数据集。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="4e98" class="ln kd ht ka b fi lo lp l lq lr">final case class JoinedDataWithEuro(<br/>    date: Date,<br/>    personId: Int,<br/>    firstName: String,<br/>    lastName: String,<br/>    initials: String,<br/>    customerName: String,<br/>    amountDollars: Double,<br/>    amountEuros: Double)</span><span id="542c" class="ln kd ht ka b fi ls lp l lq lr">  def dollarToEuro(d: Double): Double = d * 1.19</span><span id="9fd4" class="ln kd ht ka b fi ls lp l lq lr">  def initials(firstName: String, lastName: String): String =<br/>    s"${firstName.substring(0, 1)}${lastName.substring(0, 1)}"</span><span id="d92b" class="ln kd ht ka b fi ls lp l lq lr">  val joinedDataWithEuro: Dataset[JoinedDataWithEuro] =<br/>    joinedData.map(r =&gt;<br/>      JoinedDataWithEuro(<br/>        r.date,<br/>        r.personId,<br/>        r.firstName.toUpperCase(), // modified column<br/>        r.lastName.toLowerCase(), // modified column<br/>        initials(r.firstName, r.lastName), // new column<br/>        r.customerName.trim(), // modified column<br/>        r.amountDollars,<br/>        dollarToEuro(r.amountDollars) // new column<br/>      )<br/>    )</span></pre><p id="cbcd" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="8b21" class="ln kd ht ka b fi lo lp l lq lr">+----------+--------+---------+--------+--------+----------------+-------------+------------------+<br/>|      date|personId|firstName|lastName|initials|    customerName|amountDollars|       amountEuros|<br/>+----------+--------+---------+--------+--------+----------------+-------------+------------------+<br/>|2020-01-01|       1|     ERIC|    tome|      ET|      Third Bank|       100.29|          119.3451|<br/>|2020-07-01|       1|     ERIC|    tome|      ET|         PaperCo|     84990.15|101138.27849999999|<br/>|2020-10-01|       1|     ERIC|    tome|      ET|Disco Balls'r'us|        504.0|            599.76|<br/>|2020-04-01|       3|     CARA|     rae|      CR|  Pet's Paradise|   1233451.33|      1467807.0827|<br/>|2020-04-01|       2| JENNIFER|       c|      JC|     Small Shoes|      4543.35|         5406.5865|<br/>|2020-10-01|       2| JENNIFER|       c|      JC|     Big Shovels|         9.99|           11.8881|<br/>+----------+--------+---------+--------+--------+----------------+-------------+------------------+</span></pre><h1 id="c85e" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">聚集</h1><p id="0143" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">聚合是通过使用DataFrame API来完成的，但是在聚合之后我们又回到了强类型数据集。聚合中可以使用各种函数:avg、sum、count等。下面的示例按用户汇总了我们的销售数据，并计算了销售额的平均值。</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="6aaa" class="ln kd ht ka b fi lo lp l lq lr">final case class TotalSalesByPerson(<br/>    personId: Int,<br/>    firstName: String,<br/>    lastName: String,<br/>    initials: String,<br/>    sumAmountDollars: Double,<br/>    sumAmountEuros: Double,<br/>    avgAmountDollars: Double,<br/>    avgAmountEuros: Double)</span><span id="0283" class="ln kd ht ka b fi ls lp l lq lr">  val totalSalesByPerson: Dataset[TotalSalesByPerson] =<br/>    toDS {<br/>      joinedDataWithEuro<br/>        .groupBy($"personId", $"firstName", $"lastName", $"initials").agg(<br/>          sum($"amountDollars").alias("sumAmountDollars"),<br/>          sum($"amountEuros").alias("sumAmountEuros"),<br/>          avg($"amountDollars").alias("avgAmountDollars"),<br/>          avg($"amountEuros").alias("avgAmountEuros")<br/>        )<br/>    }</span></pre><p id="82c1" class="pw-post-body-paragraph iz ja ht jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">结果:</p><pre class="lf lg lh li fd lj ka lk ll aw lm bi"><span id="40fb" class="ln kd ht ka b fi lo lp l lq lr">+--------+---------+--------+--------+-----------------+------------------+------------------+------------------+<br/>|personId|firstName|lastName|initials| sumAmountDollars|    sumAmountEuros|  avgAmountDollars|    avgAmountEuros|<br/>+--------+---------+--------+--------+-----------------+------------------+------------------+------------------+<br/>|       2| JENNIFER|       c|      JC|          4553.34|5418.4746000000005|           2276.67|2709.2373000000002|<br/>|       3|     CARA|     rae|      CR|       1233451.33|      1467807.0827|        1233451.33|      1467807.0827|<br/>|       1|     ERIC|    tome|      ET|85594.43999999999|101857.38359999999|28531.479999999996|        33952.4612|<br/>+--------+---------+--------+--------+-----------------+------------------+------------------+------------------+</span></pre><h1 id="42e6" class="kc kd ht bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">结论</h1><p id="31eb" class="pw-post-body-paragraph iz ja ht jb b jc la je jf jg lb ji jj jk lc jm jn jo ld jq jr js le ju jv jw hb bi translated">这是对如何使用Scala在Spark中处理数据的简单介绍。我们关注使用数据集的转换的功能实现。如果您有任何问题，请随时发表评论！</p></div></div>    
</body>
</html>