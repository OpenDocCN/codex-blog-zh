<html>
<head>
<title>Detecting Flowers with the Iris Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用虹膜数据集检测花朵</h1>
<blockquote>原文：<a href="https://medium.com/codex/detecting-flowers-with-the-iris-dataset-b17efe16975d?source=collection_archive---------6-----------------------#2021-06-25">https://medium.com/codex/detecting-flowers-with-the-iris-dataset-b17efe16975d?source=collection_archive---------6-----------------------#2021-06-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e77ed0be1180935c93ac27a980f750e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kXYKlCF_wBBm9rIuAlz5Yw.png"/></div></div></figure><p id="7a61" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你正在学习机器学习，最好的方法是掌握监督学习。最受欢迎的练习之一是使用鸢尾数据集将鸢尾花分类为三个物种。这似乎是一个非常简单的问题，但对于任何正在练习机器学习的人来说，这是一个很好的起点。让我们开始吧！</p><h1 id="f77d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤1:提取特征和目标变量</h1><p id="4272" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在我们开始寻找最佳分类模型之前，我们首先需要看看数据<em class="kr">是否是可分类的</em>。首先，我从<a class="ae ks" href="https://www.kaggle.com/uciml/iris?select=Iris.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载了数据集。从数据集中，我通过读取数据集的文件路径从数据中提取特征和目标变量:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="bb87" class="lc jp hi ky b fi ld le l lf lg">import pandas as pd<br/>import sklearn as sk</span><span id="7dfb" class="lc jp hi ky b fi lh le l lf lg">iris_path = "/content/drive/MyDrive/Colab Notebooks/Detecting_Flowers_Improved_Files/Iris.csv"<br/>iris_data = pd.read_csv(iris_path)<br/>columns = iris_data.columns<br/>print(columns)</span></pre><p id="90a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="b14b" class="lc jp hi ky b fi ld le l lf lg">Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','Species'], dtype='object')</span></pre><p id="f283" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我知道花瓣长度、花瓣宽度、萼片长度、萼片宽度是我的<strong class="is hj">特征</strong>，物种栏是我的<strong class="is hj">目标变量</strong>。但在这一点上，我仍然不知道每个物种在数据集中的分布。这决定了我是否需要在训练我的模型之前预处理我的数据。为了进行检查，我使用了以下代码:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="1697" class="lc jp hi ky b fi ld le l lf lg">group = iris_data.groupby('Species').size()<br/>print(group)</span></pre><p id="a2c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="22c3" class="lc jp hi ky b fi ld le l lf lg">Species <br/>Iris-setosa        50 <br/>Iris-versicolor    50 <br/>Iris-virginica     50 <br/>dtype: int64</span></pre><p id="afe1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">好了，现在我知道我的数据在物种方面是平均分布的，它有六列。是时候选择我们的目标变量了。</p><h1 id="d6f1" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤2:设置目标变量和特征</h1><p id="b9ad" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">使用Scikit Learn的train-test-split功能，这个步骤非常简单。它将当前数据集分成训练子集和测试子集。要导入，请使用以下代码:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="a2ee" class="lc jp hi ky b fi ld le l lf lg">from sklearn.model_selection import train_test_split</span></pre><p id="eeb3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用训练子集训练所选择的模型，并且用测试子集评估该模型。代码如下:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="0697" class="lc jp hi ky b fi ld le l lf lg">features = ['SepalWidthCm', 'SepalLengthCm', 'PetalLengthCm', 'PetalWidthCm', 'Id']</span><span id="7f18" class="lc jp hi ky b fi lh le l lf lg">train_x, val_x, train_y, val_y = train_test_split(iris_data[features], iris_data['Species'], random_state = 1)</span></pre><p id="c6e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是创建训练和测试子集的全部内容。现在是有趣的部分——挑选模特！</p><h1 id="2d30" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤3:选择要训练的模型</h1><p id="ca44" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在选择要训练的模型时，考虑您试图解决的问题是很重要的。在这种情况下，我们试图将花分类为Setosa、Versicolor或virg nica——因此在这种情况下我们需要使用分类器。对于这个问题，我使用了四种不同的分类器——K近邻分类器、半径近邻分类器、随机梯度下降和支持向量分类器。下面是每个分类器功能的简要介绍:</p><ol class=""><li id="7f92" class="li lj hi is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated">k-最近邻分类器(KNN):使用给定范围内的所有数据点(例如，如果k = 3，它将使用3个单位范围内的所有数据)。</li><li id="8750" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">半径邻居分类器(RN):类似于KNNs，它测量给定半径内最近的数据点。</li><li id="352f" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">随机梯度下降(SGD):一种训练模型以确保误差最小的方法。</li><li id="23ff" class="li lj hi is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">支持向量分类器(SVC):通过使用数据中最佳拟合线附近的训练数据点来执行多类分类。还有助于节省内存，这也是它适用于大型数据集的原因。</li></ol><p id="17b7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解关于这些分类器的更多信息，请查看Scikit Learn的文档。</p><p id="9224" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们对分类器有了一些了解，我们需要从Scikit学习库中导入它们并实现它们。</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="9041" class="lc jp hi ky b fi ld le l lf lg">from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.neighbors import RadiusNeighborsClassifier<br/>from sklearn.linear_model import SGDClassifier<br/>from sklearn.svm import SVC</span><span id="ebeb" class="lc jp hi ky b fi lh le l lf lg">#implementing models<br/>kNN = KNeighborsClassifier(n_neighbors=3)<br/>rN = RadiusNeighborsClassifier(radius = 3)<br/>sgd = SGDClassifier()<br/>svc = SVC()</span></pre><p id="2966" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们已经创建了我们的模型，让我们用训练数据来拟合它们，并获得它们在测试数据上的准确性分数。</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="301d" class="lc jp hi ky b fi ld le l lf lg">kNN.fit(train_x, train_y)<br/>print("KNN prediction: {}".format(kNN.score(val_x, val_y)))</span><span id="89ca" class="lc jp hi ky b fi lh le l lf lg">rN.fit(train_x, train_y)<br/>print("RN prediction: {}".format(rN.score(val_x, val_y)))</span><span id="8ace" class="lc jp hi ky b fi lh le l lf lg">sgd.fit(train_x, train_y)<br/>print("SGD prediction: {}".format(sgd.score(val_x, val_y)))</span><span id="8ea9" class="lc jp hi ky b fi lh le l lf lg">svc.fit(train_x, train_y)<br/>print("SVC prediction: {}".format(svc.score(val_x, val_y)))</span></pre><p id="d425" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="22f8" class="lc jp hi ky b fi ld le l lf lg">KNN prediction: 0.9736842105263158 <br/>RN prediction: 0.9736842105263158 <br/>SGD prediction: 0.5789473684210527 <br/>SVC prediction: 0.9473684210526315</span></pre><p id="0cb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">太好了，模型可以预测结果。但是……得到一个模型的分数并不足以衡量它预测结果的能力。这将引导我们到最后一步，我们使用模型评估技术来评估我们的模型。</p><h1 id="2094" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤4:评估模型的三种方法</h1><h2 id="d123" class="lc jp hi bd jq lw lx ly ju lz ma mb jy jb mc md kc jf me mf kg jj mg mh kk mi bi translated"><strong class="ak">估计量评分法</strong></h2><p id="5b00" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我们已经使用了评估分数法，它提供了一个分数，告诉我们预测结果与实际结果有多接近。这种评分方法并不完全可靠，因为它没有考虑随机数据，或者没有比较真阳性和真阴性与假阳性和假阴性。</p><h2 id="f70c" class="lc jp hi bd jq lw lx ly ju lz ma mb jy jb mc md kc jf me mf kg jj mg mh kk mi bi translated"><strong class="ak"> K倍交叉验证</strong></h2><p id="94b8" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">K-Fold交叉验证使训练和测试数据集中使用的数据集随机化。数据集被分成k个子集，其中k-1个子集用于训练，其余的用于模型验证。这个过程不断重复k次。例如，如果数据被指定为分成5个子集，其中每个子集被命名为s1、s2、s3、s4和s5。在第一次迭代中，s1将用于验证，而s2、s3、s4、s5将用于训练。在第二次迭代中，s2将用于验证，s1、s3、s4和s5将用于训练。这个过程重复5次，总得分作为所有得分的平均值。</p><p id="8015" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">好吧，它随机化了数据集，但是为什么交叉验证有用呢？当数据集中存在不平衡时，这一点尤为重要。例如，如果数据集中的杂色物种比刚毛物种多，那么k-fold交叉验证将非常有助于评估模型。但是如果每个物种都有相同数量的样本，为什么我们要在这个例子中使用它呢？因为我们不知道物种是否在训练和测试数据集之间平分秋色，交叉验证是确保数据真正随机化的唯一方法。</p><p id="c8cd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是我们将如何实现它:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="86f2" class="lc jp hi ky b fi ld le l lf lg">from sklearn.model_selection import cross_val_score<br/>from sklearn.model_selection import KFold</span><span id="e5b8" class="lc jp hi ky b fi lh le l lf lg">kNN = KNeighborsClassifier(n_neighbors=3)<br/>rN = RadiusNeighborsClassifier(radius = 5)<br/>sgd = SGDClassifier()<br/>svc = SVC()</span><span id="dc29" class="lc jp hi ky b fi lh le l lf lg">cv = KFold(n_splits=10, random_state=1, shuffle=True)<br/>X = np.array(iris_data[features])<br/>Y = iris_data['Species']</span><span id="c736" class="lc jp hi ky b fi lh le l lf lg">kEval = cross_val_score(kNN, X, Y, scoring='accuracy', cv=cv, n_jobs=1)<br/>print("KNN CV Accuracy: %s, %s" % (mean(kEval), std(kEval)))</span><span id="a0ff" class="lc jp hi ky b fi lh le l lf lg">rNEval = cross_val_score(rN, X, Y, scoring='accuracy', cv=cv, n_jobs=1)<br/>print(f"RNN CV Accuracy: {mean(rNEval)} +/-{std(rNEval)}")</span><span id="d384" class="lc jp hi ky b fi lh le l lf lg">sgdEval = cross_val_score(sgd, X, Y, scoring='accuracy', cv=cv, n_jobs=1)<br/>print("SGD CV Accuracy: %s, %s" % (mean(sgdEval), std(sgdEval)))</span><span id="435a" class="lc jp hi ky b fi lh le l lf lg">svcEval = cross_val_score(svc, X, Y, scoring='accuracy', cv=cv, n_jobs=1)<br/>print("SVC CV Accuracy: %s, %s" % (mean(svcEval), std(svcEval)))</span></pre><p id="bf4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="3004" class="lc jp hi ky b fi ld le l lf lg">KNN CV Accuracy: 1.0, 0.0 <br/>RNN CV Accuracy: 0.9933333333333334 +/-0.019999999999999997 <br/>SGD CV Accuracy: 0.7733333333333334, 0.1818424226264781 <br/>SVC CV Accuracy: 0.9866666666666667, 0.026666666666666658</span></pre><p id="b418" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">啊哈！现在我们看到预测并不像我们想象的那样完美，尽管我们的数据分布相当均匀。</p><h2 id="3322" class="lc jp hi bd jq lw lx ly ju lz ma mb jy jb mc md kc jf me mf kg jj mg mh kk mi bi translated"><strong class="ak">分类指标(准确度)</strong></h2><p id="1b6a" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">分类指标由四个部分组成——准确度、召回率、精确度和F1分数。解释这四个因素会占用一整篇文章，但是为了简单起见，我们将只测量我们的模型做出的预测的准确性。</p><p id="8149" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">分类模型的性能基于许多正确或不正确的预测。最好用<strong class="is hj">混淆矩阵</strong>来说明:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/eecc21717736c0bb07ae0d156021270b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JZ09WSQ423wcPKTgvyGQqA.png"/></div></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">鸣谢:<a class="ae ks" href="https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2020/04/performance-evaluation-metrics-classification . html</a></figcaption></figure><p id="fc10" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">列表示真实的实际值，而行表示分类器做出的预测值。当实际值和预测值都为正时，称为真阳性(TP)，如果它们都为假，则称为假阴性(FN)。当一个预测值是正的，但实际上应该是负的，这是一个假阳性(FP)，反之为真阴性(TN)。准确度是正确预测的总数(TP + TN)除以所有做出的预测(TP + FN + FP + TN)的度量。所以这个等式看起来像这样:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="8ffe" class="lc jp hi ky b fi ld le l lf lg">Accuracy = (TP + FN)/ (TP + FN + FP + TN)</span></pre><p id="0d57" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您一定会问，为什么我们要在所有四个分类指标中衡量准确性？这是因为当目标变量平衡时，准确性是有用的(在本例中就是这样！).</p><p id="8440" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">唷，那是一大堆<em class="kr">令人困惑的</em>素材(明白了吗？).让我们用代码实现它吧！</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="b054" class="lc jp hi ky b fi ld le l lf lg">y_true = val_y #storing the actual y validation data, see how far off the model predicts</span><span id="fe6d" class="lc jp hi ky b fi lh le l lf lg">kNN.fit(train_x, train_y)<br/>rN.fit(train_x, train_y)<br/>sgd.fit(train_x, train_y)<br/>svc.fit(train_x, train_y)</span><span id="9373" class="lc jp hi ky b fi lh le l lf lg">kNN_y_pred = kNN.predict(val_x)<br/>print(f"KNN accuracy: {accuracy_score(y_true, kNN_y_pred)}")</span><span id="9ff4" class="lc jp hi ky b fi lh le l lf lg">rNN_y_pred = rN.predict(val_x)<br/>print(f"RNN accuracy: {accuracy_score(y_true, rNN_y_pred)}")</span><span id="9fea" class="lc jp hi ky b fi lh le l lf lg">sgd_y_pred = sgd.predict(val_x)<br/>print("SGD accuracy: %s" % accuracy_score(y_true, sgd_y_pred))</span><span id="be67" class="lc jp hi ky b fi lh le l lf lg">svc_y_pred = svc.predict(val_x)<br/>print("SVC accuracy: %s" % accuracy_score(y_true, svc_y_pred))</span></pre><p id="b3a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果:</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="f822" class="lc jp hi ky b fi ld le l lf lg">KNN accuracy: 0.9736842105263158 <br/>RNN accuracy: 1.0 <br/>SGD accuracy: 0.7631578947368421 <br/>SVC accuracy: 0.9473684210526315</span></pre><p id="95e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们对模型的性能有了更多的了解！看起来K-最近邻是我们使用的五个分类器中最好的模型。</p><h1 id="0d22" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">为什么模型评估如此重要？</strong></h1><p id="0eac" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">评估模型揭示了许多关于它们的分类技术，这有助于我们微调我们的结果。例如，如果我们只使用估计值评分方法来评估模型，那么RNs和KNNs将是最好的分类器。但是在经历了所有的技术之后，很明显KNN是这个问题的最佳分类器。</p><p id="d65a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对花卉进行分类似乎是一个简单的问题，但它揭示了大量的技能，如探索数据集，识别特征和目标变量，以及评估模型。这些技巧适用于几乎每一个监督学习问题，并且绝对是掌握的关键！</p><p id="679c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望你喜欢阅读这篇文章，并发现它是有帮助的。敬请关注更多内容！</p></div></div>    
</body>
</html>