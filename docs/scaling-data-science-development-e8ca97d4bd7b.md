# 扩展数据科学发展

> 原文：<https://medium.com/codex/scaling-data-science-development-e8ca97d4bd7b?source=collection_archive---------7----------------------->

大约十年前，*软件开发*曾经比今天的生产力低得多。像**代码版本**(如果存在的话)是使用文件锁或合并技术实现的，这经常会导致代码丢失。**测试**(同样，当完成时)是手动执行的。**部署**是压缩所有代码，并通过 ssh、ftp 甚至用闪存盘拷贝到服务器。**横向扩展**购买新的裸机，并将其放置在冷藏室(或开发人员的办公桌下)。

随着 DevOps 思想的兴起，大多数公司开始开发关于软件基础设施的高级抽象，并实现应用这些概念的过程。开发方法、基础设施即代码、持续集成、持续交付现在是在这个时间框架内创建的日常概念，这些概念将软件开发的生产力提升到了今天的场景。

**机器学习**需求在过去几年呈指数级增长，现在数据科学家面临着与软件开发人员多年前面临的相同的生产力困境。快速探索、训练和部署，可能在一开始是更吸引人的想法，但它可能会导致大量的麻烦。软件开发中常用的术语“技术债务”可以也应该用在[数据科学中](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)。

# 数据科学发展过程

![](img/89d5a1c98078988563591e029a7b127a.png)

CRISP-DM 流程图

[CRISP-DM](http://www.datascience-pm.com/crisp-dm-2/) 是理解*数据科学开发*过程的一个很好的模板。它概述了一个循环的过程，从理解业务问题到评估模型(或者一般意义上的*算法*)。数据科学家可能会多次经历这一循环，并在此过程中进行部署。

数据科学家花大部分时间*探索*、*研究*和*测试假设*。这通常是使用笔记本或个人脚本构建大部分代码的地方。当这些生成的脚本和笔记本变成生产模型的实际代码时，问题就出现了。

这种做法本身是无害的，但是它通常会导致一些[代码问题](https://towardsdatascience.com/how-to-avoid-common-difficulties-in-your-data-science-programming-environment-1b78af2977df)，它也可能会导致一些技术债务和手工部署。对于第一次交付，这可能意味着没有伤害，但从长远来看，维护和发展这个模型将是一个主要问题。

公司 MLOps 团队(或区域)通常只关注模型部署和服务。但是，在模型准备好部署之前，数据科学家必须处理一大堆问题。与 DevOps 一样，MLOps 关注的是定义概念和构建平台，不仅使部署，而且使整个开发过程更有成效。

# 控制过程

我们都知道*软件开发*流程远非完美，但它们比*数据科学开发*流程领先几光年，因此，为了便于讨论，它将被用作基线。

持续交付代码是一个复杂的过程，需要一些标准化层和工具来自动化和监控这些标准。虽然每个公司都不一样，但是软件开发通常有三个阶段*。*

***开发**开发人员编写代码以实现业务目标的阶段。**集成**阶段，包括构建和测试代码，以检查它是否准备好投入生产。**交付**阶段，主要目标是将新代码交付到生产环境中。这一阶段也是我们希望持续监控应用程序健康和业务指标的阶段。*

*虽然这看起来很简单，但在整个过程中有一些复杂的挑战需要应对。*

# *协作和版本控制*

*在一个公司中，我们必须确保所有的开发人员能够协作，用相同的源代码构建相同的应用程序。如今这几乎是一种必然。大多数公司已经在使用某种代码协作标准，比如 git 或 svn。*

# *环境标准化*

*外部库和其他环境依赖通常是生产环境中许多问题的原因。使用容器和一些包管理器，我们可以很容易地实现这种环境复制，将开发人员机器的完全相同的设置交付给生产。*

*![](img/7321759a8c86220334c54e4856af01a4.png)*

# *连续累计*

*持续确保代码质量对于每天(甚至每天不止一次)交付代码的公司来说是*必须具备的*。在将代码放在一个集中的存储库中之后，实现一个工具来自动化构建、测试和依赖于输出的过程，避免在生产中部署坏代码就容易多了。这里的输出是一个经过验证的包，将被部署到生产环境中。*

# *持续部署*

*通过集成过程测试和验证代码后，必须将包(例如 docker 映像)部署到生产基础设施中。有许多技术可以部署这些代码，但这不是本文的重点。*

# *监视*

*随着代码的部署，我们必须不断地确保代码在监控健康和业务指标时不会被破坏。这也是一个非常复杂的主题，但是对于本文来说，知道它的存在就足够了。*

# *发展生产力*

*随着持续的集成/部署，*软件开发*开始制造流水线来自动构建/测试/部署应用程序。这种做法导致了另一个水平的生产力和质量。*

*同样的过程可以应用于数据科学，但不幸的是，我们不能使用完全相同的抽象，因为要解决的问题略有不同。*

*首先，如前所述，数据科学家将把大部分时间用于探索和测试新算法。设置一个安全的实验环境是一项非常复杂的任务，可能需要太多的时间。*

*除了代码，模型还使用数据作为开发的一部分。这意味着除了所需的代码，您将使用数据(通常称为训练数据)来构建模型。这使得检查模型进化变得非常困难。如果您使用相同的代码但不同的数据来训练您的模型，您可能会有不同的度量。代码版本控制将只控制这个等式中的一个变量。*

*此外，培训数据科学模型是一个占用大量资源的过程，通常需要特定的资源(大量内存或 CPU、GPU ),还可能需要整个集群来处理。这是一个非常具体的模型。每个型号都有许多不同的要求。*

*记住这一点，我们可以看到手头的任务需要一些与软件开发过程稍微不同的抽象，但是我们可以使用相同的原则。[大公司](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#data_science_steps_for_ml)已经使用 [CRISP-DM](http://www.datascience-pm.com/crisp-dm-2/) 模型作为模板开发了他们自己的抽象。但是，为了简单起见，我将把*数据科学发展*的阶段定义为:*

# *探测*

*了解业务需求，测试假设，了解现有数据集和数据质量。如果要对可用数据进行任何更改，这就是触发此更改的时间。这也是应该设置需求的地方。任何所需的数据准备都应在这些要求中详细说明。*

*在这个阶段，我们需要创建一个探索环境，数据科学家可以在不损害其他模型或数据的情况下进行实验。许多工具可以提供这种环境，比如数据砖块和 T2 笔记本。这些工具为数据科学家提供了巨大的探索和实验自主权。*

# *发展*

*该探索代码可能导致模型的可能实现。但是这些代码通常是为探索任务编写，可能没有经过优化。同样，如果没有**代码**和**数据**的控制版本，将无法测量和评估模型质量。*

*有一些像 [DVC](https://dvc.org/) 这样的工具，可以帮助创建一个完全版本化的培训管道。它可以使用其他管道编排器，如 [Airflow](https://airflow.apache.org/) 或 [Flyte](https://flyte.org/) 来分配管道执行，以确保可伸缩性。*

*有了这些工具，我们可以确保训练管道的[再现性](https://towardsdatascience.com/reproducibility-in-data-science-c2ac9e689339)，这意味着，考虑到数据科学算法的不确定性，无论何时运行一个版本的管道，结果都将是相同的，或者至少非常接近。*

# *估价*

*在软件开发中，我们必须创建代码来做需要做的事情和测试。在这种情况下，我们需要创建代码(并收集数据)来训练和测试模型。但是，没有确定的方法来确保一个模型比另一个更好。*

*在软件开发中，让 CI 运行测试的主要原因是为了避免 bug 进入生产环境。也就是说，如果没有确定性的方法来测试一个模型，我们如何避免一个糟糕的模型进入生产呢？*

*这件事还有更多[聚焦文章](https://serokell.io/blog/machine-learning-testing)不是这篇文章的重点。简而言之，在训练管道中，您必须从受控数据集预测中收集质量指标。这些指标也必须用代码和数据来版本化。然后，您将这些指标与模型生产中的最后一个版本进行比较。如果指标比上一个更好，这个模型将非常适合生产。谁来定义什么是更好的是编写代码的数据科学家。*

# *模型服务和监控*

*当您的模型达到比生产中的模型更好的结果时，是时候将这个新模型投入生产了。围绕模型的部署过程有许多复杂性，我在这里只触及表面。部署一款车型大致有 [3 种方式:](https://martinfowler.com/articles/cd4ml.html#ContinuousDeliveryOrchestration)*

## *嵌入式模型*

*这是为模特服务最简单的方式。您只需将二进制文件放在应用程序代码中，并在应用程序需要时使用它。*

**优势**

*   *易于实施*

**缺点**

*   *如果不部署应用程序，就无法提供模型的另一个版本*
*   *监控模型健康状况的责任会泄露给应用程序，使得监控变得更加困难*
*   *如果这种模型在多个应用程序中使用，那么这种嵌入的二进制文件会在所有这些应用程序中重复，使得部署新版本更加困难*

## *充当数据*

*此过程旨在对整个数据集进行预评分，并将其保存为键值存储。这只有在数据集增长不快时才可行，因为并非所有预测都可用，因为它们需要到达键值存储。*

**优点**

*   *由于分数是在 CD 时间内生成的，因此易于监控*
*   *易于部署改进而不破坏界面*
*   *取决于存储，预测性能趋向于 O(1)*

**缺点**

*   *作为数据库，数据和应用程序之间存在紧密耦合，这使得很难部署新版本的模型*
*   *仅在您的预测输入有限时有效。当输入是全新的时，您将无法返回结果*

## *包装在服务中*

*这种类型旨在将模型嵌入到外观层中。该层将公开模型的完全相同的接口，并且可以由需要使用该模型的所有应用程序使用。所有健康指标都将封装在这个 facade 应用程序中。*

**优点**

*   *支持实时监控*
*   *与应用程序的松散耦合，更容易发布新版本(任何 api 版本都适用于此)*
*   *易于部署改进而不破坏界面*

**缺点**

*   *难以实现服务应用程序*
*   *根据型号的不同，这可能会导致性能问题*

*正如您所看到的，类型部署确实需要对场景进行分析。每个场景都有一个优化的部署方法。还有一些工具可以帮助你部署一个模型，比如 [AWS SageMaker](https://aws.amazon.com/sagemaker/) 和 [MlFlow](https://mlflow.org/) ，它们也可以在 [Databricks](https://databricks.com/) 中使用。*

# *ML 操作*

*所有这些工具在它们应该做的方面都很好，当你试图连接所有这些工具和概念来建立一个快节奏、高效和可靠的*数据科学开发*流程时，ML Ops 就派上了用场。*