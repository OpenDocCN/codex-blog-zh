# 数据分析初学者指南

> 原文：<https://medium.com/codex/a-beginners-guide-to-data-analysis-using-pandas-and-python-eed09f906863?source=collection_archive---------17----------------------->

![](img/c8ca5ef03c7794d9abdd10af9c2c5a5e.png)

如果你不熟悉数据分析领域，无论是作为该领域的新成员还是仅仅作为一名旁观者，那么你的数据分析知识很可能不会比你高中或大学的统计课延伸得更远。如果你的印象是，当你呆呆地看着房间另一边的恋人时，从那堂课上学到的基本概念，在专业水平上可能不是很重要，那么你就大错特错了。

甚至在专业上，统计学中的一些最基本的概念——平均值、中位数、标准差等。—通常是分析师在开始对新数据集进行分析时寻求定义的一些首要值。在这篇文章中，我将用通俗的语言介绍一个关于 SAT 和 ACT 成绩数据的基本数据分析项目，其过程远远不止是一个统计分析。让我们开始吧！

*请注意，本文不是 Python 编程语言的指南。虽然我引用了在我的项目中使用的许多代码块来实现某些目标，但本文的重点是数据科学/分析过程本身，它可以使用各种编程语言来执行。

**数据收集/导入**

数据分析的第一步很简单:收集你的数据。对于更高级的项目，为了知道哪些数据可能有用，您可能需要从识别您试图解决的问题开始。在那里，您可能会决定在线搜索现有数据集或从各种来源手动收集数据。然而，在这个项目中，我使用了预先制作的数据集(链接—[https://blog . college vine . com/here-are-the-average-sat-scores-by-state/)](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/))，这些数据集是在课堂环境中提供给我的。这些。csv 文件包括 2017 年和 2018 年的 SAT 和 ACT 成绩数据，其中一些可以在这里看到:

![](img/be8b6448bc3e02b80272646ad0eba92c.png)

一旦导入到我的笔记本中，我做的第一件事就是浏览数据集以熟悉它们的内容。每年的 SAT 数据集包括每个州的参与水平，阅读和数学的平均分数，以及平均总分。ACT 每年的数据集包括每个州的参与水平、英语、数学、阅读和科学的平均分数，以及最终的综合分数。奇怪的是，我注意到参与水平的范围很广，从个位数到 100%。我们将在本文的后面重新讨论这个问题。

**数据清理/组织**

该过程的第二步，有时称为整理或清理，包括清理和组织数据，以便为分析做准备。如果你是新手，你可能想知道这意味着什么。例如，让我们看看下面的数据片段:

![](img/69e099db48b47c748c0697d643f03943.png)

正如你所看到的，马里兰州 2017 年 SAT 的平均数学成绩据称是 800 分中的 52 分。现在，你不需要成为公共教育政策或统计方面的专家来怀疑这个数字。即使是《人鼠之间》的莱尼也能得到比这更高的分数。正如我之前提到的，这个数据集是在教室环境中提供给我的，在那里它被故意修改成错误和错别字，以便我和我的同伴识别和纠正。为了检查这个潜在的错误，我将它与网上的原始数据集进行了比较，发现平均分数实际上是 524，而不是 52。为了纠正我命名为“sat_2017”的个人数据框架中的错误，我运行了以下代码行:

> *sat_2017.loc[20，' Math'] = 524*

清理数据的过程除了纠正错别字之外，还可能涉及各种其他任务。事实上，munging 往往是数据分析师存在的祸根。这通常是整个过程中最耗时、最细致的步骤，尤其是当您处理包含数十万甚至数百万行的大型数据集时。由于这个原因，我不能遍历所有关于数据清理的可能场景，但是我将分享一些我在管理这些数据时必须执行的任务，从修改列类型开始。

dataframe 中的大多数列可以用通俗的术语描述为字母或数字(我们使用一些更细微的术语，如对象、浮点、整数和其他术语来描述这些类别的某些变体，但本质上只是字母和数字)。如果您回头看几个段落前的图像，您会注意到参与列在数字旁边列出了一个百分比符号，%,而其他列没有。这给编码界带来了一个问题。除了小数或偶尔的一些其他符号，对包含单个字母或非数字字符的数据执行数学计算都会产生错误。要解决这个问题，必须重新格式化数据，以删除那些非数字字符，以便可以对列执行计算。

我使用以下代码行从整个参与列中删除了百分比符号:

```
*sat_2017[‘Participation’] = sat_2017[‘Participation’].map(lambda x: str(x).replace(‘%’,’’))*
```

我的下一步是将参与列重新归类为“float”，这是一种允许小数的数字列。您可能想知道为什么这是必要的，考虑到我已经从参与列中删除了百分比符号。嗯，当一列的数据包含字母和其他非数字符号时，该列被视为一个“对象”值得注意的是，仅仅从“object”列中删除非数字符号并不会自动对该列进行重新分类；在程序员将列转换为另一种类型之前，它仍将被识别为“对象”。这是必要的，因为默认情况下，数学计算不能在“对象”列上执行，即使那些“对象”只是由数字组成。换句话说，我们必须先将列重新分类为数值型，然后才能对其执行计算。因此，删除了百分比符号后，我就可以使用下面的代码行将参与列从“object”转换为“float ”:

```
*sat_2017[‘Participation’] = sat_2017[‘Participation’].astype(float)*
```

![](img/bb170d9ae0b82439044ae1e37861fe4f.png)

这是删除百分比符号，然后将“object”列重新分类为“float”列后的数据帧。

请注意，试图将列类型转换为“float”而不先删除百分比符号**会产生错误**。在将列重新归类为“float”列之前，我必须使它只包含数值。(有趣的是，如果您愿意，您可以反过来将一列“浮点”数字转换成一列“对象”随机字符！)

清洗过程的倒数第二部分是重命名列。这不是出于个人喜好或审美。这样做的理由是，所有四个数据集(2017 SAT，2017 ACT，2018 SAT，2018 ACT)的每一列都需要一个唯一的名称，因为最后一步是将所有四个数据合并成一个数据框架。由于默认情况下列名不能重复——更不用说避免歧义了——我不得不相应地重命名几乎每一列(我保留了 State 列，因为这是我合并数据帧的列)。我使用了一个简单的模式，用下面的代码重命名每一列的年份、考试和主题:

```
*sat_2017 = sat_2017.rename({‘State’: ‘state’, “‘Participation”: “‘17 sat_partic”, “‘Language”: “‘17 sat_language”,’Math’:”’17 sat_math”, “‘total”:”’17 sat_total”}, axis=’columns’)**act_2017 = act_2017.rename({‘State’: ‘state’, “‘Participation”: “‘17_act_partic”, “‘English”: “‘17_act_english”, “‘Math”: “‘17_act_math”,”’Reading”: “‘17_act_reading”, “‘Science”: “‘17_act_science”, “‘Composite”: “‘17_act_composite”}, axis=’columns’)*
```

重命名 2017 列后，我将这两个数据框架合并在一起，如下所示:

```
*combined_17 = pd.merge(sat_2017, act_2017, on =’state’)*
```

这是 2017 年测试数据的合并数据框架的一部分此时的样子:

![](img/a5eafea6c91896cd2439c9e3737072b0.png)

到目前为止，我所描述的关于数据清理和组织的一切都是针对两个 2017 年数据集(SAT 和 ACT)的。对于 2018 年的两个数据集，整个过程都必须小心翼翼地重复-识别/纠正打字错误，重新格式化数据，重新分类列，重命名列，等等。到这一点，我相信你能理解为什么我之前提到 munging 是分析师存在的祸根！

在清理和组织了 2018 年的两个数据集之后，最后一步是将 2017 年的合并数据和 2018 年的合并数据合并成一个数据帧，我使用以下代码执行了该操作:

```
*combined_all = pd.merge(combined_17, combined_18, on =’state’)*
```

**探索性数据分析(EDA)——第一部分**

数据分析/科学过程的第三步通常被称为探索性数据分析，简称 EDA，听起来确实如此。现在，数据已经被清理和组织，这是分析师最终开始探索它并搜索趋势、模式甚至异常的阶段。很多时候，尤其是在商业环境中，分析师可能会得到一组原始数据，并被告知要理解它，这就是这个阶段(和下一个阶段)真正要做的。

虽然理解一个不熟悉的数据集可能需要问自己几十个问题，直到你找到“正确的”问题来进行分析，但这个特殊的学术项目并不复杂。考虑到数据无论如何都相对较少，我最现实的期望是确定每个考试每年的参与率最高和最低的是哪些州，以及从 2017 年到 2018 年，具体表现是否有明显的倾斜或下降。

我几乎总是在任何数据集上执行的一个表层分析涉及识别一些最基本的统计值。这些包括每个数字列的平均值、最大值、最小值、中值和标准差(有时还包括众数)。在这个相对简单的项目中，正如我在前面提到的，这个列表包含了我试图确定的大部分内容。我运行了以下几行 Python 代码来确定这些值，并以有组织的方式显示它们:

```
*print(“Means:”)
print()
print(combined_all.mean())
print()
print(“Medians:”)
print()
print(combined_all.median())
print()
print(“Maximums:”)
print()
print(combined_all.max())
print()
print(“Minimums:”)
print()
print(combined_all.min())
print()
print(“Standard Deviations:”)
print()
print(combined_all.std())
print()*
```

代码的输出相当长，所以我们只使用 Means 部分作为例子。如下图所示，我的笔记本显示了数据框中所有数字列的平均值。

![](img/9f48c4402afe52e601428eb7d587b36c.png)

请注意，State 列不包括在内。这是因为 State 列是一个“对象”，数学计算只针对数字列，包括“浮点数”和“整数”等等。希望现在您可以更直观地理解为什么在项目的 munging 阶段需要对参与列进行重新分类，因为不同的数据类型需要不同的处理。

根据这一数据，2017 年全国平均 SAT 参与率不到 41%，2018 年不到 47%。2017 年平均 ACT 参与率约为符合条件的学生的 64%，2018 年不到 61%。我首先想到的是，尤其是作为一名前任课老师，并不是所有的高中生都申请大学。此外，大多数大学申请者要么参加 SAT 考试，要么参加 ACT 考试，但不能两者都参加。考虑到这些重要的信息，显而易见，我们不应该期望这些数字接近 100%。根据我在分析一个给定项目时的目标，我将深入数据并从不同的角度对其进行检查。

假设，假设我被一家全国性的公司承包做研究，这家公司为大学入学考试制作学习材料，特别是数学。在这种情况下，对我来说明智的做法是仔细看看两次考试中的普通数学成绩，以及各州之间的差异。事实上，我可能会看到比考试成绩更多的数据。也许我会注意到数学成绩较低的州和公司没有投入同样多资源营销自己的州之间的相关性。如果我的客户的目标仅仅是利润最大化，那么我对他们的建议可能是在那些特定的州更多地推销自己，同时在表现良好的州继续他们目前的做法。对于像这样的更高级的项目，为了确定如何最好地探索数据并得出最明智的结论，思考你或你的客户的目标是什么是至关重要的。

最后，我想在本文中分享我的 EDA 的一个更具体的组件。与我以前的计算不同，我以前的计算只是通过识别现有数据的各个方面来执行，有时分析需要创建新的数据来探索。考虑这个项目中使用的数据集包含两个不同时期的性能。在这种情况下，探索每个类别的价值随时间的变化可能是明智的。我们以 SAT 阅读成绩为例。如果我想知道成绩的净变化，我会从每个州 2018 年的分数中减去 2017 年的 SAT 阅读平均分。仅使用下面一行代码，我在我的 dataframe 中创建了一个新列来表示 SAT 阅读性能的这个**净变化**:

```
*combined_all[‘SAT_reading_net_change’] = combined_all[“‘18_sat_language”] — combined_all[‘Evidence-Based Reading and Writing’]*
```

![](img/84bf31acdcd3ac65512f933e04f18758.png)

通过表格中的新列，你可以清楚地看到，阿拉斯加州从 2017 年到 2018 年的 SAT 阅读成绩的净变化是 15 分，而阿肯色州的成绩下降了 22 分——哎呀！在处理随时间推移而发生的数据时，探索每个类别的净价值变化可以提供非常丰富的信息，并为您提供得出有价值结论所需的洞察力。

**EDA 第二部分——可视化**

EDA 阶段通常不需要像数据清理那样多的时间，尽管它肯定比你车库里那只不肯死的蟑螂的寿命更长。然而，尽管在这一阶段的第一部分可以进行所有表面层次的探索和分析，有时创建可视化可以使发现洞察力变得容易得多。使用直方图、条形图、折线图等简单的图表，您可以更好地理解哪些数据是重要的以及为什么重要。让我们来看看我在这个项目中使用的一些可视化。

![](img/243d5c71295f7bbdef37955209dd08d6.png)

各州 2018 年 SAT 数学平均成绩

一个简单的条形图是比较所有州的表现值的好工具，上面的条形图显示了 2018 年 SAT 数学的平均分数。尽管这个图表非常拥挤，但从视觉上很容易发现高性能状态和低性能状态之间的差异。

事实上，这么多的数据对于单个条形图来说可能太多了，有时其他图表更适合传达某些信息。请看下一个柱状图，它包含了与上一个柱状图完全相同的数据。如果你想知道有多少个州在不同的分数范围内表现出色，而不是将各个州相互比较，这就更有用了。直方图非常适合将数字数据分成组，并测量每组中数据点的频率。

![](img/e2d2dbc80e881e20b469ee817e2b01be.png)

直方图也可以用来比较多组数据。以下面的直方图为例。

![](img/56d4ac7f993d8963e7f78b7423ba6df1.png)

正如你在上面看到的，我对比了 2017 年 SAT 和 ACT 的数学成绩。在我创建直方图之前，这涉及到一个额外的步骤，因为 SAT 的数学部分和 ACT 的数学部分的得分范围不同(分别是 800 和 36)。因此，为了在同一个直方图上绘制两组分数，我首先必须将两组分数转换成百分比。一旦该说的都说了，该做的都做了，看看图表，数据似乎表明 ACT 的数学部分可能比 SAT 更具挑战性。只有两个州的 ACT 数学平均分超过了 70%，而 17 个州的 SAT 数学平均分也超过了 70%。只有一个州的 SAT 数学平均分低于 60%，但是多达 29 个州的 ACT 数学平均分低于 60%。一旦您恰当地使用了数据可视化工具来帮助您，这些类型的见解就会变得容易得多。

值得注意的是，如果这个项目涉及几年而不是两年的考试数据，那么线形图将非常有助于显示一段时间内的变化。然而，在这个项目中，将 2017 年至 2018 年的净绩效变化视为一个单独的新列效果很好。

![](img/07f11306e78f825a2ddf5a2685ee40d5.png)

另一个有用的可视化(大多数人在统计学入门课程中肯定学不到)叫做热图。有两种热图—聚类热图和空间热图。在这个领域中，聚类热图更为常见。正如您在旁边观察到的，我使用了热图来可视化每个性能类别和每个其他性能类别之间的相关性。蓝色越暗，相关性越高。

**解读数据/建议**

-未完待续…