# é€»è¾‘å›å½’

> åŸæ–‡ï¼š<https://medium.com/codex/logistic-regression-eee2fd028ffd?source=collection_archive---------2----------------------->

![](img/e312f2a57156d3b721096bf55a635314.png)

å­¦å®Œå›å½’çš„åŸºç¡€ï¼Œå°±è¯¥å­¦åˆ†ç±»çš„åŸºç¡€äº†ã€‚è¿˜æœ‰ä»€ä¹ˆæ¯”é€»è¾‘å›å½’æ›´ç®€å•çš„å‘¢ï¼

å»ºè®®æ‚¨åœ¨å¼€å§‹æœ¬æ•™ç¨‹ä¹‹å‰ï¼Œå…ˆé˜…è¯»æœ¬ [**çº¿æ€§å›å½’æ•™ç¨‹**](/codex/linear-regression-on-single-variable-f35e6a73dab6) ã€‚è¿™æ˜¯çº¿æ€§å›å½’çš„å®Œæ•´æŒ‡å—ï¼Œé€»è¾‘å›å½’ä½¿ç”¨äº†å‡ ä¸ªä¸çº¿æ€§å›å½’ç›¸å…³çš„æ€æƒ³ã€‚è¯´å®Œäº†ï¼Œæˆ‘ä»¬å¼€å§‹å§ï¼

## ä»€ä¹ˆæ˜¯é€»è¾‘å›å½’ï¼Ÿ

è¿™æ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•ï¼Œé€‚ç”¨äºè¾“å‡ºå˜é‡ä¸º*åˆ†ç±»*çš„æƒ…å†µã€‚é€»è¾‘å›å½’çš„ç›®æ ‡æ˜¯å‘ç°ç‰¹å¾å’Œç‰¹å®šç»“æœçš„æ¦‚ç‡ä¹‹é—´çš„å…³ç³»ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œ

é‚®ä»¶:åƒåœ¾é‚®ä»¶/ä¸æ˜¯åƒåœ¾é‚®ä»¶ï¼Ÿ

åœ¨çº¿äº¤æ˜“:æ¬ºè¯ˆ(æ˜¯/å¦)

è¿™é‡Œï¼Œ

![](img/12dddd94a1dab741eeb9ecba0fe83ce6.png)

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹æ¥é¢„æµ‹ä¸€ä¸ªå­¦ç”Ÿæ˜¯å¦è¢«å¤§å­¦å½•å–ã€‚

## ä¸ºä»€ä¹ˆæ˜¯é€»è¾‘å›å½’ï¼Œè€Œä¸æ˜¯çº¿æ€§ï¼Ÿ

åœ¨ç®€å•çº¿æ€§å›å½’ä¸­ï¼Œå°†æ‰€æœ‰æ•°æ®ç»˜åˆ¶åˆ°ä¸€ä¸ªå›¾è¡¨(x å’Œ y)ä¸Šï¼Œå°†æ‰€æœ‰æ•°æ®æ‹Ÿåˆåˆ°ä¸€æ¡æœ€ä½³æ‹Ÿåˆçº¿ï¼Œç„¶åå°†è¾“å…¥é¢„æµ‹ä¸ºç›¸åº”çš„ yã€‚å¦ä¸€æ–¹é¢ï¼Œé€»è¾‘å›å½’å°†æ‰€æœ‰æ•°æ®æ‹Ÿåˆåˆ°ä¸€æ¡ S æ›²çº¿ï¼Œåªæœ‰ä¸¤ç§å¯èƒ½çš„è¾“å‡º(ä¸¤ç§åˆ†ç±»)ï¼Œåˆ†åˆ«è¡¨ç¤ºä¸ºé¡¶çº¿å’Œåº•çº¿ã€‚

![](img/a85eaf3291d0b534aed14f18ddce8b9c.png)

çº¿æ€§å’Œé€»è¾‘å›å½’

## Sigmoid å‡½æ•°

S æ›²çº¿ä¸æ˜¯æŒ‡å­—æ¯ S çš„å½¢çŠ¶ï¼›ç›¸åï¼Œå®ƒä»£è¡¨çš„æ˜¯ä¹™çŠ¶ç»“è‚ å‡½æ•°ã€‚è¿™æ˜¯å› ä¸º sigmoid å‡½æ•°å®Œå…¨ç¬¦åˆæˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºä¸¤ç»„çš„ç›®çš„ã€‚sigmoid å…¬å¼å¦‚ä¸‹ï¼Œå…¶ä¸­ x æ˜¯è¾“å…¥çš„æ•°é‡ã€‚

![](img/689eed2f77701631d8baf9ee5bdf20e2.png)

ä¹™çŠ¶ç»“è‚ çš„

åœ¨è‹±è¯­ä¸­ï¼Œsigmoid åªæ˜¯åŸºäºè¾“å…¥è¦ç´ çš„åŠ æƒå’Œçš„æ¦‚ç‡è®¡ç®—ã€‚åŠ æƒå’Œçš„å…¬å¼å¦‚ä¸‹:

![](img/24e36de6839968c02d2d7ffdf176b9c8.png)

åœ¨ç¼–å†™ sigmoid å‡½æ•°ä¹‹å‰ï¼Œè®©æˆ‘ä»¬åˆå§‹åŒ–æ•°æ®é›†ã€‚

```
import numpy as np
import pandas as pd
import matplotlib.pyplot as pltdata = pd.read_csv("ex2data1.txt", header=None)
data.head()
```

![](img/d6c0e369b1930cb5acb6f466211725a8.png)

data.head()

è¿™é‡Œâ€œ0â€ä»£è¡¨å­¦ç”Ÿåœ¨ 1Ë¢áµ—è€ƒè¯•ä¸­çš„åˆ†æ•°ï¼Œâ€œ1â€ä»£è¡¨å­¦ç”Ÿåœ¨ 2â¿áµˆè€ƒè¯•ä¸­çš„åˆ†æ•°ï¼Œâ€œ2â€ä»£è¡¨å­¦ç”Ÿæ˜¯å¦è¢«å½•å–(1)æˆ–ä¸è¢«å½•å–(0)ã€‚

è®©æˆ‘ä»¬å°†æ•°æ®å¯è§†åŒ–ï¼Œ

```
X = data.values[:, :-1]
y = data.values[:, -1]pos, neg = (y==1).reshape(100, 1), (y==0).reshape(100, 1)plt.scatter(X[pos[:, 0], 0], X[pos[:, 0], 1], c='r', marker='+', label="Admitted")
plt.scatter(X[neg[:, 0], 0], X[neg[:, 0], 1], marker='o', label="Not Admitted", s=10)
plt.xlabel("Exam1 Score")
plt.ylabel("Exam2 Score")
plt.legend(loc=0)
```

![](img/8344da9c8e9cbad491f7f5c65e408149.png)

åœ¨é€»è¾‘å›å½’çš„æƒ…å†µä¸‹ï¼Œå‡è®¾(h)ç”±ä»¥ä¸‹ç­‰å¼è¡¨ç¤º:

![](img/f43e82e8183e3aa4e86dc4f93075dbfc.png)

å‡è®¾

![](img/6c18710d307dd089a487f057a8cc530d.png)

å‡è®¾çš„å›¾ç¤º:

![](img/ed133a0fd797e726746c05357ecbe7b1.png)

å‡è®¾

```
def sigmoid(z):
    return 1 / (1 + np.exp(-z))print(sigmoid(0))
print(sigmoid(10))
print(sigmoid(1))
```

![](img/d3fafcd18e5a34b17fc6a24da7b963fc.png)

Sigmoid ç»“æœ

ä»ä¸Šé¢çš„æ•°å­—æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œ

![](img/b569b889b81e579eee9648ed32ba4f74.png)

## é€»è¾‘å›å½’å†³ç­–è¾¹ç•Œ

ç”±äºæˆ‘ä»¬çš„æ•°æ®é›†æœ‰ä¸¤ä¸ªç‰¹å¾:test1 å’Œ test2ï¼Œé€»è¾‘å›å½’å‡è®¾å¦‚ä¸‹:

![](img/3d868881ffaa31466e2c6c65369345f1.png)

é€»è¾‘å›å½’åˆ†ç±»å™¨å°†é¢„æµ‹â€œå…¥é™¢â€,å¦‚æœ:

![](img/eae8ddb987a3d07372043b5d4928da1c.png)

è¿™æ˜¯å› ä¸ºé€»è¾‘å›å½’â€œ*é˜ˆå€¼*è¢«è®¾ç½®ä¸º g(z)=0.5ï¼Œè¯·å‚è§ä¸Šé¢çš„é€»è¾‘å›å½’å‡½æ•°å›¾è¿›è¡ŒéªŒè¯ã€‚

![](img/fc3eef71d5c5ecf09daff2f2d03ce6f6.png)

## ä»·å€¼å‡½æ•°

![](img/7cfd5b81db543229319f2ff729cecc1d.png)

è®°å·

æˆ‘ä»¬å…ˆæ¥å®šä¹‰ä¸¤ä¸ªå…´è¶£ç‚¹çš„ logistic å›å½’ä»£ä»·å‡½æ•°:y=1ï¼Œy=0ï¼Œä¹Ÿå°±æ˜¯å‡è®¾å‡½æ•°é¢„æµ‹å½•å–æˆ–ä¸å½•å–æ—¶ï¼Œ

![](img/273583ed1dd80cf0646a25e9805e65a6.png)

ç®€åŒ–çš„æˆæœ¬å‡½æ•°å¦‚ä¸‹:

![](img/e235463de536c8ac6a5d1687d5ee1e9e.png)

ç„¶åï¼Œæˆ‘ä»¬åœ¨è¿™ä¸¤é¡¹çš„ **y** ä¸­å–ä¸€ä¸ªå‡¸ç»„åˆï¼Œå¾—å‡ºé€»è¾‘å›å½’æˆæœ¬å‡½æ•°:

![](img/844900fccbe5bdfb793946fa1ba3ed57.png)

```
def Costfunction(X, y, theta):
    m=len(y)

    h_theta = sigmoid(X@theta)
    y_pos = -y.T @ np.log(h_theta)
    y_neg = (1-y).T @ np.log(1-h_theta)
    error = y_pos - y_neg

    cost = 1/m * sum(error)
    grad = 1/m * (X.T@(h_theta - y))

    return cost[0] , grad
```

åœ¨ä½¿ç”¨æ•°æ®è®¡ç®—æˆæœ¬ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥å°†æˆ‘ä»¬çš„æ•°æ®æ ‡å‡†åŒ–(è¦äº†è§£æ›´å¤šå…³äºæ ‡å‡†åŒ–çš„ä¿¡æ¯ [***ç‚¹å‡»æ­¤å¤„***](/codex/linear-regression-on-multiple-variables-1893e4d940b1) ***)ã€‚*** )

```
def featureNormalization(X):
    mu = np.mean(X, axis=0)
    sigma = np.std(X, axis=0)
    X_Norm = (X - mu)/sigma
    return X_Norm, mu, sigmam, n = X.shape
X, mu, sigma = featureNormalization(X)
X = np.column_stack((np.ones((m, 1)), X))
y = y.reshape(m, 1)initial_theta = np.zeros((n+1, 1))
cost, grad= Costfunction(X, y, initial_theta)
print("Cost of initial theta is", cost)
print("Gradient at initial theta (zeros):", grad)
```

![](img/8064f9315e726e9c7b82c9407edaeca3.png)

## æ¢¯åº¦ä¸‹é™

é€»è¾‘å›å½’çš„æ¢¯åº¦ä¸‹é™ç®—æ³•çœ‹èµ·æ¥ä¸çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™ç®—æ³•ç›¸åŒã€‚å¯¹äºæ¢¯åº¦ä¸‹é™çš„æƒ…å†µï¼Œæœç´¢æ–¹å‘æ˜¯é€»è¾‘å›å½’æˆæœ¬å‡½æ•°ç›¸å¯¹äºå‚æ•°Î¸çš„è´Ÿåå¯¼æ•°ã€‚åœ¨å…¶æœ€åŸºæœ¬çš„å½¢å¼ä¸­ï¼Œæ¢¯åº¦ä¸‹é™å°†æ²¿ç€Î¸çš„è´Ÿæ¢¯åº¦æ–¹å‘è¿­ä»£(ç§°ä¸º*æœ€å°åŒ–åºåˆ—*)ï¼Œç›´åˆ°è¾¾åˆ°æ”¶æ•›ã€‚

![](img/2f4cb740b19c227e13096b614fbb3767.png)

```
def gradientDescent(X, y, theta, alpha, n_iters):
    m=len(y)
    J_history =[]

    for i in range(n_iters):
        cost, grad = Costfunction(X, y, theta)
        theta = theta - (alpha * grad)
        J_history.append(cost)
    return theta, J_historytheta, J_history = gradientDescent(X=X, y=y, theta=initial_theta, alpha=1, n_iters=400)
```

## ç»˜åˆ¶å†³ç­–è¾¹ç•Œ

è¿™é‡Œï¼Œå†³ç­–è¾¹ç•Œå¦‚ä¸‹:

![](img/d4b453bd00ea1434612e9309ce7d9c51.png)

```
plt.scatter(X[pos[:,0],1],X[pos[:,0],2],c="r",marker="+",label="Admitted")
plt.scatter(X[neg[:,0],1],X[neg[:,0],2],c="b",marker="x",label="Not admitted")
x_value = np.array([np.min(X[:,1]),np.max(X[:,1])])
y_value = -(theta[0] +theta[1]*x_value)/theta[2]
plt.plot(x_value,y_value, "r")
plt.xlabel("Exam 1 score")
plt.ylabel("Exam 2 score")
plt.legend(loc=0)
```

![](img/c9ec608632b106406ab4e8b0ea48c359.png)

## é¢„è¨€

![](img/3c5dc5b8d5ee442fe63413296df3c4d1.png)

```
x_sample = np.array([45, 85])
x_sample = featureNormalization(x_sample)[0]
x_sample = np.append(np.ones(1), x_sample)
prob = sigmoid(x_sample.dot(theta))
print("For a student with scores 45 and 85, we predict an admission probability of ",prob[0])
```

![](img/da7aa3fa7f1d794a300c2ff0cf2be9fb.png)

ä»ä¸Šé¢çš„è¾“å‡ºå¯ä»¥çœ‹å‡ºï¼Œ45 åˆ†å’Œ 85 åˆ†çš„å­¦ç”Ÿæœ‰ 80%çš„æ¦‚ç‡è¢«å¤§å­¦å½•å–ã€‚

```
def predict(X, theta):
    p = sigmoid(X@theta) >= 0.37#select your own threshold
    return p
```

![](img/a59c3d90475ec7ad0f9461c7cdc0215d.png)

## ç»“è®º

ä»Šå¤©ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†é€»è¾‘å›å½’çš„å‡è®¾ã€æˆæœ¬å‡½æ•°å’Œæ¢¯åº¦ä¸‹é™èƒŒåçš„æ¦‚å¿µã€‚ç„¶åç”¨ python çš„ numpyï¼Œpandas å’Œ matplotlib ä»å¤´å¼€å§‹åˆ›å»ºã€‚æ•°æ®é›†å’Œæœ€ç»ˆä»£ç ä¸Šä¼ åˆ° githubã€‚

æŸ¥çœ‹è¿™é‡Œ[é€»è¾‘å›å½’](https://github.com/jagajith23/Andrew-Ng-s-Machine-Learning-in-Python/tree/gh-pages/Logistic%20Regression)ã€‚

# å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œé‚£ä¹ˆçœ‹çœ‹æˆ‘åœ¨è¿™ä¸ªç³»åˆ—ä¸­çš„å…¶ä»–æ–‡ç« 

## 1.[ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ](/@jagajith23/what-is-machine-learning-daeac9a2ceca)

## 2.[æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ](/codex/what-are-the-types-of-machine-learning-53360b7db8b4)

## 3.[ä¸€å…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-single-variable-f35e6a73dab6)

## 4.[å¤šå…ƒçº¿æ€§å›å½’](/codex/linear-regression-on-multiple-variables-1893e4d940b1)

## 5.[ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ](/@jagajith23/what-are-neural-networks-3a0965e2ebfb)

## 6.[ä½¿ç”¨ç¥ç»ç½‘ç»œçš„æ•°å­—åˆ†ç±»å™¨](/@jagajith23/digit-classifier-using-neural-networks-ad17749a8f00)

## 7.[åˆ©ç”¨ K å‡å€¼èšç±»è¿›è¡Œå›¾åƒå‹ç¼©](/@jagajith23/image-compression-with-k-means-clustering-48e989055729)

## 8.[ä½¿ç”¨ PCA å¯¹äººè„¸è¿›è¡Œé™ç»´](/@jagajith23/dimensionality-reduction-on-face-using-pca-e3fec3bb4cee)

## 9.[ä½¿ç”¨å¼‚å¸¸æ£€æµ‹æ¥æ£€æµ‹ç½‘ç»œä¸Šçš„æ•…éšœæœåŠ¡å™¨](https://jagajith23.medium.com/detect-failing-servers-on-a-network-using-anomaly-detection-1c447bc8a46a)

# æœ€ååšçš„äº‹

*å¦‚æœä½ å–œæ¬¢æˆ‘çš„æ–‡ç« ï¼Œé¼“æŒğŸ‘ä¸€ä¸ªè¿½éšè€…å°†æ˜¯ç»å¯¹çš„åè›‹å’Œ*è¿™æ˜¯æœ‰ç›Šçš„åª’ä½“æ¨å¹¿è¿™ç¯‡æ–‡ç« ï¼Œä½¿å…¶ä»–äººå¯ä»¥é˜…è¯»å®ƒ*ã€‚æˆ‘æ˜¯ Jagajithï¼Œæˆ‘ä¼šåœ¨ä¸‹ä¸€ä¸ªé‡ŒæŠ“ä½ä½ ã€‚*