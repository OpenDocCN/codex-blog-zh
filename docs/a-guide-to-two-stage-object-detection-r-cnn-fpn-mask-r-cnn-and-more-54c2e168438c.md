# 两阶段目标探测指南:R-CNN，FPN，掩模 R-CNN

> 原文：<https://medium.com/codex/a-guide-to-two-stage-object-detection-r-cnn-fpn-mask-r-cnn-and-more-54c2e168438c?source=collection_archive---------0----------------------->

![](img/3bce32dc48d80e58acdbdcb5379237e1.png)

照片由[梅姆](https://unsplash.com/@picoftasty?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

## 多阶段(两阶段)对象检测

计算机视觉中最基本和最广泛研究的挑战之一是对象检测。该任务旨在绘制给定图像中物体的多个包围盒，这在包括自动驾驶在内的许多领域都非常重要。通常，这些目标检测算法可以分为两类:单阶段模型和多阶段模型。在本帖中，我们将通过回顾该领域中一些最重要的论文，深入探讨对象检测的多级流水线的关键见解。

![](img/f0104939ceed66a3bde15fe5c10fe388.png)

目标检测器的一个分支是基于多级模型的。源自 R-CNN 的工作，一个模型用于提取对象的区域，第二个模型用于分类和进一步改进对象的定位。众所周知，这种方法相对较慢，但非常有效，但最近的进展，如共享功能，改进了 2 级检测器，使其具有与单级检测器相似的计算成本。这些工程高度依赖于以前的工程，并且大多以以前的管道为基线。因此，了解两级检测器中的所有主要算法非常重要。

本帖论文的选取多基于调查[8]。

## 美国有线电视新闻网

2014 年的论文提出了基于 CNN 的两阶段检测算法的简单版本，在后续论文中对其进行了改进和加速。如上图所述，整个管道由三个阶段组成:

1.  生成区域建议:模型必须独立于类别，在图像中绘制候选对象。
2.  第二阶段是一个全卷积神经网络，它计算每个候选区域的特征。
3.  最后一级是全连接层，在本文中表示为支持向量机。

![](img/e0914eb9f5cc6d6904dd60ecdea20d4f.png)

R-CNN 管道概述

可以使用各种方法生成区域建议，本文选择使用选择性搜索来与先前的工作进行比较。尽管如此，管道与大多数区域提议方法兼容。选择性搜索的详细解释在[这里](https://learnopencv.com/selective-search-for-object-detection-cpp-python/)和[这个](http://vision.stanford.edu/teaching/cs231b_spring1415/slides/ssearch_schuyler.pdf)演示中提供。

概括选择性搜索，将分割算法应用于图像，并基于分割图绘制区域提议(边界框)。分割图被迭代地合并，并且从如下图所示的细化图中绘制更大的区域提议。这里详细解释了合并和方框图是如何工作的。

![](img/645c817d0e93249162eee2e5f3cb64a2.png)

[http://vision . Stanford . edu/teaching/cs 231 b _ spring 1415/slides/ssearch _ schuyler . pdf](http://vision.stanford.edu/teaching/cs231b_spring1415/slides/ssearch_schuyler.pdf)

第二和第三阶段一起可以被认为是常规的 CNN，其工作在裁剪区域提议上。本文使用 AlexNet 的卷积部分作为第二级，而可以使用任何其他 CNN 架构。由于区域建议的大小不同，本文采用最简单的方法将所有边界框弯曲和调整到所需的大小。

作者还使用训练的包围盒分类器来进一步改进由分割做出的包围盒估计。另一个完全连接的网络被训练以输入特征图并回归表示相对平移和对数标度宽度/高度标度因子的 4 元组(r，c，h，w)中的边界框偏移。这项技术在消融研究中显示出性能提升，如 *R-CNN BB* 。

![](img/832d54916936d401e2b17b95ea9cbf68.png)

为了在推理中拒绝重叠区域提议，其中两个或更多边界框指向同一个对象，作者提出了一种贪婪算法，如果一个区域与另一个具有更有把握的预测的区域具有高的交集(IoU ),则拒绝该区域。

由于图像的域被改变为扭曲窗口的图像，分类器模型在扭曲图像和新标签上被进一步训练。在训练分类器时，与地面实况(GT)框具有> 0.5 IoU 的区域被认为是该类，并且被训练以输出 GT 框的类。当盒子与任何 GT 盒子没有明显重叠时，或者当区域具有<0.5 IoU with every box, the classifier must classify the region in the *背景*类时。为了解决潜在的类别不平衡，选择 32 个阳性区域和 96 个背景区域来形成大小为 128 的小批量。

IoU > 0.5 的区域被视为完全重叠，而本文认为 IoU<0.5 的区域部分重叠。通过提供背景和 GT 盒类的混合标签，对这些情况进行了特殊处理。

与其他方法相比，R-CNN 的性能优势来自于执行自底向上风格的选择性搜索的思想，也使用 CNN 来定位对象和在对象检测数据上微调网络中使用的技术。这项工作结合了经典 CV 和深度学习的工作，以改善对象检测。但是 CNN 非常耗时，因为它将 CNN 应用于大约 2000 个扭曲的选择性搜索区域。

摘要

*   提出了用于两阶段目标检测的基线流水线:生成区域提议并对它们进行分类。
*   使用选择性搜索生成区域建议
*   分类网络调整区域提议的大小，并预测类别概率(包括背景)和边界框细化。

## SPP 网[2]

该论文建议使用空间金字塔池(SPP)图层，该图层设计用于任何图像大小，而无需将它们调整为固定大小，这可能导致信息丢失和图像失真。在 CNN 中被描述为特征提取器的卷积不是约束固定输入大小的卷积，但是输入大小约束是因为完全连接的分类层。

![](img/c442d0457bbff7372f0ddc85b9955841.png)

上图:传统 CNN 管道，下图:SPP-net 管道

因此，作者提出了一种特殊的池化图层，它可以转换不同大小的要素，并将它们提供给完全连接的图层，以消除网络的固定大小约束，如上图所示。

基本上，SPP 层在各种比例下应用最大池输出，与图像大小成比例。SPP 层使用与图像尺寸成比例的空间箱，允许任何形状的图像被映射成单一尺寸。每个空间箱最大化其区域中的值，并且空间信息可以通过该过程得以保留。下图对此进行了描述。每个过滤器用不同大小的池进行处理，这些池覆盖图像的一部分，并且结果被连接。256 是特征图中过滤器的数量。

![](img/f91ddaad6751711ec1c200c45f89edb7.png)

虽然作者没有提出 SPP 层，但他们首先考虑在 CNN 中使用 SPP 层。spp 具有以下特性:

1.  无论输入大小如何，都会生成固定长度的输出
2.  已知对对象变形具有鲁棒性(正则化)
3.  可以从各种尺度(分辨率)提取信息

![](img/fc45c9ab52b4f0ceb0866c69ad487411.png)

该论文集中于图像分类，并示出了作为泛化性能证明的对象检测的结果，但是当应用于对象检测时，具有不同于 R-CNN 算法的一些有趣的特性。

SPP-Net 的对象检测管道如上图所示。在整个图像上执行一次 CNN，并且基于通过选择性搜索检测到的区域来裁剪 CNN 的输出特征。SPP 应用于每种作物，并基于 SPP 层的输出预测类别。这样，卷积层仅应用于图像一次，并且对应于检测到的区域的数量，仅应用较亮的 FC 层。

卷积特征检测器是在图像分类任务上预先训练的，而不是在对象检测上进一步训练的。分类器 FC 层基于地面真实窗口被单独训练。尺度不变性是通过使用两种方法来预处理图像，解释了这一点。在微调 FC 网络时，还应用了 R-CNN 的许多技术。

这篇论文的贡献确实令人惊讶，因为它将训练和推理的时间减少了几个数量级，同时由于不必调整图像大小和扭曲图像，甚至提高了性能。然而，我怀疑经过图像分类训练的特征图是否真正包含了裁剪图像的空间信息。当使用深度神经网络时，这可能是一个大问题，因为接收大小将会很大，因此可能会限制 SPP-Net 管道使用更深的特征提取器。一些其他损失可以用于在对象检测数据集上一起微调特征提取器。

摘要

*   建议应用空间金字塔池来输出任意输入大小的固定长度要素。
*   改进了要处理的训练/推理过程，将每个区域的前向传递次数(每个图像约 2，000 个区域)从一次减少到整个图像的一次前向传递。

## 快速 R-CNN[3]

先前的对象检测算法，即 R-CNN，通常分别学习定位和分类阶段，这使得训练更加昂贵。此外，这些算法在测试时非常慢，不利于实时应用。快速 R-CNN 联合学习检测物体的空间位置并对其进行分类。

r-CNN 很慢，因为每个对象提议都要向前传递。虽然 SPP-Nets 确实解决了这个问题，并在测试时将 R-CNN 加速了 100 倍，但训练是一个多阶段的过程，需要许多步骤的密集计算，与 R-CNN 相比，仅加速了 3 倍。此外，固定的卷积层限制了网络的精度。

![](img/9f216ce0d830a79af0eb2ab9128784f4.png)

上图展示了快速 R-CNN 管道。CNN 对图像进行处理，并根据对象提议裁剪特征地图。然后，感兴趣区域(RoI)池层提取一个固定长度的向量，然后通过完全连接的网络对其进行处理，以预测类别概率并优化边界框。

RoI pooling 层是 SPP 层的一个特例，具有一个金字塔等级。高×宽 RoI 窗口被分成一个高×宽的网格，每个网格的大小为高/高×宽，每个网格单元上应用最大池。输出始终是一个 H × W 形状的向量。快速 R-CNN 流程与 SPP-Net 管道非常相似，只是稍有修改。

以前在 SPP-Nets 中，通过卷积层的反向传播是低效的，因为感受野可能跨越整个图像，这是非常大的。快速 R-CNN 通过小批量同时训练一幅图像的多个 RoI 样本来解决这个问题。这些特征可以在训练期间共享，这样可以加快训练速度，并且无需缓存特征。这一招被命名为*分层采样*。此外，快速 R-CNN 通过多任务损失联合优化分类器和包围盒回归器，而不是单独训练。

![](img/3c3d4e27e92d4d2f295d208ce6d25a4b.png)

分类损失和定位损失的联合训练

还对 R-CNN 算法进行了一些额外的改进。例如，快速 R-CNN 使用稳健的 L1 损失而不是 L2 损失进行回归。超参数也有修改。本文还结合了 R-CNN 和 SPP-Net 的技术。文件中提供了详细的解释。Fast R-CNN 能够实现 S.O.T.A .的准确性，同时在训练和测试方面的速度也快了几个数量级。

摘要

*   将 SPP 修改为 RoI 池
*   通过从一幅图像中采样多个面片进行高效训练->卷积层上仅一次向前/向后传递。
*   ->通过反向传播训练卷积特征提取器

## 更快的 R-CNN[4]

指出对象提议阶段是实时对象检测的计算瓶颈。作为一种解决方案，更快的 R-CNN 实现了与特征提取器网络共享卷积层的区域提议网络(RPN ),为计算对象提议引入了边际成本。管道与 Fast R-CNN 一致，只是对象提议是通过内部培训的 RPN 提出的，如下图所示。

![](img/4e3436b1235910ae0e33155df45670ec.png)

RPN 模型接收由特征提取器计算的特征图，并通过在特征图上滑动小 CNN 来输出对象提议的列表。在每个滑动窗口位置，网络预测 k 个参考框(锚)的对象提议，每个对象提议由 4 个坐标和估计对象概率的分数组成。下图描述了 RPN 模型。

![](img/3802a0a243ba9497e285bd82b7d0e07c.png)

RPN 模型与快速 R-CNN 分类管道分开训练。快速 R-CNN 模型的训练类似于原始程序，包括以图像为中心的采样策略。一个区别是 RoI 的大小可以确定，而不是任意确定。因此，受益于锚设计，训练 k 个边界框回归器，每个负责提炼相应的锚类型。

在训练 RPN 模型时，基于具有地面真实边界框的 IoU，为每个锚点分配二进制标签。标签可以是正的、负的或中性的，取决于带有真相框的欠条。RPN 模型在分数和坐标估计上被训练。本文讨论了通过梯度下降法联合训练这两个模型的三种方法。该论文使用交替训练来训练网络，其中首先训练 RPN，并且在该过程中计算的建议用于训练快速 R-CNN。

摘要

*   代替缓慢的选择性搜索，提出 RPN 来训练包围盒提议过程。
*   RPN 模型预测目标在*锚*上的概率、位置。
*   比较了各种训练方法，以便与原始的基于区域的检测网络一起有效地训练 RPN 模型。

## 特征金字塔网络(FPN) [5]

特征影像金字塔(图 a)提供了多尺度特征表示，通过支持尺度不变性，可方便地用于对象检测。该模型必须能够检测图像中对象的所有比例，并且改变金字塔的层可以容易地抵消对象的比例差异。但是，计算多级特征显然需要相当长的时间，并且不用于快速/更快速的 R-CNN 等管道中(图 b)。

![](img/430a229b865b74d5f4397f71d889cacc.png)

卷积神经网络固有地计算多尺度特征表示，因为每一层分级地计算不同分辨率的特征图。然而，以前的工作利用细胞神经网络的层次属性，以较小的计算量制作一个特征图像金字塔(图 c)是不完整的。CNN 的中间特征映射问题是特征根据网络的深度自然地传达不同的语义。要充分利用 CNN 进行多比例要素表示，图层在所有比例下都具有强大的语义非常重要。

提议的 FPN(图 d)被描述为

> 一种通过自顶向下的路径和横向连接将低分辨率、语义强的特征与高分辨率、语义弱的特征相结合的架构。

FPN 旨在为高分辨率要素提供丰富的语义，是一种类似 U-Net 的架构。一个*自下而上的*路径(红色)是前馈 CNN。每个分辨率被表示为一个*阶段*，并且为每个阶段定义一个金字塔等级。*自上而下*路径(蓝色)通过从更高的金字塔等级向上采样语义更强的特征地图来产生更高分辨率的特征。直观上，更多的操作可以增强任意比例尺的要素地图的语义，提供丰富的多比例尺要素。通过*横向连接*投射的自下而上路径的特征进一步增强了这些特征。

![](img/4c482cd3db88eee06ec00f0c8d70dd57.png)

FPN 管道为生成具有丰富语义内容的多尺度特征地图提供了通用解决方案。当应用于更快的 R-CNN 对象检测流水线时，FPN 架构被应用于用于生成边界框提议的 RPN 网络和快速的 R-CNN 基于区域的分类器中枢。通过替换主干网络和馈送 FPN 输出而不是单个特征地图，FPN 被采用到 RPN。当应用锚时，我们在金字塔输入的不同级别上应用锚的每个尺度。例如{32、64、128、256、512 }个大小的锚，每个锚用于特征地图{P2、P3、P4、P5、P6}。将更快的 R-CNN 检测网络应用于根据边界框的大小确定的特征图列表之一。

摘要

*   提出新的 FPN 网络体系结构来计算语义丰富的多尺度特征表示。
*   使用 CNN 的中间层作为多尺度特征和图像金字塔，并使用这些特征训练 RPN 和主干网络。

## 屏蔽 R-CNN[6]

![](img/b2b6a2b79f51581a3c755c930664eaa3.png)

实例分割

掩模 R-CNN 被提出来解决一个稍微不同的实例分割问题。简而言之，这个问题是对象检测和语义分割的结合。如上所述，该任务旨在生成划分对象的像素边界。

Mask R-CNN 基于更快的 R-CNN 管道，但每个对象提议有三个输出，而不是两个。附加分支预测 K(# classes)个二进制对象掩码，该掩码分割图像中每个类别的对象。使用分类分支的结果选择要绘制的最终实例分割图。这被称为*解耦*掩码和类别预测。

使用全卷积网络(FCN)从每个 RoI 中提取 m × m 掩模。与绘制边界框不同，生成像素级遮罩需要像素级的空间信息。因此，在生成掩膜分段时，该函数会在折叠要素之前进行分支，如下图所示。

RoI 是小的特征图，通过 RoI 汇集操作来计算，RoI 汇集操作将特征图严格地分割成箱。这是因为这在 RoI 和提取的特征之间引入了未对准，这在分类中被忽略，但是会损害像素级掩模，像素级掩模很大程度上受到小平移的影响。提出了 RoIAlign 层，平滑了 RoIPool 的硬切片。RoIAlgin 图层基本上是大地图到小地图的双线性插值。结果显示了很大的性能提升，并且作者提出了更多的证据表明问题出在不一致的对齐上。

![](img/2c502ec5dfc7b92be912435067c68b41.png)

为了训练掩码分支，损失项 L_mask 被添加到原始分类和边界框回归损失函数中。掩模损失项被计算为具有类别 k 的基本事实分割图和第 k 个掩模之间的交叉熵损失。

![](img/aa5e591b7e17390ad7f04211fa7921bd.png)

本文不仅实现了高性能的实例分割，而且在常规包围盒对象检测和其他任务(如姿态估计)中也产生了令人惊讶的结果。上表显示了边界框对象检测的结果，其中掩模 R-CNN 优于更快的 R-CNN。更快的 R-CNN，RoIAlgin 显示了在训练中不使用面罩丢失时的结果。结果表明，当用掩模预测目标训练时，对象检测管道学习到更可概括的丰富特征。

摘要

*   通过引入*掩码分支*，提出了一个基于快速 R-CNN 的实例分割通用框架。
*   通过解决切片中的不对齐问题来修复 RoIPooling 层。
*   简单却令人惊叹的论文:)

## 级联 R-CNN[7]

![](img/79ee32b0cde74cd194b27c5f8e1e0ede.png)

如果 IoU 高于阈值 u，则该补丁被认为是类的示例，或者被认为是*背景*类。当在使用宽松 IoU 阈值(如 u=0.5)的数据集上训练时，边界框预测变得有噪声。但是提高 IoU 阈值并不能解决问题，因为用于训练/推断的最佳 IoU 不匹配。它还会显著减少阳性样本的数量，引入不平衡数据的问题，这在右侧图中红色图表的低性能中有所说明。辨别“接近但不正确”的包围盒很重要，但在以前的工作中没有研究过。

这些图显示了三个检测器在 u = 0.5、0.6、0.7 的 IoU 阈值上进行训练。如左图所示，各型号在不同的 IoU 范围内表现最佳。该论文提供了更多的理由，说明为什么单个分类器难以在整体 IoU 水平上表现一致。基于单个检测器对于单个质量水平是最佳的假设，级联 R-CNN 训练用增加的 IoU 阈值训练的检测器序列。

![](img/9363b866514c7473b402a884d4e8037d.png)

在更快的 R-CNN(图 a)中，RPN 网络为细化框和分类提供 RoI。在级联 R-CNN 中，向头部序列提供前一头部的边界框估计，而不是 RPN 的 RoI，这被解释为迭代地改进边界框估计(图 b，d)。理论上，下一个头的输出应该逐步改善边界框位置，但是用小的 IoU 阈值训练边界框细化器将不会改善超过某个值的 IoU(上面的图 c)。因此，级联 R-CNN 被设计为不同的*专用*回归器的级联(图 d)。因此，更深的阶段能够逐步提高 IoU 阈值，如下图 IoU 直方图所示。

![](img/9d195a6f69b08b5af467c4bd4340b62e.png)![](img/55404ee14975f767698be01e55c26610.png)

摘要

*   指出 IoU 阈值在对象检测中的影响，以及简单修改阈值的问题。
*   观察到不同型号在不同 IoU 范围内表现最佳。
*   级联包围盒回归器，以确保高置信度的包围盒输出，而不会引入额外的问题。

## 结论

我们回顾了多阶段目标检测的主要方法。这些算法的进展速度真是惊人。琐碎的 R-CNN 算法既慢又低效。高级算法的许多关键见解都基于*共享特征*(例如 SPP-Net、Fast R-CNN、Mask R-CNN)，并支持对先前固定的管道组件(例如 Fast R-CNN、Fast R-CNN、Cascade R-CNN)进行梯度训练，以高效地学习更丰富的特征。目标检测是计算机视觉的一个重要领域，多阶段目标检测是目标检测的主流方法。

多阶段对象检测的最新工作是检测器，它通过提出一个*递归特征金字塔*来改善网络的主干。虽然最近对对象检测的关注已经转移到基于变压器的方法，但这些关于多阶段对象检测的论文总体上提供了对深度学习的深刻见解。本帖介绍的论文选择多以[【8】](https://arxiv.org/pdf/1907.09408.pdf)为依据。

![](img/130d021fa49bf7302bdf13074612540a.png)

[https://paperswithcode.com/sota/object-detection-on-coco](https://paperswithcode.com/sota/object-detection-on-coco)

# 参考

[1]r . gir shick、j . Donahue、t . Darrell 和 j . Malik(2014 年)。丰富的特征层次，用于精确的对象检测和语义分割。IEEE 计算机视觉和模式识别会议论文集*(第 580–587 页)。*

[2]何，王，张，徐，任，孙等(2015).用于视觉识别的深度卷积网络中的空间金字塔池。 *IEEE 模式分析与机器智能汇刊*， *37* (9)，1904–1916。

[3]吉尔希克，R. (2015 年)。快速 r-cnn。IEEE 计算机视觉国际会议论文集(第 1440-1448 页)。

[4]任，s，何，k，吉希克，r .，，孙，J. (2015)。更快的 R-CNN:用区域建议网络实现实时目标检测。*神经信息处理系统的进展*， *28* ，91–99。

[5]林，T. Y .，多拉尔，p .，吉尔希克，r .，何，k .，哈里哈兰，b .，&贝隆吉，S. (2017)。用于目标检测的特征金字塔网络。IEEE 计算机视觉和模式识别会议论文集(第 2117-2125 页)。

[6] He，k .，Gkioxari，g .，Dollár，p .，& Girshick，R. (2017 年)。屏蔽 R-CNN。IEEE 计算机视觉国际会议论文集(第 2961-2969 页)。

[7]蔡志勇，等(2018)。级联 R-CNN:钻研高质量的对象检测。IEEE 计算机视觉和模式识别会议的会议记录(第 6154-6162 页)。

[8]焦，李，张，刘，杨，李，冯，曲，等(2019)。基于深度学习的目标检测综述。 *IEEE 接入*， *7* ，128837–128868。