<html>
<head>
<title>Using Beautiful Soup’s SoupStrainer to Save Time and Memory When Web Scraping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Beautiful Soup的SoupStrainer在网页抓取时节省时间和内存</h1>
<blockquote>原文：<a href="https://medium.com/codex/using-beautiful-soups-soupstrainer-to-save-time-and-memory-when-web-scraping-ea1dbd2e886f?source=collection_archive---------1-----------------------#2021-02-05">https://medium.com/codex/using-beautiful-soups-soupstrainer-to-save-time-and-memory-when-web-scraping-ea1dbd2e886f?source=collection_archive---------1-----------------------#2021-02-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="d1db" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph"><a class="ae ge" href="http://medium.com/codex" rel="noopener">法典</a></h2><div class=""/><div class=""><h2 id="a52e" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">分析一个难以置信的特征</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/3b5d0c2c14d6546f0111a9aad6fe1f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lZf7QoQI7RmHl6UR"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">照片由<a class="ae jw" href="https://unsplash.com/@mat_graphik?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔丹·马修</a>在<a class="ae jw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h2 id="f54b" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ho bi translated">通常的做事方式</h2><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="ec52" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">上面的代码显示了BeautifulSoup构造函数(在第12行，作为Soup导入)接受一个站点的HMTL参数和一个表示我们需要的解析器类型的字符串。这创建了一个漂亮的Soup对象，我们可以用它来抓取数据。用这种设置从网站上抓取一两页应该没问题。但是，如果您需要抓取多页数据，那么这可能不是一个好方法。默认情况下，BeautifulSoup对象将解析我们提供给它的整个HTML页面。然后我们必须使用find_all()方法(在第13行)来提取我们感兴趣的特定HTML标签。当我们只需要页面的一部分时，继续为整个页面创建解析器是浪费时间和内存。一定有更好的方法。</p><h2 id="be2c" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ho bi translated">滤汤器是如何工作的？</h2><p id="3413" class="pw-post-body-paragraph ld le hi lf b lg lw is li lj lx iv ll kp ly ln lo kt lz lq lr kx ma lt lu lv hb bi translated">SoupStrainer允许我们指定我们站点的HTML中的哪些项目将被解析。我们可以指出，我们只想解析所有的p标签或任何具有特定class/id值的东西(这些只是众多选项中的几个)。如果我们正在抓取多页数据，那么我们可以确保只解析需要的信息。使用这个特性的好处是巨大的。</p><h2 id="a616" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ho bi translated">包含过滤器</h2><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="df2d" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">上面的代码显示了我们如何使用soup screen对象和BeautifulSoup对象。调用SoupStrainer构造函数(在第13行，作为过滤器导入)来创建一个对象，该对象带有提供解析规范的参数。此调用的结果存储在only_item_cells变量中。BeautifulSoup对象像往常一样使用页面的HTML参数和所需的解析器创建。但是，only_item_cells变量是作为parse_only参数的第三个参数提供的。parse_only参数将创建一个BeautifulSoup对象，该对象将只解析特定的项目(在本例中，只解析class值为“item-cell”的div标签)。现在，我们只剩下一个解析后的HTML文档，它只包含每次调用BeautifulSoup构造函数时需要的div标记。</p><p id="23cf" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">注意:从BeautifulSoup对象调用find_all()方法时，会返回一个列表。因为使用了SoupStrainer，所以不需要使用find_all()方法。我们想要的div元素已经合并到我们解析的HTML中。因此，我们需要将page_soup转换成一个列表(在第15行),以便能够有效地访问数据。</p><h2 id="c83a" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ho bi translated">看到结果</h2><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mb"><img src="../Images/fcf6bc4cc1cfad12e9f5cb730c6f3505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*szeZRXltNE-8gCiFHU42tg.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">作者图片</figcaption></figure><p id="be5d" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">如上图所示，page_soup被转换成了一个列表。该列表包含37个项目(显卡)。列表中的每一项都是一个符合我们规范的div元素。BeautifulSoup对象已成功修改。我们不再局限于从网页上抓取所有内容。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h2 id="0a8c" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ho bi translated">将SoupStrainer应用于实际的web刮刀</h2><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mc"><img src="../Images/0a453e8b956d31f8fe8ad2c84ef80c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZYoLF5DdkUYQ0UX0s_Al3Q.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">作者图片</figcaption></figure><p id="2a54" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">上图显示了用于抓取数据的URL。每个项目单元代表新蛋网站上的一个独立显卡。每页的显卡数量各不相同。像这样的网站是网络抓取和使用SoupStrainer的完美应用。</p><p id="4501" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">注意:上图中的URL将在下面的代码中稍加修改，添加“page”查询参数。这个查询参数将只允许我们抓取多页千兆字节的图形卡。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="72e9" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">当你访问新蛋的显卡网站时，你会发现一个制造商复选框。此复选框可用于指示要显示的图形卡。在第9行，我创建了一个字典来表示这个复选框的缩小版本。每个密钥是制造商的名称，其对应的值是该制造商的标识号。这个字典用于为“N”查询参数创建一个带有固定标识号的URL。然后，我使用来自checking Newegg网站的预定义数字为“page”查询参数提供值。在将每个页面的HTML转换成一个汤之后，最终的URL可以用来为千兆字节的显卡抓取多页数据。</p><p id="01e7" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">我希望大家后退一步，想想这个功能有多强大。在上面的例子中，我们抓取了六页数据。如果使用普通的约定(只包含BeautifulSoup)，那么页面中的每个元素都将是相应的解析文档的一部分。但是，每次为页面生成解析的文档时，它只包含与图形卡相关的元素。随着页面数量的不断增加，解析项的减少会节省时间和内存。</p><p id="aff5" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">注意:我已经写了一系列文章，讨论如何构建这个web scraper的一个更简单的版本(分别构建一个Newegg Web Scraper(第1部分)和(第2部分))。在那些文章中，我提供了构建所需工具的信息和深入的代码解释。这就是为什么我没有在本文中详细介绍代码如何工作的原因。</p><h2 id="bfff" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ho bi translated">参考</h2><p id="efd3" class="pw-post-body-paragraph ld le hi lf b lg lw is li lj lx iv ll kp ly ln lo kt lz lq lr kx ma lt lu lv hb bi translated">理查森，L. (2020)。漂亮的汤文档。<em class="md">邋遢</em>。从https://www.crummy.com/software/BeautifulSoup/bs4/doc/<a class="ae jw" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="f520" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">数据科学道场。(2017年1月6日)。介绍用Python和漂亮的汤进行网络抓取。【YouTube视频】。数据科学道场。从<a class="ae jw" href="https://www.youtube.com/watch?v=XQgXKtPSzUI&amp;t=205s" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=XQgXKtPSzUI&amp;取回t=205s </a></p><p id="b708" class="pw-post-body-paragraph ld le hi lf b lg lh is li lj lk iv ll kp lm ln lo kt lp lq lr kx ls lt lu lv hb bi translated">我的<a class="ae jw" href="https://github.com/wormhole85/newegg-web-scraper-soupstrainer" rel="noopener ugc nofollow" target="_blank"> GitHub回购</a>的网页抓取器代码。</p></div></div>    
</body>
</html>