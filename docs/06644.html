<html>
<head>
<title>K-Nearest Neighbors explained!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-最近邻解释！！</h1>
<blockquote>原文：<a href="https://medium.com/codex/k-nearest-neighbors-explained-fd83adea44cd?source=collection_archive---------18-----------------------#2022-05-05">https://medium.com/codex/k-nearest-neighbors-explained-fd83adea44cd?source=collection_archive---------18-----------------------#2022-05-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/9597e0958d40cf5debe7a588ba952e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*OB5TK5u3bpfeu2KWUGZsKg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq"> KNN用不同颜色的树作插图</strong></figcaption></figure><p id="64e4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">你和你的邻居是一样的，这是这个算法遵循的哲学。</p><p id="2819" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">KNN表示K个最近邻居，其中K是一个表示需要考虑的最近邻居数量的<strong class="it hj">整数</strong>。我将通过一个例子来提供广泛的理解。</p><p id="d79c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">举例:</strong> <em class="jp">假设我们在一个分类问题中取K = 5，在给定一个人的性别和薪水的情况下，我们需要预测他是否会购买某个特定的产品。</em></p><p id="943e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这里，我们将选择需要预测的新点周围的5个最近邻居(基于点之间的欧几里德距离)，然后如果我们看到5个人中有3个人购买了该商品，我们将把新点分类到已购买类别中。</p><p id="01f4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这种情况下，多数人获胜。</p><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es jq"><img src="../Images/b7af468c247c1ca4298afa6247073324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*idG8Rl84bvCKX-SceHOrPw.png"/></div></figure><p id="60cf" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">定义</strong> : KNN是一种受监督的非参数机器<strong class="it hj"> </strong>学习算法，它要求对特征进行标记，并且是一种基于距离的算法，它使用接近度来对单个数据点的分组进行分类或预测。虽然它可用于回归(N个最近邻点的平均值)或分类(N个最近邻点的多数投票)问题，但它通常用作分类算法，并假定可以在彼此附近找到相似的点。</p><p id="414b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">KNN算法中的假设是:</strong></p><ol class=""><li id="898d" class="jv jw hi it b iu iv iy iz jc jx jg jy jk jz jo ka kb kc kd bi translated">KNN假设数据是度量空间和距离的概念。</li><li id="181e" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">k应该是奇数，以避免在平等分类的情况下出现平局。</li><li id="8f3d" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">应对数据进行缩放，使所有要素的比例相等，以避免高比例值要素出现偏差。</li><li id="58ce" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">每个训练数据集都应该被标记。</li></ol><p id="3281" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">KNN被称为<strong class="it hj">懒学习者</strong>，因为它不会立即从训练集中学习；相反，它存储数据集，并在分类时对数据集执行操作。它也被称为基于实例或基于记忆的学习方法。</p><p id="5456" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">KNN的应用:</strong></p><ol class=""><li id="befe" class="jv jw hi it b iu iv iy iz jc jx jg jy jk jz jo ka kb kc kd bi translated">推荐系统</li><li id="58d4" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">用于估算数据集中要素缺失值的数据预处理</li><li id="3944" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">医疗保健中的糖尿病类型预测、癌症预测和心脏病预测</li><li id="65fb" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">银行业信用风险分析。</li><li id="fed7" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">研究基因表达</li></ol><p id="509c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我在Kaggle有一本关于使用KNN 进行糖尿病分类的笔记本。请仔细阅读，了解KNN是如何实施和优化的。</p><h1 id="b4dd" class="kk kl hi bd iq km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">KNN钾超参数</h1><p id="54bd" class="pw-post-body-paragraph ir is hi it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hb bi translated">K是一个奇整数<strong class="it hj"/>为了避免歧义，K代表需要考虑的最近邻的数量。</p><p id="fca4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">要优化K，请考虑以下情况，这总是会产生准确的结果。</p><ol class=""><li id="71e4" class="jv jw hi it b iu iv iy iz jc jx jg jy jk jz jo ka kb kc kd bi translated">K =训练数据集中数据点数量的平方根，或者，</li><li id="48c9" class="jv jw hi it b iu ke iy kf jc kg jg kh jk ki jo ka kb kc kd bi translated">采用试差法，取不同的K值，绘制误差与K值的关系图，选择最佳值。</li></ol><blockquote class="lm ln lo"><p id="132b" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">如果K=1倾向于过度拟合，这是由于高方差；它指定最近点的类别，在训练集中表现良好，但在测试中表现不佳。</p><p id="16a9" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">如果K = n，并且n是数据集中的数据点数，则欠拟合的趋势是由于高偏差。如果数据有一个百分比很高的支配类，假设85%的数据有一个单独的类，那么如果K = n，该模型将以85%的准确度进行预测，因此该模型不会对整个数据进行概括。</p><p id="0625" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">所以我们必须找到K，一个介于1和n之间的误差最小的最佳值。</p></blockquote><h1 id="e13e" class="kk kl hi bd iq km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak"> KNN距离度量超参数</strong></h1><p id="14cd" class="pw-post-body-paragraph ir is hi it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hb bi translated">KNN主要将K和距离度量作为重要的超参数，其中K如上所述。</p><blockquote class="lm ln lo"><p id="e5b3" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">让我们深入了解距离度量超参数</p></blockquote><p id="ebc4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">为了确定哪些数据点最接近给定的查询点，需要计算查询点和其他数据点之间的距离。这些距离度量有助于形成决策边界，将查询点划分为不同的区域。您通常会看到用Voronoi图可视化的决策边界。</p><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/8b17fecf3aacd4818774dd92358f6237.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*5ZW-zQj8HA6st6_l7bWV7g.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">带有决策边界的Voronoi图</strong></figcaption></figure><p id="5093" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">虽然有几种距离测量方法可供选择，但为了便于理解，我们将在二维空间中介绍以下4种:</p><blockquote class="lm ln lo"><p id="5a63" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">距离度量必须满足几个条件:</p><p id="f8a0" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">非负性:d(x，y) &gt;= 0</p><p id="14ad" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">恒等式:d(x，y) = 0当且仅当x == y</p><p id="a5a8" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">对称性:d(x，y) = d(y，x)</p><p id="cb87" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">三角形不等式:d(x，y) + d(y，z) &gt;= d(x，z)</p></blockquote><p id="4aac" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">欧几里德距离</strong>:这是最常用的距离度量，而且仅限于实值向量。使用下面的公式，它测量要预测的新点和其他点之间的直线距离。</p><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/e56785e45f8f5a09be30ae2701ef2eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*8xFRC77QbYAcaloS9y1Bag.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">几何直觉</strong></figcaption></figure><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/89bc2ddce0532bc5fbbab6e4f9510ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*pPv4R7vcoenCRjL7jAs9lA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">欧几里德距离公式</strong></figcaption></figure><p id="fe17" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">曼哈顿距离</strong>:这也是另一种流行的距离度量，测量两点之间的绝对值。它是两点之间的线段在坐标轴上的投影长度之和。简而言之，它是两点的所有维度上的测量值之间的绝对差值之和，说明了如何通过城市街道从一个地址导航到另一个地址。</p><blockquote class="lm ln lo"><p id="fd50" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">当我们有高维度的情况时，这个距离优于欧几里德距离。</p></blockquote><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/5774386f87a68af72f6e2071cbe7e09b.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*Qjo1qspWZn-oABkFoR7ssA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">曼哈顿距离和欧几里德距离的比较</strong></figcaption></figure><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/b2882e26e9431c57dd04d3c0bae67ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*CgmktqNR0qpcsRHDoXT3OQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">曼哈顿距离公式</strong></figcaption></figure><p id="619b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">闵可夫斯基距离</strong>:闵可夫斯基距离是曼哈顿距离和欧几里得距离的推广，增加了一个称为顺序的参数p。当阶数为1时，闵可夫斯基距离等于曼哈顿距离，当阶数为2时，闵可夫斯基距离等于欧几里德距离。在阶数为无穷大的极限情况下，闵可夫斯基距离等于切比雪夫距离。</p><blockquote class="lm ln lo"><p id="525c" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">闵可夫斯基距离在那些利用这个概念来寻找最佳相关性或分类数据的算法中。这是因为将顺序视为一个或两个是直截了当的，因此根据不同的需要使用曼哈顿距离或欧几里德距离。</p></blockquote><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lx"><img src="../Images/d61170905e533bc627f92bbff3680d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*bVbdc_0oPmPqbZvTRSQkew.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">闵可夫斯基距离公式</strong></figcaption></figure><p id="3f06" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">汉明距离</strong>:这种技术通常用于布尔或字符串向量，识别向量不匹配的点。</p><p id="7b70" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在比较两个等长的二进制字符串时，汉明距离是两个比特不相同的比特位置的数量。汉明距离方法查看整个数据集，并找出何时数据点一对一地相似和不相似。它给出了多少属性不同的结果。当你对数据进行一次性编码时，或者当我们需要找出两个二进制向量之间的距离时，通常会用到这种方法。</p><p id="50fe" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这可以用下面的公式来表示:</p><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/4254a2203f4efc1ecfb80244c6ca87f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*mYUFIWk4lytDOhMYZHCOJA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">汉明距离公式</strong></figcaption></figure><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es md"><img src="../Images/75e3857d196408ee8bbb1f7e8d108790.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*jOpGBnBDYpJhbJBu-i02gQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">海明距离条件</strong></figcaption></figure><p id="85b1" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">示例</strong>:假设我们有两个长度相同的字符串“ABCDE”和“AGDDF”，我们想找出它们之间的汉明距离。我们将逐个字母地检查每个字符串，看它们是否相似，比如两个字符串的第一个字母相似，然后第二个不相似，以此类推。</p><p id="e41c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj"> A </strong> BC <strong class="it hj"> D </strong> E和<strong class="it hj"> A </strong> GD <strong class="it hj"> D </strong> F</p><p id="0d6b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">当我们这样做的时候，我们将会看到字符串中只有两个用<strong class="it hj">粗体</strong>标记的字母是相似的，三个是不相似的。因此，这里的汉明距离是3。请注意，两个字符串之间的汉明距离越大，这些字符串就越不相似(反之亦然)。</p><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es me"><img src="../Images/ac2e294f7e9dfe87d6c164467aad9eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*wW5zu4BarwgAaHjlLrWm4Q.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd iq">布尔字符串中的汉明距离</strong></figcaption></figure><h1 id="6015" class="kk kl hi bd iq km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">加权KNN </strong></h1><p id="2254" class="pw-post-body-paragraph ir is hi it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hb bi translated">你听说过马克·扎克伯格对脸书的否决权吗？</p><p id="91e0" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">他的一票B类股相当于其他A类股股东的10票，扎克伯格控制着脸书58%的有表决权的股份。</p><p id="ffec" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">所以他在每个决定上都有更大的权力。加权KNN的情况也是如此。</p><p id="31b9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果较近的点比较远的点更需要影响预测，我们就使用加权KNN。</p><p id="9112" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">scikit-learn中有一个名为weights的超参数，默认情况下设置为“uniform”，它平等地考虑所有数据点。</p><p id="e849" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">但是，如果我们想认为上面的场景中更近的点比更远的点有更大的影响呢？权重中有一个称为“距离”的选项，这意味着如果新点和数据之间的距离增加，则权重会减少。</p><p id="7830" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">最简单的权重函数是1/di，其中di是数据集中新点到点的距离。</p><blockquote class="lm ln lo"><p id="cad9" class="ir is jp it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hb bi translated">因此，离点越近，对预测的影响越大。</p></blockquote><p id="aac9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">关注我获取更多此类内容！</p><p id="a634" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">感谢阅读！！</p></div></div>    
</body>
</html>