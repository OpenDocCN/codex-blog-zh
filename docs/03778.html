<html>
<head>
<title>What are Neural Networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是神经网络？</h1>
<blockquote>原文：<a href="https://medium.com/codex/what-are-neural-networks-3a0965e2ebfb?source=collection_archive---------4-----------------------#2021-09-24">https://medium.com/codex/what-are-neural-networks-3a0965e2ebfb?source=collection_archive---------4-----------------------#2021-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/40e6ee66f968d4394fb487778d63f0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*79_e9iIxfiZHMvWU"/></div></div></figure><blockquote class="iq ir is"><p id="8c46" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">“神经网络是这种不是算法的技术，它是一个上面有权重的网络，你可以调整权重，让它学习。你通过试验来教授它。”—霍华德·莱茵戈德</strong></p></blockquote><p id="1ef4" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">作为该系列的延续，我们将在本帖中探讨神经网络。这篇文章旨在指导一个完全的新手了解关于神经网络的一切。如果你已经有了一些专业知识，你应该回顾一下其中的一些，但是你可能从中有所收获。</p><p id="2e73" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这篇文章中，我们将了解什么是神经网络，它们是用来做什么的，以及它们是如何工作的，这是你们一直在等待的！</p><p id="e238" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">要做到这一点，你不需要精通技术，或者拥有数学或计算机科学学位；我将把重点放在基础上，将来我可能会发表一篇关于基础数学的更深入的文章。让我们开始派对吧！</p><h2 id="4e27" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">什么是神经网络？</h2><p id="34d7" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je js ks jh ji jt kt jl jm ju ku jp jq jr hb bi translated">人工神经网络，也称为神经网络(NNs)或模拟神经网络(SNNs)，是提供深度学习技术核心的机器学习的子集。神经网络是试图模仿大脑的算法。这些灵感来自于构成动物大脑的生物神经网络，但并不相同。这种系统通过检查例子来“学习”执行任务，并且通常没有用特定于任务的规则来编码。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/49a7597f1d98bc3664b2f3522b84d2e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GXaC0c1fS97ya3EX.gif"/></div></div></figure><p id="feb8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">他们通过观察一个物体的例子来学习，比如一只猫或一幅画，并识别重要的特征，这将允许他们在未来的照片中识别这个物体。这些网络不需要知道被分析对象的任何信息。它们足够聪明，只需看几个样本，就能迅速对事物进行分类、预测等等。</p><p id="fa4f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">现在你知道什么是神经网络，让我们看看它们是如何工作的。</p><h2 id="37e8" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">为什么要使用神经网络？</h2><p id="dac8" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je js ks jh ji jt kt jl jm ju ku jp jq jr hb bi translated">凭借其从复杂或不准确的数据中提取意义的惊人能力，神经网络可用于识别模式和发现趋势，这些模式和趋势对于人或其他计算机算法来说太复杂而无法检测。一个经过训练的神经网络可以被认为是它所负责分析的数据类别中的“专家”。然后，该专家可用于响应新的感兴趣的场景进行预测，并回答“假设”查询。</p><h2 id="fdf5" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">神经网络是如何工作的？</h2><p id="9b97" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je js ks jh ji jt kt jl jm ju ku jp jq jr hb bi translated">这个解释将分为四个部分:感知器，正向传播，激活函数，反向传播算法。</p><h2 id="17c5" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated"><strong class="ak">感知器</strong></h2><p id="9b47" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je js ks jh ji jt kt jl jm ju ku jp jq jr hb bi translated">感知器是最基本的神经网络类型。它最初是为了更好地理解大脑，并以神经元为模型。由Rosenblatt开发，它是今天几乎所有神经网络的基础。</p><p id="470a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">感知器是机器学习中二进制分类器的监督学习算法。二进制分类器是确定由数字向量表示的输入是否属于特定类别的函数。它是一种线性分类器，或一种基于线性预测函数进行预测的分类方法，该线性预测函数将一组权重与特征向量相结合。</p><p id="9150" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">感知器可以被视为神经网络的单层中的这种构建块，包括四个不同的部分:</p><ol class=""><li id="3407" class="la lb hi iw b ix iy jb jc js lc jt ld ju le jr lf lg lh li bi translated">输入值或一个输入图层</li><li id="daa9" class="la lb hi iw b ix lj jb lk js ll jt lm ju ln jr lf lg lh li bi translated">权重和偏差</li><li id="65da" class="la lb hi iw b ix lj jb lk js ll jt lm ju ln jr lf lg lh li bi translated">净和</li><li id="827a" class="la lb hi iw b ix lj jb lk js ll jt lm ju ln jr lf lg lh li bi translated">激活功能</li></ol><h2 id="16ff" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">正向传播</h2><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/6aa2c14a3512b1dad2aaf2458d0e6802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Gd98c7elkO42kmBS.png"/></div></div></figure><p id="0c4d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">上述网络采用数值输入<strong class="iw hj"> X1 </strong>和<strong class="iw hj"> X2 </strong>，并且具有与这些输入相关联的权重<strong class="iw hj"> w1 </strong>和<strong class="iw hj"> w2 </strong>。此外，还有另一个与权重<strong class="iw hj"> b </strong>相关联的输入<strong class="iw hj"> 1 </strong>(称为<strong class="iw hj">偏差</strong>)。</p><p id="6414" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">遵循感知器如何操作的图很简单:将偏差(b)加到加权输入的净和(来自前一层的每个输入乘以它们的weight[wᵢxᵢ]).的乘积)上输入可以来自输入层或前一层的感知器。然后通过激活函数发送加权净和，该函数标准化该值并返回值0或1。然后，感知器的选择被传递到下一层，供下一个感知器在决策中使用。这些部分一起构成了神经网络层中的单个感知器。</p><h2 id="e143" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated"><strong class="ak">激活功能</strong></h2><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/3897590a47acaac369f3caa92d81a44d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/0*N9ipRvxDz2z9iwqz"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">来源:来自Researchgate的安东尼奥·拉斐尔·萨比努·帕梅赞</figcaption></figure><p id="fe80" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">如上图所示，计算神经元的输出Y。非线性函数f被称为激活函数。激活函数的目标是给神经元的输出增加非线性。这很重要，因为现实世界的大部分输入是非线性的，我们希望神经元学习非线性表示。每个激活函数(或非线性)从单个整数开始，然后对其应用定义的数学运算。</p><p id="f7c8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">实际上，您可能会遇到以下激活功能:</p><ul class=""><li id="f98d" class="la lb hi iw b ix iy jb jc js lc jt ld ju le jr lv lg lh li bi translated"><strong class="iw hj"> Sigmoid: </strong>接受一个实值输入，并将其压缩到0到1之间。sigmoid的公式如下:σ(x) = 1 / (1 + e⁻ˣ)</li></ul><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/b5598e126ccee254da5f1e6590d46551.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*U8qnstM0m6LRlqKC.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">Sigmoid激活函数</figcaption></figure><ul class=""><li id="89b0" class="la lb hi iw b ix iy jb jc js lc jt ld ju le jr lv lg lh li bi translated"><strong class="iw hj"> Softmax函数:</strong>在分类任务中，我们经常使用Softmax函数作为多层感知器输出层中的激活函数，以确保输出是概率，并且总和为1。<br/>soft max函数获取一个实值分数的无界向量，并将其压缩为一个值介于0和1之间的向量，其总和为1。<br/>因此，在这种情况下，<strong class="iw hj">概率(通过)+概率(失败)= 1。</strong></li></ul><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/e7c2d0b262d5eafd2c840048a84f64c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2iE6mFiLMtL3dx3K.png"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">Softmax函数</figcaption></figure><ul class=""><li id="1455" class="la lb hi iw b ix iy jb jc js lc jt ld ju le jr lv lg lh li bi translated"><strong class="iw hj"> tanh: </strong>接受一个实值输入，并将其压缩到范围[-1，1]。公式如下:tanh(x)=(2/(1+e⁻ˣ)-1</li></ul><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/747cb4c93936bb0188fc873e771935ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*1v6lAzO1nhihSEmu.jpeg"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">Sigmoid和Tanh激活函数的比较</figcaption></figure><ul class=""><li id="37c1" class="la lb hi iw b ix iy jb jc js lc jt ld ju le jr lv lg lh li bi translated"><strong class="iw hj"> ReLU </strong> : ReLU代表整流线性单元。它接受一个实值输入，并将其阈值设置为零(用零替换负值)。ReLU的公式如下:f(x) = max(0，x)</li></ul><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/baea5f23f84de158b7bc04345690eed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:498/0*1zNtpuytiUI8fxL6"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">ReLU激活功能</figcaption></figure><p id="2524" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">下图显示了其他几种激活功能:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/3c16b85940573aa3e56fa548b92c65b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*HXHyXqMY567unisc"/></div></figure><p id="3053" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">偏置的重要性:</strong>偏置的主要作用是为每个节点提供一个可训练的常数值(除了节点接收到的正常输入)。参见<a class="ae lu" href="http://stackoverflow.com/q/2480650/3297280" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj">此链接</strong> </a>了解更多关于神经元中偏见的作用。</p><h2 id="9025" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">反向传播</h2><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/3ad7cc4b89de78e5f73b2d751d89bcb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*daf9SrpB3RT0HfPX"/></div></figure><p id="06e7" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">反向传播是一种用于改变<em class="iv">权重</em>和<em class="iv">偏差</em>的技术，以便感知器的输出变得更加准确。为了计算梯度，我们计算输出节点的总误差，并使用反向传播通过网络传播这些误差。然后，使用优化算法，如梯度下降，我们“调整”网络中的所有权重，以减少输出层的误差。</p><p id="4fc9" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">下图显示了一个神经网络误差图的示例。误差的度量是神经网络的预测与实际值之间的差距。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/f6f7756147fc411870c7c26f4192eef7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/0*lqsmX2cxQxfWmS7K.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">神经网络在训练时可能具有的误差图示例。</figcaption></figure><p id="96f0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">反向传播使用微积分技术来确定误差线在任一时间点的梯度。如上图所示，陡峭的梯度表明仍然存在较高的误差，但平坦的线表明神经网络相当准确。发现神经网络有多精确，意味着算法可以决定改变多少<em class="iv">权重</em>和<em class="iv">偏差</em>(例如，不精确时改变很多，非常精确时稍微调整)。</p><p id="c4d6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这些部分共同组成了一个神经网络。</p><h1 id="1de5" class="mc jw hi bd jx md me mf kb mg mh mi kf mj mk ml ki mm mn mo kl mp mq mr ko ms bi translated">结论</h1><p id="e3d4" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je js ks jh ji jt kt jl jm ju ku jp jq jr hb bi translated">今天我们看到了感知器、前向传播、激活函数、反向传播等神经网络的概念。</p><h1 id="cc14" class="mc jw hi bd jx md me mf kb mg mh mi kf mj mk ml ki mm mn mo kl mp mq mr ko ms bi translated">如果你喜欢这篇文章，那么看看我在这个系列中的其他文章</h1><h2 id="049f" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">1.<a class="ae lu" rel="noopener" href="/@jagajith23/what-is-machine-learning-daeac9a2ceca">什么是机器学习？</a></h2><h2 id="b516" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">2.<a class="ae lu" rel="noopener" href="/codex/what-are-the-types-of-machine-learning-53360b7db8b4">机器学习有哪些类型？</a></h2><h2 id="ac15" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">3.<a class="ae lu" rel="noopener" href="/codex/linear-regression-on-single-variable-f35e6a73dab6">一元线性回归</a></h2><h2 id="2837" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">4.<a class="ae lu" rel="noopener" href="/codex/linear-regression-on-multiple-variables-1893e4d940b1">多元线性回归</a></h2><h2 id="99b2" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">5.<a class="ae lu" rel="noopener" href="/codex/logistic-regression-eee2fd028ffd">逻辑回归</a></h2><h2 id="0fa0" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">6.<a class="ae lu" rel="noopener" href="/@jagajith23/digit-classifier-using-neural-networks-ad17749a8f00">使用神经网络的数字分类器</a></h2><h2 id="5f1c" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">7.<a class="ae lu" rel="noopener" href="/@jagajith23/image-compression-with-k-means-clustering-48e989055729">利用K均值聚类进行图像压缩</a></h2><h2 id="023b" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">8.<a class="ae lu" rel="noopener" href="/@jagajith23/dimensionality-reduction-on-face-using-pca-e3fec3bb4cee">使用PCA对人脸进行降维</a></h2><h2 id="1d6b" class="jv jw hi bd jx jy jz ka kb kc kd ke kf js kg kh ki jt kj kk kl ju km kn ko kp bi translated">9.<a class="ae lu" href="https://jagajith23.medium.com/detect-failing-servers-on-a-network-using-anomaly-detection-1c447bc8a46a" rel="noopener">使用异常检测来检测网络上的故障服务器</a></h2><h1 id="631c" class="mc jw hi bd jx md me mf kb mg mh mi kf mj mk ml ki mm mn mo kl mp mq mr ko ms bi translated">最后做的事</h1><p id="0271" class="pw-post-body-paragraph it iu hi iw b ix kq iz ja jb kr jd je js ks jh ji jt kt jl jm ju ku jp jq jr hb bi translated">如果你喜欢我的文章，请鼓掌👏一个追随者将是✨perceptionatic✨和这是有益的媒体推广这篇文章，使其他人可能会阅读它。<em class="iv">我是贾加吉思，下一场再来抓你。</em></p></div></div>    
</body>
</html>