<html>
<head>
<title>Music Mood Classification using Neural Networks and Spotify’s Web API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用神经网络和Spotify的Web API进行音乐情绪分类</h1>
<blockquote>原文：<a href="https://medium.com/codex/music-mood-classification-using-neural-networks-and-spotifys-web-api-d73b391044a4?source=collection_archive---------5-----------------------#2021-05-19">https://medium.com/codex/music-mood-classification-using-neural-networks-and-spotifys-web-api-d73b391044a4?source=collection_archive---------5-----------------------#2021-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="4e3a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">理解多类分类机器学习工作流中的最佳实践</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/aa33a64edef4a9ff4dc73e21ddd3892c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pW_V1IDkOod8jI-0"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><a class="ae jn" href="https://unsplash.com/@rachitank?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Rachit坦克</a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="eae1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">音乐和情感之间的关系已经有了很好的证明，但是如果你不仅仅是一个普通的音乐听众，你可能已经知道这两个概念有多么紧密的联系。无论是在早上听充满活力的音乐开始新的一天，还是在工作时听周围的音乐，或者在经历心碎时在谷歌上搜索悲伤的歌曲，我们中的许多人都曾在生活中的某个时候用音乐来引发一种情感或找到现有情感的终结。</p><p id="c4bc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在本文中，我们将创建一个分类模型来预测歌曲引发的情感，该模型将以歌曲的<strong class="jq hj">音频特征</strong>作为输入，并输出相应的情绪或情感标签。<strong class="jq hj"> Spotify的Web API </strong>为我们提供了音频功能，其中以下功能将用作输入(对这些功能的解释来自其API文档<a class="ae jn" href="https://developer.spotify.com/documentation/web-api/reference/#object-audiofeaturesobject" rel="noopener ugc nofollow" target="_blank"/>):</p><ul class=""><li id="c535" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated">能量:代表强度和活动的感知度量</li><li id="6005" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">活跃度:检测录音中是否有观众</li><li id="5500" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">速度:轨道的整体估计速度，单位为每分钟节拍数(BPM)</li><li id="ab43" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">语音:检测音轨中是否存在语音单词</li><li id="c334" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">声学:音轨是否声学的置信度</li><li id="57a7" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">乐器性:预测音轨是否不包含人声</li><li id="4f6b" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">可跳舞性:描述一条赛道适合跳舞的程度</li><li id="d86e" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">持续时间:音轨的持续时间，以毫秒为单位</li><li id="a266" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">响度:轨道的整体响度，单位为分贝(dB)</li><li id="12a6" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">效价:描述一首曲目所传达的音乐积极性</li></ul><p id="8205" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">所有这些属性的值都在0.0和1.0之间。我们将要用到的情绪有:<strong class="jq hj">精力充沛、放松、阴郁、好斗和快乐。</strong><code class="du ky kz la lb b">scikit-learn</code>库将帮助我们创建和分析模型，并拆分数据。</p><p id="9e84" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这篇文章的灵感来自于<a class="ae jn" href="https://neokt.github.io/projects/audio-music-mood-classification/" rel="noopener ugc nofollow" target="_blank">丁尼奥</a>和<a class="ae jn" href="https://towardsdatascience.com/predicting-the-music-mood-of-a-song-with-deep-learning-c3ac2b45229e" rel="noopener" target="_blank">克里斯托巴尔韦亚</a>各自关于音乐情绪分类的作品。<strong class="jq hj">我</strong> <strong class="jq hj">希望本教程能帮助初学者更清楚地了解ML工作流程</strong>，至少是关于在具有数字输入特征的多类分类问题的各种模型选择之间进行切换。</p><p id="61fa" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我希望这篇文章的主要观点是，ML并不总是关于运行模型和评估准确性。解释和分析我们的分类器将为我们提供重要的见解，告诉我们如何改变数据集以满足我们的需求。</p><h1 id="ba41" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">获取数据</h1><p id="e9ca" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">这些数据是使用<code class="du ky kz la lb b">spotipy</code> Python库从Spotify的用户创建的基于情绪的播放列表中获得的。首先，让我们为每种情绪获取1个播放列表的歌曲的音频特征。目前，我们的数据集有<strong class="jq hj"> 484首曲目</strong>。</p><p id="0a5e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，我们将数据分成<strong class="jq hj">训练集和</strong>测试集。稍后，我们将使用训练集来交叉验证。在交叉验证中优化模型后，测试集将用于评估我们的模型。<strong class="jq hj">训练集有324首曲目，测试集有160首曲目。</strong></p><pre class="iy iz ja jb fd lz lb ma mb aw mc bi"><span id="c012" class="md ld hi lb b fi me mf l mg mh">trainx, testx, trainy, testy = train_test_split(data, moods, test_size = 0.33, random_state = 42, stratify=moods)</span></pre><p id="d1e5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用<code class="du ky kz la lb b">stratify</code>参数确保我们的训练和测试数据的类别分布是相同的。</p><h1 id="cd4f" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">探索性分析</h1><p id="565a" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">让我们看看我们的训练和测试集中的类分布。</p><pre class="iy iz ja jb fd lz lb ma mb aw mc bi"><span id="3cc5" class="md ld hi lb b fi me mf l mg mh">Train class distribution:</span><span id="8d37" class="md ld hi lb b fi mi mf l mg mh">Dark          67<br/>Relaxing      67<br/>Energetic     67<br/>Happy         66<br/>Aggressive    56</span><span id="a1d7" class="md ld hi lb b fi mi mf l mg mh">Test class distribution:</span><span id="2617" class="md ld hi lb b fi mi mf l mg mh">Relaxing      33<br/>Happy         33<br/>Dark          33<br/>Energetic     33<br/>Aggressive    28</span></pre><p id="eda9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们的训练和测试集中，我们似乎有几乎相等的所有情绪分布。</p><p id="d4f0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在让我们来看看每种情绪的所有属性的平均值:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="4468" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如所料，激进和充满活力的歌曲能量高，而放松的歌曲能量低。放松音乐的节奏也慢得多，而且比其他情绪更倾向于器乐化。当你继续向右滚动时，你会注意到<strong class="jq hj">放松是一种很容易与其他情绪区分开来的情绪。但是我们将不得不更加努力去区别对待其他人。</strong></p><p id="7656" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，探索我们的数据给了我们一个有趣的视角，我们以后可以用它来调整我们的预测。例如，如果我们的模型给出的放松歌曲的结果很差，我们可以添加启发式方法来将歌曲分类为“放松”，而不是依赖于我们的分类器的预测。</p><h1 id="61d5" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">创建我们的第一个模型</h1><p id="77ca" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">最好从简单开始，在优化之前，先建立一个基线模型。所以让我们试试<strong class="jq hj">逻辑回归</strong>。对于预处理，我们将把数据缩放到标准的正态分布。</p><pre class="iy iz ja jb fd lz lb ma mb aw mc bi"><span id="4218" class="md ld hi lb b fi me mf l mg mh">train_scaled = scaler.fit_transform(trainx)<br/>logreg = LogisticRegression(max_iter=2000)<br/>scores = cross_val_score(logreg, train_scaled, trainy, cv=5)<br/>print (scores.mean())</span><span id="c4f6" class="md ld hi lb b fi mi mf l mg mh">0.65</span></pre><p id="a9a6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通过交叉验证，我们得到了65%的准确率<strong class="jq hj"/>。这里，我们早先的324首曲目的“训练”集已经被分割，使得其中的<strong class="jq hj"> 260 </strong>用于交叉验证的特定迭代中的训练，而<strong class="jq hj"> 64 </strong>用于验证。逻辑回归有一个称为<code class="du ky kz la lb b">C</code>的<strong class="jq hj">正则化</strong>参数，可以使用<code class="du ky kz la lb b">GridSearchCV</code>对其进行优化。这使<strong class="jq hj">的精确度略微提高了66% </strong></p><h2 id="1c3c" class="md ld hi bd le ml mm mn li mo mp mq lm jx mr ms lo kb mt mu lq kf mv mw ls mx bi translated">解释模型</h2><p id="f173" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">我们可以通过查看赋予每个特征的重要性来解释我们的模型。这可以通过计算我们的逻辑回归系数的欧拉数的幂来获得。下面向我们展示了对我们每种情绪最重要的变量。</p><pre class="iy iz ja jb fd lz lb ma mb aw mc bi"><span id="88e0" class="md ld hi lb b fi me mf l mg mh">Aggressive    speechiness<br/>Dark          acousticness<br/>Energetic     energy<br/>Happy         valence<br/>Relaxing      instrumentalness</span></pre><p id="a367" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">“能量”属性是一首歌曲是否“有活力”的良好鉴别器，这似乎不足为奇。<strong class="jq hj">攻击性的歌往往语速比较高</strong>(器乐歌要做到攻击性有点难)。高水平的听觉最容易辨别黑暗歌曲。对于快乐的歌曲，配价是决定情绪的主要特征(这与配价对音轨的音乐积极性的表示一致)，而<strong class="jq hj">器乐歌曲更有可能是“放松的”</strong>。</p><p id="a60a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">注意，这个解释是针对我们当前的484首歌曲的数据集的。虽然这似乎与我们对音乐的一般直觉一致，但通过增加我们数据集的大小，可以获得更准确和更普遍的预测。</p><h1 id="fd30" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">第二个模型——神经网络</h1><p id="6705" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">使用交叉验证，我们现在有了一个基线准确度(66%)，并且可以转移到神经网络。我们必须做出的第一个决定是关于我们神经网络的<strong class="jq hj">架构</strong>。根据<a class="ae jn" href="https://stats.stackexchange.com/a/1097" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj"> NN从业者</strong> </a>的说法，一个好的近似就是从1个隐藏层开始。<strong class="jq hj">这个隐层的神经元个数可以取输入输出层单元个数的平均值</strong>。我们的输入层有10个单元，输出层有5个单元。所以我们的隐层从8个单位开始比较合适。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/12223257e970d6d4f9d5efedea8da03f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JtpzFWg7xyLCjMO4KgXFPA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用<a class="ae jn" href="http://alexlenail.me/NN-SVG/index.html" rel="noopener ugc nofollow" target="_blank"> NN SVG </a>生成的NN架构</figcaption></figure><p id="d2be" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这种特殊的架构为我们提供了<strong class="jq hj"> 66% </strong>的CV准确度，与逻辑回归分类器的准确度相同。</p><p id="30b3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以优化表示正则化量的<strong class="jq hj">超参数</strong>“阿尔法”和我们的NN的唯一隐藏层中的神经元数量。我们得到的交叉验证精度为<strong class="jq hj"> 67% </strong>，隐含层中有10个神经元，<code class="du ky kz la lb b">alpha</code>为0.1</p><h1 id="8c8b" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated">分析我们的模型</h1><p id="851e" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">为了搞清楚接下来的步骤，当我们改变数据集的大小时，绘制训练和验证准确性是有意义的。这被称为<strong class="jq hj">学习曲线</strong>，它帮助我们确定增加更多数据是否有助于提高精确度。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/c7c24a67345622fb94ef7ed947c3b2d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*pCPXjV-NHFaEbPlXlZByJg.png"/></div></figure><p id="d1cf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">基于学习曲线，我们可以得出结论，添加更多数据似乎会有所帮助，因为训练分数和验证分数曲线尚未收敛。</p><p id="acf0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在让我们为每种情绪获取2个播放列表的曲目数据。这给了我们总共<strong class="jq hj"> 914首曲目</strong>，其中<strong class="jq hj"> 490首用于训练，122首用于验证，301首用于测试</strong>。超参数优化在alpha=1.0和100个隐藏层的情况下为我们提供了69%的准确性。</p><p id="5c53" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然而，<strong class="jq hj">我们的模型有100个隐藏层，这让我们质疑我们是否在数据集</strong>上过度拟合。通过比较训练和验证的准确性，我们发现事实确实如此。</p><pre class="iy iz ja jb fd lz lb ma mb aw mc bi"><span id="fef0" class="md ld hi lb b fi me mf l mg mh">Train      : 79%<br/>Validation : 69%</span></pre><p id="a7eb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们切换回一个有8个隐藏神经元的模型。</p><pre class="iy iz ja jb fd lz lb ma mb aw mc bi"><span id="a391" class="md ld hi lb b fi me mf l mg mh">Train      : 71%<br/>Validation : 66%</span></pre><p id="d483" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于间隙较小，这是一个更通用的分类器。</p><p id="d8de" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">另一点需要注意的是，尽管我们当前的CV准确度(66%)低于在较小数据集上获得的准确度(67%)，但我们可以预期当前模型具有更好的泛化能力，因为它是在大小几乎两倍的数据集上训练的。我们可以通过比较测试集上的结果来验证这一点:70%使用我们当前的模型，61%使用早期的模型。</p><p id="9399" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">所以我们最终的分类器在测试集上有70%的准确率。</strong></p><p id="7a78" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">误差指标</strong></p><p id="346c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">除了准确性之外，查看其他错误度量(如精确度和召回率)也是有用的，在多类分类的情况下，这些度量可以表示为混淆矩阵。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es na"><img src="../Images/0638ffa381eec0c008b13bc5aef2cd9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YSTV7b6b04iAHTuPrIurjA.png"/></div></div></figure><p id="f1e0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">感兴趣的主要领域是被分类为“黑暗”的能量轨迹，因为这些轨迹有最多的错误分类。<strong class="jq hj">另一方面，最明显的问题是“快乐”被归类为“黑暗”,反之亦然。</strong></p><h1 id="2e5c" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated"><strong class="ak">结论与未来工作</strong></h1><p id="e427" class="pw-post-body-paragraph jo jp hi jq b jr lu ij jt ju lv im jw jx lw jz ka kb lx kd ke kf ly kh ki kj hb bi translated">在本文中，我们经历了一个ML过程的工作流程。我们首先探索我们的数据，并找出哪些属性有助于区分情绪。在建模过程中，我们采用了简单的逻辑回归分类器，然后转向神经网络。执行超参数优化后，我们观察到它有时会导致过度拟合。最后，我们分析了我们的模型，以确定添加更多的数据是否有助于更好地推广。</p><p id="ca08" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有许多可以改进的地方:</p><ol class=""><li id="68f6" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj nb kq kr ks bi translated">改变我们的训练数据集，加入更多“有活力”的歌曲，因为它们是被错误分类最多的。</li><li id="e463" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj nb kq kr ks bi translated">尝试其他模型，如支持向量机和随机森林。</li><li id="942d" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj nb kq kr ks bi translated">执行特征工程以创建更善于辨别情绪的特征。</li></ol><p id="e7b1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我希望这篇文章能帮助你更好地理解多类分类。相关代码可在Github库的<a class="ae jn" href="https://github.com/kvsingh/music-mood-classification" rel="noopener ugc nofollow" target="_blank">处获得。</a></p><h1 id="e315" class="lc ld hi bd le lf lg lh li lj lk ll lm io ln ip lo ir lp is lq iu lr iv ls lt bi translated"><strong class="ak">参考文献:</strong></h1><ul class=""><li id="7f46" class="kk kl hi jq b jr lu ju lv jx nc kb nd kf ne kj kp kq kr ks bi translated"><a class="ae jn" href="https://neokt.github.io/projects/audio-music-mood-classification/" rel="noopener ugc nofollow" target="_blank">https://neokt . github . io/projects/audio-music-mood-class ification/</a></li><li id="e51c" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="https://developer.spotify.com/documentation/" rel="noopener ugc nofollow" target="_blank">https://developer.spotify.com/documentation/</a></li><li id="f814" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw/1097#1097" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-forward-neural-netw/1097 # 1097</a></li><li id="0d4c" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="https://towardsdatascience.com/predicting-the-music-mood-of-a-song-with-deep-learning-c3ac2b45229e" rel="noopener" target="_blank">https://towards data science . com/predicting-the-music-mood of-a song-with-deep-learning-c3ac2b 45229 e</a></li><li id="d4e4" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="http://alexlenail.me/NN-SVG/index.html" rel="noopener ugc nofollow" target="_blank">http://alexlenail.me/NN-SVG/index.html</a></li></ul></div></div>    
</body>
</html>