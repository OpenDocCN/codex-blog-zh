<html>
<head>
<title>Julia and Python — Use Both!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Julia和Python——两者都用！</h1>
<blockquote>原文：<a href="https://medium.com/codex/julia-and-python-use-both-e61a2e7847e0?source=collection_archive---------13-----------------------#2022-06-19">https://medium.com/codex/julia-and-python-use-both-e61a2e7847e0?source=collection_archive---------13-----------------------#2022-06-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4431" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近有很多文章比较Julia和Python。最普遍的分析是Julia是更好的语言，但是Python生态系统要成熟得多。我同意这两种说法，但这是一个错误的选择——两者都用。</p><p id="32a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我想支持我最喜欢的开发环境:用Julia编程并调用Python库。这使您能够访问Python生态系统中的所有精彩价值，同时编写运行速度提高50倍的代码。更快的Julia代码允许一个人在一个良好的类似Python的生产环境中编写CPU密集型代码，而不是开发Cython或C库所需的痛苦和时间。</p><p id="dbc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我目前工作中的一个例子。我正在为语音识别开发新的语言模型和解码器技术。该代码在深度学习模型的输出上运行。我不想开发一个全新的语音识别器，只是最后阶段。然而，解码器必须运行得很快——我的代码正在对来自深度学习模型的逻辑进行大量搜索。因此，我在识别器的第一阶段使用Pytorch和HuggingFace模型，并用Julia编写解码器。</p><p id="0ceb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是我访问PyTorch和Huggingface的Julia代码。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="df67" class="jm jn hi ji b fi jo jp l jq jr">using PyCall</span><span id="49a3" class="jm jn hi ji b fi js jp l jq jr">struct HuggingFace<br/>    torch::PyCall.PyObject<br/>    transformers::PyCall.PyObject<br/>    datasets::PyCall.PyObject<br/>    soundfile::PyCall.PyObject</span><span id="bb33" class="jm jn hi ji b fi js jp l jq jr">    function HuggingFace()<br/>        torch = PyCall.pyimport(“torch”)<br/>        transformers = PyCall.pyimport(“transformers”)<br/>        datasets = PyCall.pyimport(“datasets”)<br/>        soundfile = PyCall.pyimport(“soundfile”)<br/>        new(torch,transformers,datasets,soundfile)<br/>    end<br/>end</span></pre><p id="d2b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意Julia与Python的交互是多么容易。访问PyTorch模块非常简单</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="9753" class="jm jn hi ji b fi jo jp l jq jr">torch = PyCall.pyimport(“torch”)</span></pre><p id="fd5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这段代码中，我将所有Python和HuggingFace信息存储在一个HuggingFace结构中。在代码之外，它实际运行Python和C的事实是完全隐藏的。一切都只是一个正常的Julia值。</p><p id="9ab3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是一个使用HuggingFace结构的方法:</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="1072" class="jm jn hi ji b fi jo jp l jq jr">load_model(hf::HuggingFace,<br/>           model_name=”facebook/wav2vec2-base-960h”)= <br/>    hf.transformers.Wav2Vec2CTCTokenizer.from_pretrained(model_name)</span></pre><p id="7af6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">HuggingFace struct (hf)包含对HuggingFace transformers模块的引用，该模块包含带有from_pretrained方法的wav 2 vec 2 tctokenizer类。返回的PyTorch模型对象从Julia代码的角度来看只是一个Julia值。</p><p id="5001" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里还有一些Julia调用Python写的Pytorch代码的例子</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="0796" class="jm jn hi ji b fi jo jp l jq jr">load_dataset(hf::HuggingFace,dataset_name=”timit_asr”) = hf.datasets.load_dataset(dataset_name)</span><span id="eaa7" class="jm jn hi ji b fi js jp l jq jr">device(hf::HuggingFace) = if hf.torch.cuda.is_available() hf.torch.device(“cuda:0”) else “cpu” end</span></pre><p id="006a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当然，duck typing也适用于Python对象。不需要声明特殊类型</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="8352" class="jm jn hi ji b fi jo jp l jq jr">id_to_phoneme(processor) = processor.tokenizer.decoder</span><span id="dbc2" class="jm jn hi ji b fi js jp l jq jr">phoneme_to_id(processor) = processor.tokenizer.encoder</span></pre><p id="17df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您甚至可以在Julia代码调用Python时使用Python的“with”运算符(@pywith)</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="6d8c" class="jm jn hi ji b fi jo jp l jq jr">text_path = "text"<br/>speech_path = "file"</span><span id="2ecb" class="jm jn hi ji b fi js jp l jq jr">function get_logits(hf::HuggingFace,model,processor,item)<br/>    speech, _ = hf.soundfile.read(item[speech_path])<br/>    input_values = processor(speech, return_tensors="pt",<br/>    sampling_rate=16000).input_values.to(device(hf)) <br/>    @pywith hf.torch.no_grad() begin<br/>      logits=model(input_values["logits"].detach().to("cpu").numpy()[1,:,:]<br/>      return logsoftmax(logits,dims=2)<br/>    end<br/>end</span></pre><p id="501f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，返回值“logits”只是一个普通的Julia数组。PyCall自动将numpy对象转换成标准的Julia对象。这里唯一重要的技巧是“[1，:]”。Python使用基于0的索引，而Julia使用基于1的索引。</p><p id="8ab1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们在Julia中有了logits，我们就可以使用标准的数学库。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="1c35" class="jm jn hi ji b fi jo jp l jq jr">return logsoftmax(logits,dims=2)</span></pre><p id="500f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如许多其他人所写的那样，数字处理是Julia真正闪光的地方。和C一样快，但是一个更有生产力的开发环境，有REPL、调试器、垃圾收集器和强大的多重调度。不需要像numpy这样的库来加快速度，也不需要对代码进行矢量化。易于阅读的算法代码运行速度一样快。Julia还对剖析、查找和修复瓶颈提供了强大的支持</p><p id="915b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个对一组对数概率求和的示例函数。它使用log-sum-exp技巧来避免溢出(https://gregorygundersen . com/blog/2020/02/09/log-sum-exp/)。请注意我如何在第2行定义一个局部单行函数e()，然后通过序列(xs)传播它(e .)。- m)，其中'- m '通过xs广播。这避免了for循环，并允许后端使用fusion进行潜在优化(https://Julia lang . org/blog/2017/01/moredots/)。是的，我可以写一个更紧凑的版本，但它不会运行得更快。可以在这段代码的任何一行设置断点，不涉及C库。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="d406" class="jm jn hi ji b fi jo jp l jq jr">function logsumexp(xs)<br/>    e(x) = if x==-Inf 0.0 else exp(x) end<br/>    m=maximum(xs)<br/>    if m==-Inf<br/>        return -Inf<br/>    else<br/>        return m + log(sum(e.(xs .- m)))<br/>    end<br/>end</span></pre><p id="0d32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">没有完美的环境，但我不得不说…这个组合真的很好！所以下次你想写一些快速代码，但是要用你喜欢的所有Python库，请考虑Julia调用Python。</p><p id="6330" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢你</p><p id="c140" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">彼得（男子名）</p></div></div>    
</body>
</html>