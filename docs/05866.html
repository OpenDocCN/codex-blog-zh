<html>
<head>
<title>Fast Task Type Expanding On Apache DolphinScheduler | Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Apache DolphinScheduler的快速任务类型扩展|教程</h1>
<blockquote>原文：<a href="https://medium.com/codex/fast-task-types-expanding-on-apache-dolphinscheduler-tutorial-9dd440c76cbe?source=collection_archive---------26-----------------------#2022-03-31">https://medium.com/codex/fast-task-types-expanding-on-apache-dolphinscheduler-tutorial-9dd440c76cbe?source=collection_archive---------26-----------------------#2022-03-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/bb1b21e2c3377a7c8273f17a9210ccf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hqD3Yw0qj1LWeZti7XZCNQ.png"/></div></div></figure><h1 id="c830" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">背景</h1><p id="2954" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">目前，调度器在大数据生态中起着不可或缺的作用。Apache DolphinScheduler是Apache的一个顶级项目，是最稳定、最易于使用的调度系统之一。有了调度、分发、高可用性和易用性，随着业务的增长或更多组件用于各种需求，用户自然会希望快速、轻松、简洁地扩展Apache Dolphinscheduler任务类型。本文向您展示了如何轻松快速地扩展Apache DolphinScheduler任务。</p><h1 id="ea1d" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">作者简介</h1><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es km"><img src="../Images/da36e62feb248cccacef0229cae36058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*uquXN3DyMPBoLjQsqrzvhA.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">张百强</figcaption></figure><p id="33a9" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">张百强是一名大数据开发工程师，他对研究实时计算、元数据治理和大数据基础组件感兴趣。</p><h1 id="c05e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">1什么是SPI？</h1><p id="ecf1" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">SPI(服务提供者接口)是内置于JDK中的服务交付发现机制。大多数人可能很少使用它，因为它主要面向开发供应商，在java.util.ServiceLoader文件中有更详细的描述。SPI的抽象概念是指服务实现的动态加载。</p><h1 id="80ae" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2我们为什么要引入SPI？</h1><p id="40cd" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">不同的企业可能有其需要由任务执行的组件，例如，企业使用大数据生态系统中最常用的工具Hive的方式不同。有的企业通过HiveServer2执行任务，有的使用HiveClient执行任务。考虑到Apache DolphinScheduler提供的开箱即用任务不支持HiveClient的任务，所以大部分用户会通过Shell执行。然而，与TaskTemplate相比，Shell并不能很好地工作。所以，Apache DolphinScheduler支持TaskSPI，使用户能够根据自己的业务需求更好地定制不同的任务。</p><p id="b5b3" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">首先，我们需要了解Apache DolphinScheduler的任务迭代历史。在DS 1.3.x中，扩展一个任务需要重新编译整个Apache DolphinScheduler，这是高度耦合的，所以在Apache DolphinScheduler 2.0.x中，我们引入了SPI。我们前面提到过，SPI的本质是动态加载一个服务的实现，所以我们再具体一点，把Apache DolphinScheduler的任务看作一个执行服务，我们需要根据用户的选择执行不同的服务。如果没有服务，就需要我们自己去拓展。相比1.3.x我们只需要完成我们的任务实现逻辑，然后遵循SPI规则，编译成Jar上传到指定目录，使用我们自己编写的任务。</p><h1 id="3825" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">3谁在用？</h1><p id="af95" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">a. Apache DolphinScheduler </p><p id="20ac" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">一.任务</p><p id="1328" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">二。数据源</p><p id="ede9" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj"> b .阿帕奇·弗林克</strong></p><p id="5bc3" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">i. flink sql连接器，在用户实现了一个Flink连接器之后，Flink也是通过SPI动态加载的</p><p id="11bf" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj"> c .弹簧靴</strong></p><p id="b909" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">一、弹簧靴spi</p><p id="389c" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj"> d. Jdbc </strong></p><p id="9cc9" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">一、在jdbc4.0之前，开发者需要通过forName("xxx ")加载基于类的驱动，jdbc4也是基于spi机制来发现驱动提供者，可以通过在META-INF/services/java中指定实现类来公开驱动提供者。sql。驱动程序文件</p><p id="affc" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj"> e .更</strong></p><ul class=""><li id="e981" class="la lb hi jq b jr kv jv kw jz lc kd ld kh le kl lf lg lh li bi translated"><strong class="jq hj">杜博</strong></li><li id="6fd4" class="la lb hi jq b jr lj jv lk jz ll kd lm kh ln kl lf lg lh li bi translated"><strong class="jq hj">普通伐木</strong></li><li id="0f66" class="la lb hi jq b jr lj jv lk jz ll kd lm kh ln kl lf lg lh li bi translated"><strong class="jq hj"> …… </strong></li></ul><h1 id="5bba" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">4什么是Apache DolphinScheduler SPI进程？</h1><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/34fd6828b57ad1566c1382f9f7e3a4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*w58DIvuTGaKzkjdFJZ4E9w.png"/></div></figure><p id="ae73" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><em class="lp">注:SPI规则</em></p><p id="af3e" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><em class="lp">在将服务的具体实现编译成JAR时，我们需要在资源的dir下创建META-INF/services/ folder，然后用服务的文件名创建一个全限定类名，这就是集成接口的全限定类名。里面的内容是实现类的完全限定类名。</em></p><p id="85a2" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">为了说明上图，我把Apache DolphinScheduler分成了逻辑任务和物理任务，逻辑任务指的是DependTask、SwitchTask，物理任务指的是ShellTask、SQLTask，都是执行任务的任务。在Apache DolphinScheduler中，我们一般会扩展物理任务，交给worker来执行，所以我们需要明白的是，当我们有不止一个worker时，我们要将自定义任务分发到每台有Worker的机器上，当我们启动Worker服务时，Worker会启动一个ClassLoader来加载实现规则的相应任务库。注意，HiveClient和SeatunnelTasks是用户定义的，但是只有HiveTasks是由Apache dolphin scheduler TaskPluginManage加载的。原因是SeatunnelTask不遵循SPI规则。SPI规则在图上也有描述，或者可以参考java.util.ServiceLoader类，下面有一个简单的参考(摘录了部分代码):</p><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="199a" class="lv ir hi lr b fi lw lx l ly lz">public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; {<br/>    //scanning dir prefix<br/>    private static final String PREFIX = "META-INF/services/";<br/></span><span id="7f54" class="lv ir hi lr b fi ma lx l ly lz">    //The class or interface representing the service being loaded<br/>    private final Class&lt;S&gt; service;<br/></span><span id="2f25" class="lv ir hi lr b fi ma lx l ly lz">    //The class loader used to locate, load, and instantiate providers<br/>    private final ClassLoader loader;<br/></span><span id="9e03" class="lv ir hi lr b fi ma lx l ly lz">    //Private inner class implementing fully-lazy provider lookup<br/>    private class LazyIterator implements Iterator&lt;S&gt; {<br/>        Class&lt;S&gt; service;<br/>        ClassLoader loader;<br/>        Enumeration&lt;URL&gt; configs = null;<br/>        String nextName = null;<br/></span><span id="73c5" class="lv ir hi lr b fi ma lx l ly lz">        //......<br/>        private boolean hasNextService() {<br/>            if (configs == null) {<br/>                try {<br/>                    //get dir all class<br/>                    String fullName = PREFIX + service.getName();<br/>                    if (loader == null)<br/>                        configs = ClassLoader.getSystemResources(fullName);<br/>                    else<br/>                        configs = loader.getResources(fullName);<br/>                } catch (IOException x) {<br/>                    //......<br/>                }<br/>                //......<br/>            }<br/>        }<br/>    }<br/>}</span></pre><h1 id="ffd6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">5如何扩展数据源任务或数据源？</h1><h2 id="ea20" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.1创建Maven项目</h2><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="bb82" class="lv ir hi lr b fi lw lx l ly lz">mvn archetype:generate \<br/>    -DarchetypeGroupId=org.apache.dolphinscheduler \<br/>    -DarchetypeArtifactId=dolphinscheduler-hive-client-task \<br/>    -DarchetypeVersion=1.10.0 \<br/>    -DgroupId=org.apache.dolphinscheduler \<br/>    -DartifactId=dolphinscheduler-hive-client-task \<br/>    -Dversion=0.1 \<br/>    -Dpackage=org.apache.dolphinscheduler \<br/>    -DinteractiveMode=false</span></pre><h2 id="dae8" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.2 Maven依赖性</h2><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="e17c" class="lv ir hi lr b fi lw lx l ly lz">&lt;! --dolphinscheduler spi basic core denpendence --&gt;<br/> &lt;dependency&gt;<br/>     &lt;groupId&gt;org.apache.dolphinscheduler&lt;/groupId&gt;<br/>     &lt;artifactId&gt;dolphinscheduler-spi&lt;/artifactId&gt;<br/>     &lt;version&gt;${dolphinscheduler.lib.version}&lt;/version<br/>     &lt;scope&gt;${common.lib.scope}&lt;/scope&gt;<br/> &lt;/dependency<br/> &lt;dependency&gt;<br/>     &lt;groupId&gt;org.apache.dolphinscheduler&lt;/groupId&gt;<br/>     &lt;artifactId&gt;dolphinscheduler-task-api&lt;/artifactId&gt;<br/>     &lt;version&gt;${dolphinscheduler.lib.version}&lt;/version<br/>     &lt;scope&gt;${common.lib.scope}&lt;/scope&gt;<br/> &lt;/dependency</span></pre><h2 id="9741" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.3创建TaskChannelFactory</h2><p id="c4ce" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">首先，我们需要为任务服务创建工厂，其主要目标是帮助构建TaskChannel和TaskPlugin参数，并给出任务的唯一标识。ChannelFactory连接Apache DolphinScheduler的任务服务组，帮助前后端交互构建TaskChannel。</p><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="1960" class="lv ir hi lr b fi lw lx l ly lz">package org.apache.dolphinscheduler.plugin.task.hive;<br/></span><span id="8617" class="lv ir hi lr b fi ma lx l ly lz">import org.apache.dolphinscheduler.spi.params.base.PluginParams;<br/>import org.apache.dolphinscheduler.spi.task.TaskChannel;<br/>import org.apache.dolphinscheduler.spi.task.TaskChannelFactory;<br/></span><span id="aed3" class="lv ir hi lr b fi ma lx l ly lz">import java.util.List;<br/></span><span id="9979" class="lv ir hi lr b fi ma lx l ly lz">public class HiveClientTaskChannelFactory implements TaskChannelFactory {<br/>    /**<br/>     * Create a task channel and execute tasks based on it<br/>     * @return Task Channel<br/>     */<br/>    @Override<br/>    public TaskChannel create() {<br/>        return new HiveClientTaskChannel();<br/>    }<br/></span><span id="fe87" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * Returns the globally unique identifier of the current task<br/>     * @return Task type name<br/>     */<br/>    @Override<br/>    public String getName() {<br/>        return "HIVE CLIENT";<br/>    }<br/></span><span id="bcb4" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * The front-end pages need to be rendered, mainly into<br/>     <br/>     * @return<br/>     */<br/>    @Override<br/>    public List&lt;PluginParams&gt; getParams() {<br/>        List&lt;PluginParams&gt; pluginParams = new ArrayList&lt;&gt;();<br/>        InputParam nodeName = InputParam.newBuilder("name", "$t('Node name')")<br/>                .addValidate(Validate.newBuilder()<br/>                        .setRequired(true)<br/>                        .build())<br/>                .build();<br/>        PluginParams runFlag = RadioParam.newBuilder("runFlag", "RUN_FLAG")<br/>                .addParamsOptions(new ParamsOptions("NORMAL", "NORMAL", false))<br/>                .addParamsOptions(new ParamsOptions("FORBIDDEN", "FORBIDDEN", false))<br/>                .build();<br/></span><span id="acd4" class="lv ir hi lr b fi ma lx l ly lz">        PluginParams build = CheckboxParam.newBuilder("Hive SQL", "Test HiveSQL")<br/>                .setDisplay(true)<br/>                .setValue("-- author: \n --desc:")<br/>                .build();<br/></span><span id="592b" class="lv ir hi lr b fi ma lx l ly lz">        pluginParams.add(nodeName);<br/>        pluginParams.add(runFlag);<br/>        pluginParams.add(build);<br/></span><span id="d04f" class="lv ir hi lr b fi ma lx l ly lz">        return pluginParams;<br/>    }<br/>}</span></pre><h2 id="7a75" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.4创建任务通道</h2><p id="8bb9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在我们有了工厂之后，我们将基于它创建一个TaskChannel。TaskChannel包含取消和创建两种方法，目前我们只需要关注创建任务。</p><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="0e10" class="lv ir hi lr b fi lw lx l ly lz">void cancelApplication(boolean status);<br/></span><span id="4c39" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * Build executable tasks<br/>     */<br/>    AbstractTask createTask(TaskRequest taskRequest);</span><span id="bca9" class="lv ir hi lr b fi ma lx l ly lz">public class HiveClientTaskChannel implements TaskChannel {<br/>    @Override<br/>    public void cancelApplication(boolean b) {<br/>        //do nothing<br/>    }<br/></span><span id="6545" class="lv ir hi lr b fi ma lx l ly lz">    @Override<br/>    public AbstractTask createTask(TaskRequest taskRequest) {<br/>        return new HiveClientTask(taskRequest);<br/>    }<br/>}</span></pre><h2 id="9d39" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.5构建任务实现</h2><p id="ee31" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">通过TaskChannel，我们获得了可以执行的物理任务，但是我们需要向当前任务添加相应的实现，以允许Apache DolphinScheduler执行您的任务。</p><p id="9313" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">从上图我们可以看到，基于Yarn执行的任务会继承AbstractYarnTask，不需要Yarn执行的任务会直接继承AbstractTaskExecutor，主要包含一个AppID，以及CanalApplication setMainJar。从上面可以看到，我们的HiveClient需要继承AbstractYarnTask，在构建任务之前，我们需要构建适合HiveClient的parameters对象来反序列化JsonParam。</p><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="5d9e" class="lv ir hi lr b fi lw lx l ly lz">package org.apache.dolphinscheduler.plugin.task.hive;<br/></span><span id="a3fb" class="lv ir hi lr b fi ma lx l ly lz">import org.apache.dolphinscheduler.spi.task.AbstractParameters;<br/>import org.apache.dolphinscheduler.spi.task.ResourceInfo;<br/></span><span id="4820" class="lv ir hi lr b fi ma lx l ly lz">import java.util.List;<br/></span><span id="40e3" class="lv ir hi lr b fi ma lx l ly lz">public class HiveClientParameters extends AbstractParameters {<br/>    /**<br/>     * The easiest way to execute with HiveClient is to just paste in all the SQL, so we only need one SQL parameter<br/>     */<br/>    private String sql;<br/></span><span id="c97a" class="lv ir hi lr b fi ma lx l ly lz">    public String getSql() {<br/>        return sql;<br/>    }<br/></span><span id="9d43" class="lv ir hi lr b fi ma lx l ly lz">    public void setSql(String sql) {<br/>        this.sql = sql;<br/>    }<br/></span><span id="9d22" class="lv ir hi lr b fi ma lx l ly lz">    @Override<br/>    public boolean checkParameters() {<br/>        return sql ! = null;<br/>    }<br/></span><span id="2ad1" class="lv ir hi lr b fi ma lx l ly lz">    @Override<br/>    public List&lt;ResourceInfo&gt; getResourceFilesList() {<br/>        return null;<br/>    }<br/>}</span></pre><p id="78d3" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">实现参数对象后，让我们实现任务。示例中的实现相对简单，就是将用户的参数写入一个文件，通过Hive -f执行任务。</p><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="de17" class="lv ir hi lr b fi lw lx l ly lz">package org.apache.dolphinscheduler.plugin.task.hive;<br/></span><span id="775c" class="lv ir hi lr b fi ma lx l ly lz">import org.apache.dolphinscheduler.plugin.task.api.AbstractYarnTask;<br/>import org.apache.dolphinscheduler.spi.task.AbstractParameters;<br/>import org.apache.dolphinscheduler.spi.task.request.TaskRequest;<br/>import org.apache.dolphinscheduler.spi.utils.JSONUtils;<br/></span><span id="3303" class="lv ir hi lr b fi ma lx l ly lz">import java.io;<br/>import java.io.IOException;<br/>import java.nio.charset.StandardCharsets;<br/>import java.nio.file;<br/>import java.nio.file.Path;<br/>import java.nio.file.Paths;<br/></span><span id="2fb0" class="lv ir hi lr b fi ma lx l ly lz">public class HiveClientTask extends AbstractYarnTask {<br/></span><span id="7da5" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * hive client parameters<br/>     */<br/>    private HiveClientParameters hiveClientParameters;<br/></span><span id="9507" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * taskExecutionContext<br/>     */<br/>    private final TaskRequest taskExecutionContext;<br/></span><span id="ce64" class="lv ir hi lr b fi ma lx l ly lz">    public HiveClientTask(TaskRequest taskRequest) {<br/>        super(taskRequest);<br/>        this.taskExecutionContext = taskRequest;<br/>    }<br/></span><span id="d279" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * task init method<br/>     */<br/>    @Override<br/>    public void init() {<br/>        logger.info("hive client task param is {}", JSONUtils.toJsonString(taskExecutionContext));<br/>        this.hiveClientParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), HiveClientParameters.class);<br/></span><span id="bcf1" class="lv ir hi lr b fi ma lx l ly lz">        if (this.hiveClientParameters ! = null &amp;&amp; !hiveClientParameters.checkParameters()) {<br/>            throw new RuntimeException("hive client task params is not valid");<br/>        }<br/>    }<br/></span><span id="27fe" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * build task execution command<br/>     *<br/>     * @return task execution command or null<br/>     */<br/>    @Override<br/>    protected String buildCommand() {<br/>        String filePath = getFilePath();<br/>        if (writeExecutionContentToFile(filePath)) {<br/>            return "hive -f " + filePath;<br/>        }<br/>        return null;<br/>    }<br/></span><span id="0454" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * get hive sql write path<br/>     *<br/>     * @return file write path<br/>     */<br/>    private String getFilePath() {<br/>        return String.format("%s/hive-%s-%s.sql", this.taskExecutionContext.getExecutePath(), this.taskExecutionContext.getTaskName(), this. taskExecutionContext.getTaskInstanceId());<br/>    }<br/></span><span id="f02e" class="lv ir hi lr b fi ma lx l ly lz">    @Override<br/>    protected void setMainJarName() {<br/>        //do nothing<br/>    }<br/></span><span id="1562" class="lv ir hi lr b fi ma lx l ly lz">    /**<br/>     * write hive sql to filepath<br/>     *<br/>     * @param filePath file path<br/>     * @return write success?<br/>     */<br/>    private boolean writeExecutionContentToFile(String filePath) {<br/>        Path path = Paths.get(filePath);<br/>        try (BufferedWriter writer = Files.newBufferedWriter(path, StandardCharsets.UTF_8)) {<br/>            writer.write(this.hiveClientParameters.getSql());<br/>            logger.info("file:" + filePath + "write success.");<br/>            return true;<br/>        } catch (IOException e) {<br/>            logger.error("file:" + filePath + "write failed. please path auth.");<br/>            e.printStackTrace();<br/>            return false;<br/>        }<br/></span><span id="ae37" class="lv ir hi lr b fi ma lx l ly lz">    }<br/></span><span id="59ba" class="lv ir hi lr b fi ma lx l ly lz">    @Override<br/>    public AbstractParameters getParameters() {<br/>        return this.hiveClientParameters;<br/>    }<br/>}</span></pre><h2 id="1bb1" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.6符合SPI规则</h2><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="96ac" class="lv ir hi lr b fi lw lx l ly lz"># 1,Create META-INF/services folder under Resource, create the file with the same full class name of the interface<br/>zhang@xiaozhang resources % tree . /<br/>. /<br/>└── META-INF<br/>    └── services<br/>        └─ org.apache.dolphinscheduler.spi.task.TaskChannelFactory<br/># 2, write the fully qualified class name of the implemented class in the file<br/>zhang@xiaozhang resources % more META-INF/services/org.apache.dolphinscheduler.spi.task.TaskChannelFactory <br/>org.apache.dolphinscheduler.plugin.task.hive.HiveClientTaskChannelFactory</span></pre><h2 id="91e8" class="lv ir hi bd is mb mc md iw me mf mg ja jz mh mi je kd mj mk ji kh ml mm jm mn bi translated">5.7打包和部署</h2><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="d3eb" class="lv ir hi lr b fi lw lx l ly lz">## 1,Packing<br/>mvn clean install<br/>## 2, Deployment<br/>cp . /target/dolphinscheduler-task-hiveclient-1.0.jar $DOLPHINSCHEDULER_HOME/lib/<br/>## 3,restart dolphinscheduler server</span></pre><p id="d317" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">完成上述操作后，我们检查工作日志tail-200 f $ Apache dolphin scheduler _ HOME/log/Apache dolphin scheduler-worker . log。</p><p id="666a" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">就这些啦~以上涉及的前端修改可以在Apache dolphin scheduler-ui/src/js/conf/home/pages/Dag/_ source/form model/</p><h1 id="ccae" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">加入社区</h1><p id="86c0" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">参与DolphinScheduler社区并为其做出贡献的方式有很多，包括:</p><p id="86e7" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">文档、翻译、问答、测试、代码、文章、主题演讲等。</p><p id="79c5" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">我们假设第一个PR(文档、代码)是简单的，应该用来熟悉提交过程和社区协作风格。</p><p id="f38b" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">所以社区整理了以下适合新手的问题列表:【https://github.com/apache/dolphinscheduler/issues/5689T2】</p><p id="e12e" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">非新手问题列表:【https://github.com/apache/dolphinscheduler/issues? T4】q = is % 3A open+is % 3A issue+label % 3A % 22 volunteer+wanted % 22</p><p id="a2e3" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">如何参与投稿:<a class="ae mo" href="https://dolphinscheduler.apache.org/en-us/community/development/contribute.html" rel="noopener ugc nofollow" target="_blank">https://dolphin scheduler . Apache . org/en-us/community/development/contribute . html</a></p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="9374" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj"> GitHub代码库:</strong><a class="ae mo" href="https://github.com/apache/dolphinscheduler" rel="noopener ugc nofollow" target="_blank">https://github.com/apache/dolphinscheduler</a></p><p id="6303" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj">官网</strong>:https://dolphin scheduler . Apache . org/</p><p id="5b22" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">:dev@dolphinscheduler@apache.org邮件列表</p><p id="f853" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj">推特</strong>:@海豚时间表</p><p id="c2bc" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">https://www.youtube.com/channel/UCmrPmeE7dVqo8DYhSLHa0vA</p><p id="e551" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj">懈怠:【https://s.apache.org/dolphinscheduler-slack】T21</strong></p><p id="2f34" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated"><strong class="jq hj">投稿指南:</strong>https://dolphin scheduler . Apache . org/en-us/community/index . html</p><p id="ea2a" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">你的项目之星很重要，不要犹豫，点亮阿帕奇海豚调度❤️之星</p></div></div>    
</body>
</html>