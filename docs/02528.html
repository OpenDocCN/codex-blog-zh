<html>
<head>
<title>Basic Text Processing techniques for NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理的基本文本处理技术</h1>
<blockquote>原文：<a href="https://medium.com/codex/basic-text-processing-techniques-for-nlp-3b9e0f84b024?source=collection_archive---------12-----------------------#2021-07-24">https://medium.com/codex/basic-text-processing-techniques-for-nlp-3b9e0f84b024?source=collection_archive---------12-----------------------#2021-07-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div class="er es hg"><img src="../Images/9e62dbb5c091c2e33f4c1231ddd6dcb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*UKkB2KEX5_IWXkB4sv7m7A.jpeg"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">图片来自<a class="ae hr" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1867195" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae hr" href="https://pixabay.com/users/pexels-2286921/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1867195" rel="noopener ugc nofollow" target="_blank">像素</a></figcaption></figure><div class=""/><p id="fbe8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><em class="jp">这是一篇关于基本文本处理技术的短文:一键编码、单词袋、N-Gram和TF-IDF。</em></p><p id="da7f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在NLP中，一旦收集了原始数据，就必须将其转换成ML算法可以理解的数字形式。这被称为<strong class="it hv">文本表示</strong>，是执行特征提取之前的重要步骤。</p><p id="5f4a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">有很多技术可以应用在文本上，并以矢量的形式表现出来。在本帖中，我们将通过示例代码尝试理解几个基本问题。</p></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><h1 id="ae7e" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">样本数据集</h1><p id="3d80" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">我们将在一个玩具数据集上工作，它有如下三个文档。文档的集合被称为<strong class="it hv">文集</strong>。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6f4d" class="lj jy hu lf b fi lk ll l lm ln">Document 1:<br/>"It is raining today."</span><span id="4877" class="lj jy hu lf b fi lo ll l lm ln">Document 2:<br/>"I like when it rains."</span><span id="6cf5" class="lj jy hu lf b fi lo ll l lm ln">Document 3:<br/>"It seldom rains here."</span></pre><p id="5721" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">忽略文档的小写，如果我们从所有这些文档中提取唯一的单词，我们将得到下面的数组。来自语料库的独特单词的集合被称为<strong class="it hv">词汇</strong>。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6f28" class="lj jy hu lf b fi lk ll l lm ln">['it', 'is', 'raining',' today', 'i', 'like', 'when',  'rains', 'seldom', 'here']</span></pre><p id="5a63" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">让我们为每个单词提供一个唯一的id，如下所示:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="2fb2" class="lj jy hu lf b fi lk ll l lm ln">it      = 1<br/>is      = 2<br/>raining = 3<br/>today   = 4<br/>i       = 5<br/>like    = 6<br/>when    = 7<br/>rains   = 8<br/>seldom  = 9 <br/>here    = 10</span></pre><h1 id="446c" class="jx jy hu bd jz ka lp kc kd ke lq kg kh ki lr kk kl km ls ko kp kq lt ks kt ku bi translated">一键编码</h1><p id="bf0f" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">这是最简单的技术。在一键编码中，一个单词将被表示为一个向量，其大小等于词汇表的大小。该向量的元素或项目将由0组成，除了在词汇表中该单词的索引处将被设置为1。</p><p id="26c1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">例如，对于我们由10个单词组成的样本数据集，单词<strong class="it hv"> 'it' </strong>将被表示为[ <strong class="it hv"> 1 </strong>，0，0，0，0，0，0，0，0，0，0，0]，<strong class="it hv">将被表示为[0，<strong class="it hv"> 1 </strong>，0，0，0，0，0，0，0，0，<strong class="it hv"> 'rains' </strong>将被表示为[0，0，0，0，0，0，0，0</strong></p><p id="88db" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果我们在文档1中替换这些值，我们现在可以将文档1表示为:</p><p id="cf9a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi">[ [1,0,0,0,0,0,0,0,0,0] , [0,1,0,0,0,0,0,0,0,0] , [0,0,1,0,0,0,0,0,0,0] , [0,0,0,1,0,0,0,0,0,0] ]</p><p id="8dea" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">用于一键编码的简单python脚本可能如下所示。当然这不是优化，只是为了学习。</p><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es lu"><img src="../Images/9743665878bd2851bd4757d110de655d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vYwQyx9v1o2ZFu1CtUj8xQ.png"/></div></div></figure><h1 id="47c6" class="jx jy hu bd jz ka lp kc kd ke lq kg kh ki lr kk kl km ls ko kp kq lt ks kt ku bi translated">单词袋(蝴蝶结)</h1><p id="7313" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">这种技术主要用于文本分类问题。Bag只不过是一个类，属于这个类的文本包含数据集中唯一的一组单词。如果两个文本包含相似的单词，则认为这两个文本属于同一类别(包)。</p><p id="abba" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">词汇表中的每个单词都根据它在文本中出现的次数来评分。例如，文档d1将是[1，1，1，1，0，0，0，0，0]，因为‘it’，‘is’，‘raining’，‘today’在句子中仅出现一次，而词汇中的其他单词不存在，因此得分为0。你会注意到，与一键编码相比，这种方法减少了向量的维数。</p><p id="b9b0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">下面的例子基于来自<strong class="it hv"> sklearn </strong>的<strong class="it hv">计数矢量器</strong>类。</p><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es lz"><img src="../Images/77b2039e7491b5b511384c4cec581931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P9x_roWsaKcB_0CP_8wGWA.png"/></div></div></figure><p id="8801" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这里使用的文档与我们的原始文档略有不同，并且条目的索引也有所更改。如果您仔细观察文档3，单词“rain”重复了两次，因此向量在索引5处包含计数2(单词“rain”的索引由CountVectorizer设置为5)，而“go”(索引=1)和“away”(索引=0)出现了一次，因此这两个单词的索引处的值都设置为1。</p><p id="652a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">文档3的BoW实现如下所示，并提供相同的输出。</p><figure class="la lb lc ld fd hk er es paragraph-image"><div class="er es ma"><img src="../Images/a89f598823d08de666f609ca9cc55752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*J5FvE7A16-BZ5rbTQRmW2Q.png"/></div></figure><h1 id="76a9" class="jx jy hu bd jz ka lp kc kd ke lq kg kh ki lr kk kl km ls ko kp kq lt ks kt ku bi translated">一袋N克(BoN)</h1><p id="826e" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">在这种方法中，我们不是将文本分解成多个单词，而是将文本分解成由<strong class="it hv"> <em class="jp"> n </em> </strong>单词组成的组块(克)，因此得名<strong class="it hv"> n-gram </strong>。例如，如果我们在数据集上应用2-gram，那么我们的词汇将是10个组块，每个组块由2个单词组成。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6fb2" class="lj jy hu lf b fi lk ll l lm ln">['it is' , 'is raining' , 'raining today' , 'i like' , 'like when'  , 'when it' , 'it rains' , 'it seldom' , 'seldom rains' , 'rains here']</span></pre><p id="8953" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这种方法保留了前两种方法中没有的一些文本上下文。此外，我们可以说BoW是n-gram的一个特例，其中<strong class="it hv"> <em class="jp"> n </em> </strong>的值等于<strong class="it hv"> 1。</strong></p><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es mb"><img src="../Images/164f467ad378f8952e4d804311dd4e91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XkYXtKb_EYgSi21mEDtFTg.png"/></div></div></figure><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="b328" class="lj jy hu lf b fi lk ll l lm ln"><em class="jp">Output:</em><br/>Vocabulary:  {'it is': 2, 'is raining': 1, 'raining today': 6, 'it seldom': 3, 'seldom rains': 8, 'rains here': 7, 'rain rain': 5, 'rain go': 4, 'go away': 0} <br/>Document 1: [[0 1 1 0 0 0 1 0 0]]</span></pre><h1 id="a6f9" class="jx jy hu bd jz ka lp kc kd ke lq kg kh ki lr kk kl km ls ko kp kq lt ks kt ku bi translated">术语频率-逆文档频率(TF-IDF)</h1><p id="efac" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">这种技术通常用于信息检索系统。以前的方法给予所有单词同等的重要性。根据这种方法，如果一个单词<strong class="it hv"> <em class="jp"> w </em> </strong>在文档<strong class="it hv"> <em class="jp"> d </em> </strong>中出现的次数较多，但是在语料库的其他文档中出现的次数较少，那么可以假设单词<strong class="it hv"><em class="jp"/></strong>对文档<strong class="it hv"><em class="jp"/></strong>更重要。为了确定这一点，我们必须计算2个因素:</p><h2 id="4cc3" class="lj jy hu bd jz mc md me kd mf mg mh kh jc mi mj kl jg mk ml kp jk mm mn kt mo bi translated">术语频率</h2><p id="ec91" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">它测量一个单词在文档中的出现频率，计算方法如下:</p><figure class="la lb lc ld fd hk er es paragraph-image"><div class="er es mp"><img src="../Images/145ac980391a6c9f262482754a6fb1f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*PUiu8BFdkhJ1juN0WVaY5w.png"/></div></figure><h2 id="9ab0" class="lj jy hu bd jz mc md me kd mf mg mh kh jc mi mj kl jg mk ml kp jk mm mn kt mo bi translated">反向文档频率</h2><p id="4f28" class="pw-post-body-paragraph ir is hu it b iu kv iw ix iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo hb bi translated">TF赋予文档中所有单词同等的重要性，而IDF用于确定单词在整个语料库中的重要性。文档可能包含停用词或类似“it”、“is”、“of”等经常出现但不太重要的词。IDF降低了文档中常用术语的重要性，提高了罕见术语的重要性。其计算如下:</p><figure class="la lb lc ld fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/a23f8ae7a6daf93ae9fe3d22bbc57f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*7M5u4-hEU-8OsO85AgLzdA.png"/></div></figure><p id="9afb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">最后用TF乘以IDF就可以得到一个词的TF-IDF值。</p><figure class="la lb lc ld fd hk er es paragraph-image"><div class="er es mr"><img src="../Images/ec24334f8a30136cb27dc6cf7ad94a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*Hqlk4xm9e-8G0PlNoirweA.png"/></div></figure><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es ms"><img src="../Images/2f692e84e852ac3b0766539334d65a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4i5pqFqITaM8LRNLdNucIg.png"/></div></div></figure></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><h1 id="5a55" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">比较</h1><figure class="la lb lc ld fd hk er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es mt"><img src="../Images/e272bb5f2f7c7efc18deea69d8acb1e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BYLZ0G0wpj-YO3_JObE0VA.png"/></div></div></figure></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><p id="292f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我希望这篇文章对你有所帮助，感谢你花时间阅读它！</p><h1 id="1b01" class="jx jy hu bd jz ka lp kc kd ke lq kg kh ki lr kk kl km ls ko kp kq lt ks kt ku bi translated">参考</h1><ol class=""><li id="fae5" class="mu mv hu it b iu kv iy kw jc mw jg mx jk my jo mz na nb nc bi translated">实用自然语言处理:<em class="jp">第三章</em></li></ol></div></div>    
</body>
</html>