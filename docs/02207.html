<html>
<head>
<title>Utilizing BigQuery as a Data Warehouse in a distributed application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在分布式应用程序中使用BigQuery作为数据仓库</h1>
<blockquote>原文：<a href="https://medium.com/codex/utilizing-bigquery-as-a-data-warehouse-in-a-distributed-application-d60af9133453?source=collection_archive---------8-----------------------#2021-07-07">https://medium.com/codex/utilizing-bigquery-as-a-data-warehouse-in-a-distributed-application-d60af9133453?source=collection_archive---------8-----------------------#2021-07-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/34011c3b045260ddfee5a6019921fcc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Z3xpFGwyrK6R5Oe4.png"/></div></div></figure><h1 id="c6c7" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="e34d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">数据在任何组织中都扮演着不可或缺的角色。由于现代组织的数据驱动性质，几乎所有业务及其技术决策都基于可用数据。假设我们有一个应用程序分布在云服务提供商不同区域的多个服务器上，我们需要将该应用程序数据存储在一个集中的位置。理想的解决方案是使用某种类型的数据库。然而，传统数据库不适合处理超大型数据集，并且缺乏有助于数据分析的功能。在这种情况下，我们需要一个合适的数据仓库解决方案，比如Google BigQuery。</p><h1 id="e346" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是Google BigQuery？</h1><p id="3506" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">BigQuery是一个企业级的、完全托管的数据仓库解决方案，是Google云平台的一部分。它旨在存储和查询海量数据集，同时使用户能够通过基于标准SQL方言的BigQuery数据操作语言(DML)来管理数据。</p><p id="618e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">BigQuery还提供了一套强大的工具来管理数据集，从其云控制台到BigQuery REST API，支持多种编程语言，如Java、Python、.网等。…此外，BigQuery为机器学习和人工智能集成提供了内置支持，并与BigQueryML、人工智能平台和TensorFlow集成。凭借其强大的BI引擎，BigQuery可用于支持任何类型的现代商业智能平台。</p><h2 id="abf9" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">BigQuery的替代方案</h2><p id="a993" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hj"> Amazon Redshift — </strong>完全托管的云数据仓库解决方案，用于收集和存储AWS提供的数据。</p><p id="442a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> Azure Synapse Analytics — </strong>微软Azure提供的企业数据仓库和数据分析解决方案</p><h1 id="7a09" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">利用BigQuery作为数据仓库</h1><p id="be96" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为数据仓库解决方案从多个服务器收集数据的最佳方式是定期将数据从应用程序同步(推送)到数据仓库。</p><p id="9903" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们看看下面的图表。有三个应用服务器分布在多个地区，一个脚本被配置为定期将数据从每个服务器推送到BigQuery。在本文中，我们将主要关注开发人员如何与BigQuery存储和查询数据进行交互。</p><h2 id="9a1f" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">示例解决方案架构</h2><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/066349f12b8a78de122472470250d86d.png" data-original-src="https://miro.medium.com/v2/0*D0cyoFOdJqr2Faye"/></div></figure><h2 id="d815" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">样本数据结构</h2><p id="7fa5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">出于演示目的，我们将在BigQuery中使用下面的表结构。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/d360883b90fa23460ae7e346cb080b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*feQpUC1WBgZAKU2BloEjfg.png"/></div></div></figure><h1 id="5451" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">创建BigQuery项目</h1><p id="9be8" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">要与BigQuery交互，首先，我们需要创建一个BigQuery帐户。为此，只需在谷歌云平台中导航到<a class="ae ll" href="https://cloud.google.com/bigquery/" rel="noopener ugc nofollow" target="_blank"> BigQuery </a>，注册一个GCP账户，并在那里创建一个新项目。我们将在这个项目中使用BigQuery。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/902a31aefd170357cffb22b8545261a6.png" data-original-src="https://miro.medium.com/v2/0*_TSgaq7pXF94rkkc"/></div></figure><p id="470b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然后，导航到BigQuery，用户将看到云控制台，在那里他们可以使用GUI或通过运行SQL查询与BigQuery进行交互。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/0cfebca66f645d82d3f88d152898c718.png" data-original-src="https://miro.medium.com/v2/0*YXGa9I8RCOLOgov_"/></div></figure><h1 id="8bee" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">创建BigQuery表</h1><p id="2601" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在将数据插入BigQuery之前，我们需要创建一个数据集和底层表，以便我们可以正确地将相关数据映射和推送到BigQuery。</p><h2 id="e121" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">步骤1 —创建一个大查询数据集</h2><p id="3f90" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><a class="ae ll" href="https://cloud.google.com/bigquery/docs/datasets-intro" rel="noopener ugc nofollow" target="_blank">数据集</a>是BigQuery中的顶层容器，用于组织和控制底层的表和视图。这类似于传统的数据库。</p><p id="636f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">使用云控制台</strong>创建数据集<br/>点击项目然后点击“创建数据集”然后，我们将看到数据集创建面板。提供名称和数据集位置(数据集所在的区域)，然后单击“创建数据集”</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/cfeac7b63b8ebf89f40062a722fcbbb6.png" data-original-src="https://miro.medium.com/v2/0*ACJKVylDpBVLeW3F"/></div></figure><p id="840b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">以编程方式创建数据集</strong> <br/>我们可以使用以下用Python编写的代码块来创建数据集:</p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="ff86" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/># Create credentials object using a service account<br/>creds = service_account.Credentials.from_service_account_file('test-project-xxxxxxxx.json')<br/>client = bigquery.Client(credentials=creds)<br/># Define Dataset Name<br/>dataset_id = "{}.Test_Data_Set02".format(client.project)<br/># Construct a Dataset object.<br/>dataset = bigquery.Dataset(dataset_id)<br/># Specify the Dataset location<br/>dataset.location = "US"<br/># Create the Dataset<br/>dataset = client.create_dataset(dataset, timeout=30)<br/>print("Created dataset {}.{}".format(client.project, dataset.dataset_id))</span></pre><h2 id="53b0" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">步骤2 —创建一个大查询表</h2><p id="c511" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">数据集由作为存储所需数据的基础的表组成，类似于常规数据库中的表。<br/> <br/> <strong class="jq hj">云控制台建表</strong> <br/>点击需要的数据集，会打开数据集视图。然后点击“创建表格”选项:</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/757006837f4a3e9c132fa79daa07a7f3.png" data-original-src="https://miro.medium.com/v2/0*cDxeidkRTNZBMVMr"/></div></figure><p id="5be0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这将打开创建表部分。提供表名，定义表模式，最后单击“创建表”</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/67c5ebfd808a98c3808ace3db7db5293.png" data-original-src="https://miro.medium.com/v2/0*zxZUKixkqeMx_eHx"/></div></figure><p id="3390" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">使用SQL创建表</strong> <br/>由于BigQuery支持标准的SQL方言，我们可以使用带有适当数据类型的“CREATE TABLE”命令来创建所需的表。为此，只需在云控制台中执行以下SQL查询。</p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="b718" class="kr ir hi ln b fi lr ls l lt lu">CREATE TABLE IF NOT EXISTS `Test_Data_Set01.app_data_table` (<br/>`user_id` INT64 NOT NULL,<br/>`username` STRING NOT NULL,<br/>`user_type` STRING,<br/>`origin_ip` STRING NOT NULL,<br/>`session_start` DATETIME NOT NULL,<br/>`session_end` DATETIME,<br/>`country` STRING NOT NULL<br/>);</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/aec42de2b4fa8589f7480122eff15e56.png" data-original-src="https://miro.medium.com/v2/0*hnw6xeur4hnGvRAH"/></div></figure><p id="c04a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">以编程方式创建表格</strong> <br/>创建表格的另一种方式是使用google客户端库创建脚本。以下代码块演示了如何使用Python在BigQuery中创建表。</p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="cc3c" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>creds = service_account.Credentials.from_service_account_file('test-project-xxxxxxx.json')<br/>client = bigquery.Client(credentials=creds)<br/># Configure a Table Name<br/>table_id = "{}.Test_Data_Set01.app_data_table02".format(client.project)<br/># Define the Schema<br/>schema = [<br/>	bigquery.SchemaField("user_id", "INTEGER", mode="REQUIRED"),<br/>	bigquery.SchemaField("username", "STRING", mode="REQUIRED"),<br/>	bigquery.SchemaField("user_type", "STRING", mode="NULLABLE"),<br/>	bigquery.SchemaField("origin_ip", "STRING", mode="REQUIRED"),<br/>	bigquery.SchemaField("session_start", "DATETIME", mode="REQUIRED"),<br/>	bigquery.SchemaField("session_end", "DATETIME", mode="NULLABLE"),<br/>	bigquery.SchemaField("country", "STRING", mode="REQUIRED"),<br/>]<br/># Create the Table<br/>table = bigquery.Table(table_id, schema=schema)<br/>table = client.create_table(table)<br/>print(<br/>"Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id)<br/>)</span></pre><h1 id="554c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">向BigQuery插入数据</h1><p id="722e" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在我们知道了如何创建数据集和表。下一步是插入数据。在向BigQuery中插入数据时，有两种选择:</p><ol class=""><li id="90a6" class="lv lw hi jq b jr km jv kn jz lx kd ly kh lz kl ma mb mc md bi translated">使用SQL插入数据(DML)</li><li id="29db" class="lv lw hi jq b jr me jv mf jz mg kd mh kh mi kl ma mb mc md bi translated">流数据</li></ol><p id="a08c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">以上两个选项都是插入数据的可行方法。让我们来看看每个选项。</p><h2 id="8419" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">数据操作语言</h2><p id="8f4c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">BigQuery DML使用户能够使用标准SQL方言对BigQuery表执行各种操作，如插入、更新和删除。这个选项提供了最大的灵活性，因为它允许我们使用DML创建查询来匹配任何需求。</p><p id="84fa" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">使用DML的一个主要限制是，您不能操作通过流式传输写入表中的最新数据(行)(通常是30分钟内发生的写入)。您可以参考<a class="ae ll" href="https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language" rel="noopener ugc nofollow" target="_blank"> GCP文档</a>来获得对BigQuery DML的完整理解。</p><p id="cbba" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们可以创建一个简单的插入查询，方法是用数据集和项目名定义表名，然后定义列和值，如下所示。</p><p id="f70b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">样本插入查询</strong></p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="ec6c" class="kr ir hi ln b fi lr ls l lt lu">INSERT INTO<br/>`test-project-312821.Test_Data_Set01.app_data_table` (user_id,<br/>username,<br/>user_type,<br/>origin_ip,<br/>session_start,<br/>session_end,<br/>country)<br/>VALUES<br/>(1560,'barry','admin','75.44.21.110', '2021-05-05 10:46:01', '2021-05-05 11:16:51', 'United Kingdom')</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/fd4f8ff26aaf9909fc6d096c348a954e.png" data-original-src="https://miro.medium.com/v2/0*tKoPMh_qS7aNzobK"/></div></figure><p id="c028" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">样本脚本</strong></p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="5df2" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>creds = service_account.Credentials.from_service_account_file('test-project-xxxxxxx.json')<br/>client = bigquery.Client(credentials=creds)<br/># Define the Table<br/>table_id = "{}.Test_Data_Set01.app_data_table".format(client.project)<br/># Define the Columns<br/>columns = "(user_id, username, user_type, origin_ip, session_start, session_end, country)"<br/># Define the Data<br/>data = "(1560,'barry','admin','75.44.21.110', '2021-05-05 10:46:01', '2021-05-05 11:16:51', 'United Kingdom')"<br/># Create the Query<br/>insert_data_query = f"""<br/>INSERT `{table_id}` {columns}<br/>VALUES {data}<br/>"""<br/>query_job = client.query(insert_data_query)<br/>print(query_job.result())<br/>results = query_job.result()<br/>for row in results:<br/>print(row)</span></pre><h2 id="dcb6" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">流式数据</h2><p id="0d64" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">流数据使用户能够使用“tabledata.insertAll”方法一次发送(流)一条记录或成批发送数据。与使用作业将数据加载到BigQuery(使用DML)相比，这是一种相对更快的方式。参考Google的官方文档了解更多关于流数据的信息。</p><p id="83fe" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们使用“insert_rows_json”方法通过在下面的代码块中将所需的数据定义为json字符串来传输数据。</p><p id="b101" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">样本脚本</strong></p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="03b3" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>creds = service_account.Credentials.from_service_account_file('test-project-xxxxxxx.json')<br/>client = bigquery.Client(credentials=creds)<br/># Define the Table<br/>table_id = "{}.Test_Data_Set01.app_data_table".format(client.project)<br/># Define the rows to INSERT<br/>rows_to_insert = [<br/>{"user_id": 2054, "username": 'jake', "user_type": 'user', "origin_ip": '277.12.12.55',<br/>"session_start": '2021-05-06 05:05:41', "session_end": '2021-05-06 10:10:15', "country": 'United States'},<br/>{"user_id": 8755, "username": 'harry', "user_type": 'user', "origin_ip": '155.15.22.222',<br/>"session_start": '2021-05-04 01:10:01', "session_end": '2021-05-04 03:45:15', "country": 'Japan'},<br/>]<br/># Stream the Data<br/>errors = client.insert_rows_json(table_id, rows_to_insert)<br/># Capture Errors<br/>if errors == []:<br/>print("New rows have been added.")<br/>else:<br/>print("Encountered errors while inserting rows: {}".format(errors))</span></pre><p id="365d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">既然我们知道了如何插入数据。在我们的分布式应用程序场景中，我们可以创建一个脚本，将数据流式传输到BigQuery，并通过cron作业定期触发。让我们假设我们的分布式应用程序将所需的数据保存到一个JSON文件中，并且我们需要在每天午夜将该数据流式传输到BigQuery。我们可以通过在所有服务器上运行以下脚本来流式传输数据来实现这一点。</p><p id="d13f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">流数据(Cronjob — 0 0 * * *) </strong></p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="9063" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>import datetime as dt<br/>import json<br/>creds = service_account.Credentials.from_service_account_file('test-project-312821-ebd8bff1ae68.json')<br/>client = bigquery.Client(credentials=creds)<br/># Opening JSON file (JSON file for the specific day)<br/>currnet_date = current_date = dt.date.today().strftime("%Y-%m-%d")<br/>f = open(f'{currnet_date}-app-data.json')<br/># Load the JSON data<br/>app_data = json.load(f)<br/># Define the Table<br/>table_id = "{}.Test_Data_Set01.app_data_table".format(client.project)<br/># Stream the JSON data<br/>errors = client.insert_rows_json(table_id, app_data)<br/># Capture Errors<br/>if errors == []:<br/>print("New rows have been added.")<br/>else:<br/>print("Encountered errors while inserting rows: {}".format(errors))</span></pre><p id="7b0b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们使用流，因为我们不需要使用DML更新或删除新添加的记录。当我们通过互联网传输多个数据流(多个服务器)时，通过流传输获得的性能优势至关重要。</p><h1 id="ef95" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">从BigQuery检索数据</h1><p id="d1a4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">困难的部分已经过去，现在我们成功地将数据从每个应用服务器传输到BigQuery。下一步是从BigQuery读取数据。我们可以使用一个简单的SELECT语句从BigQuery读取数据。</p><p id="6cb9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">由于BigQuery支持标准的SQL方言，因此我们可以使用各种语句(如WHERE、ORDER BY、GROUP BY、LIMIT和JOIN)来过滤和提取所需的数据集。</p><h2 id="6be0" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">样本选择查询</h2><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="f466" class="kr ir hi ln b fi lr ls l lt lu">SELECT * FROM `test-project-312821.Test_Data_Set01.app_data_table` LIMIT 1000<br/>SELECT<br/>user_id AS `USER_ID`,<br/>username AS `USERNAME`,<br/>user_type AS `USER_TYPE`,<br/>origin_ip AS `ORIGIN_IP`,<br/>COUNT(user_id) AS `COUNT`<br/>FROM<br/>`test-project-312821.Test_Data_Set01.app_data_table`<br/>WHERE<br/>country = 'United Kingdom'<br/>GROUP BY<br/>user_id,<br/>username,<br/>user_type,<br/>origin_ip<br/>ORDER BY<br/>user_id ASC;</span></pre><p id="7e53" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在让我们看看如何通过BigQuery API将这些数据发送给python程序。当处理大型数据集时，Python库的Pandas是允许开发人员使用数据框轻松管理和转换数据的最佳选择。</p><p id="7d1b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下面的代码块从BigQuery中检索按每个国家分组的记录数。</p><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="3727" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>import pandas as pd<br/>creds = service_account.Credentials.from_service_account_file('test-project-312821-ebd8bff1ae68.json')<br/>client = bigquery.Client(credentials=creds)<br/># Define the Table<br/>table_id = "{}.Test_Data_Set01.app_data_table".format(client.project)<br/># Create the SELECT Query<br/>select_data_query = f"""<br/>SELECT<br/>country AS `COUNTRY`,<br/>COUNT(user_id) AS `COUNT`<br/>FROM<br/>`Test_Data_Set01.app_data_table`<br/>GROUP BY<br/>country<br/>ORDER BY<br/>country ASC;<br/>"""<br/># Create a Data Frame from the Results<br/>results_df = client.query(select_data_query).to_dataframe()<br/>print(results_df)</span></pre><p id="f0f0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然后，我们可以使用此数据框来可视化数据，以便更好地理解底层数据集。我们将根据从BigQuery检索到的数据创建一个饼图，以直观显示每个国家的用户数量。</p><h1 id="7f93" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">示例数据可视化脚本</h1><pre class="lf lg lh li fd lm ln lo lp aw lq bi"><span id="f114" class="kr ir hi ln b fi lr ls l lt lu">from google.cloud import bigquery<br/>from google.oauth2 import service_account<br/>import pandas as pd<br/>import matplotlib<br/>import pyarrow<br/>creds = service_account.Credentials.from_service_account_file('test-project-312821-ebd8bff1ae68.json')<br/>client = bigquery.Client(credentials=creds)<br/># Define the Table<br/>table_id = "{}.Test_Data_Set01.app_data_table".format(client.project)<br/># Create the SELECT Query<br/>select_data_query = f"""<br/>SELECT<br/>country AS `COUNTRY`,<br/>COUNT(user_id) AS `COUNT`<br/>FROM<br/>`Test_Data_Set01.app_data_table`<br/>GROUP BY<br/>country<br/>ORDER BY<br/>country ASC;<br/>"""<br/># Create a Data Frame from the results<br/>results_df = client.query(select_data_query).to_dataframe()<br/>results_df = results_df.set_index('COUNTRY')<br/>print(results_df)<br/># Visualize the data as a Pie chart<br/>plot = results_df.plot.pie(y='COUNT', figsize=(10, 10))</span></pre><h2 id="5d35" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">结果</h2><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lj"><img src="../Images/221491d950320cadb4cbb2e19228848e.png" data-original-src="https://miro.medium.com/v2/0*E6wseqw3bKy2Mj7w"/></div></figure><p id="18b9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这只是一个简单的例子，我们可以将数据传递给各种工具和库，如Google Data Studio、Power BI等。更有效地将它们可视化。</p><h1 id="64bb" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="9a99" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这就是全部，我们已经涵盖了BigQuery的所有基础知识。通过本文，我们了解了如何通过将数据流式传输到BigQuery数据集中，将BigQuery用作分布式应用程序的数据仓库。下一步是深入挖掘BigQuery和应用程序，在此基础上进行扩展，以BigQuery为基础构建一个全面的数据分析解决方案。</p></div></div>    
</body>
</html>