# 人工智能伦理将很快成为法律

> 原文：<https://medium.com/codex/ai-ethics-will-soon-be-law-7f66fb929cd?source=collection_archive---------8----------------------->

## 人工智能是一种令人难以置信的工具，具有改善人类状况的巨大潜力。然而，这也是一个技术发展领域，如果任其发展而没有社会制衡，可能会造成重大伤害。

![](img/cc76ee7323ed4e23d5ace0c1fb144140.png)

马库斯·温克勒在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

11 月 24 日星期三，联合国教育、科学及文化组织(UNESCO)的 193 个成员国通过了正式的人工智能伦理和指导原则。

这份报告在建立最佳实践方面迈出了巨大的国际步伐，以确保人工智能的发展和应用造福人类，同时防止伤害。

本文研究了这份 26 页的文件，向成员国解释了四个首要价值观、十个指导原则和 11 个建议政策行动领域。如果你的工作涉及到制作、维护，或者使用 AI 算法，我建议你在看完我的总结之后，再去读一下[全文](https://unesdoc.unesco.org/ark:/48223/pf0000379920.page=14)。

# 价值观念

## 1.尊重、保护和促进人权和基本自由以及人的尊严

这份文件是联合国追求更美好人类精神的延续。因此，它首先重申其他现有的文件和社会价值观。

## 2.环境和生态系统繁荣

由于人工智能可以对我们的星球产生巨大影响，无论是在计算资源还是应用方式方面，我们都需要确保负责任地使用它。人工智能需要保护我们的环境，并允许所有生态系统蓬勃发展。

## 3.确保多样性和包容性

现在，这个领域严重偏向来自富裕国家的白人男性开发者。我们需要确保来自各种背景的观点都受到欢迎，积极寻求，并融入社区。该文件规定了许多需要关注的领域，特别是:

> “这可以通过促进所有个人或群体的积极参与来实现，不分种族、肤色、血统、性别、年龄、语言、宗教、政治观点、民族血统、族裔血统、社会出身、出生的经济或社会条件、残疾或任何其他理由。”

## 4.生活在和平、公正和相互联系的社会中

人类是群居动物。我们需要确保我们开发的任何东西都能够让我们和平地生活，与其他人相互联系，并且不会受到虐待。

# 指导原则

## 1.相称性和无害性

不要用海量算法求 4 的平方根。同样，不要创建主动伤害人们的算法。

## 2.安全和保障

数据需要保持安全可靠。如果坏演员可以轻易操纵你的 AI 算法，那你就设计错了。

## 3.公平和不歧视

有许多例子表明，计算机视觉与太多的浅色皮肤的人一起训练，给深色皮肤的人带来了无数的问题。

例子包括【自信地】[指认](https://www.npr.org/2020/06/24/882683463/the-computer-got-it-wrong-how-facial-recognition-led-to-a-false-arrest-in-michig)一名无辜黑人为持枪抢劫者，[没有给黑人发放洗手液](https://reporter.rit.edu/tech/bigotry-encoded-racial-bias-technology)，以及[在视频通话中看到一名黑人作为背景](https://onezero.medium.com/zooms-virtual-background-feature-isn-t-built-for-black-faces-e0a97b591955)而不是持有通话的人。在设计人工智能系统时，需要小心防止这些和许多其他类似的问题。

## 4.可持续性

如果你烧掉一堆不必要的资源，那你就做错了。你的系统应该尽可能的精简实用。它应该有适当的文档、版本和来源，以便尽可能长久地使用。

## 5.隐私权和数据保护

这一部分回到了第二点，但更明确地强调了隐私的重要性。GDPR 是最近立法保护隐私的一个例子。如果您的系统用户不知道他们的数据是如何被保护的，您需要澄清这一点。

## 6.人的监督和决定

当算法出错时，需要有一个人或人类组织对发生的事情负责。

## 7.透明度和可解释性

人工智能系统需要得到人类的信任，这意味着黑箱模型并不好。如果你不能“让它有意义”，那么你需要做一些不同的事情。如果结果不合理，要么重新设计模型，要么创建一个能够解释发生了什么的 topper。

## 8.责任和问责

这一节可以追溯到#6。不要以为只是代码，设计不好的后果就无所谓了。相反，设计你的系统要有清晰的职责和责任线。

## 9.认识和识字

人工智能相对较新。当你设计系统时，你需要让涉众知道你的新系统是如何工作的，以及他们如何最好地使用它。

大量的自动化将取代现有的工作，同时创造新的工作。确保将要失去工作的人知道如何找到一份新的更好的工作(AI 素养)。如果你让某人的工作过时了，你应该努力给他们提供一份更好的新工作。

## 10.多利益主体和适应性治理与协作

不要在真空中开发系统。为了遵循其他原则并努力实现这些价值，您需要在一个不断变化的世界中与领域专家和那些受您的系统影响的人一起工作。

# 政策建议

## 1.道德影响评估

因为每个国家都有自己的一套社会习俗，所以他们应该从这份文件开始，创建一个正式的方法来评估在其管辖范围内设计和部署的系统的道德影响。

> “伦理影响评估应当透明，并酌情向公众开放。这种评估还应该是多学科、多利益攸关方、多文化、多元化和包容性的。”

## 2.道德治理和管理

每个国家都应该制定自己的一套规则，将这些建议正式化，并让各组织承担责任。然后，就像公司有责任遵守适当的金融规则一样，政府应该建立类似的制度来确保人工智能道德得到遵守。

## 3.数据策略

GDPR 是数据政策的一个很好的实现。每个成员国都应该设计或采用类似的东西，详见本节。

## 4.发展和国际合作

人工智能的发展将是巨大的。因此，每个会员国都应鼓励其境内的发展和境外的国际合作。

## 5.环境和生态系统

当我们强调成为我们环境的好管家时，我们需要确保立法符合这一目标。基础设施应该具有抗灾能力。人工智能系统应该是数据、能源和资源高效的。所有系统都应该能够向监督委员会证明自己是适当有效的。

## 6.性别

立法应鼓励开发和使用的所有阶段的性别多样性。

> “会员国应该通过向女孩和妇女提供进入该领域的激励措施，建立机制，打击人工智能研究界的性别陈规定型观念和骚扰，并鼓励学术和私营实体分享如何加强性别多样性的最佳实践，来促进学术界和工业界人工智能研究的性别多样性。”

## 7.文化

人工智能系统可以帮助策划艺术。它们甚至可以帮助创作艺术。因此，成员国应该鼓励他们的文化中心找到整合人工智能的方法，以突出显示、访问和创作内容。

## 8.教育和研究

许多国家和组织认识到 STEM 教育的重要性。然而，需要额外的教育和资助的研究来形成一个知识渊博的从业者和有价值的系统的丰富环境。因此，这一节有很多重要的建议。

> “会员国应与国际组织、教育机构以及私营和非政府实体合作，为所有国家各级公众提供充分的人工智能扫盲教育，以增强人们的权能，减少因广泛采用人工智能系统而产生的数字鸿沟和数字接入不平等。”

## 9.通信和信息

在与语音助手、图像查找服务和翻译服务进行交互时，我们已经在使用人工智能系统。然而，各国需要正式的方式来促进更多的沟通和方法来理解人工智能生成和人工智能策划的信息。

> “成员国应该使用人工智能系统来改善信息和知识的获取。这可以包括支持研究人员、学术界、记者、公众和开发者，以加强言论自由、学术和科学自由、获取信息，以及更多主动公开官方数据和信息。”

## 10.经济和劳工

我保留了 labor 的英式拼写，以便在文档中更快地查找。人工智能系统对劳动力的影响将和工业革命一样大。

政府和非政府组织需要设计和实施项目来提高将被取代的工人的技能，以防止大规模失业。这些员工应该得到公平的过渡，各国应该与所有利益相关方合作确保这一点。

## 11.健康和社会福利

人工智能系统可以在医疗保健系统中提供相当大的帮助。然而，如果不负责任地实施，它们也会对许多医疗保健专业造成巨大伤害。因此，各国需要实施适当的立法准则，以取得最佳结果。

> “会员国应努力采用有效的人工智能系统来改善人类健康和保护生命权，包括缓解疾病爆发，同时建立和维护国际团结，以应对全球健康风险和不确定性，并确保其在医疗保健中部署人工智能系统符合国际法及其人权法义务。会员国应确保参与医疗保健人工智能系统的行为者考虑到患者与其家人和医疗保健人员关系的重要性。”

# 结论

这份文件没有约束力，但却是经过深思熟虑的。每个积极从事人工智能工作的人都应该阅读它，并找到将建议落实到工作中的方法。立法的出台只是一个时间问题，它将正式规定公司必须如何遵循这些指导方针，并将其作为其经营所在国的法律。

你认为在未来的迭代中应该包含额外的想法或项目吗？如果是这样，请留下你的评论，和那些觉得这篇文章有帮助的人分享。谢谢大家！